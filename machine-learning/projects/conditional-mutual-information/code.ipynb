{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential  # Poprawiony import z TensorFlow\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "import keras \n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DV_loss(y_true, T_x):\n",
    "    n1 = tf.math.reduce_sum(y_true)\n",
    "    n2 = tf.math.reduce_sum(tf.subtract(tf.convert_to_tensor(1.0), y_true))\n",
    "    first_term = tf.math.reduce_sum(tf.math.multiply(T_x, y_true))/n1\n",
    "    second_term = tf.math.log(tf.math.reduce_sum(tf.math.multiply(tf.math.exp(T_x), tf.subtract(tf.convert_to_tensor(1.0), y_true)))/n2)\n",
    "    return -(first_term - second_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NWJ_loss(y_true, y_pred):\n",
    "    n1 = tf.math.reduce_sum(y_true)\n",
    "    n2 = tf.math.reduce_sum(tf.subtract(tf.convert_to_tensor(1.0), y_true))\n",
    "    first_term = tf.math.reduce_sum(tf.math.multiply(y_pred, y_true))/n1\n",
    "    second_term = tf.math.reduce_sum(tf.math.multiply(tf.math.exp(y_pred-1), tf.subtract(tf.convert_to_tensor(1.0), y_true)))/n2\n",
    "    return -(first_term - second_term) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_net(x, y, loss_fun=DV_loss):\n",
    "    model_inputs = keras.Input(shape=(x.shape[1],))\n",
    "    layer_out = Dense(128, activation='relu', kernel_initializer='he_normal')(model_inputs)\n",
    "    layer_out = BatchNormalization()(layer_out)\n",
    "    layer_out = Dropout(0.5)(layer_out)\n",
    "    layer_out = Dense(128, activation='relu', kernel_initializer='he_normal')(layer_out)\n",
    "    layer_out = BatchNormalization()(layer_out)\n",
    "    model_outputs = Dense(1)(layer_out)\n",
    "    model = keras.Model(model_inputs, model_outputs)\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=1e-4, clipnorm=1.0)\n",
    "    es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fun)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "    hist = model.fit(x_train, y_train, epochs=200, batch_size=64, validation_data=(x_test, y_test), callbacks=[es, reduce_lr])\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# W metodzie z Runge-KNN chcemy stworzyć taki X_perm, żeby CMI(X_perm,Y|Z) = 0, czyli X_perm był warunkowo niezależny od Y pod warunkiem Z\n",
    "# Czyli nie chcemy tak bezpośrednio wyestymować p(x,z)p(y|z), tylko dostać próbę , w której (X_perm, Z) i (X_perm, Y) bedą miały takie same rozkłady \n",
    "# jak (X, Z) i (X, Y), ale (X,Y,Z) będzie z rozkladu p(x,z)p(y|z)=p(x|z)p(y|z)p(z)\n",
    "# (przy czym oryginalne dane są z p(x,y,z))\n",
    "\n",
    "# czyli teraz mamy próbę z p(x,y,z) -> (X,Y,Z) i próbę z p(x,z)p(y|z) -> (X_perm, Y, Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) kNN method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w tej części chcemy skorzystać z tego, że CMI = D_KL (definicja 2 z Mukherjee)\n",
    "# i skorzystać z lab 7, żeby wyliczać D_KL(p(x,y,z)||p(x,z)p(y|z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kNN_shaffle_X(X, Y, Z, k_perm=5):\n",
    "    n = len(X)\n",
    "    assert len(Y) == n and len(Z) == n, \"Input arrays must have the same length.\"\n",
    "\n",
    "    # Compute nearest neighbors for each sample point in z\n",
    "    tree = cKDTree(Z)\n",
    "    nearest_neighbors = [tree.query_ball_point(Z[i], r=k_perm) for i in range(n)]\n",
    "\n",
    "    # Initialize empty list U and array X*\n",
    "    used_indices = set()\n",
    "    X_star = np.zeros_like(X)\n",
    "\n",
    "    # Shuffle nearest neighbor lists\n",
    "    shuffled_neighbors = [np.random.permutation(neighbors) for neighbors in nearest_neighbors]\n",
    "\n",
    "    # Create random permutation of indices\n",
    "    permutation = np.random.permutation(n)\n",
    "\n",
    "    # Assign surrogate values\n",
    "    for i in permutation:\n",
    "        m = 0\n",
    "        while m < len(shuffled_neighbors[i]):\n",
    "            j = shuffled_neighbors[i][m]\n",
    "            if j not in used_indices:\n",
    "                X_star[i] = X[j]\n",
    "                used_indices.add(j)\n",
    "                break\n",
    "            m += 1\n",
    "\n",
    "    return X_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def est1(X, Y, Z, kperm=5, loss_fun=DV_loss, if_fun_plot=0):\n",
    "    X_perm = kNN_shaffle_X(X, Y, Z, kperm)\n",
    "\n",
    "    # we adapt x_train and y_train\n",
    "    sample_original = np.hstack([X,Y,Z])\n",
    "    sample_conditional_independence = np.hstack([X_perm,Y,Z])\n",
    "\n",
    "    # x_train consists of both (X,Y,Z) and (X_perm, Y, Z) concatenated\n",
    "    x = np.vstack([sample_original, sample_conditional_independence])\n",
    "    # y_train: y_i=1 if the observation comes from (X,Y,Z) and y_i=0 if (X_perm, Y, Z), i=1,2,...,2*n_samples\n",
    "    y = np.concatenate((1.0*np.ones(n_samples), 0.0*np.ones(n_samples)))\n",
    "\n",
    "    hist = neural_net(x, y, loss_fun)\n",
    "\n",
    "    if if_fun_plot == 1:\n",
    "        plt.plot(hist.history['loss'])\n",
    "        plt.plot(hist.history['val_loss'])\n",
    "        plt.show()\n",
    "\n",
    "    # cmi\n",
    "    return max(0.0, -hist.history['loss'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) chain rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estymujemy MI((X,Z), Y) jak w: pierwszy myślnik druga kropka\n",
    "# estymujemy MI((X), Y) jak w: pierwszy myślnik druga kropka\n",
    "\n",
    "# potem żeby dostać CMI: MI((X,Z), Y) - MI((X), Y) - czyli korzystamy z drugiego myślnika pierwszej kropki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estymacja MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def est_mi(X, Y, loss_fun, if_fun_plot):\n",
    "    # p(X,Z,Y)\n",
    "    XY = np.hstack([X, Y])\n",
    "    # p(X,Z)p(Y)\n",
    "    Y_perm = np.random.permutation(Y)\n",
    "    X_Y = np.hstack([X, Y_perm])\n",
    "    x = np.vstack([XY, X_Y])\n",
    "    y = np.concatenate((1.0*np.ones(n_samples), 0.0*np.ones(n_samples)))\n",
    "\n",
    "    hist = neural_net(x, y, loss_fun)\n",
    "\n",
    "    if if_fun_plot == 1:\n",
    "        plt.plot(hist.history['loss'])\n",
    "        plt.plot(hist.history['val_loss'])\n",
    "        plt.show()\n",
    "\n",
    "    return max(0.0, -hist.history['loss'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estymacja CMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def est2(X, Y, Z, loss_fun=DV_loss, if_fun_plot=0):\n",
    "    # est I((X,Z),Y)\n",
    "    XZ = np.hstack([X,Z])\n",
    "    I_XZ_Y = est_mi(XZ, Y, loss_fun, if_fun_plot)\n",
    "    # est I(X,Y)\n",
    "    I_X_Y = est_mi(X, Y, loss_fun, if_fun_plot)\n",
    "\n",
    "    # cmi\n",
    "    return max(0.0, I_XZ_Y - I_X_Y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est2(X, Y, Z, DV_loss, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) comparative estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_info(X, Y):\n",
    "    \"\"\"Oblicza wzajemną informację między X a Y.\"\"\"\n",
    "    return mutual_info_regression(X, Y, discrete_features=False, n_neighbors=10).sum()\n",
    "\n",
    "def estimate_cmi(X, Y, Z):\n",
    "    \"\"\"Oblicza wzajemną informację warunkową I(X, Y | Z).\"\"\"\n",
    "\n",
    "    # I(X, Z; Y)\n",
    "    XZ = np.hstack([X, Z])\n",
    "    I_XZY = mutual_info(XZ, Y)\n",
    "    print(\"I_XZY:\", I_XZY)\n",
    "\n",
    "    # I(X; Y)\n",
    "    I_XY = mutual_info(X, Y)\n",
    "    print(\"I_XY:\", I_XY)\n",
    "\n",
    "    # I(X, Y | Z) = I(X, Z; Y) - I(X; Y)\n",
    "    I_XY_given_Z = I_XZY - I_XY\n",
    "    return I_XY_given_Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   An example, for which the formula for CMI is known and exact CMI can be computed (on a grid of parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute exact CMI for Gaussian variables\n",
    "def compute_gaussian_cmi(sigma):\n",
    "\n",
    "    \n",
    "    sigma_xz = sigma[:2, :2]  \n",
    "    sigma_yz = sigma[1:, 1:]  \n",
    "    sigma_xyz = sigma \n",
    "\n",
    "    det_xz = np.linalg.det(sigma_xz)\n",
    "    det_yz = np.linalg.det(sigma_yz)\n",
    "    det_xyz = np.linalg.det(sigma_xyz)\n",
    "\n",
    "    cmi = 0.5 * np.log(det_xz * det_yz / det_xyz)\n",
    "    return cmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I_XZY: 0.011094693914565745\n",
      "I_XY: 0.007274237816185192\n",
      "I_XZY: 0.041086471339506936\n",
      "I_XY: 0.025888980932256445\n",
      "I_XZY: 0.08347890925272683\n",
      "I_XY: 0.04122077349501296\n",
      "I_XZY: 0.13300303612588582\n",
      "I_XY: 0.06162324541428088\n",
      "I_XZY: 0.18966496176993797\n",
      "I_XY: 0.09553614068615968\n",
      "I_XZY: 0.2828460591445241\n",
      "I_XY: 0.1459088502351511\n",
      "I_XZY: 0.3809413330040856\n",
      "I_XY: 0.19017079767088063\n",
      "I_XZY: 0.532126030712309\n",
      "I_XY: 0.2552420554438237\n",
      "Pominięto rho=0.7222222222222222 - macierz kowariancji nie jest dodatnio określona\n",
      "Pominięto rho=0.8 - macierz kowariancji nie jest dodatnio określona\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "grid_size = 10\n",
    "results = []\n",
    "\n",
    "rho_values = np.linspace(0.1, 0.8, grid_size) \n",
    "for rho in rho_values:\n",
    "    \n",
    "    sigma = np.array([\n",
    "        [1, rho, 0],\n",
    "        [rho, 1, rho],\n",
    "        [0, rho, 1]\n",
    "    ])\n",
    "\n",
    "    # Sprawdzanie dodatniej określoności macierzy\n",
    "    if np.all(np.linalg.eigvals(sigma) > 0):  \n",
    "        # Generowanie danych\n",
    "        mean = np.zeros(3)\n",
    "        data = np.random.multivariate_normal(mean, sigma, size=10000)\n",
    "        X = data[:, [0]]\n",
    "        Y = data[:, [1]]\n",
    "        Z = data[:, [2]]\n",
    "        \n",
    "        \n",
    "        exact_cmi = compute_gaussian_cmi(sigma)\n",
    "        estimated_cmi = estimate_cmi(X, Y.ravel(), Z)\n",
    "\n",
    "        \n",
    "        results.append((rho, exact_cmi, estimated_cmi))\n",
    "    else:\n",
    "        print(f\"Pominięto rho={rho} - macierz kowariancji nie jest dodatnio określona\")\n",
    "\n",
    "\n",
    "rho_values_valid = [item[0] for item in results]\n",
    "exact_cmi_values = [item[1] for item in results]\n",
    "estimated_cmi_values = [item[2] for item in results]\n",
    "\n",
    "# Tworzenie wykresu\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(rho_values_valid, exact_cmi_values, label=\"Exact CMI\", marker='o')\n",
    "plt.plot(rho_values_valid, estimated_cmi_values, label=\"Estimated CMI\", marker='s')\n",
    "plt.xlabel(\"Correlation Coefficient (rho)\")\n",
    "plt.ylabel(\"Conditional Mutual Information (CMI)\")\n",
    "plt.title(\"Comparison of Exact and Estimated CMI (Adjusted rho Range)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.5442 - val_loss: 0.0627 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.3566 - val_loss: 0.0518 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.2518 - val_loss: 0.0340 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.2084 - val_loss: 0.0251 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.1399 - val_loss: 0.0212 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.1355 - val_loss: 0.0200 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.1206 - val_loss: 0.0163 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0999 - val_loss: 0.0104 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0792 - val_loss: 0.0162 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0880 - val_loss: 0.0109 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0826 - val_loss: 0.0155 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0720 - val_loss: 0.0103 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0657 - val_loss: 0.0153 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0791 - val_loss: 0.0138 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0726 - val_loss: 0.0103 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0737 - val_loss: 0.0112 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0656 - val_loss: 0.0113 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0609 - val_loss: 0.0084 - learning_rate: 5.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0497 - val_loss: 0.0103 - learning_rate: 5.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0460 - val_loss: 0.0093 - learning_rate: 5.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0571 - val_loss: 0.0055 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0473 - val_loss: 0.0068 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0465 - val_loss: 0.0070 - learning_rate: 5.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0518 - val_loss: 0.0058 - learning_rate: 5.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0535 - val_loss: 0.0066 - learning_rate: 5.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0429 - val_loss: 0.0102 - learning_rate: 5.0000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0396 - val_loss: 0.0079 - learning_rate: 2.5000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0405 - val_loss: 0.0070 - learning_rate: 2.5000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0453 - val_loss: 0.0072 - learning_rate: 2.5000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0348 - val_loss: 0.0065 - learning_rate: 2.5000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0338 - val_loss: 0.0068 - learning_rate: 2.5000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.4565 - val_loss: 0.0283 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.3316 - val_loss: 0.0184 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.2318 - val_loss: 0.0121 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1731 - val_loss: 0.0105 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1327 - val_loss: 0.0045 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1117 - val_loss: 0.0035 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1251 - val_loss: 0.0015 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0932 - val_loss: 0.0044 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0891 - val_loss: 0.0037 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0936 - val_loss: 0.0084 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0828 - val_loss: 9.0741e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0718 - val_loss: 0.0014 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0608 - val_loss: 2.9235e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0756 - val_loss: -0.0026 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0560 - val_loss: -8.0457e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0648 - val_loss: -9.0887e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0562 - val_loss: 0.0017 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0565 - val_loss: -2.6966e-05 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0444 - val_loss: -0.0064 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0428 - val_loss: -0.0059 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0436 - val_loss: -0.0032 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0357 - val_loss: -0.0064 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0441 - val_loss: -0.0075 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0419 - val_loss: -0.0055 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0247 - val_loss: -0.0092 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0251 - val_loss: -0.0077 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0316 - val_loss: -0.0070 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0253 - val_loss: -0.0088 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0213 - val_loss: -0.0065 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0166 - val_loss: -0.0087 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0329 - val_loss: -0.0080 - learning_rate: 5.0000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0196 - val_loss: -0.0089 - learning_rate: 5.0000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0147 - val_loss: -0.0092 - learning_rate: 5.0000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0295 - val_loss: -0.0096 - learning_rate: 5.0000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0225 - val_loss: -0.0097 - learning_rate: 5.0000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0098 - val_loss: -0.0096 - learning_rate: 5.0000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0160 - val_loss: -0.0107 - learning_rate: 5.0000e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0142 - val_loss: -0.0096 - learning_rate: 5.0000e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0117 - val_loss: -0.0111 - learning_rate: 5.0000e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0117 - val_loss: -0.0105 - learning_rate: 5.0000e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0221 - val_loss: -0.0100 - learning_rate: 5.0000e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0164 - val_loss: -0.0098 - learning_rate: 5.0000e-05\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0169 - val_loss: -0.0104 - learning_rate: 5.0000e-05\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0220 - val_loss: -0.0114 - learning_rate: 5.0000e-05\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0210 - val_loss: -0.0114 - learning_rate: 5.0000e-05\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0017 - val_loss: -0.0095 - learning_rate: 5.0000e-05\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0162 - val_loss: -0.0110 - learning_rate: 5.0000e-05\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0127 - val_loss: -0.0101 - learning_rate: 5.0000e-05\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0242 - val_loss: -0.0097 - learning_rate: 5.0000e-05\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0132 - val_loss: -0.0101 - learning_rate: 2.5000e-05\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0084 - val_loss: -0.0109 - learning_rate: 2.5000e-05\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0254 - val_loss: -0.0108 - learning_rate: 2.5000e-05\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0172 - val_loss: -0.0103 - learning_rate: 2.5000e-05\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0149 - val_loss: -0.0108 - learning_rate: 2.5000e-05\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0053 - val_loss: -0.0105 - learning_rate: 1.2500e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.5542 - val_loss: 0.0401 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.3242 - val_loss: 0.0162 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1931 - val_loss: 0.0050 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1712 - val_loss: 0.0059 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1338 - val_loss: -0.0109 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.1077 - val_loss: -0.0065 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0747 - val_loss: -0.0171 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0711 - val_loss: -0.0115 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0744 - val_loss: -0.0170 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0497 - val_loss: -0.0129 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0660 - val_loss: -0.0151 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0540 - val_loss: -0.0159 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0581 - val_loss: -0.0211 - learning_rate: 5.0000e-05\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0360 - val_loss: -0.0226 - learning_rate: 5.0000e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0363 - val_loss: -0.0179 - learning_rate: 5.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0266 - val_loss: -0.0200 - learning_rate: 5.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0436 - val_loss: -0.0188 - learning_rate: 5.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0394 - val_loss: -0.0200 - learning_rate: 5.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0344 - val_loss: -0.0213 - learning_rate: 5.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0368 - val_loss: -0.0218 - learning_rate: 2.5000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0418 - val_loss: -0.0211 - learning_rate: 2.5000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0382 - val_loss: -0.0213 - learning_rate: 2.5000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0215 - val_loss: -0.0201 - learning_rate: 2.5000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0199 - val_loss: -0.0208 - learning_rate: 2.5000e-05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Obliczanie CMI\u001b[39;00m\n\u001b[0;32m     27\u001b[0m exact_cmi \u001b[38;5;241m=\u001b[39m compute_gaussian_cmi(sigma)\n\u001b[1;32m---> 28\u001b[0m estimated_cmi \u001b[38;5;241m=\u001b[39m \u001b[43mest1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDV_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Zapis wyników\u001b[39;00m\n\u001b[0;32m     30\u001b[0m results\u001b[38;5;241m.\u001b[39mappend((rho, exact_cmi, estimated_cmi))\n",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36mest1\u001b[1;34m(X, Y, Z, kperm, loss_fun, if_fun_plot)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mest1\u001b[39m(X, Y, Z, kperm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, loss_fun\u001b[38;5;241m=\u001b[39mDV_loss, if_fun_plot\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     X_perm \u001b[38;5;241m=\u001b[39m \u001b[43mkNN_shaffle_X\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkperm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# we adapt x_train and y_train\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     sample_original \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack([X,Y,Z])\n",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36mkNN_shaffle_X\u001b[1;34m(X, Y, Z, k_perm)\u001b[0m\n\u001b[0;32m     11\u001b[0m X_star \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros_like(X)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Shuffle nearest neighbor lists\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m shuffled_neighbors \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mpermutation(neighbors) \u001b[38;5;28;01mfor\u001b[39;00m neighbors \u001b[38;5;129;01min\u001b[39;00m nearest_neighbors]\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Create random permutation of indices\u001b[39;00m\n\u001b[0;32m     17\u001b[0m permutation \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mpermutation(n)\n",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     11\u001b[0m X_star \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros_like(X)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Shuffle nearest neighbor lists\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m shuffled_neighbors \u001b[38;5;241m=\u001b[39m [\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermutation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneighbors\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m neighbors \u001b[38;5;129;01min\u001b[39;00m nearest_neighbors]\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Create random permutation of indices\u001b[39;00m\n\u001b[0;32m     17\u001b[0m permutation \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mpermutation(n)\n",
      "File \u001b[1;32mmtrand.pyx:4600\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.permutation\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mmay_share_memory\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "grid_size = 10\n",
    "results = []\n",
    "\n",
    "rho_values = np.linspace(0.1, 0.8, grid_size)  \n",
    "for rho in rho_values:\n",
    "    \n",
    "    sigma = np.array([\n",
    "        [1, rho, 0],\n",
    "        [rho, 1, rho],\n",
    "        [0, rho, 1]\n",
    "    ])\n",
    "\n",
    "    # Sprawdzanie dodatniej określoności macierzy\n",
    "    if np.all(np.linalg.eigvals(sigma) > 0):\n",
    "        # Generowanie danych\n",
    "        mean = np.zeros(3)\n",
    "        data = np.random.multivariate_normal(mean, sigma, size=10000)\n",
    "        X = data[:, [0]]\n",
    "        Y = data[:, [1]]\n",
    "        Z = data[:, [2]]\n",
    "        \n",
    "        \n",
    "        exact_cmi = compute_gaussian_cmi(sigma)\n",
    "        estimated_cmi = est1(X, Y, Z, 5, DV_loss, 0)\n",
    "        \n",
    "        results.append((rho, exact_cmi, estimated_cmi))\n",
    "    else:\n",
    "        print(f\"Pominięto rho={rho} - macierz kowariancji nie jest dodatnio określona\")\n",
    "\n",
    "rho_values_valid = [item[0] for item in results]\n",
    "exact_cmi_values = [item[1] for item in results]\n",
    "estimated_cmi_values = [item[2] for item in results]\n",
    "\n",
    "# Tworzenie wykresu\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(rho_values_valid, exact_cmi_values, label=\"Exact CMI\", marker='o')\n",
    "plt.plot(rho_values_valid, estimated_cmi_values, label=\"Estimated CMI\", marker='s')\n",
    "plt.xlabel(\"Correlation Coefficient (rho)\")\n",
    "plt.ylabel(\"Conditional Mutual Information (CMI)\")\n",
    "plt.title(\"Comparison of Exact and Estimated CMI (Adjusted rho Range)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "##dane niezależne \n",
    "np.random.seed(42)\n",
    "sigma = np.array([\n",
    "        [1, 0, 0],\n",
    "        [0, 1, 0],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "\n",
    "mean = np.zeros(3)\n",
    "data = np.random.multivariate_normal(mean, sigma, size=10000)\n",
    "X = data[:, [0]]\n",
    "Y = data[:, [1]]\n",
    "Z = data[:, [2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 1.1335 - val_loss: 0.6003 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.5670 - val_loss: 0.3609 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.3757 - val_loss: 0.2264 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.2801 - val_loss: 0.1379 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.2385 - val_loss: 0.1113 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1923 - val_loss: 0.0805 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1492 - val_loss: 0.0635 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1355 - val_loss: 0.0512 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1316 - val_loss: 0.0463 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1046 - val_loss: 0.0458 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1030 - val_loss: 0.0418 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1132 - val_loss: 0.0319 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0998 - val_loss: 0.0291 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0837 - val_loss: 0.0289 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1003 - val_loss: 0.0283 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0943 - val_loss: 0.0238 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0638 - val_loss: 0.0249 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0795 - val_loss: 0.0206 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0738 - val_loss: 0.0218 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0488 - val_loss: 0.0178 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0672 - val_loss: 0.0189 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0609 - val_loss: 0.0182 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0430 - val_loss: 0.0187 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0622 - val_loss: 0.0153 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0353 - val_loss: 0.0155 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0364 - val_loss: 0.0143 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0496 - val_loss: 0.0137 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0342 - val_loss: 0.0125 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0419 - val_loss: 0.0157 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0465 - val_loss: 0.0117 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0392 - val_loss: 0.0142 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0341 - val_loss: 0.0137 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0384 - val_loss: 0.0089 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0357 - val_loss: 0.0090 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0354 - val_loss: 0.0088 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0181 - val_loss: 0.0100 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0483 - val_loss: 0.0081 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0338 - val_loss: 0.0097 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0283 - val_loss: 0.0099 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0267 - val_loss: 0.0101 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0309 - val_loss: 0.0069 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0309 - val_loss: 0.0086 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0176 - val_loss: 0.0084 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0295 - val_loss: 0.0082 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0203 - val_loss: 0.0089 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0175 - val_loss: 0.0072 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0250 - val_loss: 0.0060 - learning_rate: 5.0000e-05\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0121 - val_loss: 0.0069 - learning_rate: 5.0000e-05\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0181 - val_loss: 0.0064 - learning_rate: 5.0000e-05\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0153 - val_loss: 0.0069 - learning_rate: 5.0000e-05\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0190 - val_loss: 0.0058 - learning_rate: 5.0000e-05\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0234 - val_loss: 0.0066 - learning_rate: 5.0000e-05\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0189 - val_loss: 0.0068 - learning_rate: 5.0000e-05\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0207 - val_loss: 0.0058 - learning_rate: 5.0000e-05\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0218 - val_loss: 0.0061 - learning_rate: 5.0000e-05\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0272 - val_loss: 0.0068 - learning_rate: 5.0000e-05\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0188 - val_loss: 0.0060 - learning_rate: 2.5000e-05\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0149 - val_loss: 0.0060 - learning_rate: 2.5000e-05\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0261 - val_loss: 0.0056 - learning_rate: 2.5000e-05\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0182 - val_loss: 0.0054 - learning_rate: 2.5000e-05\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0205 - val_loss: 0.0055 - learning_rate: 2.5000e-05\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0197 - val_loss: 0.0058 - learning_rate: 2.5000e-05\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0190 - val_loss: 0.0055 - learning_rate: 2.5000e-05\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0124 - val_loss: 0.0060 - learning_rate: 2.5000e-05\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0239 - val_loss: 0.0060 - learning_rate: 2.5000e-05\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0090 - val_loss: 0.0059 - learning_rate: 1.2500e-05\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0077 - val_loss: 0.0057 - learning_rate: 1.2500e-05\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0092 - val_loss: 0.0055 - learning_rate: 1.2500e-05\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0213 - val_loss: 0.0057 - learning_rate: 1.2500e-05\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0184 - val_loss: 0.0058 - learning_rate: 1.2500e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.8426 - val_loss: 0.2224 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.4750 - val_loss: 0.1043 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.3155 - val_loss: 0.0478 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.2174 - val_loss: 0.0223 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.1884 - val_loss: 0.0155 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.1370 - val_loss: 0.0122 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1377 - val_loss: 0.0170 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.1088 - val_loss: 0.0174 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0993 - val_loss: 0.0154 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1066 - val_loss: 0.0174 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0750 - val_loss: 0.0099 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0875 - val_loss: 0.0119 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0725 - val_loss: 0.0081 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0689 - val_loss: 0.0074 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0661 - val_loss: 0.0089 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0643 - val_loss: 0.0080 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0517 - val_loss: 0.0088 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0473 - val_loss: 0.0130 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0518 - val_loss: 0.0145 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0452 - val_loss: 0.0097 - learning_rate: 5.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0551 - val_loss: 0.0096 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0571 - val_loss: 0.0073 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0429 - val_loss: 0.0085 - learning_rate: 5.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0440 - val_loss: 0.0081 - learning_rate: 5.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0383 - val_loss: 0.0085 - learning_rate: 5.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0410 - val_loss: 0.0087 - learning_rate: 5.0000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0371 - val_loss: 0.0086 - learning_rate: 5.0000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0475 - val_loss: 0.0078 - learning_rate: 2.5000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0364 - val_loss: 0.0088 - learning_rate: 2.5000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0358 - val_loss: 0.0074 - learning_rate: 2.5000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0331 - val_loss: 0.0071 - learning_rate: 2.5000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0425 - val_loss: 0.0072 - learning_rate: 2.5000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0210 - val_loss: 0.0074 - learning_rate: 2.5000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0320 - val_loss: 0.0070 - learning_rate: 2.5000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0268 - val_loss: 0.0070 - learning_rate: 2.5000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0245 - val_loss: 0.0066 - learning_rate: 2.5000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0346 - val_loss: 0.0076 - learning_rate: 2.5000e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0339 - val_loss: 0.0079 - learning_rate: 2.5000e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0474 - val_loss: 0.0083 - learning_rate: 2.5000e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0341 - val_loss: 0.0081 - learning_rate: 2.5000e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0266 - val_loss: 0.0075 - learning_rate: 2.5000e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0294 - val_loss: 0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0297 - val_loss: 0.0075 - learning_rate: 1.2500e-05\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0367 - val_loss: 0.0082 - learning_rate: 1.2500e-05\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0285 - val_loss: 0.0079 - learning_rate: 1.2500e-05\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0383 - val_loss: 0.0074 - learning_rate: 1.2500e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "exact_cmi = compute_gaussian_cmi(sigma)\n",
    "\n",
    "\n",
    "estimated_cmi = est2(X, Y, Z, NWJ_loss, 0) \n",
    "exact_cmi, estimated_cmi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simulation example of ranking variable importance based on our estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miary jakości\n",
    "def count_inversions(rank1, rank2):\n",
    "    \"\"\"Liczy liczbę odwróconych par między dwoma rankingami.\"\"\"\n",
    "    inversions = 0\n",
    "    for i in range(len(rank1)):\n",
    "        for j in range(i + 1, len(rank1)):\n",
    "            if (rank1[i] < rank1[j] and rank2[i] > rank2[j]) or (rank1[i] > rank1[j] and rank2[i] < rank2[j]):\n",
    "                inversions += 1\n",
    "    return inversions\n",
    "\n",
    "def top_k_agreement(rank1, rank2, k):\n",
    "    \"\"\"Liczy, ile zmiennych z top k w rankingu 1 pojawi się w top k w rankingu 2.\"\"\"\n",
    "    top_k_rank1 = set(rank1[:k])\n",
    "    top_k_rank2 = set(rank2[:k])\n",
    "    return len(top_k_rank1 & top_k_rank2) / k\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 przyklad 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generowanie danych (10000 próbek, 20 zmiennych)\n",
    "np.random.seed(42)\n",
    "n_samples = 10000\n",
    "n_features = 20\n",
    "X, Y = make_regression(n_samples=n_samples, n_features=n_features, noise=0.1, random_state=42)\n",
    "\n",
    "# Dodajemy sztucznie silniejsze cechy\n",
    "X[:, 10] = X[:, 0] * 3 + np.random.normal(0, 0.1, n_samples)\n",
    "X[:, 6] = X[:, 1] * 2 + np.random.normal(0, 0.1, n_samples)\n",
    "X[:, 15] = X[:, 2] * 2 + np.random.normal(0, 0.1, n_samples)\n",
    "\n",
    "# Ranking na podstawie LASSO\n",
    "lasso = LassoCV(cv=5).fit(X, Y)\n",
    "lasso_importances = np.abs(lasso.coef_)\n",
    "lasso_ranking = np.argsort(lasso_importances)[::-1]\n",
    "Y = Y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.7156 - val_loss: 0.0259 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4232 - val_loss: 0.0156 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2641 - val_loss: 0.0075 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2390 - val_loss: 0.0082 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1764 - val_loss: 0.0155 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1286 - val_loss: 0.0042 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1035 - val_loss: 0.0075 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0880 - val_loss: 0.0067 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0769 - val_loss: 0.0038 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0768 - val_loss: 0.0020 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0724 - val_loss: 0.0044 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0626 - val_loss: 0.0028 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0709 - val_loss: 0.0062 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0518 - val_loss: 0.0027 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0567 - val_loss: 0.0039 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0516 - val_loss: 0.0037 - learning_rate: 5.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0387 - val_loss: 0.0038 - learning_rate: 5.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0505 - val_loss: 0.0029 - learning_rate: 5.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0348 - val_loss: 0.0048 - learning_rate: 5.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0424 - val_loss: 0.0045 - learning_rate: 5.0000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.5582 - val_loss: 0.0674 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3494 - val_loss: 0.0178 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2163 - val_loss: 0.0153 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1674 - val_loss: 0.0132 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1019 - val_loss: 0.0177 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0981 - val_loss: 0.0060 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0865 - val_loss: 0.0027 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0741 - val_loss: 0.0103 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0673 - val_loss: 0.0064 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0713 - val_loss: 0.0080 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0486 - val_loss: 0.0087 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0508 - val_loss: 0.0088 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0276 - val_loss: 0.0049 - learning_rate: 5.0000e-05\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0489 - val_loss: 0.0047 - learning_rate: 5.0000e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0376 - val_loss: 0.0050 - learning_rate: 5.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0410 - val_loss: 0.0041 - learning_rate: 5.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0379 - val_loss: 0.0031 - learning_rate: 5.0000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.7335 - val_loss: 0.0393 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3424 - val_loss: 0.0303 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2248 - val_loss: 0.0091 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1693 - val_loss: 0.0134 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1205 - val_loss: 0.0088 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1159 - val_loss: 0.0072 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1020 - val_loss: 0.0051 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0665 - val_loss: 0.0042 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0785 - val_loss: 0.0043 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0728 - val_loss: 0.0126 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0604 - val_loss: 0.0074 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0446 - val_loss: 0.0182 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0558 - val_loss: 0.0044 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0444 - val_loss: 0.0049 - learning_rate: 5.0000e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0521 - val_loss: 0.0026 - learning_rate: 5.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0403 - val_loss: 0.0043 - learning_rate: 5.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0390 - val_loss: 0.0015 - learning_rate: 5.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0418 - val_loss: 0.0023 - learning_rate: 5.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0302 - val_loss: 0.0024 - learning_rate: 5.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0290 - val_loss: 0.0065 - learning_rate: 5.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0312 - val_loss: 0.0032 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0277 - val_loss: 0.0037 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0360 - val_loss: 0.0047 - learning_rate: 2.5000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0242 - val_loss: 0.0026 - learning_rate: 2.5000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0027 - learning_rate: 2.5000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0301 - val_loss: 0.0030 - learning_rate: 2.5000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0152 - val_loss: 0.0043 - learning_rate: 2.5000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.6077 - val_loss: 0.0119 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3848 - val_loss: 0.0094 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2544 - val_loss: 0.0119 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2009 - val_loss: 0.0152 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1536 - val_loss: 0.0076 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1117 - val_loss: 0.0135 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1059 - val_loss: 0.0134 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0933 - val_loss: 0.0076 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0687 - val_loss: 0.0081 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0793 - val_loss: 0.0103 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0634 - val_loss: 0.0081 - learning_rate: 5.0000e-05\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0622 - val_loss: 0.0038 - learning_rate: 5.0000e-05\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0662 - val_loss: 0.0078 - learning_rate: 5.0000e-05\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0502 - val_loss: 0.0054 - learning_rate: 5.0000e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0655 - val_loss: 0.0033 - learning_rate: 5.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0488 - val_loss: 0.0037 - learning_rate: 5.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0363 - val_loss: 0.0061 - learning_rate: 5.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0567 - val_loss: 0.0041 - learning_rate: 5.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0453 - val_loss: 0.0082 - learning_rate: 5.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0321 - val_loss: 0.0069 - learning_rate: 5.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0268 - val_loss: 0.0042 - learning_rate: 2.5000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0383 - val_loss: 0.0042 - learning_rate: 2.5000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0423 - val_loss: 0.0046 - learning_rate: 2.5000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0242 - val_loss: 0.0028 - learning_rate: 2.5000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0409 - val_loss: 0.0033 - learning_rate: 2.5000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0348 - val_loss: 0.0033 - learning_rate: 2.5000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0329 - val_loss: 0.0027 - learning_rate: 2.5000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0286 - val_loss: 0.0016 - learning_rate: 2.5000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0358 - val_loss: 0.0031 - learning_rate: 2.5000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0311 - val_loss: 0.0039 - learning_rate: 2.5000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0291 - val_loss: 0.0042 - learning_rate: 2.5000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0354 - val_loss: 0.0039 - learning_rate: 2.5000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0384 - val_loss: 0.0020 - learning_rate: 2.5000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0339 - val_loss: 0.0035 - learning_rate: 1.2500e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0310 - val_loss: 0.0035 - learning_rate: 1.2500e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0032 - learning_rate: 1.2500e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0308 - val_loss: 0.0045 - learning_rate: 1.2500e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0305 - val_loss: 0.0042 - learning_rate: 1.2500e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.6806 - val_loss: 0.0226 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3568 - val_loss: 0.0262 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2803 - val_loss: 0.0305 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1841 - val_loss: 0.0150 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1219 - val_loss: 0.0196 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1481 - val_loss: 0.0182 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0912 - val_loss: 0.0086 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0807 - val_loss: 0.0066 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0647 - val_loss: 0.0038 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0539 - val_loss: 0.0153 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0570 - val_loss: 0.0065 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0429 - val_loss: 0.0033 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0468 - val_loss: 0.0012 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0354 - val_loss: -1.5340e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0400 - val_loss: 0.0014 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0300 - val_loss: 3.2245e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0229 - val_loss: 0.0012 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0309 - val_loss: 6.1514e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0242 - val_loss: -0.0014 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0287 - val_loss: -0.0025 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0199 - val_loss: -0.0035 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0016 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0139 - val_loss: -0.0022 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0109 - val_loss: -7.6039e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: -0.0056 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0135 - val_loss: -0.0081 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0016 - val_loss: -0.0092 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0075 - val_loss: -0.0114 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0086 - val_loss: -0.0093 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0094 - val_loss: -0.0097 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0041 - val_loss: -0.0077 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0055 - val_loss: -0.0120 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0058 - val_loss: -0.0162 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0018 - val_loss: -0.0152 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0053 - val_loss: -0.0179 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0081 - val_loss: -0.0181 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0039 - val_loss: -0.0218 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0037 - val_loss: -0.0226 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0019 - val_loss: -0.0196 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0075 - val_loss: -0.0213 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0136 - val_loss: -0.0301 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.0109 - val_loss: -0.0308 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0024 - val_loss: -0.0323 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.0038 - val_loss: -0.0321 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0097 - val_loss: -0.0327 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0115 - val_loss: -0.0337 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0171 - val_loss: -0.0338 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0204 - val_loss: -0.0320 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0116 - val_loss: -0.0360 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0221 - val_loss: -0.0340 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0194 - val_loss: -0.0354 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0251 - val_loss: -0.0380 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0176 - val_loss: -0.0383 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0261 - val_loss: -0.0385 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0180 - val_loss: -0.0396 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0248 - val_loss: -0.0403 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0172 - val_loss: -0.0384 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.0371 - val_loss: -0.0398 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: -0.0391 - val_loss: -0.0408 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: -0.0284 - val_loss: -0.0452 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0343 - val_loss: -0.0462 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0289 - val_loss: -0.0461 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0383 - val_loss: -0.0451 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0353 - val_loss: -0.0481 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0292 - val_loss: -0.0500 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0411 - val_loss: -0.0490 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0407 - val_loss: -0.0461 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0365 - val_loss: -0.0503 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0368 - val_loss: -0.0494 - learning_rate: 1.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0382 - val_loss: -0.0516 - learning_rate: 1.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0445 - val_loss: -0.0523 - learning_rate: 1.0000e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0402 - val_loss: -0.0536 - learning_rate: 1.0000e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.0465 - val_loss: -0.0534 - learning_rate: 1.0000e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.0405 - val_loss: -0.0535 - learning_rate: 1.0000e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0462 - val_loss: -0.0556 - learning_rate: 1.0000e-04\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0346 - val_loss: -0.0584 - learning_rate: 1.0000e-04\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0454 - val_loss: -0.0588 - learning_rate: 1.0000e-04\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0541 - val_loss: -0.0574 - learning_rate: 1.0000e-04\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0451 - val_loss: -0.0581 - learning_rate: 1.0000e-04\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0622 - val_loss: -0.0614 - learning_rate: 1.0000e-04\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0539 - val_loss: -0.0591 - learning_rate: 1.0000e-04\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0548 - val_loss: -0.0634 - learning_rate: 1.0000e-04\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0642 - val_loss: -0.0664 - learning_rate: 1.0000e-04\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0529 - val_loss: -0.0660 - learning_rate: 1.0000e-04\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0633 - val_loss: -0.0716 - learning_rate: 1.0000e-04\n",
      "Epoch 86/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.0622 - val_loss: -0.0720 - learning_rate: 1.0000e-04\n",
      "Epoch 87/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0697 - val_loss: -0.0715 - learning_rate: 1.0000e-04\n",
      "Epoch 88/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0525 - val_loss: -0.0758 - learning_rate: 1.0000e-04\n",
      "Epoch 89/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0688 - val_loss: -0.0729 - learning_rate: 1.0000e-04\n",
      "Epoch 90/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0736 - val_loss: -0.0802 - learning_rate: 1.0000e-04\n",
      "Epoch 91/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0747 - val_loss: -0.0838 - learning_rate: 1.0000e-04\n",
      "Epoch 92/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0700 - val_loss: -0.0862 - learning_rate: 1.0000e-04\n",
      "Epoch 93/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0831 - val_loss: -0.0898 - learning_rate: 1.0000e-04\n",
      "Epoch 94/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0725 - val_loss: -0.0931 - learning_rate: 1.0000e-04\n",
      "Epoch 95/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0789 - val_loss: -0.0968 - learning_rate: 1.0000e-04\n",
      "Epoch 96/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0940 - val_loss: -0.1001 - learning_rate: 1.0000e-04\n",
      "Epoch 97/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0919 - val_loss: -0.1031 - learning_rate: 1.0000e-04\n",
      "Epoch 98/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0753 - val_loss: -0.1110 - learning_rate: 1.0000e-04\n",
      "Epoch 99/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0936 - val_loss: -0.1136 - learning_rate: 1.0000e-04\n",
      "Epoch 100/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.1026 - val_loss: -0.1143 - learning_rate: 1.0000e-04\n",
      "Epoch 101/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0941 - val_loss: -0.1196 - learning_rate: 1.0000e-04\n",
      "Epoch 102/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.0925 - val_loss: -0.1296 - learning_rate: 1.0000e-04\n",
      "Epoch 103/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.1071 - val_loss: -0.1312 - learning_rate: 1.0000e-04\n",
      "Epoch 104/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.1058 - val_loss: -0.1318 - learning_rate: 1.0000e-04\n",
      "Epoch 105/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.1033 - val_loss: -0.1436 - learning_rate: 1.0000e-04\n",
      "Epoch 106/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.1153 - val_loss: -0.1552 - learning_rate: 1.0000e-04\n",
      "Epoch 107/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1136 - val_loss: -0.1573 - learning_rate: 1.0000e-04\n",
      "Epoch 108/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.1298 - val_loss: -0.1613 - learning_rate: 1.0000e-04\n",
      "Epoch 109/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1425 - val_loss: -0.1704 - learning_rate: 1.0000e-04\n",
      "Epoch 110/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1382 - val_loss: -0.1776 - learning_rate: 1.0000e-04\n",
      "Epoch 111/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1331 - val_loss: -0.1835 - learning_rate: 1.0000e-04\n",
      "Epoch 112/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1563 - val_loss: -0.1976 - learning_rate: 1.0000e-04\n",
      "Epoch 113/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1529 - val_loss: -0.2045 - learning_rate: 1.0000e-04\n",
      "Epoch 114/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1662 - val_loss: -0.2163 - learning_rate: 1.0000e-04\n",
      "Epoch 115/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1759 - val_loss: -0.2167 - learning_rate: 1.0000e-04\n",
      "Epoch 116/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.1866 - val_loss: -0.2358 - learning_rate: 1.0000e-04\n",
      "Epoch 117/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1797 - val_loss: -0.2464 - learning_rate: 1.0000e-04\n",
      "Epoch 118/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1892 - val_loss: -0.2579 - learning_rate: 1.0000e-04\n",
      "Epoch 119/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1888 - val_loss: -0.2674 - learning_rate: 1.0000e-04\n",
      "Epoch 120/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1836 - val_loss: -0.2694 - learning_rate: 1.0000e-04\n",
      "Epoch 121/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1985 - val_loss: -0.2924 - learning_rate: 1.0000e-04\n",
      "Epoch 122/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2125 - val_loss: -0.3056 - learning_rate: 1.0000e-04\n",
      "Epoch 123/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2151 - val_loss: -0.3177 - learning_rate: 1.0000e-04\n",
      "Epoch 124/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2337 - val_loss: -0.3252 - learning_rate: 1.0000e-04\n",
      "Epoch 125/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.2405 - val_loss: -0.3242 - learning_rate: 1.0000e-04\n",
      "Epoch 126/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.2293 - val_loss: -0.3478 - learning_rate: 1.0000e-04\n",
      "Epoch 127/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.2496 - val_loss: -0.3576 - learning_rate: 1.0000e-04\n",
      "Epoch 128/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.2698 - val_loss: -0.3683 - learning_rate: 1.0000e-04\n",
      "Epoch 129/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2405 - val_loss: -0.3791 - learning_rate: 1.0000e-04\n",
      "Epoch 130/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2751 - val_loss: -0.3936 - learning_rate: 1.0000e-04\n",
      "Epoch 131/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2597 - val_loss: -0.3975 - learning_rate: 1.0000e-04\n",
      "Epoch 132/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.2885 - val_loss: -0.4164 - learning_rate: 1.0000e-04\n",
      "Epoch 133/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.2674 - val_loss: -0.4179 - learning_rate: 1.0000e-04\n",
      "Epoch 134/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.2959 - val_loss: -0.4274 - learning_rate: 1.0000e-04\n",
      "Epoch 135/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.2994 - val_loss: -0.4321 - learning_rate: 1.0000e-04\n",
      "Epoch 136/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2933 - val_loss: -0.4439 - learning_rate: 1.0000e-04\n",
      "Epoch 137/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.3046 - val_loss: -0.4432 - learning_rate: 1.0000e-04\n",
      "Epoch 138/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.3054 - val_loss: -0.4466 - learning_rate: 1.0000e-04\n",
      "Epoch 139/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3078 - val_loss: -0.4716 - learning_rate: 1.0000e-04\n",
      "Epoch 140/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.3250 - val_loss: -0.4683 - learning_rate: 1.0000e-04\n",
      "Epoch 141/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3230 - val_loss: -0.4800 - learning_rate: 1.0000e-04\n",
      "Epoch 142/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3369 - val_loss: -0.4813 - learning_rate: 1.0000e-04\n",
      "Epoch 143/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3356 - val_loss: -0.4899 - learning_rate: 1.0000e-04\n",
      "Epoch 144/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3241 - val_loss: -0.4836 - learning_rate: 1.0000e-04\n",
      "Epoch 145/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.3547 - val_loss: -0.4999 - learning_rate: 1.0000e-04\n",
      "Epoch 146/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.3253 - val_loss: -0.4981 - learning_rate: 1.0000e-04\n",
      "Epoch 147/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3464 - val_loss: -0.5057 - learning_rate: 1.0000e-04\n",
      "Epoch 148/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3553 - val_loss: -0.5143 - learning_rate: 1.0000e-04\n",
      "Epoch 149/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3233 - val_loss: -0.5131 - learning_rate: 1.0000e-04\n",
      "Epoch 150/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3757 - val_loss: -0.5124 - learning_rate: 1.0000e-04\n",
      "Epoch 151/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3608 - val_loss: -0.5013 - learning_rate: 1.0000e-04\n",
      "Epoch 152/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3455 - val_loss: -0.5266 - learning_rate: 1.0000e-04\n",
      "Epoch 153/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3835 - val_loss: -0.5222 - learning_rate: 1.0000e-04\n",
      "Epoch 154/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3672 - val_loss: -0.5290 - learning_rate: 1.0000e-04\n",
      "Epoch 155/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.3696 - val_loss: -0.5283 - learning_rate: 1.0000e-04\n",
      "Epoch 156/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.3780 - val_loss: -0.5329 - learning_rate: 1.0000e-04\n",
      "Epoch 157/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3834 - val_loss: -0.5333 - learning_rate: 1.0000e-04\n",
      "Epoch 158/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3727 - val_loss: -0.5373 - learning_rate: 1.0000e-04\n",
      "Epoch 159/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.4055 - val_loss: -0.5387 - learning_rate: 1.0000e-04\n",
      "Epoch 160/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.3801 - val_loss: -0.5431 - learning_rate: 1.0000e-04\n",
      "Epoch 161/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.3812 - val_loss: -0.5343 - learning_rate: 1.0000e-04\n",
      "Epoch 162/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.3976 - val_loss: -0.5410 - learning_rate: 1.0000e-04\n",
      "Epoch 163/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.4113 - val_loss: -0.5390 - learning_rate: 1.0000e-04\n",
      "Epoch 164/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4109 - val_loss: -0.5366 - learning_rate: 1.0000e-04\n",
      "Epoch 165/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4127 - val_loss: -0.5377 - learning_rate: 1.0000e-04\n",
      "Epoch 166/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4064 - val_loss: -0.5468 - learning_rate: 5.0000e-05\n",
      "Epoch 167/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4459 - val_loss: -0.5455 - learning_rate: 5.0000e-05\n",
      "Epoch 168/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4130 - val_loss: -0.5478 - learning_rate: 5.0000e-05\n",
      "Epoch 169/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4197 - val_loss: -0.5494 - learning_rate: 5.0000e-05\n",
      "Epoch 170/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3973 - val_loss: -0.5481 - learning_rate: 5.0000e-05\n",
      "Epoch 171/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3993 - val_loss: -0.5365 - learning_rate: 5.0000e-05\n",
      "Epoch 172/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4624 - val_loss: -0.5423 - learning_rate: 5.0000e-05\n",
      "Epoch 173/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3926 - val_loss: -0.5456 - learning_rate: 5.0000e-05\n",
      "Epoch 174/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4138 - val_loss: -0.5482 - learning_rate: 5.0000e-05\n",
      "Epoch 175/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3780 - val_loss: -0.5536 - learning_rate: 2.5000e-05\n",
      "Epoch 176/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4215 - val_loss: -0.5531 - learning_rate: 2.5000e-05\n",
      "Epoch 177/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3825 - val_loss: -0.5507 - learning_rate: 2.5000e-05\n",
      "Epoch 178/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4367 - val_loss: -0.5529 - learning_rate: 2.5000e-05\n",
      "Epoch 179/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4146 - val_loss: -0.5538 - learning_rate: 2.5000e-05\n",
      "Epoch 180/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4257 - val_loss: -0.5494 - learning_rate: 2.5000e-05\n",
      "Epoch 181/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4455 - val_loss: -0.5519 - learning_rate: 2.5000e-05\n",
      "Epoch 182/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4364 - val_loss: -0.5520 - learning_rate: 2.5000e-05\n",
      "Epoch 183/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4149 - val_loss: -0.5481 - learning_rate: 2.5000e-05\n",
      "Epoch 184/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4342 - val_loss: -0.5538 - learning_rate: 2.5000e-05\n",
      "Epoch 185/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4407 - val_loss: -0.5495 - learning_rate: 1.2500e-05\n",
      "Epoch 186/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4402 - val_loss: -0.5532 - learning_rate: 1.2500e-05\n",
      "Epoch 187/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.4304 - val_loss: -0.5516 - learning_rate: 1.2500e-05\n",
      "Epoch 188/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4025 - val_loss: -0.5530 - learning_rate: 1.2500e-05\n",
      "Epoch 189/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4136 - val_loss: -0.5525 - learning_rate: 1.2500e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.6277 - val_loss: 0.0136 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.4270 - val_loss: 0.0040 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2904 - val_loss: -0.0017 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2108 - val_loss: 0.0026 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1399 - val_loss: 0.0037 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1184 - val_loss: -0.0024 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1060 - val_loss: -0.0024 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0815 - val_loss: -0.0021 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0739 - val_loss: -0.0035 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0711 - val_loss: -0.0067 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0529 - val_loss: -0.0070 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0541 - val_loss: -0.0079 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0519 - val_loss: -0.0046 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0501 - val_loss: -0.0079 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0447 - val_loss: -0.0097 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0324 - val_loss: -0.0098 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0325 - val_loss: -0.0091 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0243 - val_loss: -0.0121 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0099 - val_loss: -0.0135 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0252 - val_loss: -0.0134 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0298 - val_loss: -0.0153 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0212 - val_loss: -0.0155 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0062 - val_loss: -0.0173 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0044 - val_loss: -0.0198 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0080 - val_loss: -0.0214 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0037 - val_loss: -0.0214 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0029 - val_loss: -0.0248 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0017 - val_loss: -0.0265 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3.6642e-04 - val_loss: -0.0272 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -3.0917e-05 - val_loss: -0.0286 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0089 - val_loss: -0.0275 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0091 - val_loss: -0.0330 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0147 - val_loss: -0.0348 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0141 - val_loss: -0.0377 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0123 - val_loss: -0.0379 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0128 - val_loss: -0.0411 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0136 - val_loss: -0.0428 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0205 - val_loss: -0.0436 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0261 - val_loss: -0.0483 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0136 - val_loss: -0.0494 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0165 - val_loss: -0.0535 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0147 - val_loss: -0.0559 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0299 - val_loss: -0.0620 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0271 - val_loss: -0.0615 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0353 - val_loss: -0.0651 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0468 - val_loss: -0.0708 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0442 - val_loss: -0.0745 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0481 - val_loss: -0.0787 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0451 - val_loss: -0.0812 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0654 - val_loss: -0.0862 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0565 - val_loss: -0.0867 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0408 - val_loss: -0.0944 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0553 - val_loss: -0.0979 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0589 - val_loss: -0.1012 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0815 - val_loss: -0.1041 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0607 - val_loss: -0.1115 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0709 - val_loss: -0.1133 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0786 - val_loss: -0.1182 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0732 - val_loss: -0.1269 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0798 - val_loss: -0.1296 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0877 - val_loss: -0.1370 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.1003 - val_loss: -0.1407 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0920 - val_loss: -0.1450 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1056 - val_loss: -0.1555 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1102 - val_loss: -0.1649 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1143 - val_loss: -0.1693 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0986 - val_loss: -0.1740 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1066 - val_loss: -0.1808 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1147 - val_loss: -0.1919 - learning_rate: 1.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1372 - val_loss: -0.2004 - learning_rate: 1.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1361 - val_loss: -0.2143 - learning_rate: 1.0000e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1295 - val_loss: -0.2200 - learning_rate: 1.0000e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.1509 - val_loss: -0.2329 - learning_rate: 1.0000e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1525 - val_loss: -0.2463 - learning_rate: 1.0000e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.1610 - val_loss: -0.2521 - learning_rate: 1.0000e-04\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1469 - val_loss: -0.2602 - learning_rate: 1.0000e-04\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.1770 - val_loss: -0.2688 - learning_rate: 1.0000e-04\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.1701 - val_loss: -0.2775 - learning_rate: 1.0000e-04\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.1827 - val_loss: -0.2840 - learning_rate: 1.0000e-04\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.2003 - val_loss: -0.2958 - learning_rate: 1.0000e-04\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.1883 - val_loss: -0.2983 - learning_rate: 1.0000e-04\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1840 - val_loss: -0.3043 - learning_rate: 1.0000e-04\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1888 - val_loss: -0.3186 - learning_rate: 1.0000e-04\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2000 - val_loss: -0.3377 - learning_rate: 1.0000e-04\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.1964 - val_loss: -0.3408 - learning_rate: 1.0000e-04\n",
      "Epoch 86/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.2070 - val_loss: -0.3498 - learning_rate: 1.0000e-04\n",
      "Epoch 87/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.2180 - val_loss: -0.3679 - learning_rate: 1.0000e-04\n",
      "Epoch 88/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2528 - val_loss: -0.3799 - learning_rate: 1.0000e-04\n",
      "Epoch 89/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2554 - val_loss: -0.3824 - learning_rate: 1.0000e-04\n",
      "Epoch 90/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2469 - val_loss: -0.3999 - learning_rate: 1.0000e-04\n",
      "Epoch 91/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2331 - val_loss: -0.3994 - learning_rate: 1.0000e-04\n",
      "Epoch 92/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2600 - val_loss: -0.4141 - learning_rate: 1.0000e-04\n",
      "Epoch 93/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2485 - val_loss: -0.4198 - learning_rate: 1.0000e-04\n",
      "Epoch 94/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2554 - val_loss: -0.4332 - learning_rate: 1.0000e-04\n",
      "Epoch 95/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2561 - val_loss: -0.4384 - learning_rate: 1.0000e-04\n",
      "Epoch 96/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.2599 - val_loss: -0.4386 - learning_rate: 1.0000e-04\n",
      "Epoch 97/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2732 - val_loss: -0.4453 - learning_rate: 1.0000e-04\n",
      "Epoch 98/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2865 - val_loss: -0.4605 - learning_rate: 1.0000e-04\n",
      "Epoch 99/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2707 - val_loss: -0.4634 - learning_rate: 1.0000e-04\n",
      "Epoch 100/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2690 - val_loss: -0.4680 - learning_rate: 1.0000e-04\n",
      "Epoch 101/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2914 - val_loss: -0.4742 - learning_rate: 1.0000e-04\n",
      "Epoch 102/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2966 - val_loss: -0.4843 - learning_rate: 1.0000e-04\n",
      "Epoch 103/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3197 - val_loss: -0.4970 - learning_rate: 1.0000e-04\n",
      "Epoch 104/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2968 - val_loss: -0.4997 - learning_rate: 1.0000e-04\n",
      "Epoch 105/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2906 - val_loss: -0.5049 - learning_rate: 1.0000e-04\n",
      "Epoch 106/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3105 - val_loss: -0.5142 - learning_rate: 1.0000e-04\n",
      "Epoch 107/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3135 - val_loss: -0.5171 - learning_rate: 1.0000e-04\n",
      "Epoch 108/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3107 - val_loss: -0.5304 - learning_rate: 1.0000e-04\n",
      "Epoch 109/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3398 - val_loss: -0.5132 - learning_rate: 1.0000e-04\n",
      "Epoch 110/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3261 - val_loss: -0.5388 - learning_rate: 1.0000e-04\n",
      "Epoch 111/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3152 - val_loss: -0.5415 - learning_rate: 1.0000e-04\n",
      "Epoch 112/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.3331 - val_loss: -0.5484 - learning_rate: 1.0000e-04\n",
      "Epoch 113/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3281 - val_loss: -0.5389 - learning_rate: 1.0000e-04\n",
      "Epoch 114/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3385 - val_loss: -0.5513 - learning_rate: 1.0000e-04\n",
      "Epoch 115/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3374 - val_loss: -0.5631 - learning_rate: 1.0000e-04\n",
      "Epoch 116/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.3368 - val_loss: -0.5517 - learning_rate: 1.0000e-04\n",
      "Epoch 117/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3759 - val_loss: -0.5679 - learning_rate: 1.0000e-04\n",
      "Epoch 118/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3744 - val_loss: -0.5745 - learning_rate: 1.0000e-04\n",
      "Epoch 119/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3651 - val_loss: -0.5428 - learning_rate: 1.0000e-04\n",
      "Epoch 120/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3261 - val_loss: -0.5688 - learning_rate: 1.0000e-04\n",
      "Epoch 121/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3280 - val_loss: -0.5875 - learning_rate: 1.0000e-04\n",
      "Epoch 122/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3533 - val_loss: -0.5938 - learning_rate: 1.0000e-04\n",
      "Epoch 123/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3561 - val_loss: -0.5940 - learning_rate: 1.0000e-04\n",
      "Epoch 124/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3631 - val_loss: -0.5884 - learning_rate: 1.0000e-04\n",
      "Epoch 125/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.3708 - val_loss: -0.6067 - learning_rate: 1.0000e-04\n",
      "Epoch 126/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3780 - val_loss: -0.5907 - learning_rate: 1.0000e-04\n",
      "Epoch 127/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3862 - val_loss: -0.6030 - learning_rate: 1.0000e-04\n",
      "Epoch 128/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.3775 - val_loss: -0.6064 - learning_rate: 1.0000e-04\n",
      "Epoch 129/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4008 - val_loss: -0.6043 - learning_rate: 1.0000e-04\n",
      "Epoch 130/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4096 - val_loss: -0.6001 - learning_rate: 1.0000e-04\n",
      "Epoch 131/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.4201 - val_loss: -0.6111 - learning_rate: 5.0000e-05\n",
      "Epoch 132/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.3989 - val_loss: -0.6150 - learning_rate: 5.0000e-05\n",
      "Epoch 133/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.3868 - val_loss: -0.6145 - learning_rate: 5.0000e-05\n",
      "Epoch 134/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.3759 - val_loss: -0.6190 - learning_rate: 5.0000e-05\n",
      "Epoch 135/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.4057 - val_loss: -0.6138 - learning_rate: 5.0000e-05\n",
      "Epoch 136/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.3866 - val_loss: -0.6210 - learning_rate: 5.0000e-05\n",
      "Epoch 137/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.4026 - val_loss: -0.6150 - learning_rate: 5.0000e-05\n",
      "Epoch 138/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.4066 - val_loss: -0.6177 - learning_rate: 5.0000e-05\n",
      "Epoch 139/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.4158 - val_loss: -0.6192 - learning_rate: 5.0000e-05\n",
      "Epoch 140/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4045 - val_loss: -0.6255 - learning_rate: 5.0000e-05\n",
      "Epoch 141/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4200 - val_loss: -0.6290 - learning_rate: 5.0000e-05\n",
      "Epoch 142/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4113 - val_loss: -0.6309 - learning_rate: 5.0000e-05\n",
      "Epoch 143/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4195 - val_loss: -0.6318 - learning_rate: 5.0000e-05\n",
      "Epoch 144/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4122 - val_loss: -0.6280 - learning_rate: 5.0000e-05\n",
      "Epoch 145/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4364 - val_loss: -0.6256 - learning_rate: 5.0000e-05\n",
      "Epoch 146/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4224 - val_loss: -0.6325 - learning_rate: 5.0000e-05\n",
      "Epoch 147/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4300 - val_loss: -0.6334 - learning_rate: 5.0000e-05\n",
      "Epoch 148/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4098 - val_loss: -0.6379 - learning_rate: 5.0000e-05\n",
      "Epoch 149/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4046 - val_loss: -0.6310 - learning_rate: 5.0000e-05\n",
      "Epoch 150/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4391 - val_loss: -0.6376 - learning_rate: 5.0000e-05\n",
      "Epoch 151/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4357 - val_loss: -0.6377 - learning_rate: 5.0000e-05\n",
      "Epoch 152/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4438 - val_loss: -0.6409 - learning_rate: 5.0000e-05\n",
      "Epoch 153/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4336 - val_loss: -0.6422 - learning_rate: 5.0000e-05\n",
      "Epoch 154/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4293 - val_loss: -0.6436 - learning_rate: 5.0000e-05\n",
      "Epoch 155/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4330 - val_loss: -0.6409 - learning_rate: 5.0000e-05\n",
      "Epoch 156/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4554 - val_loss: -0.6520 - learning_rate: 5.0000e-05\n",
      "Epoch 157/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4366 - val_loss: -0.6503 - learning_rate: 5.0000e-05\n",
      "Epoch 158/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4347 - val_loss: -0.6471 - learning_rate: 5.0000e-05\n",
      "Epoch 159/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4421 - val_loss: -0.6510 - learning_rate: 5.0000e-05\n",
      "Epoch 160/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3907 - val_loss: -0.6521 - learning_rate: 5.0000e-05\n",
      "Epoch 161/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4316 - val_loss: -0.6575 - learning_rate: 5.0000e-05\n",
      "Epoch 162/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4492 - val_loss: -0.6496 - learning_rate: 5.0000e-05\n",
      "Epoch 163/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4776 - val_loss: -0.6603 - learning_rate: 5.0000e-05\n",
      "Epoch 164/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4557 - val_loss: -0.6561 - learning_rate: 5.0000e-05\n",
      "Epoch 165/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.4608 - val_loss: -0.6524 - learning_rate: 5.0000e-05\n",
      "Epoch 166/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.4377 - val_loss: -0.6607 - learning_rate: 5.0000e-05\n",
      "Epoch 167/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4375 - val_loss: -0.6626 - learning_rate: 5.0000e-05\n",
      "Epoch 168/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4774 - val_loss: -0.6598 - learning_rate: 5.0000e-05\n",
      "Epoch 169/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4502 - val_loss: -0.6645 - learning_rate: 5.0000e-05\n",
      "Epoch 170/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.4597 - val_loss: -0.6575 - learning_rate: 5.0000e-05\n",
      "Epoch 171/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4342 - val_loss: -0.6731 - learning_rate: 5.0000e-05\n",
      "Epoch 172/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.4345 - val_loss: -0.6649 - learning_rate: 5.0000e-05\n",
      "Epoch 173/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4274 - val_loss: -0.6615 - learning_rate: 5.0000e-05\n",
      "Epoch 174/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4758 - val_loss: -0.6690 - learning_rate: 5.0000e-05\n",
      "Epoch 175/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.5059 - val_loss: -0.6729 - learning_rate: 5.0000e-05\n",
      "Epoch 176/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4637 - val_loss: -0.6666 - learning_rate: 5.0000e-05\n",
      "Epoch 177/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4662 - val_loss: -0.6733 - learning_rate: 2.5000e-05\n",
      "Epoch 178/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.4428 - val_loss: -0.6747 - learning_rate: 2.5000e-05\n",
      "Epoch 179/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.4404 - val_loss: -0.6714 - learning_rate: 2.5000e-05\n",
      "Epoch 180/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.5003 - val_loss: -0.6691 - learning_rate: 2.5000e-05\n",
      "Epoch 181/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.4773 - val_loss: -0.6727 - learning_rate: 2.5000e-05\n",
      "Epoch 182/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.4680 - val_loss: -0.6754 - learning_rate: 2.5000e-05\n",
      "Epoch 183/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.4683 - val_loss: -0.6762 - learning_rate: 2.5000e-05\n",
      "Epoch 184/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4740 - val_loss: -0.6782 - learning_rate: 2.5000e-05\n",
      "Epoch 185/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4441 - val_loss: -0.6763 - learning_rate: 2.5000e-05\n",
      "Epoch 186/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4470 - val_loss: -0.6803 - learning_rate: 2.5000e-05\n",
      "Epoch 187/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4937 - val_loss: -0.6727 - learning_rate: 2.5000e-05\n",
      "Epoch 188/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4679 - val_loss: -0.6733 - learning_rate: 2.5000e-05\n",
      "Epoch 189/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.4701 - val_loss: -0.6798 - learning_rate: 2.5000e-05\n",
      "Epoch 190/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4607 - val_loss: -0.6801 - learning_rate: 2.5000e-05\n",
      "Epoch 191/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.5246 - val_loss: -0.6712 - learning_rate: 2.5000e-05\n",
      "Epoch 192/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.4596 - val_loss: -0.6806 - learning_rate: 1.2500e-05\n",
      "Epoch 193/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.4947 - val_loss: -0.6818 - learning_rate: 1.2500e-05\n",
      "Epoch 194/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.4542 - val_loss: -0.6805 - learning_rate: 1.2500e-05\n",
      "Epoch 195/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.4726 - val_loss: -0.6803 - learning_rate: 1.2500e-05\n",
      "Epoch 196/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4948 - val_loss: -0.6839 - learning_rate: 1.2500e-05\n",
      "Epoch 197/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4872 - val_loss: -0.6857 - learning_rate: 1.2500e-05\n",
      "Epoch 198/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4737 - val_loss: -0.6817 - learning_rate: 1.2500e-05\n",
      "Epoch 199/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4669 - val_loss: -0.6820 - learning_rate: 1.2500e-05\n",
      "Epoch 200/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.4812 - val_loss: -0.6840 - learning_rate: 1.2500e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.7791 - val_loss: 0.0676 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.4819 - val_loss: 0.0350 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2700 - val_loss: 0.0369 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1904 - val_loss: 0.0227 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1915 - val_loss: 0.0223 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1464 - val_loss: 0.0140 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1190 - val_loss: 0.0164 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0899 - val_loss: 0.0166 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0898 - val_loss: 0.0116 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0709 - val_loss: 0.0045 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0702 - val_loss: 0.0095 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0565 - val_loss: 0.0087 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0448 - val_loss: 0.0054 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0375 - val_loss: 3.5603e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0482 - val_loss: -0.0016 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0393 - val_loss: -5.1100e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0466 - val_loss: -0.0047 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0513 - val_loss: -0.0059 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0408 - val_loss: -0.0073 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0186 - val_loss: 2.2533e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0224 - val_loss: -0.0095 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0336 - val_loss: -0.0115 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0296 - val_loss: -0.0122 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0141 - val_loss: -0.0171 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0206 - val_loss: -0.0151 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: -0.0150 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0188 - val_loss: -0.0183 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0122 - val_loss: -0.0242 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0070 - val_loss: -0.0279 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0034 - val_loss: -0.0290 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0136 - val_loss: -0.0367 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0036 - val_loss: -0.0412 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0099 - val_loss: -0.0418 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0116 - val_loss: -0.0633 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0255 - val_loss: -0.0690 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.0268 - val_loss: -0.0798 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0327 - val_loss: -0.0896 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.0385 - val_loss: -0.0971 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0738 - val_loss: -0.1170 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0665 - val_loss: -0.1232 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0712 - val_loss: -0.1474 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0911 - val_loss: -0.1656 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1163 - val_loss: -0.1803 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1080 - val_loss: -0.2063 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1168 - val_loss: -0.2333 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1296 - val_loss: -0.2610 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1708 - val_loss: -0.2942 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1880 - val_loss: -0.3283 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2005 - val_loss: -0.3644 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2354 - val_loss: -0.4082 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2378 - val_loss: -0.4417 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2840 - val_loss: -0.4790 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3020 - val_loss: -0.5206 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3130 - val_loss: -0.5599 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3329 - val_loss: -0.6009 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3519 - val_loss: -0.6337 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3698 - val_loss: -0.6784 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4135 - val_loss: -0.7266 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4445 - val_loss: -0.7615 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4400 - val_loss: -0.8044 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4813 - val_loss: -0.8513 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4917 - val_loss: -0.8817 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4871 - val_loss: -0.9181 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.5485 - val_loss: -0.9544 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.5452 - val_loss: -1.0043 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.5742 - val_loss: -1.0313 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.5946 - val_loss: -1.0681 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.5942 - val_loss: -1.0869 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.6111 - val_loss: -1.1242 - learning_rate: 1.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.6201 - val_loss: -1.1589 - learning_rate: 1.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.6275 - val_loss: -1.1804 - learning_rate: 1.0000e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.6486 - val_loss: -1.2099 - learning_rate: 1.0000e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.6668 - val_loss: -1.2140 - learning_rate: 1.0000e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.6618 - val_loss: -1.2249 - learning_rate: 1.0000e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.6851 - val_loss: -1.2206 - learning_rate: 1.0000e-04\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.6591 - val_loss: -1.2596 - learning_rate: 1.0000e-04\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.6597 - val_loss: -1.2727 - learning_rate: 1.0000e-04\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.6961 - val_loss: -1.2809 - learning_rate: 1.0000e-04\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.6758 - val_loss: -1.2870 - learning_rate: 1.0000e-04\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.7529 - val_loss: -1.3109 - learning_rate: 1.0000e-04\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.7260 - val_loss: -1.3203 - learning_rate: 1.0000e-04\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.7299 - val_loss: -1.3486 - learning_rate: 1.0000e-04\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.7220 - val_loss: -1.3426 - learning_rate: 1.0000e-04\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.7469 - val_loss: -1.3690 - learning_rate: 1.0000e-04\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.7517 - val_loss: -1.3784 - learning_rate: 1.0000e-04\n",
      "Epoch 86/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.7615 - val_loss: -1.3725 - learning_rate: 1.0000e-04\n",
      "Epoch 87/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.7635 - val_loss: -1.4237 - learning_rate: 1.0000e-04\n",
      "Epoch 88/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.8060 - val_loss: -1.4359 - learning_rate: 1.0000e-04\n",
      "Epoch 89/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.8036 - val_loss: -1.4313 - learning_rate: 1.0000e-04\n",
      "Epoch 90/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.7996 - val_loss: -1.4490 - learning_rate: 1.0000e-04\n",
      "Epoch 91/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.8235 - val_loss: -1.4635 - learning_rate: 1.0000e-04\n",
      "Epoch 92/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.8344 - val_loss: -1.4719 - learning_rate: 1.0000e-04\n",
      "Epoch 93/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.8815 - val_loss: -1.4995 - learning_rate: 1.0000e-04\n",
      "Epoch 94/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.8142 - val_loss: -1.5021 - learning_rate: 1.0000e-04\n",
      "Epoch 95/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.8677 - val_loss: -1.4954 - learning_rate: 1.0000e-04\n",
      "Epoch 96/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.8785 - val_loss: -1.5319 - learning_rate: 1.0000e-04\n",
      "Epoch 97/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.8901 - val_loss: -1.5371 - learning_rate: 1.0000e-04\n",
      "Epoch 98/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.9046 - val_loss: -1.5632 - learning_rate: 1.0000e-04\n",
      "Epoch 99/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.9139 - val_loss: -1.5619 - learning_rate: 1.0000e-04\n",
      "Epoch 100/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.8689 - val_loss: -1.5776 - learning_rate: 1.0000e-04\n",
      "Epoch 101/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.9278 - val_loss: -1.5807 - learning_rate: 1.0000e-04\n",
      "Epoch 102/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.9082 - val_loss: -1.6166 - learning_rate: 1.0000e-04\n",
      "Epoch 103/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.9647 - val_loss: -1.6232 - learning_rate: 1.0000e-04\n",
      "Epoch 104/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.8915 - val_loss: -1.6186 - learning_rate: 1.0000e-04\n",
      "Epoch 105/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.9717 - val_loss: -1.6196 - learning_rate: 1.0000e-04\n",
      "Epoch 106/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.9713 - val_loss: -1.6610 - learning_rate: 1.0000e-04\n",
      "Epoch 107/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.0204 - val_loss: -1.6746 - learning_rate: 1.0000e-04\n",
      "Epoch 108/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.9931 - val_loss: -1.6731 - learning_rate: 1.0000e-04\n",
      "Epoch 109/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -1.0172 - val_loss: -1.7047 - learning_rate: 1.0000e-04\n",
      "Epoch 110/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.0257 - val_loss: -1.7106 - learning_rate: 1.0000e-04\n",
      "Epoch 111/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.0708 - val_loss: -1.7343 - learning_rate: 1.0000e-04\n",
      "Epoch 112/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.9903 - val_loss: -1.7058 - learning_rate: 1.0000e-04\n",
      "Epoch 113/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.0767 - val_loss: -1.7296 - learning_rate: 1.0000e-04\n",
      "Epoch 114/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.0676 - val_loss: -1.7516 - learning_rate: 1.0000e-04\n",
      "Epoch 115/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.1032 - val_loss: -1.7595 - learning_rate: 1.0000e-04\n",
      "Epoch 116/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.0434 - val_loss: -1.7391 - learning_rate: 1.0000e-04\n",
      "Epoch 117/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.1166 - val_loss: -1.7753 - learning_rate: 1.0000e-04\n",
      "Epoch 118/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.0676 - val_loss: -1.7170 - learning_rate: 1.0000e-04\n",
      "Epoch 119/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.1041 - val_loss: -1.7910 - learning_rate: 1.0000e-04\n",
      "Epoch 120/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.1651 - val_loss: -1.7631 - learning_rate: 1.0000e-04\n",
      "Epoch 121/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.1567 - val_loss: -1.7924 - learning_rate: 1.0000e-04\n",
      "Epoch 122/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.0676 - val_loss: -1.7854 - learning_rate: 1.0000e-04\n",
      "Epoch 123/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.1772 - val_loss: -1.8312 - learning_rate: 1.0000e-04\n",
      "Epoch 124/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.1346 - val_loss: -1.8020 - learning_rate: 1.0000e-04\n",
      "Epoch 125/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.1218 - val_loss: -1.8331 - learning_rate: 1.0000e-04\n",
      "Epoch 126/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.1507 - val_loss: -1.8062 - learning_rate: 1.0000e-04\n",
      "Epoch 127/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.1305 - val_loss: -1.8443 - learning_rate: 1.0000e-04\n",
      "Epoch 128/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.1648 - val_loss: -1.8643 - learning_rate: 1.0000e-04\n",
      "Epoch 129/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.1788 - val_loss: -1.8841 - learning_rate: 1.0000e-04\n",
      "Epoch 130/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.2183 - val_loss: -1.8563 - learning_rate: 1.0000e-04\n",
      "Epoch 131/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.1541 - val_loss: -1.8980 - learning_rate: 1.0000e-04\n",
      "Epoch 132/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -1.2269 - val_loss: -1.8967 - learning_rate: 1.0000e-04\n",
      "Epoch 133/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.2041 - val_loss: -1.8992 - learning_rate: 1.0000e-04\n",
      "Epoch 134/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.1933 - val_loss: -1.9099 - learning_rate: 1.0000e-04\n",
      "Epoch 135/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.2811 - val_loss: -1.9072 - learning_rate: 1.0000e-04\n",
      "Epoch 136/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.1985 - val_loss: -1.9111 - learning_rate: 1.0000e-04\n",
      "Epoch 137/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.2994 - val_loss: -1.9519 - learning_rate: 1.0000e-04\n",
      "Epoch 138/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -1.2891 - val_loss: -1.9477 - learning_rate: 1.0000e-04\n",
      "Epoch 139/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.2746 - val_loss: -1.9644 - learning_rate: 1.0000e-04\n",
      "Epoch 140/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.2269 - val_loss: -1.9894 - learning_rate: 1.0000e-04\n",
      "Epoch 141/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -1.3456 - val_loss: -1.9935 - learning_rate: 1.0000e-04\n",
      "Epoch 142/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.2743 - val_loss: -1.9899 - learning_rate: 1.0000e-04\n",
      "Epoch 143/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.3018 - val_loss: -1.9997 - learning_rate: 1.0000e-04\n",
      "Epoch 144/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -1.2925 - val_loss: -1.9966 - learning_rate: 1.0000e-04\n",
      "Epoch 145/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -1.3673 - val_loss: -1.9847 - learning_rate: 1.0000e-04\n",
      "Epoch 146/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -1.3416 - val_loss: -2.0104 - learning_rate: 1.0000e-04\n",
      "Epoch 147/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -1.3788 - val_loss: -2.0276 - learning_rate: 1.0000e-04\n",
      "Epoch 148/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -1.3536 - val_loss: -2.0302 - learning_rate: 1.0000e-04\n",
      "Epoch 149/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -1.3716 - val_loss: -2.0470 - learning_rate: 1.0000e-04\n",
      "Epoch 150/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.3326 - val_loss: -2.0660 - learning_rate: 1.0000e-04\n",
      "Epoch 151/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -1.3853 - val_loss: -2.0413 - learning_rate: 1.0000e-04\n",
      "Epoch 152/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -1.4163 - val_loss: -2.0509 - learning_rate: 1.0000e-04\n",
      "Epoch 153/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.4291 - val_loss: -2.0652 - learning_rate: 1.0000e-04\n",
      "Epoch 154/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -1.4411 - val_loss: -2.1077 - learning_rate: 1.0000e-04\n",
      "Epoch 155/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.4707 - val_loss: -2.0824 - learning_rate: 1.0000e-04\n",
      "Epoch 156/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -1.4478 - val_loss: -2.1177 - learning_rate: 1.0000e-04\n",
      "Epoch 157/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -1.4283 - val_loss: -2.1160 - learning_rate: 1.0000e-04\n",
      "Epoch 158/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.4379 - val_loss: -2.1373 - learning_rate: 1.0000e-04\n",
      "Epoch 159/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.4292 - val_loss: -2.0945 - learning_rate: 1.0000e-04\n",
      "Epoch 160/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -1.5290 - val_loss: -2.1063 - learning_rate: 1.0000e-04\n",
      "Epoch 161/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.4395 - val_loss: -2.1558 - learning_rate: 1.0000e-04\n",
      "Epoch 162/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.4545 - val_loss: -2.1272 - learning_rate: 1.0000e-04\n",
      "Epoch 163/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.4977 - val_loss: -2.1755 - learning_rate: 1.0000e-04\n",
      "Epoch 164/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -1.4733 - val_loss: -2.1961 - learning_rate: 1.0000e-04\n",
      "Epoch 165/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -1.4844 - val_loss: -2.1694 - learning_rate: 1.0000e-04\n",
      "Epoch 166/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.5084 - val_loss: -2.2085 - learning_rate: 1.0000e-04\n",
      "Epoch 167/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.4806 - val_loss: -2.2285 - learning_rate: 1.0000e-04\n",
      "Epoch 168/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.5380 - val_loss: -2.1805 - learning_rate: 1.0000e-04\n",
      "Epoch 169/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.4840 - val_loss: -2.1464 - learning_rate: 1.0000e-04\n",
      "Epoch 170/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.5811 - val_loss: -2.2167 - learning_rate: 1.0000e-04\n",
      "Epoch 171/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.5948 - val_loss: -2.2092 - learning_rate: 1.0000e-04\n",
      "Epoch 172/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.5124 - val_loss: -2.2021 - learning_rate: 1.0000e-04\n",
      "Epoch 173/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.5157 - val_loss: -2.1908 - learning_rate: 5.0000e-05\n",
      "Epoch 174/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.5638 - val_loss: -2.2257 - learning_rate: 5.0000e-05\n",
      "Epoch 175/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.6492 - val_loss: -2.2259 - learning_rate: 5.0000e-05\n",
      "Epoch 176/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.5653 - val_loss: -2.2392 - learning_rate: 5.0000e-05\n",
      "Epoch 177/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.6498 - val_loss: -2.2021 - learning_rate: 5.0000e-05\n",
      "Epoch 178/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -1.6964 - val_loss: -2.2725 - learning_rate: 5.0000e-05\n",
      "Epoch 179/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -1.5990 - val_loss: -2.2410 - learning_rate: 5.0000e-05\n",
      "Epoch 180/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.5536 - val_loss: -2.2611 - learning_rate: 5.0000e-05\n",
      "Epoch 181/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.6140 - val_loss: -2.2665 - learning_rate: 5.0000e-05\n",
      "Epoch 182/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.5964 - val_loss: -2.2820 - learning_rate: 5.0000e-05\n",
      "Epoch 183/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.6661 - val_loss: -2.2684 - learning_rate: 5.0000e-05\n",
      "Epoch 184/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -1.6301 - val_loss: -2.2915 - learning_rate: 5.0000e-05\n",
      "Epoch 185/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.6560 - val_loss: -2.2988 - learning_rate: 5.0000e-05\n",
      "Epoch 186/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -1.6606 - val_loss: -2.3159 - learning_rate: 5.0000e-05\n",
      "Epoch 187/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.6537 - val_loss: -2.2964 - learning_rate: 5.0000e-05\n",
      "Epoch 188/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -1.5822 - val_loss: -2.2923 - learning_rate: 5.0000e-05\n",
      "Epoch 189/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -1.7805 - val_loss: -2.3056 - learning_rate: 5.0000e-05\n",
      "Epoch 190/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.6784 - val_loss: -2.2922 - learning_rate: 5.0000e-05\n",
      "Epoch 191/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -1.6370 - val_loss: -2.2855 - learning_rate: 5.0000e-05\n",
      "Epoch 192/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.5645 - val_loss: -2.3143 - learning_rate: 2.5000e-05\n",
      "Epoch 193/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.6206 - val_loss: -2.3118 - learning_rate: 2.5000e-05\n",
      "Epoch 194/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.6556 - val_loss: -2.2993 - learning_rate: 2.5000e-05\n",
      "Epoch 195/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.6929 - val_loss: -2.3062 - learning_rate: 2.5000e-05\n",
      "Epoch 196/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -1.6294 - val_loss: -2.3273 - learning_rate: 2.5000e-05\n",
      "Epoch 197/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -1.7446 - val_loss: -2.3426 - learning_rate: 2.5000e-05\n",
      "Epoch 198/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.7031 - val_loss: -2.3209 - learning_rate: 2.5000e-05\n",
      "Epoch 199/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.6895 - val_loss: -2.3255 - learning_rate: 2.5000e-05\n",
      "Epoch 200/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -1.6641 - val_loss: -2.3251 - learning_rate: 2.5000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.5868 - val_loss: 0.0236 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3866 - val_loss: 0.0116 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2577 - val_loss: 0.0219 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2122 - val_loss: 0.0112 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1474 - val_loss: 0.0243 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1093 - val_loss: 0.0118 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1050 - val_loss: 0.0079 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1054 - val_loss: 0.0068 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0807 - val_loss: 0.0042 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0574 - val_loss: 0.0016 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0555 - val_loss: 0.0042 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0592 - val_loss: 0.0028 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0552 - val_loss: 0.0038 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0489 - val_loss: 0.0030 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0421 - val_loss: 0.0179 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0462 - val_loss: 0.0034 - learning_rate: 5.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0451 - val_loss: 0.0035 - learning_rate: 5.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0372 - val_loss: 0.0035 - learning_rate: 5.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0415 - val_loss: 0.0028 - learning_rate: 5.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0400 - val_loss: 0.0028 - learning_rate: 5.0000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.5216 - val_loss: 0.0208 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2780 - val_loss: 0.0103 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2081 - val_loss: 0.0050 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1349 - val_loss: 0.0066 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1144 - val_loss: 1.6318e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0953 - val_loss: 5.7018e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0811 - val_loss: 0.0021 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0567 - val_loss: 0.0026 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0721 - val_loss: 0.0033 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0509 - val_loss: 0.0033 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0366 - val_loss: 0.0011 - learning_rate: 5.0000e-05\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0394 - val_loss: 0.0025 - learning_rate: 5.0000e-05\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0390 - val_loss: 0.0027 - learning_rate: 5.0000e-05\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0536 - val_loss: 0.0021 - learning_rate: 5.0000e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0373 - val_loss: 0.0025 - learning_rate: 5.0000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.6127 - val_loss: 0.0238 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3387 - val_loss: 0.0213 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2586 - val_loss: 0.0133 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2153 - val_loss: 0.0145 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1641 - val_loss: 0.0103 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1233 - val_loss: 0.0103 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1166 - val_loss: 0.0100 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0911 - val_loss: 0.0099 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0919 - val_loss: 0.0133 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0718 - val_loss: 0.0156 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0659 - val_loss: 0.0150 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0558 - val_loss: 0.0068 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0652 - val_loss: 0.0096 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0351 - val_loss: 0.0059 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0592 - val_loss: 0.0066 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0388 - val_loss: 0.0053 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0402 - val_loss: 0.0054 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0436 - val_loss: 0.0065 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0386 - val_loss: 0.0040 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0401 - val_loss: 0.0044 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0311 - val_loss: 0.0048 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0351 - val_loss: 0.0066 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0034 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0228 - val_loss: 0.0034 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0234 - val_loss: 0.0041 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0236 - val_loss: 0.0023 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0181 - val_loss: 0.0024 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0205 - val_loss: 0.0024 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0235 - val_loss: 0.0020 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0175 - val_loss: 0.0048 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0205 - val_loss: 0.0054 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0121 - val_loss: 0.0029 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0214 - val_loss: 0.0025 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0259 - val_loss: 0.0028 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0186 - val_loss: 0.0021 - learning_rate: 5.0000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0171 - val_loss: 0.0020 - learning_rate: 5.0000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0152 - val_loss: 0.0018 - learning_rate: 5.0000e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0135 - val_loss: 0.0020 - learning_rate: 5.0000e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0137 - val_loss: 0.0017 - learning_rate: 5.0000e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0025 - learning_rate: 5.0000e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0088 - val_loss: 0.0023 - learning_rate: 5.0000e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0138 - val_loss: 0.0017 - learning_rate: 5.0000e-05\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0166 - val_loss: 0.0017 - learning_rate: 5.0000e-05\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0139 - val_loss: 0.0016 - learning_rate: 5.0000e-05\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0145 - val_loss: 0.0017 - learning_rate: 5.0000e-05\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0129 - val_loss: 0.0018 - learning_rate: 5.0000e-05\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0163 - val_loss: 0.0018 - learning_rate: 5.0000e-05\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0108 - val_loss: 0.0019 - learning_rate: 5.0000e-05\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0148 - val_loss: 0.0016 - learning_rate: 5.0000e-05\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0115 - val_loss: 0.0014 - learning_rate: 2.5000e-05\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0172 - val_loss: 0.0014 - learning_rate: 2.5000e-05\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0173 - val_loss: 0.0014 - learning_rate: 2.5000e-05\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0016 - learning_rate: 2.5000e-05\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0060 - val_loss: 0.0014 - learning_rate: 2.5000e-05\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0149 - val_loss: 0.0017 - learning_rate: 2.5000e-05\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0122 - val_loss: 0.0016 - learning_rate: 1.2500e-05\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0015 - learning_rate: 1.2500e-05\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0015 - learning_rate: 1.2500e-05\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0166 - val_loss: 0.0015 - learning_rate: 1.2500e-05\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0120 - val_loss: 0.0014 - learning_rate: 1.2500e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.4914 - val_loss: 0.0420 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3255 - val_loss: 0.0181 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2193 - val_loss: 0.0159 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1643 - val_loss: 0.0121 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1324 - val_loss: 0.0083 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1010 - val_loss: 0.0072 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0847 - val_loss: 0.0094 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0811 - val_loss: 0.0044 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0657 - val_loss: 0.0094 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0654 - val_loss: 0.0067 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0678 - val_loss: 0.0092 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0657 - val_loss: 0.0041 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0547 - val_loss: 0.0017 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0363 - val_loss: 0.0011 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0395 - val_loss: 0.0040 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0392 - val_loss: 0.0022 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0239 - val_loss: -9.1682e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0275 - val_loss: -0.0014 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0308 - val_loss: -0.0011 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0271 - val_loss: -0.0015 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0186 - val_loss: -0.0019 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0352 - val_loss: -0.0020 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0164 - val_loss: -0.0031 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0130 - val_loss: -0.0035 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0240 - val_loss: -0.0015 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: -0.0048 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0096 - val_loss: -0.0066 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0120 - val_loss: -0.0101 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0186 - val_loss: -0.0125 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -5.8848e-04 - val_loss: -0.0145 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0113 - val_loss: -0.0140 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -5.8052e-04 - val_loss: -0.0188 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0017 - val_loss: -0.0219 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0112 - val_loss: -0.0290 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0026 - val_loss: -0.0344 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0118 - val_loss: -0.0417 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0289 - val_loss: -0.0529 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -0.0308 - val_loss: -0.0599 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -0.0347 - val_loss: -0.0696 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0508 - val_loss: -0.0844 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0583 - val_loss: -0.0948 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0629 - val_loss: -0.1143 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -0.0733 - val_loss: -0.1348 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0845 - val_loss: -0.1605 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1129 - val_loss: -0.1809 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -0.1071 - val_loss: -0.1995 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1249 - val_loss: -0.2437 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1601 - val_loss: -0.2692 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1803 - val_loss: -0.3096 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2157 - val_loss: -0.3368 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2289 - val_loss: -0.3724 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2423 - val_loss: -0.4198 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2826 - val_loss: -0.4545 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3049 - val_loss: -0.5094 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3175 - val_loss: -0.5550 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3625 - val_loss: -0.6040 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4004 - val_loss: -0.6568 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -0.4621 - val_loss: -0.7146 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4648 - val_loss: -0.7550 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.5080 - val_loss: -0.7925 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4917 - val_loss: -0.8437 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.5376 - val_loss: -0.8799 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.5864 - val_loss: -0.9308 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -0.6343 - val_loss: -0.9684 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.6147 - val_loss: -1.0169 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.6850 - val_loss: -1.0699 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.6776 - val_loss: -1.1086 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.7000 - val_loss: -1.1470 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.7120 - val_loss: -1.1884 - learning_rate: 1.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.7465 - val_loss: -1.2039 - learning_rate: 1.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.7652 - val_loss: -1.2602 - learning_rate: 1.0000e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.8293 - val_loss: -1.2868 - learning_rate: 1.0000e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.8054 - val_loss: -1.3202 - learning_rate: 1.0000e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.8441 - val_loss: -1.3378 - learning_rate: 1.0000e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.8558 - val_loss: -1.3868 - learning_rate: 1.0000e-04\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.8463 - val_loss: -1.3900 - learning_rate: 1.0000e-04\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.9007 - val_loss: -1.4186 - learning_rate: 1.0000e-04\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.8886 - val_loss: -1.4413 - learning_rate: 1.0000e-04\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -0.9162 - val_loss: -1.4556 - learning_rate: 1.0000e-04\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -0.9360 - val_loss: -1.4964 - learning_rate: 1.0000e-04\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.9442 - val_loss: -1.5087 - learning_rate: 1.0000e-04\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.9897 - val_loss: -1.5298 - learning_rate: 1.0000e-04\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.9815 - val_loss: -1.5465 - learning_rate: 1.0000e-04\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.9743 - val_loss: -1.5556 - learning_rate: 1.0000e-04\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.0392 - val_loss: -1.5795 - learning_rate: 1.0000e-04\n",
      "Epoch 86/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -1.0191 - val_loss: -1.5885 - learning_rate: 1.0000e-04\n",
      "Epoch 87/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -0.9775 - val_loss: -1.6049 - learning_rate: 1.0000e-04\n",
      "Epoch 88/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -1.0397 - val_loss: -1.6468 - learning_rate: 1.0000e-04\n",
      "Epoch 89/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -1.0269 - val_loss: -1.6311 - learning_rate: 1.0000e-04\n",
      "Epoch 90/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -1.1125 - val_loss: -1.6631 - learning_rate: 1.0000e-04\n",
      "Epoch 91/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.1122 - val_loss: -1.6857 - learning_rate: 1.0000e-04\n",
      "Epoch 92/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -1.1478 - val_loss: -1.6772 - learning_rate: 1.0000e-04\n",
      "Epoch 93/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.1068 - val_loss: -1.7146 - learning_rate: 1.0000e-04\n",
      "Epoch 94/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.1611 - val_loss: -1.7256 - learning_rate: 1.0000e-04\n",
      "Epoch 95/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.1597 - val_loss: -1.7490 - learning_rate: 1.0000e-04\n",
      "Epoch 96/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.2038 - val_loss: -1.7659 - learning_rate: 1.0000e-04\n",
      "Epoch 97/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.2019 - val_loss: -1.7304 - learning_rate: 1.0000e-04\n",
      "Epoch 98/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.1663 - val_loss: -1.7892 - learning_rate: 1.0000e-04\n",
      "Epoch 99/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.1576 - val_loss: -1.8269 - learning_rate: 1.0000e-04\n",
      "Epoch 100/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.2204 - val_loss: -1.8109 - learning_rate: 1.0000e-04\n",
      "Epoch 101/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.1879 - val_loss: -1.8410 - learning_rate: 1.0000e-04\n",
      "Epoch 102/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.3014 - val_loss: -1.8730 - learning_rate: 1.0000e-04\n",
      "Epoch 103/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.2617 - val_loss: -1.8837 - learning_rate: 1.0000e-04\n",
      "Epoch 104/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.2829 - val_loss: -1.9063 - learning_rate: 1.0000e-04\n",
      "Epoch 105/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.3122 - val_loss: -1.9071 - learning_rate: 1.0000e-04\n",
      "Epoch 106/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.3609 - val_loss: -1.9268 - learning_rate: 1.0000e-04\n",
      "Epoch 107/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.3644 - val_loss: -1.9395 - learning_rate: 1.0000e-04\n",
      "Epoch 108/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.3281 - val_loss: -1.9282 - learning_rate: 1.0000e-04\n",
      "Epoch 109/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.3550 - val_loss: -1.9604 - learning_rate: 1.0000e-04\n",
      "Epoch 110/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.3807 - val_loss: -1.9853 - learning_rate: 1.0000e-04\n",
      "Epoch 111/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.3890 - val_loss: -1.9692 - learning_rate: 1.0000e-04\n",
      "Epoch 112/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.3351 - val_loss: -1.9765 - learning_rate: 1.0000e-04\n",
      "Epoch 113/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.3684 - val_loss: -2.0265 - learning_rate: 1.0000e-04\n",
      "Epoch 114/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.3570 - val_loss: -1.9743 - learning_rate: 1.0000e-04\n",
      "Epoch 115/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.4135 - val_loss: -2.0294 - learning_rate: 1.0000e-04\n",
      "Epoch 116/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.3982 - val_loss: -2.0203 - learning_rate: 1.0000e-04\n",
      "Epoch 117/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.4194 - val_loss: -2.0949 - learning_rate: 1.0000e-04\n",
      "Epoch 118/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.4748 - val_loss: -2.1096 - learning_rate: 1.0000e-04\n",
      "Epoch 119/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.4524 - val_loss: -2.0783 - learning_rate: 1.0000e-04\n",
      "Epoch 120/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.5783 - val_loss: -2.1304 - learning_rate: 1.0000e-04\n",
      "Epoch 121/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.4449 - val_loss: -2.1108 - learning_rate: 1.0000e-04\n",
      "Epoch 122/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.4466 - val_loss: -2.1505 - learning_rate: 1.0000e-04\n",
      "Epoch 123/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.5488 - val_loss: -2.1552 - learning_rate: 1.0000e-04\n",
      "Epoch 124/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.5900 - val_loss: -2.1767 - learning_rate: 1.0000e-04\n",
      "Epoch 125/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.5340 - val_loss: -2.1898 - learning_rate: 1.0000e-04\n",
      "Epoch 126/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.5850 - val_loss: -2.2084 - learning_rate: 1.0000e-04\n",
      "Epoch 127/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.6281 - val_loss: -2.2001 - learning_rate: 1.0000e-04\n",
      "Epoch 128/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.6074 - val_loss: -2.1122 - learning_rate: 1.0000e-04\n",
      "Epoch 129/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.4849 - val_loss: -2.2078 - learning_rate: 1.0000e-04\n",
      "Epoch 130/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.5639 - val_loss: -2.2262 - learning_rate: 1.0000e-04\n",
      "Epoch 131/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -1.5583 - val_loss: -2.2113 - learning_rate: 1.0000e-04\n",
      "Epoch 132/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -1.5543 - val_loss: -2.2176 - learning_rate: 1.0000e-04\n",
      "Epoch 133/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.6179 - val_loss: -2.1974 - learning_rate: 1.0000e-04\n",
      "Epoch 134/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -1.6156 - val_loss: -2.2593 - learning_rate: 1.0000e-04\n",
      "Epoch 135/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -1.6705 - val_loss: -2.2015 - learning_rate: 1.0000e-04\n",
      "Epoch 136/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -1.6615 - val_loss: -2.2469 - learning_rate: 1.0000e-04\n",
      "Epoch 137/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -1.6459 - val_loss: -2.3347 - learning_rate: 1.0000e-04\n",
      "Epoch 138/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.6000 - val_loss: -2.3129 - learning_rate: 1.0000e-04\n",
      "Epoch 139/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -1.6504 - val_loss: -2.3280 - learning_rate: 1.0000e-04\n",
      "Epoch 140/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -1.6678 - val_loss: -2.3420 - learning_rate: 1.0000e-04\n",
      "Epoch 141/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -1.6272 - val_loss: -2.3119 - learning_rate: 1.0000e-04\n",
      "Epoch 142/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.7556 - val_loss: -2.2820 - learning_rate: 1.0000e-04\n",
      "Epoch 143/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.6665 - val_loss: -2.3592 - learning_rate: 1.0000e-04\n",
      "Epoch 144/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.6597 - val_loss: -2.3136 - learning_rate: 1.0000e-04\n",
      "Epoch 145/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.6788 - val_loss: -2.3516 - learning_rate: 1.0000e-04\n",
      "Epoch 146/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -1.7090 - val_loss: -2.3386 - learning_rate: 1.0000e-04\n",
      "Epoch 147/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.7407 - val_loss: -2.3300 - learning_rate: 1.0000e-04\n",
      "Epoch 148/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -1.6676 - val_loss: -2.3331 - learning_rate: 1.0000e-04\n",
      "Epoch 149/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.8183 - val_loss: -2.3631 - learning_rate: 5.0000e-05\n",
      "Epoch 150/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.7808 - val_loss: -2.3973 - learning_rate: 5.0000e-05\n",
      "Epoch 151/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -1.6258 - val_loss: -2.4036 - learning_rate: 5.0000e-05\n",
      "Epoch 152/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.7104 - val_loss: -2.3585 - learning_rate: 5.0000e-05\n",
      "Epoch 153/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.7200 - val_loss: -2.3540 - learning_rate: 5.0000e-05\n",
      "Epoch 154/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.7610 - val_loss: -2.4152 - learning_rate: 5.0000e-05\n",
      "Epoch 155/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.7683 - val_loss: -2.4222 - learning_rate: 5.0000e-05\n",
      "Epoch 156/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.7710 - val_loss: -2.4168 - learning_rate: 5.0000e-05\n",
      "Epoch 157/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.8947 - val_loss: -2.4161 - learning_rate: 5.0000e-05\n",
      "Epoch 158/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.7836 - val_loss: -2.4361 - learning_rate: 5.0000e-05\n",
      "Epoch 159/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -1.6592 - val_loss: -2.4467 - learning_rate: 5.0000e-05\n",
      "Epoch 160/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.8606 - val_loss: -2.4574 - learning_rate: 5.0000e-05\n",
      "Epoch 161/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.6968 - val_loss: -2.4447 - learning_rate: 5.0000e-05\n",
      "Epoch 162/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.7466 - val_loss: -2.4473 - learning_rate: 5.0000e-05\n",
      "Epoch 163/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.7334 - val_loss: -2.3889 - learning_rate: 5.0000e-05\n",
      "Epoch 164/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.8392 - val_loss: -2.4260 - learning_rate: 5.0000e-05\n",
      "Epoch 165/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.7889 - val_loss: -2.4577 - learning_rate: 5.0000e-05\n",
      "Epoch 166/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.7913 - val_loss: -2.4632 - learning_rate: 5.0000e-05\n",
      "Epoch 167/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.8428 - val_loss: -2.4662 - learning_rate: 5.0000e-05\n",
      "Epoch 168/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.6936 - val_loss: -2.4360 - learning_rate: 5.0000e-05\n",
      "Epoch 169/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.7543 - val_loss: -2.4480 - learning_rate: 5.0000e-05\n",
      "Epoch 170/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.8518 - val_loss: -2.4456 - learning_rate: 5.0000e-05\n",
      "Epoch 171/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.7503 - val_loss: -2.4093 - learning_rate: 5.0000e-05\n",
      "Epoch 172/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.8198 - val_loss: -2.3811 - learning_rate: 5.0000e-05\n",
      "Epoch 173/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -1.8859 - val_loss: -2.4670 - learning_rate: 2.5000e-05\n",
      "Epoch 174/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.8344 - val_loss: -2.4842 - learning_rate: 2.5000e-05\n",
      "Epoch 175/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.8865 - val_loss: -2.5014 - learning_rate: 2.5000e-05\n",
      "Epoch 176/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.8082 - val_loss: -2.4890 - learning_rate: 2.5000e-05\n",
      "Epoch 177/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.8033 - val_loss: -2.4865 - learning_rate: 2.5000e-05\n",
      "Epoch 178/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.8485 - val_loss: -2.5022 - learning_rate: 2.5000e-05\n",
      "Epoch 179/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -1.7842 - val_loss: -2.4918 - learning_rate: 2.5000e-05\n",
      "Epoch 180/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -1.9023 - val_loss: -2.5085 - learning_rate: 2.5000e-05\n",
      "Epoch 181/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -1.8011 - val_loss: -2.5165 - learning_rate: 2.5000e-05\n",
      "Epoch 182/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -1.8430 - val_loss: -2.4936 - learning_rate: 2.5000e-05\n",
      "Epoch 183/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.8656 - val_loss: -2.5175 - learning_rate: 2.5000e-05\n",
      "Epoch 184/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -1.8158 - val_loss: -2.5255 - learning_rate: 2.5000e-05\n",
      "Epoch 185/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.8069 - val_loss: -2.5229 - learning_rate: 2.5000e-05\n",
      "Epoch 186/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.8414 - val_loss: -2.5066 - learning_rate: 2.5000e-05\n",
      "Epoch 187/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -1.8637 - val_loss: -2.5094 - learning_rate: 2.5000e-05\n",
      "Epoch 188/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.9061 - val_loss: -2.4964 - learning_rate: 2.5000e-05\n",
      "Epoch 189/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.9628 - val_loss: -2.5204 - learning_rate: 2.5000e-05\n",
      "Epoch 190/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -1.8699 - val_loss: -2.5077 - learning_rate: 1.2500e-05\n",
      "Epoch 191/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.8145 - val_loss: -2.5168 - learning_rate: 1.2500e-05\n",
      "Epoch 192/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -1.7470 - val_loss: -2.5220 - learning_rate: 1.2500e-05\n",
      "Epoch 193/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.9262 - val_loss: -2.5258 - learning_rate: 1.2500e-05\n",
      "Epoch 194/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.8527 - val_loss: -2.5310 - learning_rate: 1.2500e-05\n",
      "Epoch 195/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -1.7763 - val_loss: -2.5191 - learning_rate: 1.2500e-05\n",
      "Epoch 196/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -1.8865 - val_loss: -2.5254 - learning_rate: 1.2500e-05\n",
      "Epoch 197/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.7869 - val_loss: -2.5166 - learning_rate: 1.2500e-05\n",
      "Epoch 198/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.9387 - val_loss: -2.5335 - learning_rate: 1.2500e-05\n",
      "Epoch 199/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -1.8192 - val_loss: -2.5329 - learning_rate: 1.2500e-05\n",
      "Epoch 200/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.8852 - val_loss: -2.5303 - learning_rate: 1.2500e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.7925 - val_loss: 0.0192 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3649 - val_loss: 0.0387 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2953 - val_loss: 0.0252 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2164 - val_loss: 0.0317 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1611 - val_loss: 0.0161 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1516 - val_loss: 0.0145 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1514 - val_loss: 0.0127 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0873 - val_loss: 0.0141 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0965 - val_loss: 0.0115 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0785 - val_loss: 0.0103 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0713 - val_loss: 0.0099 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0618 - val_loss: 0.0120 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0718 - val_loss: 0.0105 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0548 - val_loss: 0.0068 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0421 - val_loss: 0.0059 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0514 - val_loss: 0.0085 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0541 - val_loss: 0.0118 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0378 - val_loss: 0.0045 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0399 - val_loss: 0.0026 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0366 - val_loss: 0.0031 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0312 - val_loss: 0.0033 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0294 - val_loss: 0.0037 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0398 - val_loss: 0.0040 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0346 - val_loss: 0.0057 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0196 - val_loss: 0.0026 - learning_rate: 5.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0226 - val_loss: 0.0025 - learning_rate: 5.0000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0192 - val_loss: 9.3181e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0215 - val_loss: 0.0017 - learning_rate: 5.0000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0200 - val_loss: 0.0017 - learning_rate: 5.0000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0173 - val_loss: 0.0014 - learning_rate: 5.0000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0195 - val_loss: 0.0026 - learning_rate: 5.0000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0249 - val_loss: 0.0019 - learning_rate: 5.0000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0122 - val_loss: 0.0015 - learning_rate: 2.5000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0183 - val_loss: 0.0015 - learning_rate: 2.5000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0141 - val_loss: 0.0020 - learning_rate: 2.5000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0260 - val_loss: 0.0019 - learning_rate: 2.5000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0171 - val_loss: 0.0017 - learning_rate: 2.5000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.6532 - val_loss: 0.0276 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.4222 - val_loss: -0.0052 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2941 - val_loss: -0.0068 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2161 - val_loss: 8.1733e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1853 - val_loss: -0.0016 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1122 - val_loss: -0.0089 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0893 - val_loss: 0.0022 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0816 - val_loss: -0.0118 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0881 - val_loss: -0.0147 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0797 - val_loss: -0.0158 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0591 - val_loss: -0.0157 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0392 - val_loss: -0.0208 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0409 - val_loss: -0.0245 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0328 - val_loss: -0.0270 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0306 - val_loss: -0.0257 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0159 - val_loss: -0.0323 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0355 - val_loss: -0.0292 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0016 - val_loss: -0.0342 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0015 - val_loss: -0.0419 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 9.7028e-04 - val_loss: -0.0443 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0025 - val_loss: -0.0423 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -0.0028 - val_loss: -0.0360 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0079 - val_loss: -0.0507 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0237 - val_loss: -0.0539 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0095 - val_loss: -0.0515 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0269 - val_loss: -0.0606 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0069 - val_loss: -0.0566 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0398 - val_loss: -0.0608 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.0274 - val_loss: -0.0614 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0354 - val_loss: -0.0674 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0329 - val_loss: -0.0655 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0452 - val_loss: -0.0681 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0389 - val_loss: -0.0663 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -0.0362 - val_loss: -0.0692 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0469 - val_loss: -0.0727 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0484 - val_loss: -0.0774 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0392 - val_loss: -0.0764 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0507 - val_loss: -0.0785 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0476 - val_loss: -0.0796 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0616 - val_loss: -0.0836 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0526 - val_loss: -0.0841 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0326 - val_loss: -0.0870 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0500 - val_loss: -0.0866 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0545 - val_loss: -0.0868 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0575 - val_loss: -0.0887 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0655 - val_loss: -0.0914 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0584 - val_loss: -0.0964 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0770 - val_loss: -0.0949 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0681 - val_loss: -0.0952 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0698 - val_loss: -0.0998 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0666 - val_loss: -0.1003 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0809 - val_loss: -0.1062 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0710 - val_loss: -0.1096 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0781 - val_loss: -0.1080 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0718 - val_loss: -0.1162 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0807 - val_loss: -0.1192 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0789 - val_loss: -0.1195 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0767 - val_loss: -0.1258 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0853 - val_loss: -0.1261 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -0.0902 - val_loss: -0.1318 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0992 - val_loss: -0.1338 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0791 - val_loss: -0.1407 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0979 - val_loss: -0.1443 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -0.1091 - val_loss: -0.1521 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1047 - val_loss: -0.1587 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1004 - val_loss: -0.1660 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1233 - val_loss: -0.1741 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -0.1380 - val_loss: -0.1788 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -0.1287 - val_loss: -0.1868 - learning_rate: 1.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1387 - val_loss: -0.1946 - learning_rate: 1.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1249 - val_loss: -0.1984 - learning_rate: 1.0000e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1264 - val_loss: -0.2096 - learning_rate: 1.0000e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1551 - val_loss: -0.2189 - learning_rate: 1.0000e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1583 - val_loss: -0.2293 - learning_rate: 1.0000e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1319 - val_loss: -0.2352 - learning_rate: 1.0000e-04\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1500 - val_loss: -0.2415 - learning_rate: 1.0000e-04\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1686 - val_loss: -0.2544 - learning_rate: 1.0000e-04\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1638 - val_loss: -0.2597 - learning_rate: 1.0000e-04\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.1741 - val_loss: -0.2746 - learning_rate: 1.0000e-04\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.1901 - val_loss: -0.2811 - learning_rate: 1.0000e-04\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.1789 - val_loss: -0.2904 - learning_rate: 1.0000e-04\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.1886 - val_loss: -0.3077 - learning_rate: 1.0000e-04\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.1846 - val_loss: -0.3184 - learning_rate: 1.0000e-04\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2193 - val_loss: -0.3307 - learning_rate: 1.0000e-04\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2029 - val_loss: -0.3390 - learning_rate: 1.0000e-04\n",
      "Epoch 86/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2264 - val_loss: -0.3480 - learning_rate: 1.0000e-04\n",
      "Epoch 87/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2356 - val_loss: -0.3551 - learning_rate: 1.0000e-04\n",
      "Epoch 88/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2425 - val_loss: -0.3776 - learning_rate: 1.0000e-04\n",
      "Epoch 89/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2454 - val_loss: -0.3896 - learning_rate: 1.0000e-04\n",
      "Epoch 90/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2654 - val_loss: -0.4069 - learning_rate: 1.0000e-04\n",
      "Epoch 91/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2491 - val_loss: -0.4118 - learning_rate: 1.0000e-04\n",
      "Epoch 92/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2589 - val_loss: -0.4384 - learning_rate: 1.0000e-04\n",
      "Epoch 93/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2570 - val_loss: -0.4391 - learning_rate: 1.0000e-04\n",
      "Epoch 94/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2589 - val_loss: -0.4465 - learning_rate: 1.0000e-04\n",
      "Epoch 95/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2449 - val_loss: -0.4480 - learning_rate: 1.0000e-04\n",
      "Epoch 96/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2835 - val_loss: -0.4725 - learning_rate: 1.0000e-04\n",
      "Epoch 97/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2762 - val_loss: -0.4777 - learning_rate: 1.0000e-04\n",
      "Epoch 98/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3003 - val_loss: -0.4911 - learning_rate: 1.0000e-04\n",
      "Epoch 99/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3150 - val_loss: -0.5052 - learning_rate: 1.0000e-04\n",
      "Epoch 100/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3147 - val_loss: -0.5085 - learning_rate: 1.0000e-04\n",
      "Epoch 101/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3253 - val_loss: -0.5155 - learning_rate: 1.0000e-04\n",
      "Epoch 102/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3099 - val_loss: -0.5411 - learning_rate: 1.0000e-04\n",
      "Epoch 103/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3305 - val_loss: -0.5419 - learning_rate: 1.0000e-04\n",
      "Epoch 104/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3243 - val_loss: -0.5521 - learning_rate: 1.0000e-04\n",
      "Epoch 105/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3360 - val_loss: -0.5650 - learning_rate: 1.0000e-04\n",
      "Epoch 106/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3297 - val_loss: -0.5596 - learning_rate: 1.0000e-04\n",
      "Epoch 107/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3473 - val_loss: -0.5713 - learning_rate: 1.0000e-04\n",
      "Epoch 108/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3640 - val_loss: -0.5782 - learning_rate: 1.0000e-04\n",
      "Epoch 109/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3724 - val_loss: -0.5890 - learning_rate: 1.0000e-04\n",
      "Epoch 110/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3903 - val_loss: -0.5924 - learning_rate: 1.0000e-04\n",
      "Epoch 111/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3615 - val_loss: -0.6023 - learning_rate: 1.0000e-04\n",
      "Epoch 112/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -0.3538 - val_loss: -0.6077 - learning_rate: 1.0000e-04\n",
      "Epoch 113/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4067 - val_loss: -0.6078 - learning_rate: 1.0000e-04\n",
      "Epoch 114/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.3680 - val_loss: -0.6313 - learning_rate: 1.0000e-04\n",
      "Epoch 115/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.3860 - val_loss: -0.6206 - learning_rate: 1.0000e-04\n",
      "Epoch 116/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.4038 - val_loss: -0.6327 - learning_rate: 1.0000e-04\n",
      "Epoch 117/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3908 - val_loss: -0.6419 - learning_rate: 1.0000e-04\n",
      "Epoch 118/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.3852 - val_loss: -0.6297 - learning_rate: 1.0000e-04\n",
      "Epoch 119/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4155 - val_loss: -0.6444 - learning_rate: 1.0000e-04\n",
      "Epoch 120/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.4295 - val_loss: -0.6469 - learning_rate: 1.0000e-04\n",
      "Epoch 121/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.4068 - val_loss: -0.6338 - learning_rate: 1.0000e-04\n",
      "Epoch 122/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4548 - val_loss: -0.6649 - learning_rate: 1.0000e-04\n",
      "Epoch 123/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4050 - val_loss: -0.6658 - learning_rate: 1.0000e-04\n",
      "Epoch 124/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4128 - val_loss: -0.6728 - learning_rate: 1.0000e-04\n",
      "Epoch 125/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.4680 - val_loss: -0.6451 - learning_rate: 1.0000e-04\n",
      "Epoch 126/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4540 - val_loss: -0.6785 - learning_rate: 1.0000e-04\n",
      "Epoch 127/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4413 - val_loss: -0.6794 - learning_rate: 1.0000e-04\n",
      "Epoch 128/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4464 - val_loss: -0.6853 - learning_rate: 1.0000e-04\n",
      "Epoch 129/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.4866 - val_loss: -0.6866 - learning_rate: 1.0000e-04\n",
      "Epoch 130/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4610 - val_loss: -0.7028 - learning_rate: 1.0000e-04\n",
      "Epoch 131/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.4575 - val_loss: -0.6886 - learning_rate: 1.0000e-04\n",
      "Epoch 132/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.4500 - val_loss: -0.7067 - learning_rate: 1.0000e-04\n",
      "Epoch 133/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4626 - val_loss: -0.6950 - learning_rate: 1.0000e-04\n",
      "Epoch 134/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4398 - val_loss: -0.7128 - learning_rate: 1.0000e-04\n",
      "Epoch 135/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4662 - val_loss: -0.7028 - learning_rate: 1.0000e-04\n",
      "Epoch 136/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4842 - val_loss: -0.7131 - learning_rate: 1.0000e-04\n",
      "Epoch 137/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4776 - val_loss: -0.7088 - learning_rate: 1.0000e-04\n",
      "Epoch 138/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4997 - val_loss: -0.7373 - learning_rate: 1.0000e-04\n",
      "Epoch 139/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.5108 - val_loss: -0.7422 - learning_rate: 1.0000e-04\n",
      "Epoch 140/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.5096 - val_loss: -0.7406 - learning_rate: 1.0000e-04\n",
      "Epoch 141/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.5019 - val_loss: -0.7296 - learning_rate: 1.0000e-04\n",
      "Epoch 142/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.5183 - val_loss: -0.7346 - learning_rate: 1.0000e-04\n",
      "Epoch 143/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.4951 - val_loss: -0.7349 - learning_rate: 1.0000e-04\n",
      "Epoch 144/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.5643 - val_loss: -0.7217 - learning_rate: 1.0000e-04\n",
      "Epoch 145/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.5383 - val_loss: -0.7470 - learning_rate: 5.0000e-05\n",
      "Epoch 146/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.5424 - val_loss: -0.7401 - learning_rate: 5.0000e-05\n",
      "Epoch 147/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.5238 - val_loss: -0.7415 - learning_rate: 5.0000e-05\n",
      "Epoch 148/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.5185 - val_loss: -0.7414 - learning_rate: 5.0000e-05\n",
      "Epoch 149/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.5310 - val_loss: -0.7504 - learning_rate: 5.0000e-05\n",
      "Epoch 150/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.5296 - val_loss: -0.7553 - learning_rate: 5.0000e-05\n",
      "Epoch 151/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.5257 - val_loss: -0.7485 - learning_rate: 5.0000e-05\n",
      "Epoch 152/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.5428 - val_loss: -0.7510 - learning_rate: 5.0000e-05\n",
      "Epoch 153/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.5224 - val_loss: -0.7558 - learning_rate: 5.0000e-05\n",
      "Epoch 154/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.5713 - val_loss: -0.7522 - learning_rate: 5.0000e-05\n",
      "Epoch 155/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.5214 - val_loss: -0.7582 - learning_rate: 5.0000e-05\n",
      "Epoch 156/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.5204 - val_loss: -0.7565 - learning_rate: 5.0000e-05\n",
      "Epoch 157/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.5417 - val_loss: -0.7612 - learning_rate: 5.0000e-05\n",
      "Epoch 158/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.5275 - val_loss: -0.7582 - learning_rate: 5.0000e-05\n",
      "Epoch 159/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.5674 - val_loss: -0.7604 - learning_rate: 5.0000e-05\n",
      "Epoch 160/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.5484 - val_loss: -0.7589 - learning_rate: 5.0000e-05\n",
      "Epoch 161/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.5465 - val_loss: -0.7535 - learning_rate: 5.0000e-05\n",
      "Epoch 162/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.5725 - val_loss: -0.7648 - learning_rate: 5.0000e-05\n",
      "Epoch 163/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.5139 - val_loss: -0.7704 - learning_rate: 5.0000e-05\n",
      "Epoch 164/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.5505 - val_loss: -0.7675 - learning_rate: 5.0000e-05\n",
      "Epoch 165/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.5428 - val_loss: -0.7582 - learning_rate: 5.0000e-05\n",
      "Epoch 166/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -0.5435 - val_loss: -0.7593 - learning_rate: 5.0000e-05\n",
      "Epoch 167/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -0.5876 - val_loss: -0.7559 - learning_rate: 5.0000e-05\n",
      "Epoch 168/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -0.5207 - val_loss: -0.7696 - learning_rate: 5.0000e-05\n",
      "Epoch 169/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.5565 - val_loss: -0.7687 - learning_rate: 2.5000e-05\n",
      "Epoch 170/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.5562 - val_loss: -0.7727 - learning_rate: 2.5000e-05\n",
      "Epoch 171/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.5538 - val_loss: -0.7695 - learning_rate: 2.5000e-05\n",
      "Epoch 172/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -0.5396 - val_loss: -0.7697 - learning_rate: 2.5000e-05\n",
      "Epoch 173/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.5249 - val_loss: -0.7748 - learning_rate: 2.5000e-05\n",
      "Epoch 174/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.5344 - val_loss: -0.7701 - learning_rate: 2.5000e-05\n",
      "Epoch 175/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.5360 - val_loss: -0.7740 - learning_rate: 2.5000e-05\n",
      "Epoch 176/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.5615 - val_loss: -0.7712 - learning_rate: 2.5000e-05\n",
      "Epoch 177/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.5546 - val_loss: -0.7686 - learning_rate: 2.5000e-05\n",
      "Epoch 178/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -0.5685 - val_loss: -0.7684 - learning_rate: 2.5000e-05\n",
      "Epoch 179/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.5617 - val_loss: -0.7702 - learning_rate: 1.2500e-05\n",
      "Epoch 180/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.5660 - val_loss: -0.7721 - learning_rate: 1.2500e-05\n",
      "Epoch 181/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.5596 - val_loss: -0.7691 - learning_rate: 1.2500e-05\n",
      "Epoch 182/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.5353 - val_loss: -0.7697 - learning_rate: 1.2500e-05\n",
      "Epoch 183/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.5844 - val_loss: -0.7707 - learning_rate: 1.2500e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.6133 - val_loss: 0.0402 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3646 - val_loss: 0.0231 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2233 - val_loss: 0.0110 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1678 - val_loss: 0.0099 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1190 - val_loss: 0.0109 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1142 - val_loss: 0.0065 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0962 - val_loss: 0.0055 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0726 - val_loss: 0.0075 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0833 - val_loss: 0.0062 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0683 - val_loss: 0.0143 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0454 - val_loss: 0.0055 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0600 - val_loss: 0.0071 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0508 - val_loss: 0.0062 - learning_rate: 5.0000e-05\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0371 - val_loss: 0.0064 - learning_rate: 5.0000e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0342 - val_loss: 0.0057 - learning_rate: 5.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0448 - val_loss: 0.0043 - learning_rate: 5.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0352 - val_loss: 0.0038 - learning_rate: 5.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0411 - val_loss: 0.0048 - learning_rate: 5.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0252 - val_loss: 0.0053 - learning_rate: 5.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0292 - val_loss: 0.0047 - learning_rate: 5.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0331 - val_loss: 0.0036 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0303 - val_loss: 0.0039 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0233 - val_loss: 0.0036 - learning_rate: 5.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0189 - val_loss: 0.0036 - learning_rate: 5.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0296 - val_loss: 0.0035 - learning_rate: 5.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0231 - val_loss: 0.0043 - learning_rate: 5.0000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0268 - val_loss: 0.0046 - learning_rate: 5.0000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0217 - val_loss: 0.0044 - learning_rate: 5.0000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0151 - val_loss: 0.0033 - learning_rate: 5.0000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0206 - val_loss: 0.0041 - learning_rate: 5.0000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0333 - val_loss: 0.0042 - learning_rate: 5.0000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0156 - val_loss: 0.0040 - learning_rate: 5.0000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0251 - val_loss: 0.0046 - learning_rate: 5.0000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0226 - val_loss: 0.0042 - learning_rate: 5.0000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0173 - val_loss: 0.0036 - learning_rate: 2.5000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0225 - val_loss: 0.0035 - learning_rate: 2.5000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0159 - val_loss: 0.0037 - learning_rate: 2.5000e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0170 - val_loss: 0.0030 - learning_rate: 2.5000e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0206 - val_loss: 0.0030 - learning_rate: 2.5000e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0139 - val_loss: 0.0028 - learning_rate: 2.5000e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0188 - val_loss: 0.0027 - learning_rate: 2.5000e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0214 - val_loss: 0.0029 - learning_rate: 2.5000e-05\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0180 - val_loss: 0.0027 - learning_rate: 2.5000e-05\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0087 - val_loss: 0.0027 - learning_rate: 2.5000e-05\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0177 - val_loss: 0.0028 - learning_rate: 2.5000e-05\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0242 - val_loss: 0.0032 - learning_rate: 2.5000e-05\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0107 - val_loss: 0.0039 - learning_rate: 2.5000e-05\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0203 - val_loss: 0.0037 - learning_rate: 2.5000e-05\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0190 - val_loss: 0.0035 - learning_rate: 1.2500e-05\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0175 - val_loss: 0.0036 - learning_rate: 1.2500e-05\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0164 - val_loss: 0.0035 - learning_rate: 1.2500e-05\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0035 - learning_rate: 1.2500e-05\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0179 - val_loss: 0.0033 - learning_rate: 1.2500e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.9714 - val_loss: 0.0515 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.4815 - val_loss: 0.0516 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3333 - val_loss: 0.0254 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2371 - val_loss: 0.0247 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1444 - val_loss: 0.0218 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1325 - val_loss: 0.0230 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1003 - val_loss: 0.0136 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0929 - val_loss: 0.0136 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0826 - val_loss: 0.0149 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0648 - val_loss: 0.0097 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0599 - val_loss: 0.0109 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0678 - val_loss: 0.0079 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0676 - val_loss: 0.0082 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0667 - val_loss: 0.0066 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0523 - val_loss: 0.0059 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0466 - val_loss: 0.0086 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0441 - val_loss: 0.0058 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0345 - val_loss: 0.0063 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0456 - val_loss: 0.0072 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0305 - val_loss: 0.0056 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0235 - val_loss: 0.0039 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0326 - val_loss: 0.0043 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0231 - val_loss: 0.0078 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0274 - val_loss: 0.0039 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0311 - val_loss: 0.0038 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0287 - val_loss: 0.0033 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0245 - val_loss: 0.0042 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0225 - val_loss: 0.0059 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0198 - val_loss: 0.0044 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0277 - val_loss: 0.0050 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0133 - val_loss: 0.0049 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0196 - val_loss: 0.0034 - learning_rate: 5.0000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0118 - val_loss: 0.0041 - learning_rate: 5.0000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0176 - val_loss: 0.0033 - learning_rate: 5.0000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0180 - val_loss: 0.0034 - learning_rate: 5.0000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0160 - val_loss: 0.0038 - learning_rate: 5.0000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0216 - val_loss: 0.0037 - learning_rate: 2.5000e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0176 - val_loss: 0.0033 - learning_rate: 2.5000e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0182 - val_loss: 0.0033 - learning_rate: 2.5000e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0187 - val_loss: 0.0031 - learning_rate: 2.5000e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0128 - val_loss: 0.0030 - learning_rate: 2.5000e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0161 - val_loss: 0.0030 - learning_rate: 2.5000e-05\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0163 - val_loss: 0.0030 - learning_rate: 2.5000e-05\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0117 - val_loss: 0.0033 - learning_rate: 2.5000e-05\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0138 - val_loss: 0.0030 - learning_rate: 2.5000e-05\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0176 - val_loss: 0.0034 - learning_rate: 2.5000e-05\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0177 - val_loss: 0.0029 - learning_rate: 2.5000e-05\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0187 - val_loss: 0.0031 - learning_rate: 2.5000e-05\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0154 - val_loss: 0.0033 - learning_rate: 2.5000e-05\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0163 - val_loss: 0.0030 - learning_rate: 2.5000e-05\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0142 - val_loss: 0.0028 - learning_rate: 1.2500e-05\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0062 - val_loss: 0.0028 - learning_rate: 1.2500e-05\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0139 - val_loss: 0.0029 - learning_rate: 1.2500e-05\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0184 - val_loss: 0.0030 - learning_rate: 1.2500e-05\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0101 - val_loss: 0.0029 - learning_rate: 1.2500e-05\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0176 - val_loss: 0.0028 - learning_rate: 1.2500e-05\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0099 - val_loss: 0.0028 - learning_rate: 6.2500e-06\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0160 - val_loss: 0.0028 - learning_rate: 6.2500e-06\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0029 - learning_rate: 6.2500e-06\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0121 - val_loss: 0.0029 - learning_rate: 6.2500e-06\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0153 - val_loss: 0.0028 - learning_rate: 6.2500e-06\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0143 - val_loss: 0.0029 - learning_rate: 3.1250e-06\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0110 - val_loss: 0.0028 - learning_rate: 3.1250e-06\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0139 - val_loss: 0.0028 - learning_rate: 3.1250e-06\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0106 - val_loss: 0.0029 - learning_rate: 3.1250e-06\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0134 - val_loss: 0.0029 - learning_rate: 3.1250e-06\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0163 - val_loss: 0.0028 - learning_rate: 1.5625e-06\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0107 - val_loss: 0.0030 - learning_rate: 1.5625e-06\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.5046 - val_loss: 0.0209 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3488 - val_loss: 0.0116 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2596 - val_loss: 0.0184 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1912 - val_loss: 0.0266 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1460 - val_loss: 0.0125 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1327 - val_loss: 0.0122 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1158 - val_loss: 0.0222 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1004 - val_loss: 0.0140 - learning_rate: 5.0000e-05\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0749 - val_loss: 0.0113 - learning_rate: 5.0000e-05\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0816 - val_loss: 0.0086 - learning_rate: 5.0000e-05\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0792 - val_loss: 0.0102 - learning_rate: 5.0000e-05\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0663 - val_loss: 0.0100 - learning_rate: 5.0000e-05\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0777 - val_loss: 0.0088 - learning_rate: 5.0000e-05\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0629 - val_loss: 0.0126 - learning_rate: 5.0000e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0703 - val_loss: 0.0081 - learning_rate: 5.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0455 - val_loss: 0.0087 - learning_rate: 5.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0559 - val_loss: 0.0086 - learning_rate: 5.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0504 - val_loss: 0.0097 - learning_rate: 5.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0472 - val_loss: 0.0091 - learning_rate: 5.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0629 - val_loss: 0.0097 - learning_rate: 5.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0343 - val_loss: 0.0086 - learning_rate: 2.5000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0435 - val_loss: 0.0093 - learning_rate: 2.5000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0472 - val_loss: 0.0089 - learning_rate: 2.5000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0493 - val_loss: 0.0087 - learning_rate: 2.5000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0369 - val_loss: 0.0095 - learning_rate: 2.5000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.7983 - val_loss: 0.0244 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.5059 - val_loss: 0.0088 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2954 - val_loss: 0.0031 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1950 - val_loss: 0.0135 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1276 - val_loss: 0.0045 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1177 - val_loss: 0.0076 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0968 - val_loss: 0.0033 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0723 - val_loss: -0.0029 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1011 - val_loss: 0.0048 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0751 - val_loss: -0.0033 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0584 - val_loss: -0.0020 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0573 - val_loss: 9.9684e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0394 - val_loss: 0.0045 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0387 - val_loss: 0.0038 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0312 - val_loss: -0.0050 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0181 - val_loss: -0.0060 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0174 - val_loss: -0.0089 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0214 - val_loss: -0.0103 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0353 - val_loss: -0.0096 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0119 - val_loss: -0.0091 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0100 - val_loss: -0.0132 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0148 - val_loss: -0.0138 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0015 - val_loss: -0.0130 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 2.6100e-04 - val_loss: -0.0162 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.3927e-04 - val_loss: -0.0135 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0118 - val_loss: -0.0206 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0125 - val_loss: -0.0241 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0032 - val_loss: -0.0252 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0125 - val_loss: -0.0252 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0115 - val_loss: -0.0263 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0055 - val_loss: -0.0269 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0017 - val_loss: -0.0291 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0081 - val_loss: -0.0305 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0074 - val_loss: -0.0308 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0176 - val_loss: -0.0304 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0068 - val_loss: -0.0326 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0194 - val_loss: -0.0297 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0143 - val_loss: -0.0317 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0280 - val_loss: -0.0317 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0224 - val_loss: -0.0352 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0182 - val_loss: -0.0358 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0077 - val_loss: -0.0355 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0217 - val_loss: -0.0371 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0226 - val_loss: -0.0375 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0222 - val_loss: -0.0384 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0336 - val_loss: -0.0354 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0182 - val_loss: -0.0378 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0317 - val_loss: -0.0411 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0338 - val_loss: -0.0388 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0350 - val_loss: -0.0408 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0308 - val_loss: -0.0396 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0403 - val_loss: -0.0435 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0473 - val_loss: -0.0431 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0303 - val_loss: -0.0431 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0296 - val_loss: -0.0437 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0288 - val_loss: -0.0401 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0362 - val_loss: -0.0419 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0404 - val_loss: -0.0441 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0459 - val_loss: -0.0448 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0296 - val_loss: -0.0459 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0332 - val_loss: -0.0480 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0455 - val_loss: -0.0468 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0467 - val_loss: -0.0445 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0453 - val_loss: -0.0502 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0371 - val_loss: -0.0517 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0452 - val_loss: -0.0543 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0401 - val_loss: -0.0538 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0544 - val_loss: -0.0553 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0584 - val_loss: -0.0550 - learning_rate: 1.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0508 - val_loss: -0.0594 - learning_rate: 1.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0413 - val_loss: -0.0637 - learning_rate: 1.0000e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0692 - val_loss: -0.0635 - learning_rate: 1.0000e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0532 - val_loss: -0.0646 - learning_rate: 1.0000e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0669 - val_loss: -0.0635 - learning_rate: 1.0000e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0539 - val_loss: -0.0667 - learning_rate: 1.0000e-04\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0665 - val_loss: -0.0683 - learning_rate: 1.0000e-04\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0632 - val_loss: -0.0653 - learning_rate: 1.0000e-04\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0656 - val_loss: -0.0688 - learning_rate: 1.0000e-04\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0688 - val_loss: -0.0719 - learning_rate: 1.0000e-04\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0664 - val_loss: -0.0767 - learning_rate: 1.0000e-04\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0857 - val_loss: -0.0706 - learning_rate: 1.0000e-04\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0693 - val_loss: -0.0825 - learning_rate: 1.0000e-04\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0751 - val_loss: -0.0849 - learning_rate: 1.0000e-04\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0884 - val_loss: -0.0926 - learning_rate: 1.0000e-04\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1050 - val_loss: -0.1006 - learning_rate: 1.0000e-04\n",
      "Epoch 86/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0845 - val_loss: -0.1018 - learning_rate: 1.0000e-04\n",
      "Epoch 87/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.1031 - val_loss: -0.1040 - learning_rate: 1.0000e-04\n",
      "Epoch 88/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1055 - val_loss: -0.1094 - learning_rate: 1.0000e-04\n",
      "Epoch 89/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1117 - val_loss: -0.1190 - learning_rate: 1.0000e-04\n",
      "Epoch 90/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0894 - val_loss: -0.1290 - learning_rate: 1.0000e-04\n",
      "Epoch 91/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1093 - val_loss: -0.1323 - learning_rate: 1.0000e-04\n",
      "Epoch 92/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1141 - val_loss: -0.1397 - learning_rate: 1.0000e-04\n",
      "Epoch 93/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1244 - val_loss: -0.1420 - learning_rate: 1.0000e-04\n",
      "Epoch 94/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1112 - val_loss: -0.1559 - learning_rate: 1.0000e-04\n",
      "Epoch 95/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1148 - val_loss: -0.1575 - learning_rate: 1.0000e-04\n",
      "Epoch 96/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1345 - val_loss: -0.1682 - learning_rate: 1.0000e-04\n",
      "Epoch 97/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1443 - val_loss: -0.1739 - learning_rate: 1.0000e-04\n",
      "Epoch 98/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1290 - val_loss: -0.1805 - learning_rate: 1.0000e-04\n",
      "Epoch 99/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1517 - val_loss: -0.1859 - learning_rate: 1.0000e-04\n",
      "Epoch 100/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1633 - val_loss: -0.1964 - learning_rate: 1.0000e-04\n",
      "Epoch 101/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1694 - val_loss: -0.2065 - learning_rate: 1.0000e-04\n",
      "Epoch 102/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1582 - val_loss: -0.2190 - learning_rate: 1.0000e-04\n",
      "Epoch 103/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1922 - val_loss: -0.2381 - learning_rate: 1.0000e-04\n",
      "Epoch 104/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2016 - val_loss: -0.2472 - learning_rate: 1.0000e-04\n",
      "Epoch 105/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2020 - val_loss: -0.2657 - learning_rate: 1.0000e-04\n",
      "Epoch 106/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2005 - val_loss: -0.2682 - learning_rate: 1.0000e-04\n",
      "Epoch 107/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1937 - val_loss: -0.2817 - learning_rate: 1.0000e-04\n",
      "Epoch 108/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2106 - val_loss: -0.2962 - learning_rate: 1.0000e-04\n",
      "Epoch 109/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2306 - val_loss: -0.3132 - learning_rate: 1.0000e-04\n",
      "Epoch 110/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2411 - val_loss: -0.3291 - learning_rate: 1.0000e-04\n",
      "Epoch 111/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2452 - val_loss: -0.3376 - learning_rate: 1.0000e-04\n",
      "Epoch 112/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2380 - val_loss: -0.3569 - learning_rate: 1.0000e-04\n",
      "Epoch 113/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2787 - val_loss: -0.3562 - learning_rate: 1.0000e-04\n",
      "Epoch 114/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2478 - val_loss: -0.3832 - learning_rate: 1.0000e-04\n",
      "Epoch 115/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2675 - val_loss: -0.3939 - learning_rate: 1.0000e-04\n",
      "Epoch 116/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2820 - val_loss: -0.4002 - learning_rate: 1.0000e-04\n",
      "Epoch 117/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2833 - val_loss: -0.4159 - learning_rate: 1.0000e-04\n",
      "Epoch 118/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3003 - val_loss: -0.4138 - learning_rate: 1.0000e-04\n",
      "Epoch 119/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3026 - val_loss: -0.4329 - learning_rate: 1.0000e-04\n",
      "Epoch 120/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3113 - val_loss: -0.4471 - learning_rate: 1.0000e-04\n",
      "Epoch 121/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3315 - val_loss: -0.4644 - learning_rate: 1.0000e-04\n",
      "Epoch 122/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3326 - val_loss: -0.4847 - learning_rate: 1.0000e-04\n",
      "Epoch 123/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.3517 - val_loss: -0.4857 - learning_rate: 1.0000e-04\n",
      "Epoch 124/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3422 - val_loss: -0.4869 - learning_rate: 1.0000e-04\n",
      "Epoch 125/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3675 - val_loss: -0.5117 - learning_rate: 1.0000e-04\n",
      "Epoch 126/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3863 - val_loss: -0.5147 - learning_rate: 1.0000e-04\n",
      "Epoch 127/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3805 - val_loss: -0.5108 - learning_rate: 1.0000e-04\n",
      "Epoch 128/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3687 - val_loss: -0.5268 - learning_rate: 1.0000e-04\n",
      "Epoch 129/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4069 - val_loss: -0.5281 - learning_rate: 1.0000e-04\n",
      "Epoch 130/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3942 - val_loss: -0.5332 - learning_rate: 1.0000e-04\n",
      "Epoch 131/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3750 - val_loss: -0.5256 - learning_rate: 1.0000e-04\n",
      "Epoch 132/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.3888 - val_loss: -0.5410 - learning_rate: 1.0000e-04\n",
      "Epoch 133/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3873 - val_loss: -0.5292 - learning_rate: 1.0000e-04\n",
      "Epoch 134/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.4098 - val_loss: -0.5550 - learning_rate: 1.0000e-04\n",
      "Epoch 135/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.3845 - val_loss: -0.5499 - learning_rate: 1.0000e-04\n",
      "Epoch 136/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3998 - val_loss: -0.5716 - learning_rate: 1.0000e-04\n",
      "Epoch 137/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4166 - val_loss: -0.5520 - learning_rate: 1.0000e-04\n",
      "Epoch 138/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3818 - val_loss: -0.5746 - learning_rate: 1.0000e-04\n",
      "Epoch 139/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4349 - val_loss: -0.5416 - learning_rate: 1.0000e-04\n",
      "Epoch 140/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4280 - val_loss: -0.5700 - learning_rate: 1.0000e-04\n",
      "Epoch 141/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4379 - val_loss: -0.5519 - learning_rate: 1.0000e-04\n",
      "Epoch 142/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4215 - val_loss: -0.5653 - learning_rate: 1.0000e-04\n",
      "Epoch 143/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4542 - val_loss: -0.5801 - learning_rate: 1.0000e-04\n",
      "Epoch 144/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4464 - val_loss: -0.5561 - learning_rate: 1.0000e-04\n",
      "Epoch 145/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4356 - val_loss: -0.5757 - learning_rate: 1.0000e-04\n",
      "Epoch 146/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.4390 - val_loss: -0.5773 - learning_rate: 1.0000e-04\n",
      "Epoch 147/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.4599 - val_loss: -0.5795 - learning_rate: 1.0000e-04\n",
      "Epoch 148/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4350 - val_loss: -0.5698 - learning_rate: 1.0000e-04\n",
      "Epoch 149/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4575 - val_loss: -0.5881 - learning_rate: 5.0000e-05\n",
      "Epoch 150/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4693 - val_loss: -0.5777 - learning_rate: 5.0000e-05\n",
      "Epoch 151/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4620 - val_loss: -0.5843 - learning_rate: 5.0000e-05\n",
      "Epoch 152/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4645 - val_loss: -0.5885 - learning_rate: 5.0000e-05\n",
      "Epoch 153/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4289 - val_loss: -0.5900 - learning_rate: 5.0000e-05\n",
      "Epoch 154/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4430 - val_loss: -0.5792 - learning_rate: 5.0000e-05\n",
      "Epoch 155/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4814 - val_loss: -0.5820 - learning_rate: 5.0000e-05\n",
      "Epoch 156/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4681 - val_loss: -0.5910 - learning_rate: 5.0000e-05\n",
      "Epoch 157/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4657 - val_loss: -0.5922 - learning_rate: 5.0000e-05\n",
      "Epoch 158/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4726 - val_loss: -0.5749 - learning_rate: 5.0000e-05\n",
      "Epoch 159/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4433 - val_loss: -0.5864 - learning_rate: 5.0000e-05\n",
      "Epoch 160/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4532 - val_loss: -0.5896 - learning_rate: 5.0000e-05\n",
      "Epoch 161/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4781 - val_loss: -0.5939 - learning_rate: 5.0000e-05\n",
      "Epoch 162/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4572 - val_loss: -0.5935 - learning_rate: 5.0000e-05\n",
      "Epoch 163/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4663 - val_loss: -0.5864 - learning_rate: 5.0000e-05\n",
      "Epoch 164/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4954 - val_loss: -0.5894 - learning_rate: 5.0000e-05\n",
      "Epoch 165/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4698 - val_loss: -0.5956 - learning_rate: 5.0000e-05\n",
      "Epoch 166/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4501 - val_loss: -0.5861 - learning_rate: 5.0000e-05\n",
      "Epoch 167/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4724 - val_loss: -0.5888 - learning_rate: 5.0000e-05\n",
      "Epoch 168/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4970 - val_loss: -0.5881 - learning_rate: 5.0000e-05\n",
      "Epoch 169/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4944 - val_loss: -0.5892 - learning_rate: 5.0000e-05\n",
      "Epoch 170/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4811 - val_loss: -0.5869 - learning_rate: 5.0000e-05\n",
      "Epoch 171/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.5038 - val_loss: -0.5884 - learning_rate: 2.5000e-05\n",
      "Epoch 172/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.5042 - val_loss: -0.5931 - learning_rate: 2.5000e-05\n",
      "Epoch 173/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4623 - val_loss: -0.5938 - learning_rate: 2.5000e-05\n",
      "Epoch 174/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4552 - val_loss: -0.5941 - learning_rate: 2.5000e-05\n",
      "Epoch 175/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.4890 - val_loss: -0.5905 - learning_rate: 2.5000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.6127 - val_loss: 0.0493 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3202 - val_loss: 0.0190 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2265 - val_loss: 0.0123 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1752 - val_loss: 0.0150 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1360 - val_loss: 0.0139 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1133 - val_loss: 0.0086 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1195 - val_loss: 0.0030 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0965 - val_loss: 0.0065 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0778 - val_loss: 0.0038 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0696 - val_loss: 0.0045 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0599 - val_loss: 0.0056 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0575 - val_loss: 0.0158 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0508 - val_loss: 0.0055 - learning_rate: 5.0000e-05\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0581 - val_loss: 0.0056 - learning_rate: 5.0000e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0346 - val_loss: 0.0053 - learning_rate: 5.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0311 - val_loss: 0.0068 - learning_rate: 5.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0345 - val_loss: 0.0081 - learning_rate: 5.0000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.6618 - val_loss: 0.0235 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3827 - val_loss: 0.0190 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2540 - val_loss: 0.0106 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1871 - val_loss: 0.0098 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1633 - val_loss: 0.0075 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1137 - val_loss: 0.0088 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1007 - val_loss: 0.0058 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0820 - val_loss: 0.0049 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0951 - val_loss: 0.0068 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0708 - val_loss: 0.0025 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0740 - val_loss: 0.0120 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0508 - val_loss: 0.0033 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0810 - val_loss: 0.0029 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0561 - val_loss: 0.0035 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0570 - val_loss: 0.0024 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0299 - val_loss: 8.9613e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0376 - val_loss: 0.0020 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0416 - val_loss: 0.0045 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0467 - val_loss: 0.0028 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0272 - val_loss: 0.0014 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0363 - val_loss: 0.0065 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0209 - val_loss: 0.0012 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0314 - val_loss: 0.0021 - learning_rate: 5.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0240 - val_loss: 0.0013 - learning_rate: 5.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0264 - val_loss: 0.0012 - learning_rate: 5.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0226 - val_loss: 0.0043 - learning_rate: 5.0000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 1.3120 - val_loss: 0.0578 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.4558 - val_loss: 0.0258 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3107 - val_loss: 0.0145 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2339 - val_loss: 0.0159 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1559 - val_loss: 0.0133 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1182 - val_loss: 0.0092 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1021 - val_loss: 0.0071 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0793 - val_loss: 0.0064 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0696 - val_loss: 0.0106 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0842 - val_loss: 0.0057 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0746 - val_loss: 0.0047 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0725 - val_loss: 0.0046 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0483 - val_loss: 0.0023 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0508 - val_loss: 0.0028 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0314 - val_loss: 0.0055 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0477 - val_loss: 0.0096 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0544 - val_loss: 0.0040 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0362 - val_loss: 0.0053 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0374 - val_loss: 0.0032 - learning_rate: 5.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0311 - val_loss: 0.0026 - learning_rate: 5.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0330 - val_loss: 0.0028 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0375 - val_loss: 0.0031 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0231 - val_loss: 0.0031 - learning_rate: 5.0000e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 zmiennych na podstawie CMI: [11  7 13  6 17  5 20  8  2  3]\n",
      "Top 10 zmiennych na podstawie LASSO: [13  6 17  5 12  4  2  8  7 20]\n",
      "Liczba odwróconych par: 78\n",
      "Top 10 agreement score: 0.8\n",
      "Top 5 agreement score: 0.6\n"
     ]
    }
   ],
   "source": [
    "#est1\n",
    "\n",
    "cmi_scores = []\n",
    "for i in range(X.shape[1]):\n",
    "    # Zmienna Z to wszystkie cechy oprócz jednej\n",
    "    Z = np.delete(X, i, axis=1)\n",
    "    cmi_scores.append(est1(X[:, i].reshape(-1, 1), Y, Z))\n",
    "\n",
    "cmi_ranking = np.argsort(cmi_scores)[::-1]\n",
    "\n",
    "# Wizualizacja rankingów\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "plt.bar(range(1, n_features + 1), np.array(cmi_scores)[cmi_ranking], tick_label=cmi_ranking + 1)\n",
    "plt.title(\"CMI Ranking\")\n",
    "plt.xlabel(\"Feature Index\")\n",
    "plt.ylabel(\"Conditional Mutual Information\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(range(1, n_features + 1), np.array(lasso_importances)[lasso_ranking], tick_label=lasso_ranking + 1)\n",
    "plt.title(\"LASSO Ranking\")\n",
    "plt.xlabel(\"Feature Index\")\n",
    "plt.ylabel(\"LASSO Coefficients\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Wyświetlanie top 10 zmiennych\n",
    "print(\"Top 10 zmiennych na podstawie CMI:\", cmi_ranking[:10] + 1)\n",
    "print(\"Top 10 zmiennych na podstawie LASSO:\", lasso_ranking[:10] + 1)\n",
    "\n",
    "\n",
    "# Liczenie liczby odwróconych par\n",
    "inversions = count_inversions(cmi_ranking, lasso_ranking)\n",
    "print(f\"Liczba odwróconych par: {inversions}\")\n",
    "\n",
    "# Liczenie liczby przypadków, w których top 10 zmiennych się pokrywają\n",
    "top_k_agreement_10 = top_k_agreement(cmi_ranking, lasso_ranking, 10)\n",
    "top_k_agreement_5 = top_k_agreement(cmi_ranking, lasso_ranking, 5)\n",
    "\n",
    "print(f\"Top 10 agreement score: {top_k_agreement_10}\")\n",
    "print(f\"Top 5 agreement score: {top_k_agreement_5}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.5741 - val_loss: -0.0011 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3015 - val_loss: -0.0147 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1816 - val_loss: -0.0302 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1309 - val_loss: -0.0447 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1046 - val_loss: -0.0468 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0767 - val_loss: -0.0796 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0436 - val_loss: -0.0935 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0237 - val_loss: -0.1229 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.0068 - val_loss: -0.1484 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.0439 - val_loss: -0.1869 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.0455 - val_loss: -0.2254 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.0815 - val_loss: -0.2626 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.1069 - val_loss: -0.2869 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.1485 - val_loss: -0.3199 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.1490 - val_loss: -0.3415 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.1724 - val_loss: -0.3745 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.2184 - val_loss: -0.4054 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.2549 - val_loss: -0.4349 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.2533 - val_loss: -0.4662 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.2919 - val_loss: -0.4954 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.3446 - val_loss: -0.5391 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.3436 - val_loss: -0.5620 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.3360 - val_loss: -0.5960 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3585 - val_loss: -0.6415 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.4149 - val_loss: -0.6739 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.4615 - val_loss: -0.7132 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.4578 - val_loss: -0.7475 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.4677 - val_loss: -0.7872 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5695 - val_loss: -0.8259 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.6069 - val_loss: -0.8429 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6429 - val_loss: -0.8883 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6470 - val_loss: -0.8948 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6395 - val_loss: -0.9300 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.6563 - val_loss: -0.9594 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7109 - val_loss: -0.9996 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.7532 - val_loss: -1.0258 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.7779 - val_loss: -1.0358 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -0.7782 - val_loss: -1.0443 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -0.7675 - val_loss: -1.0677 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7698 - val_loss: -1.0988 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.8794 - val_loss: -1.0963 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.8328 - val_loss: -1.1310 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.8545 - val_loss: -1.1563 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.9399 - val_loss: -1.1360 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.8750 - val_loss: -1.1503 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.8856 - val_loss: -1.1959 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.9346 - val_loss: -1.1836 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.9668 - val_loss: -1.1767 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.9207 - val_loss: -1.1793 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.9348 - val_loss: -1.2278 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.9724 - val_loss: -1.2121 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.9710 - val_loss: -1.2400 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.0404 - val_loss: -1.2637 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.9740 - val_loss: -1.2182 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.0907 - val_loss: -1.2487 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.9775 - val_loss: -1.2246 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -1.0462 - val_loss: -1.2667 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.0212 - val_loss: -1.2405 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.0437 - val_loss: -1.2759 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.0585 - val_loss: -1.2887 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.9928 - val_loss: -1.2785 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.0960 - val_loss: -1.2879 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -1.0750 - val_loss: -1.2780 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -1.1009 - val_loss: -1.3014 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.0783 - val_loss: -1.3118 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -1.0514 - val_loss: -1.2449 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.0925 - val_loss: -1.2867 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.0879 - val_loss: -1.2887 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.1872 - val_loss: -1.3079 - learning_rate: 1.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -1.1718 - val_loss: -1.2818 - learning_rate: 1.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.0912 - val_loss: -1.2795 - learning_rate: 5.0000e-05\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.1382 - val_loss: -1.3051 - learning_rate: 5.0000e-05\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.0834 - val_loss: -1.3158 - learning_rate: 5.0000e-05\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.1181 - val_loss: -1.3037 - learning_rate: 5.0000e-05\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.1384 - val_loss: -1.3080 - learning_rate: 5.0000e-05\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.1447 - val_loss: -1.3030 - learning_rate: 5.0000e-05\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -1.1669 - val_loss: -1.3136 - learning_rate: 5.0000e-05\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.1194 - val_loss: -1.2933 - learning_rate: 5.0000e-05\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.1774 - val_loss: -1.2796 - learning_rate: 2.5000e-05\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.1171 - val_loss: -1.3176 - learning_rate: 2.5000e-05\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -1.1111 - val_loss: -1.3085 - learning_rate: 2.5000e-05\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.1486 - val_loss: -1.3037 - learning_rate: 2.5000e-05\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.2203 - val_loss: -1.2968 - learning_rate: 2.5000e-05\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.1936 - val_loss: -1.3021 - learning_rate: 2.5000e-05\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.1649 - val_loss: -1.3202 - learning_rate: 2.5000e-05\n",
      "Epoch 86/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.1288 - val_loss: -1.3278 - learning_rate: 2.5000e-05\n",
      "Epoch 87/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.1099 - val_loss: -1.3270 - learning_rate: 2.5000e-05\n",
      "Epoch 88/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.0904 - val_loss: -1.3270 - learning_rate: 2.5000e-05\n",
      "Epoch 89/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.1287 - val_loss: -1.3342 - learning_rate: 2.5000e-05\n",
      "Epoch 90/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.0882 - val_loss: -1.3222 - learning_rate: 2.5000e-05\n",
      "Epoch 91/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -1.1499 - val_loss: -1.3242 - learning_rate: 2.5000e-05\n",
      "Epoch 92/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -1.1208 - val_loss: -1.3082 - learning_rate: 2.5000e-05\n",
      "Epoch 93/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.1721 - val_loss: -1.3047 - learning_rate: 2.5000e-05\n",
      "Epoch 94/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.1189 - val_loss: -1.3178 - learning_rate: 2.5000e-05\n",
      "Epoch 95/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.0626 - val_loss: -1.3253 - learning_rate: 1.2500e-05\n",
      "Epoch 96/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -1.1906 - val_loss: -1.3231 - learning_rate: 1.2500e-05\n",
      "Epoch 97/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -1.2069 - val_loss: -1.3207 - learning_rate: 1.2500e-05\n",
      "Epoch 98/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.1356 - val_loss: -1.3211 - learning_rate: 1.2500e-05\n",
      "Epoch 99/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -1.1713 - val_loss: -1.3282 - learning_rate: 1.2500e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.5430 - val_loss: 0.0471 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3642 - val_loss: 0.0247 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.2600 - val_loss: 0.0192 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.1882 - val_loss: 0.0232 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.1510 - val_loss: 0.0140 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.1209 - val_loss: 0.0122 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1127 - val_loss: 0.0079 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0899 - val_loss: 0.0088 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0816 - val_loss: 0.0109 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0630 - val_loss: 0.0113 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0728 - val_loss: 0.0121 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0573 - val_loss: 0.0061 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0566 - val_loss: 0.0195 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0518 - val_loss: 0.0046 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0413 - val_loss: 0.0122 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0564 - val_loss: 0.0234 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0436 - val_loss: 0.0056 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0405 - val_loss: 0.0075 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0454 - val_loss: 0.0052 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0284 - val_loss: 0.0090 - learning_rate: 5.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0346 - val_loss: 0.0056 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0230 - val_loss: 0.0057 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0277 - val_loss: 0.0062 - learning_rate: 5.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0249 - val_loss: 0.0036 - learning_rate: 5.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0180 - val_loss: 0.0079 - learning_rate: 5.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0168 - val_loss: 0.0059 - learning_rate: 5.0000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0235 - val_loss: 0.0084 - learning_rate: 5.0000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0266 - val_loss: 0.0026 - learning_rate: 5.0000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0324 - val_loss: 0.0049 - learning_rate: 5.0000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0210 - val_loss: 0.0054 - learning_rate: 5.0000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0155 - val_loss: 0.0031 - learning_rate: 5.0000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0269 - val_loss: 0.0027 - learning_rate: 5.0000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0219 - val_loss: 0.0027 - learning_rate: 5.0000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0140 - val_loss: 0.0035 - learning_rate: 2.5000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0220 - val_loss: 0.0024 - learning_rate: 2.5000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0224 - val_loss: 0.0026 - learning_rate: 2.5000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0184 - val_loss: 0.0035 - learning_rate: 2.5000e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0206 - val_loss: 0.0028 - learning_rate: 2.5000e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0189 - val_loss: 0.0030 - learning_rate: 2.5000e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0159 - val_loss: 0.0019 - learning_rate: 2.5000e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0219 - val_loss: 0.0028 - learning_rate: 2.5000e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0144 - val_loss: 0.0030 - learning_rate: 2.5000e-05\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0195 - val_loss: 0.0034 - learning_rate: 2.5000e-05\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0145 - val_loss: 0.0027 - learning_rate: 2.5000e-05\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0125 - val_loss: 0.0022 - learning_rate: 2.5000e-05\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0128 - val_loss: 0.0022 - learning_rate: 1.2500e-05\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0115 - val_loss: 0.0022 - learning_rate: 1.2500e-05\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0174 - val_loss: 0.0024 - learning_rate: 1.2500e-05\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0151 - val_loss: 0.0023 - learning_rate: 1.2500e-05\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0130 - val_loss: 0.0026 - learning_rate: 1.2500e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 0.7235 - val_loss: 0.0832 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.4032 - val_loss: 0.0499 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.2765 - val_loss: 0.0301 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.2095 - val_loss: 0.0074 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1445 - val_loss: 0.0043 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1101 - val_loss: -0.0091 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1112 - val_loss: -0.0173 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0730 - val_loss: -0.0349 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0540 - val_loss: -0.0597 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0368 - val_loss: -0.0785 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0078 - val_loss: -0.1034 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.0130 - val_loss: -0.1285 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0316 - val_loss: -0.1488 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.0409 - val_loss: -0.1636 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.0523 - val_loss: -0.1900 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.1013 - val_loss: -0.2201 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.1234 - val_loss: -0.2322 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.1464 - val_loss: -0.2628 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.1463 - val_loss: -0.2838 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.1723 - val_loss: -0.3040 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.1992 - val_loss: -0.3353 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.2036 - val_loss: -0.3613 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.2348 - val_loss: -0.3970 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.2349 - val_loss: -0.4162 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.2927 - val_loss: -0.4500 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.2861 - val_loss: -0.4946 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.3174 - val_loss: -0.5203 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3446 - val_loss: -0.5627 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3789 - val_loss: -0.6180 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.3953 - val_loss: -0.6533 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.4036 - val_loss: -0.6782 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.4409 - val_loss: -0.7422 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.4643 - val_loss: -0.7748 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.4736 - val_loss: -0.8071 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.5245 - val_loss: -0.8455 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.5469 - val_loss: -0.8831 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: -0.5783 - val_loss: -0.9162 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.5618 - val_loss: -0.9385 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.5733 - val_loss: -0.9868 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.6649 - val_loss: -1.0084 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: -0.6635 - val_loss: -1.0405 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.6448 - val_loss: -1.0660 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.6910 - val_loss: -1.0985 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.7147 - val_loss: -1.1254 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.7346 - val_loss: -1.1364 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.7456 - val_loss: -1.1730 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.7338 - val_loss: -1.1874 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.7524 - val_loss: -1.2029 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.7430 - val_loss: -1.2299 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.7923 - val_loss: -1.2394 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.7870 - val_loss: -1.2180 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.7610 - val_loss: -1.2885 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.8423 - val_loss: -1.2875 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.8175 - val_loss: -1.3038 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.7966 - val_loss: -1.3217 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: -0.8492 - val_loss: -1.2820 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.8429 - val_loss: -1.2991 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.8962 - val_loss: -1.3162 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.8730 - val_loss: -1.3402 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.8617 - val_loss: -1.3384 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.8874 - val_loss: -1.3567 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9503 - val_loss: -1.3709 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.9201 - val_loss: -1.3671 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: -0.8706 - val_loss: -1.3803 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.8798 - val_loss: -1.3792 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.9353 - val_loss: -1.3959 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.9389 - val_loss: -1.4057 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.9863 - val_loss: -1.4002 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.9565 - val_loss: -1.4297 - learning_rate: 1.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.9589 - val_loss: -1.4165 - learning_rate: 1.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.9983 - val_loss: -1.4179 - learning_rate: 1.0000e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -1.0013 - val_loss: -1.4258 - learning_rate: 1.0000e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.9465 - val_loss: -1.4138 - learning_rate: 1.0000e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0177 - val_loss: -1.4531 - learning_rate: 1.0000e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.9889 - val_loss: -1.4272 - learning_rate: 1.0000e-04\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -1.0160 - val_loss: -1.4168 - learning_rate: 1.0000e-04\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -1.0457 - val_loss: -1.4434 - learning_rate: 1.0000e-04\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.9573 - val_loss: -1.4246 - learning_rate: 1.0000e-04\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -1.0155 - val_loss: -1.4643 - learning_rate: 1.0000e-04\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -1.0100 - val_loss: -1.4744 - learning_rate: 1.0000e-04\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -1.0024 - val_loss: -1.4810 - learning_rate: 1.0000e-04\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.9502 - val_loss: -1.4402 - learning_rate: 1.0000e-04\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -1.0111 - val_loss: -1.4793 - learning_rate: 1.0000e-04\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0347 - val_loss: -1.4808 - learning_rate: 1.0000e-04\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0203 - val_loss: -1.4703 - learning_rate: 1.0000e-04\n",
      "Epoch 86/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -1.0164 - val_loss: -1.4847 - learning_rate: 1.0000e-04\n",
      "Epoch 87/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -1.0180 - val_loss: -1.5022 - learning_rate: 1.0000e-04\n",
      "Epoch 88/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -1.0909 - val_loss: -1.4869 - learning_rate: 1.0000e-04\n",
      "Epoch 89/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -1.0025 - val_loss: -1.5042 - learning_rate: 1.0000e-04\n",
      "Epoch 90/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -1.0554 - val_loss: -1.5095 - learning_rate: 1.0000e-04\n",
      "Epoch 91/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.0356 - val_loss: -1.4781 - learning_rate: 1.0000e-04\n",
      "Epoch 92/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.0153 - val_loss: -1.4902 - learning_rate: 1.0000e-04\n",
      "Epoch 93/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.0115 - val_loss: -1.4909 - learning_rate: 1.0000e-04\n",
      "Epoch 94/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.0033 - val_loss: -1.5157 - learning_rate: 1.0000e-04\n",
      "Epoch 95/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.1021 - val_loss: -1.5107 - learning_rate: 1.0000e-04\n",
      "Epoch 96/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.1130 - val_loss: -1.5082 - learning_rate: 1.0000e-04\n",
      "Epoch 97/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.0626 - val_loss: -1.5154 - learning_rate: 1.0000e-04\n",
      "Epoch 98/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.9849 - val_loss: -1.5085 - learning_rate: 1.0000e-04\n",
      "Epoch 99/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.1142 - val_loss: -1.5220 - learning_rate: 1.0000e-04\n",
      "Epoch 100/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.1493 - val_loss: -1.5186 - learning_rate: 1.0000e-04\n",
      "Epoch 101/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.1017 - val_loss: -1.5192 - learning_rate: 1.0000e-04\n",
      "Epoch 102/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.0436 - val_loss: -1.5082 - learning_rate: 1.0000e-04\n",
      "Epoch 103/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.0913 - val_loss: -1.5195 - learning_rate: 1.0000e-04\n",
      "Epoch 104/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.0381 - val_loss: -1.4932 - learning_rate: 1.0000e-04\n",
      "Epoch 105/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.0627 - val_loss: -1.5061 - learning_rate: 5.0000e-05\n",
      "Epoch 106/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.1047 - val_loss: -1.5148 - learning_rate: 5.0000e-05\n",
      "Epoch 107/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.1033 - val_loss: -1.5264 - learning_rate: 5.0000e-05\n",
      "Epoch 108/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.0532 - val_loss: -1.5160 - learning_rate: 5.0000e-05\n",
      "Epoch 109/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.1578 - val_loss: -1.5199 - learning_rate: 5.0000e-05\n",
      "Epoch 110/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.0989 - val_loss: -1.5068 - learning_rate: 5.0000e-05\n",
      "Epoch 111/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.0157 - val_loss: -1.5175 - learning_rate: 5.0000e-05\n",
      "Epoch 112/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.0989 - val_loss: -1.5176 - learning_rate: 5.0000e-05\n",
      "Epoch 113/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.1615 - val_loss: -1.5210 - learning_rate: 2.5000e-05\n",
      "Epoch 114/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.1535 - val_loss: -1.5225 - learning_rate: 2.5000e-05\n",
      "Epoch 115/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.0969 - val_loss: -1.5195 - learning_rate: 2.5000e-05\n",
      "Epoch 116/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.0829 - val_loss: -1.5302 - learning_rate: 2.5000e-05\n",
      "Epoch 117/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.0629 - val_loss: -1.5303 - learning_rate: 2.5000e-05\n",
      "Epoch 118/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -1.1238 - val_loss: -1.5322 - learning_rate: 2.5000e-05\n",
      "Epoch 119/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.0436 - val_loss: -1.5337 - learning_rate: 2.5000e-05\n",
      "Epoch 120/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.0705 - val_loss: -1.5320 - learning_rate: 2.5000e-05\n",
      "Epoch 121/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.1327 - val_loss: -1.5307 - learning_rate: 2.5000e-05\n",
      "Epoch 122/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.0865 - val_loss: -1.5188 - learning_rate: 2.5000e-05\n",
      "Epoch 123/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.0462 - val_loss: -1.5230 - learning_rate: 2.5000e-05\n",
      "Epoch 124/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.1069 - val_loss: -1.5307 - learning_rate: 2.5000e-05\n",
      "Epoch 125/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.1922 - val_loss: -1.5304 - learning_rate: 1.2500e-05\n",
      "Epoch 126/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.0597 - val_loss: -1.5260 - learning_rate: 1.2500e-05\n",
      "Epoch 127/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.1133 - val_loss: -1.5312 - learning_rate: 1.2500e-05\n",
      "Epoch 128/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.0508 - val_loss: -1.5331 - learning_rate: 1.2500e-05\n",
      "Epoch 129/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.0426 - val_loss: -1.5375 - learning_rate: 1.2500e-05\n",
      "Epoch 130/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.1191 - val_loss: -1.5297 - learning_rate: 1.2500e-05\n",
      "Epoch 131/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.1590 - val_loss: -1.5318 - learning_rate: 1.2500e-05\n",
      "Epoch 132/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.0602 - val_loss: -1.5348 - learning_rate: 1.2500e-05\n",
      "Epoch 133/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.0729 - val_loss: -1.5346 - learning_rate: 1.2500e-05\n",
      "Epoch 134/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.1415 - val_loss: -1.5277 - learning_rate: 1.2500e-05\n",
      "Epoch 135/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.0978 - val_loss: -1.5344 - learning_rate: 6.2500e-06\n",
      "Epoch 136/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.0860 - val_loss: -1.5282 - learning_rate: 6.2500e-06\n",
      "Epoch 137/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.0885 - val_loss: -1.5338 - learning_rate: 6.2500e-06\n",
      "Epoch 138/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.1468 - val_loss: -1.5369 - learning_rate: 6.2500e-06\n",
      "Epoch 139/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.0694 - val_loss: -1.5391 - learning_rate: 6.2500e-06\n",
      "Epoch 140/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.0924 - val_loss: -1.5362 - learning_rate: 6.2500e-06\n",
      "Epoch 141/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.0314 - val_loss: -1.5348 - learning_rate: 6.2500e-06\n",
      "Epoch 142/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.1711 - val_loss: -1.5294 - learning_rate: 6.2500e-06\n",
      "Epoch 143/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.0441 - val_loss: -1.5338 - learning_rate: 6.2500e-06\n",
      "Epoch 144/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -1.1418 - val_loss: -1.5357 - learning_rate: 6.2500e-06\n",
      "Epoch 145/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.0558 - val_loss: -1.5331 - learning_rate: 3.1250e-06\n",
      "Epoch 146/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.0395 - val_loss: -1.5344 - learning_rate: 3.1250e-06\n",
      "Epoch 147/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.0876 - val_loss: -1.5327 - learning_rate: 3.1250e-06\n",
      "Epoch 148/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.0730 - val_loss: -1.5309 - learning_rate: 3.1250e-06\n",
      "Epoch 149/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.1385 - val_loss: -1.5310 - learning_rate: 3.1250e-06\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.6583 - val_loss: 0.0581 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.4209 - val_loss: 0.0308 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.3284 - val_loss: 0.0221 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1827 - val_loss: 0.0285 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1562 - val_loss: 0.0147 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1307 - val_loss: 0.0113 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1055 - val_loss: 0.0227 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0842 - val_loss: 0.0043 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0498 - val_loss: 0.0041 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0665 - val_loss: 0.0012 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0609 - val_loss: 3.7691e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0530 - val_loss: 0.0054 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0520 - val_loss: 2.4063e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0500 - val_loss: -0.0034 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0490 - val_loss: -0.0042 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0301 - val_loss: -0.0050 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0208 - val_loss: -0.0049 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0301 - val_loss: -0.0017 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0260 - val_loss: -0.0071 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0243 - val_loss: -0.0064 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0225 - val_loss: 8.4958e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0303 - val_loss: -0.0072 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0155 - val_loss: -0.0042 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0209 - val_loss: -0.0025 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0243 - val_loss: -0.0053 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0339 - val_loss: -0.0067 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0153 - val_loss: -0.0053 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0160 - val_loss: -0.0051 - learning_rate: 5.0000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0167 - val_loss: 9.4207e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0143 - val_loss: -0.0074 - learning_rate: 5.0000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0037 - val_loss: -0.0072 - learning_rate: 5.0000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0186 - val_loss: -0.0065 - learning_rate: 5.0000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0081 - val_loss: -0.0053 - learning_rate: 5.0000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0175 - val_loss: -0.0067 - learning_rate: 5.0000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0148 - val_loss: -0.0068 - learning_rate: 5.0000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0196 - val_loss: -0.0060 - learning_rate: 2.5000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0086 - val_loss: -0.0068 - learning_rate: 2.5000e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0087 - val_loss: -0.0078 - learning_rate: 2.5000e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0140 - val_loss: -0.0085 - learning_rate: 2.5000e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0123 - val_loss: -0.0085 - learning_rate: 2.5000e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0241 - val_loss: -0.0082 - learning_rate: 2.5000e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0120 - val_loss: -0.0083 - learning_rate: 2.5000e-05\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0152 - val_loss: -0.0083 - learning_rate: 2.5000e-05\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0128 - val_loss: -0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0147 - val_loss: -0.0081 - learning_rate: 1.2500e-05\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0066 - val_loss: -0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0129 - val_loss: -0.0074 - learning_rate: 1.2500e-05\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0092 - val_loss: -0.0074 - learning_rate: 1.2500e-05\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0134 - val_loss: -0.0074 - learning_rate: 1.2500e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.4677 - val_loss: 0.0145 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.3213 - val_loss: -0.0057 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1998 - val_loss: -0.0216 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1428 - val_loss: -0.0370 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0936 - val_loss: -0.0528 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0589 - val_loss: -0.0705 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0384 - val_loss: -0.0924 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0489 - val_loss: -0.1191 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.0168 - val_loss: -0.1605 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.0494 - val_loss: -0.1929 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.0591 - val_loss: -0.2070 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.0484 - val_loss: -0.2424 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.1194 - val_loss: -0.2654 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.1133 - val_loss: -0.2850 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.1150 - val_loss: -0.3119 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.1896 - val_loss: -0.3414 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -0.1889 - val_loss: -0.3726 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.2067 - val_loss: -0.3873 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.2450 - val_loss: -0.4203 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.2412 - val_loss: -0.4481 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3227 - val_loss: -0.4934 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.2904 - val_loss: -0.5094 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.3371 - val_loss: -0.5693 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.3515 - val_loss: -0.5902 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.3596 - val_loss: -0.5945 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4111 - val_loss: -0.6284 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4259 - val_loss: -0.6764 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4610 - val_loss: -0.7175 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4887 - val_loss: -0.7355 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5066 - val_loss: -0.7852 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5453 - val_loss: -0.7852 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.5693 - val_loss: -0.8307 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5996 - val_loss: -0.8358 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5873 - val_loss: -0.8371 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6525 - val_loss: -0.8736 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.6873 - val_loss: -0.9197 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.6779 - val_loss: -0.9029 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.7339 - val_loss: -0.9765 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.7373 - val_loss: -0.9563 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.7387 - val_loss: -1.0275 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.7161 - val_loss: -1.0095 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.7843 - val_loss: -1.0384 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.8109 - val_loss: -1.0745 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.8131 - val_loss: -1.0632 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.8259 - val_loss: -1.0748 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.8117 - val_loss: -1.0703 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.8286 - val_loss: -1.0720 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.8355 - val_loss: -1.1322 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.8886 - val_loss: -1.1104 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.8982 - val_loss: -1.1217 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.8455 - val_loss: -1.1501 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.9305 - val_loss: -1.1780 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.9437 - val_loss: -1.1621 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.8613 - val_loss: -1.1776 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -0.8911 - val_loss: -1.1922 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.9654 - val_loss: -1.2366 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.9085 - val_loss: -1.2110 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.9010 - val_loss: -1.2155 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.9041 - val_loss: -1.2141 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -0.9360 - val_loss: -1.2281 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -0.9623 - val_loss: -1.2350 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -0.9700 - val_loss: -1.2533 - learning_rate: 5.0000e-05\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.9885 - val_loss: -1.2358 - learning_rate: 5.0000e-05\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.9766 - val_loss: -1.2544 - learning_rate: 5.0000e-05\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -1.0099 - val_loss: -1.2388 - learning_rate: 5.0000e-05\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -1.0204 - val_loss: -1.2404 - learning_rate: 5.0000e-05\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.9650 - val_loss: -1.2770 - learning_rate: 5.0000e-05\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -1.0552 - val_loss: -1.2762 - learning_rate: 5.0000e-05\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.9547 - val_loss: -1.2638 - learning_rate: 5.0000e-05\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.9656 - val_loss: -1.2752 - learning_rate: 5.0000e-05\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.0376 - val_loss: -1.2751 - learning_rate: 5.0000e-05\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.0342 - val_loss: -1.2561 - learning_rate: 5.0000e-05\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.0495 - val_loss: -1.2541 - learning_rate: 2.5000e-05\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.9775 - val_loss: -1.2848 - learning_rate: 2.5000e-05\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.0143 - val_loss: -1.2762 - learning_rate: 2.5000e-05\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.9742 - val_loss: -1.2732 - learning_rate: 2.5000e-05\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -1.0661 - val_loss: -1.2879 - learning_rate: 2.5000e-05\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.0826 - val_loss: -1.2798 - learning_rate: 2.5000e-05\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.0789 - val_loss: -1.2831 - learning_rate: 2.5000e-05\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.9855 - val_loss: -1.2717 - learning_rate: 2.5000e-05\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.0287 - val_loss: -1.2860 - learning_rate: 2.5000e-05\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -1.0162 - val_loss: -1.2846 - learning_rate: 2.5000e-05\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -1.0724 - val_loss: -1.2903 - learning_rate: 1.2500e-05\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.0851 - val_loss: -1.2884 - learning_rate: 1.2500e-05\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.0930 - val_loss: -1.2983 - learning_rate: 1.2500e-05\n",
      "Epoch 86/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -1.0054 - val_loss: -1.2957 - learning_rate: 1.2500e-05\n",
      "Epoch 87/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.9177 - val_loss: -1.2952 - learning_rate: 1.2500e-05\n",
      "Epoch 88/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -1.0568 - val_loss: -1.2938 - learning_rate: 1.2500e-05\n",
      "Epoch 89/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -1.0075 - val_loss: -1.2965 - learning_rate: 1.2500e-05\n",
      "Epoch 90/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.0649 - val_loss: -1.2883 - learning_rate: 1.2500e-05\n",
      "Epoch 91/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.0581 - val_loss: -1.2939 - learning_rate: 6.2500e-06\n",
      "Epoch 92/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.9970 - val_loss: -1.2958 - learning_rate: 6.2500e-06\n",
      "Epoch 93/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.0683 - val_loss: -1.2949 - learning_rate: 6.2500e-06\n",
      "Epoch 94/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.0118 - val_loss: -1.2961 - learning_rate: 6.2500e-06\n",
      "Epoch 95/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.9746 - val_loss: -1.2909 - learning_rate: 6.2500e-06\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.5785 - val_loss: 0.0568 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3398 - val_loss: 0.0221 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2588 - val_loss: 0.0098 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1751 - val_loss: 0.0049 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1296 - val_loss: 0.0042 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1027 - val_loss: 0.0063 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0810 - val_loss: 0.0037 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0720 - val_loss: 0.0041 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0519 - val_loss: 0.0018 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0628 - val_loss: 0.0083 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0562 - val_loss: 0.0043 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0509 - val_loss: 0.0021 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0573 - val_loss: 0.0044 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0405 - val_loss: 0.0026 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0320 - val_loss: 0.0027 - learning_rate: 5.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0330 - val_loss: 0.0022 - learning_rate: 5.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0361 - val_loss: 0.0013 - learning_rate: 5.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0434 - val_loss: 0.0025 - learning_rate: 5.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0301 - val_loss: 0.0030 - learning_rate: 5.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0312 - val_loss: 0.0027 - learning_rate: 5.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0222 - val_loss: 0.0026 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0289 - val_loss: 0.0019 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0416 - val_loss: 0.0014 - learning_rate: 2.5000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0205 - val_loss: 0.0017 - learning_rate: 2.5000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0163 - val_loss: 0.0032 - learning_rate: 2.5000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0226 - val_loss: 0.0032 - learning_rate: 2.5000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0238 - val_loss: 0.0021 - learning_rate: 2.5000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.6803 - val_loss: 0.0086 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.3537 - val_loss: -0.0176 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2596 - val_loss: -0.0335 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1734 - val_loss: -0.0518 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0864 - val_loss: -0.0668 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0615 - val_loss: -0.1263 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0190 - val_loss: -0.1530 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.0130 - val_loss: -0.1783 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.0512 - val_loss: -0.2226 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.0777 - val_loss: -0.2574 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.1258 - val_loss: -0.2852 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.1275 - val_loss: -0.3124 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.1498 - val_loss: -0.3375 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.1750 - val_loss: -0.3648 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.2186 - val_loss: -0.3867 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.2346 - val_loss: -0.4030 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.2167 - val_loss: -0.4237 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.2627 - val_loss: -0.4522 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.2962 - val_loss: -0.4877 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.2998 - val_loss: -0.5067 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.3377 - val_loss: -0.5367 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.3605 - val_loss: -0.5492 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3867 - val_loss: -0.5962 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.4201 - val_loss: -0.5946 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.4536 - val_loss: -0.6445 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4685 - val_loss: -0.6724 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4665 - val_loss: -0.6933 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -0.5249 - val_loss: -0.7186 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4903 - val_loss: -0.7513 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.5369 - val_loss: -0.7619 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.5380 - val_loss: -0.8114 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.6274 - val_loss: -0.7797 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5867 - val_loss: -0.8386 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6328 - val_loss: -0.8632 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6604 - val_loss: -0.8626 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.7004 - val_loss: -0.8383 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.6320 - val_loss: -0.9036 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.7081 - val_loss: -0.8854 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.7210 - val_loss: -0.9417 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.7364 - val_loss: -0.9768 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7371 - val_loss: -0.9677 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.7720 - val_loss: -0.9850 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.7527 - val_loss: -0.9599 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.8071 - val_loss: -1.0107 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.8105 - val_loss: -0.9933 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.8158 - val_loss: -1.0031 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.8527 - val_loss: -1.0546 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.8711 - val_loss: -1.0457 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.8416 - val_loss: -1.0950 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.8655 - val_loss: -1.0663 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.8158 - val_loss: -1.0144 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -0.8487 - val_loss: -1.0983 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -0.9060 - val_loss: -1.0963 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.8848 - val_loss: -1.1213 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.9487 - val_loss: -1.1320 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.8463 - val_loss: -1.1308 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -0.9025 - val_loss: -1.1463 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.9728 - val_loss: -1.1583 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.9556 - val_loss: -1.1668 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.9953 - val_loss: -1.1527 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.9907 - val_loss: -1.1987 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.8943 - val_loss: -1.1702 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.0593 - val_loss: -1.1731 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.9755 - val_loss: -1.2065 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.9749 - val_loss: -1.1541 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.9430 - val_loss: -1.2099 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.9839 - val_loss: -1.1796 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.9555 - val_loss: -1.1632 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -1.0318 - val_loss: -1.1967 - learning_rate: 1.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.0313 - val_loss: -1.1963 - learning_rate: 1.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.0145 - val_loss: -1.2235 - learning_rate: 1.0000e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -1.0096 - val_loss: -1.1991 - learning_rate: 1.0000e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -1.0370 - val_loss: -1.2337 - learning_rate: 1.0000e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.9983 - val_loss: -1.2056 - learning_rate: 1.0000e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -1.0551 - val_loss: -1.1757 - learning_rate: 1.0000e-04\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -1.0612 - val_loss: -1.2265 - learning_rate: 1.0000e-04\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -1.0397 - val_loss: -1.2504 - learning_rate: 1.0000e-04\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -1.0073 - val_loss: -1.2004 - learning_rate: 1.0000e-04\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.9769 - val_loss: -1.2327 - learning_rate: 1.0000e-04\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -1.0270 - val_loss: -1.2091 - learning_rate: 1.0000e-04\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.9976 - val_loss: -1.2060 - learning_rate: 1.0000e-04\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -1.0399 - val_loss: -1.2326 - learning_rate: 1.0000e-04\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -1.1221 - val_loss: -1.2272 - learning_rate: 5.0000e-05\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.0138 - val_loss: -1.2089 - learning_rate: 5.0000e-05\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.9248 - val_loss: -1.1745 - learning_rate: 5.0000e-05\n",
      "Epoch 86/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.0559 - val_loss: -1.2094 - learning_rate: 5.0000e-05\n",
      "Epoch 87/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -1.0539 - val_loss: -1.2527 - learning_rate: 5.0000e-05\n",
      "Epoch 88/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.0178 - val_loss: -1.2387 - learning_rate: 5.0000e-05\n",
      "Epoch 89/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -1.0072 - val_loss: -1.2296 - learning_rate: 5.0000e-05\n",
      "Epoch 90/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -1.0374 - val_loss: -1.2355 - learning_rate: 5.0000e-05\n",
      "Epoch 91/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -1.0857 - val_loss: -1.2225 - learning_rate: 5.0000e-05\n",
      "Epoch 92/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -1.0096 - val_loss: -1.1969 - learning_rate: 5.0000e-05\n",
      "Epoch 93/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -1.0698 - val_loss: -1.2350 - learning_rate: 2.5000e-05\n",
      "Epoch 94/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -1.0619 - val_loss: -1.2254 - learning_rate: 2.5000e-05\n",
      "Epoch 95/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -1.0940 - val_loss: -1.2248 - learning_rate: 2.5000e-05\n",
      "Epoch 96/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.9947 - val_loss: -1.2325 - learning_rate: 2.5000e-05\n",
      "Epoch 97/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.0411 - val_loss: -1.2268 - learning_rate: 2.5000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.6671 - val_loss: 0.0361 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.4435 - val_loss: 0.0299 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.3153 - val_loss: 0.0206 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.2036 - val_loss: 0.0051 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1820 - val_loss: 0.0068 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1282 - val_loss: 3.6810e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0867 - val_loss: 8.0280e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1044 - val_loss: -0.0020 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0821 - val_loss: -0.0030 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0791 - val_loss: -0.0031 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0615 - val_loss: -0.0057 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0493 - val_loss: 0.0089 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0551 - val_loss: -0.0067 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0293 - val_loss: -0.0057 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0295 - val_loss: -0.0071 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0421 - val_loss: -0.0078 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0293 - val_loss: -0.0104 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0292 - val_loss: -0.0057 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0263 - val_loss: -0.0072 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0222 - val_loss: 0.0039 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0327 - val_loss: -0.0094 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0236 - val_loss: -0.0115 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0101 - val_loss: -0.0126 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0113 - val_loss: -0.0119 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0216 - val_loss: -0.0099 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0164 - val_loss: -0.0091 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0109 - val_loss: -0.0118 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0111 - val_loss: -0.0122 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0115 - val_loss: -0.0056 - learning_rate: 5.0000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0105 - val_loss: -0.0072 - learning_rate: 5.0000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.0026 - val_loss: -0.0133 - learning_rate: 5.0000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0104 - val_loss: -0.0119 - learning_rate: 5.0000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0041 - val_loss: -0.0125 - learning_rate: 5.0000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0018 - val_loss: -0.0092 - learning_rate: 5.0000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0212 - val_loss: -0.0119 - learning_rate: 5.0000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0050 - val_loss: -0.0119 - learning_rate: 5.0000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0094 - val_loss: -0.0127 - learning_rate: 2.5000e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0105 - val_loss: -0.0124 - learning_rate: 2.5000e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0073 - val_loss: -0.0134 - learning_rate: 2.5000e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0021 - val_loss: -0.0119 - learning_rate: 2.5000e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0074 - val_loss: -0.0130 - learning_rate: 2.5000e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -6.9721e-04 - val_loss: -0.0128 - learning_rate: 2.5000e-05\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.0037 - val_loss: -0.0133 - learning_rate: 2.5000e-05\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.0032 - val_loss: -0.0121 - learning_rate: 2.5000e-05\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.0054 - val_loss: -0.0123 - learning_rate: 1.2500e-05\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0050 - val_loss: -0.0115 - learning_rate: 1.2500e-05\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.0025 - val_loss: -0.0122 - learning_rate: 1.2500e-05\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.0038 - val_loss: -0.0125 - learning_rate: 1.2500e-05\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.0020 - val_loss: -0.0123 - learning_rate: 1.2500e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.6687 - val_loss: 0.0124 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.3190 - val_loss: -0.0199 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.2058 - val_loss: -0.0434 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1075 - val_loss: -0.0579 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1022 - val_loss: -0.0712 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0475 - val_loss: -0.0725 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0579 - val_loss: -0.0919 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.0022 - val_loss: -0.1119 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.0183 - val_loss: -0.1297 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.0334 - val_loss: -0.1445 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.0594 - val_loss: -0.1653 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.0559 - val_loss: -0.1842 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.0806 - val_loss: -0.2061 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.1031 - val_loss: -0.2148 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.0935 - val_loss: -0.2356 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.1327 - val_loss: -0.2616 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -0.1321 - val_loss: -0.2842 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.1869 - val_loss: -0.3081 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.1899 - val_loss: -0.3352 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.2305 - val_loss: -0.3700 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.2765 - val_loss: -0.3981 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.2761 - val_loss: -0.4298 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3074 - val_loss: -0.4575 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.2944 - val_loss: -0.4977 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.3483 - val_loss: -0.5309 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.3783 - val_loss: -0.5671 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.4234 - val_loss: -0.6006 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.4689 - val_loss: -0.6289 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.5122 - val_loss: -0.6681 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.5306 - val_loss: -0.7197 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.5234 - val_loss: -0.7344 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.5709 - val_loss: -0.7701 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.6300 - val_loss: -0.8036 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.6283 - val_loss: -0.8296 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.6523 - val_loss: -0.8705 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.7053 - val_loss: -0.8919 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.7148 - val_loss: -0.9282 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.7110 - val_loss: -0.9537 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.7705 - val_loss: -0.9669 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.7582 - val_loss: -0.9790 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.8344 - val_loss: -1.0279 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.8017 - val_loss: -1.0286 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.8624 - val_loss: -1.0345 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.8062 - val_loss: -1.0481 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.8755 - val_loss: -1.0958 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.8748 - val_loss: -1.0808 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.9236 - val_loss: -1.0677 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.8908 - val_loss: -1.1000 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -0.9180 - val_loss: -1.1379 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.9015 - val_loss: -1.1489 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.9535 - val_loss: -1.1281 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.9867 - val_loss: -1.1333 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.9278 - val_loss: -1.1386 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -1.0166 - val_loss: -1.1659 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.9631 - val_loss: -1.1491 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.9471 - val_loss: -1.1897 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.9957 - val_loss: -1.1998 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -1.0148 - val_loss: -1.2153 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -1.0225 - val_loss: -1.1843 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -1.0237 - val_loss: -1.1719 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -1.0718 - val_loss: -1.1819 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -1.1273 - val_loss: -1.1887 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -1.0261 - val_loss: -1.1522 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -1.0755 - val_loss: -1.1877 - learning_rate: 5.0000e-05\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.0866 - val_loss: -1.2055 - learning_rate: 5.0000e-05\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.1046 - val_loss: -1.2300 - learning_rate: 5.0000e-05\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.0708 - val_loss: -1.2295 - learning_rate: 5.0000e-05\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.0051 - val_loss: -1.2314 - learning_rate: 5.0000e-05\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.1215 - val_loss: -1.2221 - learning_rate: 5.0000e-05\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.1514 - val_loss: -1.2332 - learning_rate: 5.0000e-05\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.0622 - val_loss: -1.2299 - learning_rate: 5.0000e-05\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.0713 - val_loss: -1.2314 - learning_rate: 5.0000e-05\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -1.1351 - val_loss: -1.2475 - learning_rate: 5.0000e-05\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -1.0963 - val_loss: -1.2138 - learning_rate: 5.0000e-05\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -1.0935 - val_loss: -1.2503 - learning_rate: 5.0000e-05\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -1.1477 - val_loss: -1.2537 - learning_rate: 5.0000e-05\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -1.0625 - val_loss: -1.2422 - learning_rate: 5.0000e-05\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.1391 - val_loss: -1.2311 - learning_rate: 5.0000e-05\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -1.1327 - val_loss: -1.2608 - learning_rate: 5.0000e-05\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.1307 - val_loss: -1.2331 - learning_rate: 5.0000e-05\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -1.1402 - val_loss: -1.2359 - learning_rate: 5.0000e-05\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -1.1239 - val_loss: -1.2419 - learning_rate: 5.0000e-05\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -1.1348 - val_loss: -1.2419 - learning_rate: 5.0000e-05\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -1.1169 - val_loss: -1.2446 - learning_rate: 5.0000e-05\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -1.1258 - val_loss: -1.2403 - learning_rate: 2.5000e-05\n",
      "Epoch 86/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -1.1717 - val_loss: -1.2292 - learning_rate: 2.5000e-05\n",
      "Epoch 87/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -1.2025 - val_loss: -1.2343 - learning_rate: 2.5000e-05\n",
      "Epoch 88/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -1.1468 - val_loss: -1.2463 - learning_rate: 2.5000e-05\n",
      "Epoch 89/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -1.1435 - val_loss: -1.2543 - learning_rate: 2.5000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.5406 - val_loss: 0.0025 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.3353 - val_loss: -0.0188 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.2353 - val_loss: -0.0389 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1732 - val_loss: -0.0359 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1320 - val_loss: -0.0306 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0924 - val_loss: -0.0469 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0666 - val_loss: -0.0375 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0551 - val_loss: -0.0498 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0394 - val_loss: -0.0553 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0233 - val_loss: -0.0595 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0143 - val_loss: -0.0535 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0119 - val_loss: -0.0555 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0080 - val_loss: -0.0440 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.0090 - val_loss: -0.0541 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0072 - val_loss: -0.0596 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.0066 - val_loss: -0.0593 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.0076 - val_loss: -0.0597 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.0153 - val_loss: -0.0605 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.0040 - val_loss: -0.0595 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.0168 - val_loss: -0.0602 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0280 - val_loss: -0.0622 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.0134 - val_loss: -0.0623 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.0046 - val_loss: -0.0590 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.0238 - val_loss: -0.0627 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.0153 - val_loss: -0.0647 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.0348 - val_loss: -0.0587 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.0237 - val_loss: -0.0616 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.0179 - val_loss: -0.0566 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.0319 - val_loss: -0.0602 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.0421 - val_loss: -0.0652 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.0396 - val_loss: -0.0650 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.0246 - val_loss: -0.0673 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.0097 - val_loss: -0.0645 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.0295 - val_loss: -0.0633 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.0289 - val_loss: -0.0631 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.0301 - val_loss: -0.0641 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0351 - val_loss: -0.0667 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.0189 - val_loss: -0.0613 - learning_rate: 5.0000e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.0323 - val_loss: -0.0655 - learning_rate: 5.0000e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.0276 - val_loss: -0.0639 - learning_rate: 5.0000e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.0440 - val_loss: -0.0667 - learning_rate: 5.0000e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.0314 - val_loss: -0.0638 - learning_rate: 5.0000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.6716 - val_loss: 0.0462 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.4456 - val_loss: 0.0105 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.2975 - val_loss: 0.0094 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.1819 - val_loss: -0.0051 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1107 - val_loss: -0.0042 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1137 - val_loss: -0.0145 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0604 - val_loss: -0.0210 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0794 - val_loss: -0.0321 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0431 - val_loss: -0.0453 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0053 - val_loss: -0.0598 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0277 - val_loss: -0.0792 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.0055 - val_loss: -0.0918 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.0193 - val_loss: -0.1112 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.0269 - val_loss: -0.1351 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.0590 - val_loss: -0.1568 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.0715 - val_loss: -0.1674 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.1006 - val_loss: -0.1945 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.1008 - val_loss: -0.1867 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.1020 - val_loss: -0.2257 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.1195 - val_loss: -0.2436 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.1453 - val_loss: -0.2598 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.1739 - val_loss: -0.2752 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.1810 - val_loss: -0.3000 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.1991 - val_loss: -0.3220 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.2036 - val_loss: -0.3349 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.2470 - val_loss: -0.3566 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.2427 - val_loss: -0.3806 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.2590 - val_loss: -0.4124 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.3031 - val_loss: -0.4298 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.3205 - val_loss: -0.4594 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.3338 - val_loss: -0.4786 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.3834 - val_loss: -0.5197 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.3816 - val_loss: -0.5495 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.3722 - val_loss: -0.5803 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.4453 - val_loss: -0.6035 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.4755 - val_loss: -0.6368 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4527 - val_loss: -0.6399 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5007 - val_loss: -0.6836 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.5071 - val_loss: -0.7203 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.5879 - val_loss: -0.7250 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5580 - val_loss: -0.7701 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6105 - val_loss: -0.8146 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.6090 - val_loss: -0.7996 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -0.6284 - val_loss: -0.8609 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.6627 - val_loss: -0.8732 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.6798 - val_loss: -0.8936 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.6800 - val_loss: -0.9252 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.6813 - val_loss: -0.9316 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7433 - val_loss: -0.9667 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.7122 - val_loss: -0.9870 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.7680 - val_loss: -1.0114 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.8004 - val_loss: -0.9929 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.8118 - val_loss: -1.0246 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7998 - val_loss: -1.0530 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7760 - val_loss: -1.0802 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.8131 - val_loss: -1.0416 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.7912 - val_loss: -1.1007 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.9096 - val_loss: -1.1130 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.8878 - val_loss: -1.0929 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.9081 - val_loss: -1.1231 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.8577 - val_loss: -1.1449 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.8725 - val_loss: -1.1442 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.9200 - val_loss: -1.1487 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.9170 - val_loss: -1.1396 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -0.8368 - val_loss: -1.1231 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.9248 - val_loss: -1.1743 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.9974 - val_loss: -1.1926 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.9097 - val_loss: -1.1685 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.9661 - val_loss: -1.1859 - learning_rate: 1.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.9522 - val_loss: -1.2165 - learning_rate: 1.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.9703 - val_loss: -1.2008 - learning_rate: 1.0000e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -1.0048 - val_loss: -1.1740 - learning_rate: 1.0000e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.9966 - val_loss: -1.2111 - learning_rate: 1.0000e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.9691 - val_loss: -1.1806 - learning_rate: 1.0000e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.9733 - val_loss: -1.2022 - learning_rate: 1.0000e-04\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.9990 - val_loss: -1.1819 - learning_rate: 5.0000e-05\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -1.0181 - val_loss: -1.2076 - learning_rate: 5.0000e-05\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.9693 - val_loss: -1.1959 - learning_rate: 5.0000e-05\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.9984 - val_loss: -1.2016 - learning_rate: 5.0000e-05\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.9703 - val_loss: -1.2034 - learning_rate: 5.0000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.5833 - val_loss: 0.0720 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.4150 - val_loss: 0.0226 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.2619 - val_loss: -0.0108 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.1762 - val_loss: -0.0105 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1434 - val_loss: -0.0177 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.1148 - val_loss: -0.0384 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0704 - val_loss: -0.0596 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0388 - val_loss: -0.0620 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0307 - val_loss: -0.0611 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0409 - val_loss: -0.0742 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0097 - val_loss: -0.0774 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0194 - val_loss: -0.0861 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0135 - val_loss: -0.0939 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.0067 - val_loss: -0.0972 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.0257 - val_loss: -0.1041 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.0142 - val_loss: -0.1066 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.0259 - val_loss: -0.1110 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.0154 - val_loss: -0.1115 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.0341 - val_loss: -0.1104 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.0305 - val_loss: -0.1186 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.0400 - val_loss: -0.1201 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.0432 - val_loss: -0.1178 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.0413 - val_loss: -0.1141 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.0452 - val_loss: -0.1133 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.0257 - val_loss: -0.1141 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.0487 - val_loss: -0.1143 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.0614 - val_loss: -0.1201 - learning_rate: 5.0000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.0517 - val_loss: -0.1182 - learning_rate: 5.0000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.0441 - val_loss: -0.1205 - learning_rate: 5.0000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.0431 - val_loss: -0.1150 - learning_rate: 5.0000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.0602 - val_loss: -0.1148 - learning_rate: 5.0000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.0352 - val_loss: -0.1182 - learning_rate: 5.0000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.0593 - val_loss: -0.1147 - learning_rate: 5.0000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.0619 - val_loss: -0.1210 - learning_rate: 5.0000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -0.0483 - val_loss: -0.1107 - learning_rate: 5.0000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0399 - val_loss: -0.1165 - learning_rate: 5.0000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0479 - val_loss: -0.1194 - learning_rate: 5.0000e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0460 - val_loss: -0.1171 - learning_rate: 5.0000e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0555 - val_loss: -0.1213 - learning_rate: 5.0000e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.0553 - val_loss: -0.1174 - learning_rate: 5.0000e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.0473 - val_loss: -0.1170 - learning_rate: 5.0000e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.0536 - val_loss: -0.1196 - learning_rate: 5.0000e-05\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.0523 - val_loss: -0.1152 - learning_rate: 5.0000e-05\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.0517 - val_loss: -0.1191 - learning_rate: 5.0000e-05\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.0651 - val_loss: -0.1191 - learning_rate: 2.5000e-05\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.0503 - val_loss: -0.1190 - learning_rate: 2.5000e-05\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0611 - val_loss: -0.1184 - learning_rate: 2.5000e-05\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -0.0477 - val_loss: -0.1175 - learning_rate: 2.5000e-05\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.0667 - val_loss: -0.1190 - learning_rate: 2.5000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.6887 - val_loss: 0.0098 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.3008 - val_loss: -0.0128 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1751 - val_loss: -0.0556 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.1330 - val_loss: -0.0782 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0348 - val_loss: -0.1270 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0202 - val_loss: -0.1555 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.0076 - val_loss: -0.1852 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.0626 - val_loss: -0.2144 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.0811 - val_loss: -0.2410 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.1013 - val_loss: -0.2464 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.0967 - val_loss: -0.2855 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.1290 - val_loss: -0.3041 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.1419 - val_loss: -0.3312 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.1752 - val_loss: -0.3532 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.1897 - val_loss: -0.3805 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.2259 - val_loss: -0.4083 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.2413 - val_loss: -0.4351 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.2678 - val_loss: -0.4653 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3010 - val_loss: -0.4959 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3123 - val_loss: -0.5240 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3038 - val_loss: -0.5548 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -0.3322 - val_loss: -0.5786 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.3792 - val_loss: -0.6138 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4260 - val_loss: -0.6528 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4480 - val_loss: -0.6853 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.4683 - val_loss: -0.7104 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4995 - val_loss: -0.7351 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5289 - val_loss: -0.7651 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5143 - val_loss: -0.7870 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.5832 - val_loss: -0.8197 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.5740 - val_loss: -0.8373 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5842 - val_loss: -0.8685 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6026 - val_loss: -0.8998 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6464 - val_loss: -0.9359 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.6873 - val_loss: -0.9402 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6695 - val_loss: -0.9657 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6655 - val_loss: -0.9798 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7245 - val_loss: -1.0022 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.7590 - val_loss: -1.0158 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.7698 - val_loss: -1.0526 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7117 - val_loss: -1.0589 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.8265 - val_loss: -1.0831 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.7579 - val_loss: -1.0657 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.8153 - val_loss: -1.0866 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.8638 - val_loss: -1.1182 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.8274 - val_loss: -1.1181 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.8365 - val_loss: -1.1315 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.8191 - val_loss: -1.1592 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.9135 - val_loss: -1.1354 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.8473 - val_loss: -1.1817 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.9464 - val_loss: -1.1883 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.8987 - val_loss: -1.1724 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.9243 - val_loss: -1.1752 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.8818 - val_loss: -1.2030 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.9598 - val_loss: -1.2075 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.9323 - val_loss: -1.2113 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.0020 - val_loss: -1.2082 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.9812 - val_loss: -1.2123 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.9755 - val_loss: -1.2123 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.8899 - val_loss: -1.2535 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -1.0097 - val_loss: -1.2057 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.9809 - val_loss: -1.2377 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.9897 - val_loss: -1.2356 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.9500 - val_loss: -1.2534 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -1.0683 - val_loss: -1.2701 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -1.0143 - val_loss: -1.2641 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.9961 - val_loss: -1.2653 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -1.0613 - val_loss: -1.2952 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -1.0329 - val_loss: -1.2756 - learning_rate: 1.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -1.1250 - val_loss: -1.2906 - learning_rate: 1.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -1.0154 - val_loss: -1.2719 - learning_rate: 1.0000e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -1.0155 - val_loss: -1.2882 - learning_rate: 1.0000e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -1.0487 - val_loss: -1.2817 - learning_rate: 1.0000e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -1.0283 - val_loss: -1.2919 - learning_rate: 5.0000e-05\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -1.0423 - val_loss: -1.2881 - learning_rate: 5.0000e-05\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -1.0680 - val_loss: -1.2847 - learning_rate: 5.0000e-05\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -1.0893 - val_loss: -1.2882 - learning_rate: 5.0000e-05\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -1.1154 - val_loss: -1.2616 - learning_rate: 5.0000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.6139 - val_loss: 0.0132 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.3474 - val_loss: 0.0217 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.2416 - val_loss: 0.0140 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2089 - val_loss: 0.0163 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1467 - val_loss: 0.0125 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1129 - val_loss: 0.0107 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1117 - val_loss: 0.0158 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0999 - val_loss: 0.0080 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0856 - val_loss: 0.0073 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0912 - val_loss: -8.0968e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0665 - val_loss: -3.2619e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0588 - val_loss: 1.2699e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0574 - val_loss: 0.0012 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0604 - val_loss: 0.0016 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0453 - val_loss: -0.0035 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0426 - val_loss: 0.0011 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0328 - val_loss: -0.0017 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0199 - val_loss: 8.7199e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0262 - val_loss: -7.1971e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0260 - val_loss: -0.0035 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0249 - val_loss: -0.0036 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0186 - val_loss: -0.0033 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0188 - val_loss: -0.0053 - learning_rate: 5.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0311 - val_loss: -0.0055 - learning_rate: 5.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0203 - val_loss: -0.0040 - learning_rate: 5.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0240 - val_loss: -0.0049 - learning_rate: 5.0000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0320 - val_loss: -0.0043 - learning_rate: 5.0000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0226 - val_loss: -0.0041 - learning_rate: 5.0000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0286 - val_loss: -0.0046 - learning_rate: 5.0000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0146 - val_loss: -0.0044 - learning_rate: 2.5000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0208 - val_loss: -0.0046 - learning_rate: 2.5000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0232 - val_loss: -0.0046 - learning_rate: 2.5000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0201 - val_loss: -0.0041 - learning_rate: 2.5000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0074 - val_loss: -0.0048 - learning_rate: 2.5000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.5259 - val_loss: 0.0138 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.2951 - val_loss: -0.0607 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.2472 - val_loss: -0.0781 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.1250 - val_loss: -0.0978 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1152 - val_loss: -0.1003 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0609 - val_loss: -0.1309 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.0064 - val_loss: -0.1575 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 4.9064e-04 - val_loss: -0.1752 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.0323 - val_loss: -0.1938 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.0559 - val_loss: -0.2007 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.0785 - val_loss: -0.2331 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.1090 - val_loss: -0.2566 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.1222 - val_loss: -0.2787 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -0.1353 - val_loss: -0.2970 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.1671 - val_loss: -0.3496 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.1768 - val_loss: -0.3880 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.2180 - val_loss: -0.4240 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.2591 - val_loss: -0.4661 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.2738 - val_loss: -0.4962 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.3082 - val_loss: -0.5247 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.3114 - val_loss: -0.5638 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.3178 - val_loss: -0.5955 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.3375 - val_loss: -0.6164 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.3712 - val_loss: -0.6602 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.4185 - val_loss: -0.7001 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.4379 - val_loss: -0.7162 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4472 - val_loss: -0.7463 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.5069 - val_loss: -0.7759 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.5400 - val_loss: -0.8122 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.5598 - val_loss: -0.8584 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.5924 - val_loss: -0.8736 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.5661 - val_loss: -0.9157 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6029 - val_loss: -0.9494 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.6032 - val_loss: -0.9515 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -0.6582 - val_loss: -0.9854 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.6943 - val_loss: -1.0304 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6997 - val_loss: -1.0488 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.7065 - val_loss: -1.0751 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.6808 - val_loss: -1.1078 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7304 - val_loss: -1.1291 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7242 - val_loss: -1.1460 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7340 - val_loss: -1.1711 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.8000 - val_loss: -1.1726 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7709 - val_loss: -1.1968 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.8286 - val_loss: -1.2112 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.8077 - val_loss: -1.2196 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7793 - val_loss: -1.2289 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.8660 - val_loss: -1.2640 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.8849 - val_loss: -1.1973 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.8855 - val_loss: -1.2779 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.8614 - val_loss: -1.2572 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.8335 - val_loss: -1.2899 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.8281 - val_loss: -1.3014 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.9415 - val_loss: -1.3108 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.9354 - val_loss: -1.3227 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.9444 - val_loss: -1.3198 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.9306 - val_loss: -1.3580 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.8914 - val_loss: -1.3147 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.9634 - val_loss: -1.3503 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.9834 - val_loss: -1.3544 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.9859 - val_loss: -1.3675 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.9873 - val_loss: -1.3507 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.9765 - val_loss: -1.3640 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.9815 - val_loss: -1.3626 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -1.0501 - val_loss: -1.3890 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.9632 - val_loss: -1.3705 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -1.0118 - val_loss: -1.4218 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -1.0032 - val_loss: -1.3820 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.0549 - val_loss: -1.3834 - learning_rate: 1.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.0316 - val_loss: -1.4314 - learning_rate: 1.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.9586 - val_loss: -1.4304 - learning_rate: 1.0000e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -1.0635 - val_loss: -1.3997 - learning_rate: 1.0000e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0738 - val_loss: -1.3978 - learning_rate: 1.0000e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -1.0877 - val_loss: -1.4184 - learning_rate: 1.0000e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0248 - val_loss: -1.3912 - learning_rate: 1.0000e-04\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.9526 - val_loss: -1.4279 - learning_rate: 5.0000e-05\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0541 - val_loss: -1.4246 - learning_rate: 5.0000e-05\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0574 - val_loss: -1.4175 - learning_rate: 5.0000e-05\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0776 - val_loss: -1.4360 - learning_rate: 5.0000e-05\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: -1.0212 - val_loss: -1.4442 - learning_rate: 5.0000e-05\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -1.0376 - val_loss: -1.4499 - learning_rate: 5.0000e-05\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: -1.0949 - val_loss: -1.4472 - learning_rate: 5.0000e-05\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -1.0931 - val_loss: -1.4470 - learning_rate: 5.0000e-05\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0480 - val_loss: -1.4215 - learning_rate: 5.0000e-05\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -1.0353 - val_loss: -1.4475 - learning_rate: 5.0000e-05\n",
      "Epoch 86/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -1.0736 - val_loss: -1.4388 - learning_rate: 5.0000e-05\n",
      "Epoch 87/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -1.0701 - val_loss: -1.4307 - learning_rate: 2.5000e-05\n",
      "Epoch 88/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -1.0745 - val_loss: -1.4318 - learning_rate: 2.5000e-05\n",
      "Epoch 89/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -1.0434 - val_loss: -1.4344 - learning_rate: 2.5000e-05\n",
      "Epoch 90/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -1.0941 - val_loss: -1.4297 - learning_rate: 2.5000e-05\n",
      "Epoch 91/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -1.1343 - val_loss: -1.4328 - learning_rate: 2.5000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 0.6254 - val_loss: 0.0323 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.3482 - val_loss: 0.0168 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.2008 - val_loss: 0.0144 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.1759 - val_loss: 0.0099 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.1309 - val_loss: 0.0030 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.1250 - val_loss: 0.0012 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0839 - val_loss: -9.5553e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0687 - val_loss: -0.0049 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0836 - val_loss: 3.6871e-06 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0567 - val_loss: 0.0092 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.0596 - val_loss: 9.9587e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0467 - val_loss: -2.8101e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.0426 - val_loss: -0.0011 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0572 - val_loss: 6.1859e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.0244 - val_loss: -1.4730e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0460 - val_loss: -5.0932e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0199 - val_loss: 0.0045 - learning_rate: 5.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0235 - val_loss: -6.2376e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 1.2432 - val_loss: 0.0844 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.5934 - val_loss: 0.0110 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.3554 - val_loss: -0.0035 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.2100 - val_loss: -0.0064 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.1349 - val_loss: -0.0254 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.1179 - val_loss: -0.0370 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0889 - val_loss: -0.0417 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0765 - val_loss: -0.0692 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0270 - val_loss: -0.1089 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.0032 - val_loss: -0.1441 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.0168 - val_loss: -0.1787 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.0473 - val_loss: -0.2162 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.0974 - val_loss: -0.2444 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.1081 - val_loss: -0.2463 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.1376 - val_loss: -0.2722 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.1251 - val_loss: -0.3183 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.1920 - val_loss: -0.3585 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.1828 - val_loss: -0.3686 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.2548 - val_loss: -0.4196 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.2440 - val_loss: -0.4449 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.2759 - val_loss: -0.4913 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3103 - val_loss: -0.5242 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3140 - val_loss: -0.5642 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3592 - val_loss: -0.6051 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.3883 - val_loss: -0.6416 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.3905 - val_loss: -0.6765 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4179 - val_loss: -0.7088 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4276 - val_loss: -0.7544 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4504 - val_loss: -0.7920 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: -0.5187 - val_loss: -0.8389 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5490 - val_loss: -0.8859 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5709 - val_loss: -0.9168 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5947 - val_loss: -0.9326 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: -0.5763 - val_loss: -0.9662 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6589 - val_loss: -1.0203 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6633 - val_loss: -1.0607 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6703 - val_loss: -1.0792 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6708 - val_loss: -1.1103 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6976 - val_loss: -1.1393 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.7571 - val_loss: -1.1458 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7808 - val_loss: -1.2054 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.7766 - val_loss: -1.2045 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.8446 - val_loss: -1.2454 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7902 - val_loss: -1.2563 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7980 - val_loss: -1.2825 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7999 - val_loss: -1.2702 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.7822 - val_loss: -1.3084 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8599 - val_loss: -1.3340 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8051 - val_loss: -1.3070 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8884 - val_loss: -1.3400 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8766 - val_loss: -1.3468 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9020 - val_loss: -1.3248 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9082 - val_loss: -1.3723 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8928 - val_loss: -1.3857 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.9020 - val_loss: -1.3842 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.9395 - val_loss: -1.4065 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0004 - val_loss: -1.4269 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.9900 - val_loss: -1.4179 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.9444 - val_loss: -1.4423 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.9228 - val_loss: -1.4214 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.9009 - val_loss: -1.4456 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.9963 - val_loss: -1.4651 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -1.0214 - val_loss: -1.4585 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.9448 - val_loss: -1.4726 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -1.0055 - val_loss: -1.4533 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0085 - val_loss: -1.4850 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.9973 - val_loss: -1.4877 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.9921 - val_loss: -1.4924 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.9936 - val_loss: -1.5092 - learning_rate: 1.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -1.0079 - val_loss: -1.5098 - learning_rate: 1.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9826 - val_loss: -1.5157 - learning_rate: 1.0000e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0548 - val_loss: -1.5123 - learning_rate: 1.0000e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0826 - val_loss: -1.5078 - learning_rate: 1.0000e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -1.0152 - val_loss: -1.5313 - learning_rate: 1.0000e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0738 - val_loss: -1.5418 - learning_rate: 1.0000e-04\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -1.0719 - val_loss: -1.5109 - learning_rate: 1.0000e-04\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -1.0213 - val_loss: -1.5043 - learning_rate: 1.0000e-04\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -1.0777 - val_loss: -1.5218 - learning_rate: 1.0000e-04\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -1.0260 - val_loss: -1.4858 - learning_rate: 1.0000e-04\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -1.0638 - val_loss: -1.5348 - learning_rate: 1.0000e-04\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -1.0327 - val_loss: -1.5257 - learning_rate: 5.0000e-05\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -1.0051 - val_loss: -1.5220 - learning_rate: 5.0000e-05\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -1.0449 - val_loss: -1.5068 - learning_rate: 5.0000e-05\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.9815 - val_loss: -1.5238 - learning_rate: 5.0000e-05\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -1.0459 - val_loss: -1.5317 - learning_rate: 5.0000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - loss: 0.6285 - val_loss: 0.0469 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.3784 - val_loss: 0.0146 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.2384 - val_loss: 0.0125 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.1887 - val_loss: 0.0179 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.1459 - val_loss: 0.0082 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.1035 - val_loss: 0.0040 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.1027 - val_loss: 0.0196 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0974 - val_loss: 0.0074 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0961 - val_loss: 0.0018 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0739 - val_loss: 2.9027e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0641 - val_loss: 0.0032 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0579 - val_loss: 0.0074 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0472 - val_loss: 0.0036 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0327 - val_loss: 0.0047 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0471 - val_loss: 0.0157 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0359 - val_loss: 0.0070 - learning_rate: 5.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0441 - val_loss: 0.0070 - learning_rate: 5.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0280 - val_loss: 0.0054 - learning_rate: 5.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.0322 - val_loss: 0.0039 - learning_rate: 5.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0237 - val_loss: 0.0060 - learning_rate: 5.0000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.6902 - val_loss: -0.0011 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.4400 - val_loss: -0.0324 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.2464 - val_loss: -0.0461 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.1641 - val_loss: -0.0620 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.1682 - val_loss: -0.0734 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0834 - val_loss: -0.1010 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0296 - val_loss: -0.1431 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0074 - val_loss: -0.1662 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.0382 - val_loss: -0.1929 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.0416 - val_loss: -0.2161 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.0624 - val_loss: -0.2366 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.0754 - val_loss: -0.2587 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.0868 - val_loss: -0.2760 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.1248 - val_loss: -0.3037 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.1454 - val_loss: -0.3292 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.1830 - val_loss: -0.3498 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.2094 - val_loss: -0.3703 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.2363 - val_loss: -0.3981 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.2326 - val_loss: -0.4271 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.2584 - val_loss: -0.4495 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2930 - val_loss: -0.4615 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3033 - val_loss: -0.4989 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3219 - val_loss: -0.5114 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3445 - val_loss: -0.5384 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3786 - val_loss: -0.5716 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.4391 - val_loss: -0.6081 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4334 - val_loss: -0.6486 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4353 - val_loss: -0.6596 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4901 - val_loss: -0.6988 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5453 - val_loss: -0.7360 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5199 - val_loss: -0.7748 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5641 - val_loss: -0.7994 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5584 - val_loss: -0.8056 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: -0.6189 - val_loss: -0.8572 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6007 - val_loss: -0.8730 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6553 - val_loss: -0.9115 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6850 - val_loss: -0.9362 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6829 - val_loss: -0.9466 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6500 - val_loss: -0.9338 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7424 - val_loss: -1.0058 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7424 - val_loss: -0.9926 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7047 - val_loss: -1.0124 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: -0.7092 - val_loss: -1.0193 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7751 - val_loss: -1.0248 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7606 - val_loss: -0.9992 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7795 - val_loss: -1.0428 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8210 - val_loss: -1.0741 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8515 - val_loss: -1.0685 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8242 - val_loss: -1.1006 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8272 - val_loss: -1.1177 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8755 - val_loss: -1.0597 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9224 - val_loss: -1.1187 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9241 - val_loss: -1.1231 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9131 - val_loss: -1.1401 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8737 - val_loss: -1.1372 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.9073 - val_loss: -1.1705 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9667 - val_loss: -1.1314 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9072 - val_loss: -1.1382 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9193 - val_loss: -1.1584 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9012 - val_loss: -1.1863 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9426 - val_loss: -1.1701 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8949 - val_loss: -1.1733 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9353 - val_loss: -1.2112 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9784 - val_loss: -1.2044 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0630 - val_loss: -1.1801 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0139 - val_loss: -1.2196 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.9820 - val_loss: -1.2354 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -1.0333 - val_loss: -1.2015 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -1.0838 - val_loss: -1.1903 - learning_rate: 1.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -1.0401 - val_loss: -1.1873 - learning_rate: 1.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -1.0474 - val_loss: -1.2360 - learning_rate: 1.0000e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -1.0186 - val_loss: -1.2176 - learning_rate: 1.0000e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -1.0460 - val_loss: -1.2004 - learning_rate: 1.0000e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -1.0158 - val_loss: -1.2213 - learning_rate: 1.0000e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -1.0278 - val_loss: -1.2015 - learning_rate: 1.0000e-04\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0174 - val_loss: -1.2441 - learning_rate: 1.0000e-04\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -1.0812 - val_loss: -1.2561 - learning_rate: 1.0000e-04\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -1.0781 - val_loss: -1.2393 - learning_rate: 1.0000e-04\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0128 - val_loss: -1.2284 - learning_rate: 1.0000e-04\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0211 - val_loss: -1.2440 - learning_rate: 1.0000e-04\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -1.0639 - val_loss: -1.2399 - learning_rate: 1.0000e-04\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.1039 - val_loss: -1.2514 - learning_rate: 1.0000e-04\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -1.1497 - val_loss: -1.2204 - learning_rate: 5.0000e-05\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0732 - val_loss: -1.2083 - learning_rate: 5.0000e-05\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -1.1131 - val_loss: -1.2432 - learning_rate: 5.0000e-05\n",
      "Epoch 86/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -1.1227 - val_loss: -1.2296 - learning_rate: 5.0000e-05\n",
      "Epoch 87/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -1.1041 - val_loss: -1.2409 - learning_rate: 5.0000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 0.6407 - val_loss: 0.0622 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.4069 - val_loss: 0.0616 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.2917 - val_loss: 0.0244 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.1876 - val_loss: 0.0175 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.1242 - val_loss: 0.0173 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.1309 - val_loss: 0.0121 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0873 - val_loss: 0.0121 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0699 - val_loss: 0.0136 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0826 - val_loss: 0.0052 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0720 - val_loss: 0.0070 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0656 - val_loss: 0.0051 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0601 - val_loss: 0.0030 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0645 - val_loss: 0.0044 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0532 - val_loss: 0.0028 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0577 - val_loss: 0.0215 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0472 - val_loss: 0.0049 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0351 - val_loss: 0.0035 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0251 - val_loss: 0.0024 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0331 - val_loss: 0.0044 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.0321 - val_loss: 0.0042 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0382 - val_loss: 0.0022 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0220 - val_loss: 0.0039 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0261 - val_loss: 0.0051 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0359 - val_loss: 0.0031 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.0155 - val_loss: 0.0021 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0219 - val_loss: 0.0015 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0265 - val_loss: 0.0036 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0225 - val_loss: 0.0017 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0217 - val_loss: 0.0014 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0214 - val_loss: 0.0024 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0247 - val_loss: 0.0016 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0260 - val_loss: 0.0022 - learning_rate: 5.0000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0126 - val_loss: 0.0012 - learning_rate: 5.0000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0170 - val_loss: 0.0022 - learning_rate: 5.0000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.0199 - val_loss: 0.0019 - learning_rate: 5.0000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0166 - val_loss: 0.0015 - learning_rate: 5.0000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0147 - val_loss: 0.0025 - learning_rate: 5.0000e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0133 - val_loss: 0.0016 - learning_rate: 5.0000e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0153 - val_loss: 0.0015 - learning_rate: 2.5000e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0152 - val_loss: 0.0012 - learning_rate: 2.5000e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0168 - val_loss: 0.0013 - learning_rate: 2.5000e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0156 - val_loss: 0.0011 - learning_rate: 2.5000e-05\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0118 - val_loss: 0.0015 - learning_rate: 2.5000e-05\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0102 - val_loss: 0.0012 - learning_rate: 1.2500e-05\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0129 - val_loss: 0.0011 - learning_rate: 1.2500e-05\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0129 - val_loss: 0.0010 - learning_rate: 1.2500e-05\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0127 - val_loss: 0.0010 - learning_rate: 1.2500e-05\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0131 - val_loss: 0.0012 - learning_rate: 1.2500e-05\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0082 - val_loss: 9.9833e-04 - learning_rate: 1.2500e-05\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0031 - val_loss: 0.0010 - learning_rate: 1.2500e-05\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0095 - val_loss: 0.0011 - learning_rate: 1.2500e-05\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0132 - val_loss: 0.0012 - learning_rate: 6.2500e-06\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0172 - val_loss: 0.0013 - learning_rate: 6.2500e-06\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0170 - val_loss: 0.0013 - learning_rate: 6.2500e-06\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0096 - val_loss: 0.0013 - learning_rate: 6.2500e-06\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0049 - val_loss: 0.0011 - learning_rate: 6.2500e-06\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0151 - val_loss: 0.0012 - learning_rate: 3.1250e-06\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.0101 - val_loss: 0.0011 - learning_rate: 3.1250e-06\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0138 - val_loss: 0.0011 - learning_rate: 3.1250e-06\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.8262 - val_loss: 0.0604 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.4241 - val_loss: 0.0160 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.2542 - val_loss: -0.0079 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.1897 - val_loss: -0.0216 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.1094 - val_loss: -0.0735 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0750 - val_loss: -0.1198 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0293 - val_loss: -0.1432 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0188 - val_loss: -0.1575 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.0252 - val_loss: -0.1829 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.0386 - val_loss: -0.1963 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.0643 - val_loss: -0.2227 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.0763 - val_loss: -0.2414 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.0878 - val_loss: -0.2491 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.1024 - val_loss: -0.2766 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.1162 - val_loss: -0.2818 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.1428 - val_loss: -0.2979 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.1523 - val_loss: -0.3203 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.1745 - val_loss: -0.3410 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.1737 - val_loss: -0.3626 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.1848 - val_loss: -0.3720 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.2136 - val_loss: -0.3832 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.2064 - val_loss: -0.4088 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.2217 - val_loss: -0.4180 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.2382 - val_loss: -0.4424 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.2513 - val_loss: -0.4564 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.2664 - val_loss: -0.4754 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2940 - val_loss: -0.5066 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3289 - val_loss: -0.5248 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3596 - val_loss: -0.5582 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3600 - val_loss: -0.5755 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3879 - val_loss: -0.6066 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3804 - val_loss: -0.6353 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4281 - val_loss: -0.6517 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: -0.3899 - val_loss: -0.6623 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4065 - val_loss: -0.7038 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4545 - val_loss: -0.7227 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4493 - val_loss: -0.7534 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4671 - val_loss: -0.7656 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5307 - val_loss: -0.8057 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5384 - val_loss: -0.8293 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5531 - val_loss: -0.8477 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5578 - val_loss: -0.8569 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5506 - val_loss: -0.8687 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6648 - val_loss: -0.9112 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6569 - val_loss: -0.9233 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6700 - val_loss: -0.9345 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6728 - val_loss: -0.9502 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7074 - val_loss: -0.9849 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7234 - val_loss: -0.9889 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7180 - val_loss: -0.9916 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7382 - val_loss: -1.0226 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7298 - val_loss: -1.0233 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7372 - val_loss: -1.0276 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8104 - val_loss: -1.0596 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7961 - val_loss: -1.0660 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7772 - val_loss: -1.1009 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8161 - val_loss: -1.1003 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8259 - val_loss: -1.1009 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8628 - val_loss: -1.1088 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7843 - val_loss: -1.1127 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8069 - val_loss: -1.1302 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9023 - val_loss: -1.1178 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8587 - val_loss: -1.1494 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8654 - val_loss: -1.1453 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9232 - val_loss: -1.1357 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8546 - val_loss: -1.1326 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9075 - val_loss: -1.1661 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8281 - val_loss: -1.1846 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9334 - val_loss: -1.1784 - learning_rate: 1.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9563 - val_loss: -1.1851 - learning_rate: 1.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9400 - val_loss: -1.2171 - learning_rate: 1.0000e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9140 - val_loss: -1.2133 - learning_rate: 1.0000e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9186 - val_loss: -1.2249 - learning_rate: 1.0000e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8988 - val_loss: -1.2125 - learning_rate: 1.0000e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9431 - val_loss: -1.2399 - learning_rate: 1.0000e-04\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9986 - val_loss: -1.2372 - learning_rate: 1.0000e-04\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0471 - val_loss: -1.1897 - learning_rate: 1.0000e-04\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9575 - val_loss: -1.2440 - learning_rate: 1.0000e-04\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9784 - val_loss: -1.2109 - learning_rate: 1.0000e-04\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0138 - val_loss: -1.2517 - learning_rate: 1.0000e-04\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9692 - val_loss: -1.2321 - learning_rate: 1.0000e-04\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9874 - val_loss: -1.2557 - learning_rate: 1.0000e-04\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9500 - val_loss: -1.2460 - learning_rate: 1.0000e-04\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0499 - val_loss: -1.2577 - learning_rate: 1.0000e-04\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9651 - val_loss: -1.1952 - learning_rate: 1.0000e-04\n",
      "Epoch 86/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9061 - val_loss: -1.2683 - learning_rate: 1.0000e-04\n",
      "Epoch 87/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0556 - val_loss: -1.2586 - learning_rate: 1.0000e-04\n",
      "Epoch 88/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9879 - val_loss: -1.2658 - learning_rate: 1.0000e-04\n",
      "Epoch 89/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0004 - val_loss: -1.2728 - learning_rate: 1.0000e-04\n",
      "Epoch 90/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0330 - val_loss: -1.2520 - learning_rate: 1.0000e-04\n",
      "Epoch 91/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0081 - val_loss: -1.2809 - learning_rate: 1.0000e-04\n",
      "Epoch 92/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0478 - val_loss: -1.2508 - learning_rate: 1.0000e-04\n",
      "Epoch 93/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9784 - val_loss: -1.2449 - learning_rate: 1.0000e-04\n",
      "Epoch 94/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -1.0821 - val_loss: -1.2672 - learning_rate: 1.0000e-04\n",
      "Epoch 95/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9712 - val_loss: -1.2830 - learning_rate: 1.0000e-04\n",
      "Epoch 96/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0260 - val_loss: -1.2729 - learning_rate: 1.0000e-04\n",
      "Epoch 97/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0037 - val_loss: -1.2593 - learning_rate: 1.0000e-04\n",
      "Epoch 98/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.1117 - val_loss: -1.2639 - learning_rate: 1.0000e-04\n",
      "Epoch 99/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.1007 - val_loss: -1.2724 - learning_rate: 1.0000e-04\n",
      "Epoch 100/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0898 - val_loss: -1.2675 - learning_rate: 1.0000e-04\n",
      "Epoch 101/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0599 - val_loss: -1.2262 - learning_rate: 5.0000e-05\n",
      "Epoch 102/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9914 - val_loss: -1.2528 - learning_rate: 5.0000e-05\n",
      "Epoch 103/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9761 - val_loss: -1.2824 - learning_rate: 5.0000e-05\n",
      "Epoch 104/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0437 - val_loss: -1.3031 - learning_rate: 5.0000e-05\n",
      "Epoch 105/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.1251 - val_loss: -1.2868 - learning_rate: 5.0000e-05\n",
      "Epoch 106/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0298 - val_loss: -1.2965 - learning_rate: 5.0000e-05\n",
      "Epoch 107/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0636 - val_loss: -1.3022 - learning_rate: 5.0000e-05\n",
      "Epoch 108/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0636 - val_loss: -1.2948 - learning_rate: 5.0000e-05\n",
      "Epoch 109/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0472 - val_loss: -1.2944 - learning_rate: 5.0000e-05\n",
      "Epoch 110/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0285 - val_loss: -1.3088 - learning_rate: 2.5000e-05\n",
      "Epoch 111/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0886 - val_loss: -1.2985 - learning_rate: 2.5000e-05\n",
      "Epoch 112/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0956 - val_loss: -1.2987 - learning_rate: 2.5000e-05\n",
      "Epoch 113/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0262 - val_loss: -1.2894 - learning_rate: 2.5000e-05\n",
      "Epoch 114/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -1.0010 - val_loss: -1.2919 - learning_rate: 2.5000e-05\n",
      "Epoch 115/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.1374 - val_loss: -1.2708 - learning_rate: 2.5000e-05\n",
      "Epoch 116/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0676 - val_loss: -1.2876 - learning_rate: 1.2500e-05\n",
      "Epoch 117/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.1615 - val_loss: -1.2992 - learning_rate: 1.2500e-05\n",
      "Epoch 118/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.1427 - val_loss: -1.2947 - learning_rate: 1.2500e-05\n",
      "Epoch 119/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0845 - val_loss: -1.2892 - learning_rate: 1.2500e-05\n",
      "Epoch 120/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.1689 - val_loss: -1.2822 - learning_rate: 1.2500e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 15ms/step - loss: 0.8301 - val_loss: 0.0322 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.4640 - val_loss: 0.0264 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.3094 - val_loss: 0.0254 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1965 - val_loss: 0.0162 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.1626 - val_loss: 0.0130 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1259 - val_loss: 0.0043 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1183 - val_loss: 0.0112 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0942 - val_loss: 0.0054 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0888 - val_loss: 0.0067 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0955 - val_loss: 0.0043 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0706 - val_loss: 0.0142 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0728 - val_loss: 0.0035 - learning_rate: 5.0000e-05\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0468 - val_loss: 0.0040 - learning_rate: 5.0000e-05\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0557 - val_loss: 0.0082 - learning_rate: 5.0000e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0464 - val_loss: 0.0177 - learning_rate: 5.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0654 - val_loss: 0.0084 - learning_rate: 5.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0616 - val_loss: 0.0104 - learning_rate: 5.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0552 - val_loss: 0.0078 - learning_rate: 2.5000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0405 - val_loss: 0.0090 - learning_rate: 2.5000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0439 - val_loss: 0.0059 - learning_rate: 2.5000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0446 - val_loss: 0.0058 - learning_rate: 2.5000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0516 - val_loss: 0.0065 - learning_rate: 2.5000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.5689 - val_loss: -0.0019 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.2604 - val_loss: -0.0244 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.2046 - val_loss: -0.0251 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.1393 - val_loss: -0.0268 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0812 - val_loss: -0.0572 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0487 - val_loss: -0.0665 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.0416 - val_loss: -0.0851 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0227 - val_loss: -0.1090 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.0114 - val_loss: -0.1211 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.0419 - val_loss: -0.1503 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.0606 - val_loss: -0.1643 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.0691 - val_loss: -0.1818 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.0834 - val_loss: -0.2093 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.1213 - val_loss: -0.2284 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.1266 - val_loss: -0.2627 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.1647 - val_loss: -0.2842 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.1793 - val_loss: -0.3104 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.1872 - val_loss: -0.3461 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.2107 - val_loss: -0.3850 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.2348 - val_loss: -0.4155 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.2587 - val_loss: -0.4452 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3066 - val_loss: -0.4810 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3265 - val_loss: -0.5219 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.3404 - val_loss: -0.5457 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.3611 - val_loss: -0.6154 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4149 - val_loss: -0.6317 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.4224 - val_loss: -0.6750 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.4327 - val_loss: -0.7268 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5116 - val_loss: -0.7900 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5357 - val_loss: -0.8401 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: -0.5418 - val_loss: -0.8759 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5538 - val_loss: -0.9122 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6102 - val_loss: -0.9493 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6305 - val_loss: -0.9738 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6772 - val_loss: -1.0160 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6784 - val_loss: -1.0231 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.7266 - val_loss: -1.0937 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.7401 - val_loss: -1.0920 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7377 - val_loss: -1.1225 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.7436 - val_loss: -1.1326 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.7572 - val_loss: -1.1998 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7905 - val_loss: -1.2112 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7494 - val_loss: -1.2125 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.8435 - val_loss: -1.2289 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.8685 - val_loss: -1.2710 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.8740 - val_loss: -1.2912 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.8662 - val_loss: -1.3173 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.8600 - val_loss: -1.3300 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.8591 - val_loss: -1.3610 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8693 - val_loss: -1.3535 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8474 - val_loss: -1.3713 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9319 - val_loss: -1.3293 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.9272 - val_loss: -1.3641 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0052 - val_loss: -1.3505 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.9217 - val_loss: -1.3672 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9494 - val_loss: -1.4136 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -1.0060 - val_loss: -1.4361 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9828 - val_loss: -1.4106 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: -0.9746 - val_loss: -1.4516 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.9652 - val_loss: -1.4674 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -1.0029 - val_loss: -1.4668 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.9631 - val_loss: -1.4454 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -1.0525 - val_loss: -1.4232 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.9473 - val_loss: -1.4875 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -1.0271 - val_loss: -1.4575 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0040 - val_loss: -1.4788 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -1.0364 - val_loss: -1.4858 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0190 - val_loss: -1.4813 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0796 - val_loss: -1.5138 - learning_rate: 1.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -1.0084 - val_loss: -1.4469 - learning_rate: 1.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -1.0656 - val_loss: -1.5187 - learning_rate: 1.0000e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -1.0689 - val_loss: -1.5444 - learning_rate: 1.0000e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -1.0804 - val_loss: -1.5510 - learning_rate: 1.0000e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -1.0077 - val_loss: -1.5305 - learning_rate: 1.0000e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9332 - val_loss: -1.5552 - learning_rate: 1.0000e-04\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -1.0203 - val_loss: -1.5305 - learning_rate: 1.0000e-04\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -1.1028 - val_loss: -1.5180 - learning_rate: 1.0000e-04\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0743 - val_loss: -1.4994 - learning_rate: 1.0000e-04\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -1.1568 - val_loss: -1.5558 - learning_rate: 1.0000e-04\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -1.0668 - val_loss: -1.5553 - learning_rate: 1.0000e-04\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0642 - val_loss: -1.5468 - learning_rate: 1.0000e-04\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -1.0817 - val_loss: -1.5357 - learning_rate: 1.0000e-04\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0987 - val_loss: -1.5477 - learning_rate: 1.0000e-04\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 1s/step - loss: -1.1057 - val_loss: -1.5684 - learning_rate: 1.0000e-04\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.0812 - val_loss: -1.5687 - learning_rate: 1.0000e-04\n",
      "Epoch 86/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.9908 - val_loss: -1.5726 - learning_rate: 1.0000e-04\n",
      "Epoch 87/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.1298 - val_loss: -1.5673 - learning_rate: 1.0000e-04\n",
      "Epoch 88/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0877 - val_loss: -1.5818 - learning_rate: 1.0000e-04\n",
      "Epoch 89/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.1624 - val_loss: -1.5651 - learning_rate: 1.0000e-04\n",
      "Epoch 90/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -1.1614 - val_loss: -1.5662 - learning_rate: 1.0000e-04\n",
      "Epoch 91/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.1603 - val_loss: -1.5777 - learning_rate: 1.0000e-04\n",
      "Epoch 92/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0424 - val_loss: -1.5757 - learning_rate: 1.0000e-04\n",
      "Epoch 93/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.1666 - val_loss: -1.5524 - learning_rate: 1.0000e-04\n",
      "Epoch 94/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -1.1278 - val_loss: -1.5807 - learning_rate: 5.0000e-05\n",
      "Epoch 95/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.1499 - val_loss: -1.5675 - learning_rate: 5.0000e-05\n",
      "Epoch 96/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0750 - val_loss: -1.5621 - learning_rate: 5.0000e-05\n",
      "Epoch 97/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.1470 - val_loss: -1.5732 - learning_rate: 5.0000e-05\n",
      "Epoch 98/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.1328 - val_loss: -1.5799 - learning_rate: 5.0000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.7894 - val_loss: 0.0139 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.3269 - val_loss: 4.5913e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.2117 - val_loss: -0.0053 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.1616 - val_loss: -0.0140 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.1292 - val_loss: -0.0172 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.1072 - val_loss: -0.0226 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0903 - val_loss: -0.0246 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0908 - val_loss: -0.0293 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0732 - val_loss: -0.0251 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0497 - val_loss: -0.0220 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0520 - val_loss: -0.0182 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0313 - val_loss: -0.0204 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0374 - val_loss: -0.0194 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0171 - val_loss: -0.0248 - learning_rate: 5.0000e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0143 - val_loss: -0.0212 - learning_rate: 5.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0331 - val_loss: -0.0229 - learning_rate: 5.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0273 - val_loss: -0.0172 - learning_rate: 5.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0244 - val_loss: -0.0227 - learning_rate: 5.0000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.7414 - val_loss: 0.0762 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.4982 - val_loss: 0.0167 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.3072 - val_loss: -0.0233 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.2026 - val_loss: -0.0463 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.1723 - val_loss: -0.0591 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1091 - val_loss: -0.0996 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0522 - val_loss: -0.1263 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0294 - val_loss: -0.1478 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0020 - val_loss: -0.1810 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.0466 - val_loss: -0.2106 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.0720 - val_loss: -0.2358 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.0745 - val_loss: -0.2635 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.0949 - val_loss: -0.2842 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.1567 - val_loss: -0.3270 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.1758 - val_loss: -0.3484 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.1836 - val_loss: -0.3797 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.2022 - val_loss: -0.3938 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: -0.2299 - val_loss: -0.4449 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.2591 - val_loss: -0.4695 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.2401 - val_loss: -0.5130 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3276 - val_loss: -0.5473 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3096 - val_loss: -0.5667 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3625 - val_loss: -0.6013 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3691 - val_loss: -0.6367 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4037 - val_loss: -0.6591 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4267 - val_loss: -0.6932 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4539 - val_loss: -0.7358 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4408 - val_loss: -0.7610 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4814 - val_loss: -0.7775 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5134 - val_loss: -0.8210 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5336 - val_loss: -0.8319 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5542 - val_loss: -0.8791 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5897 - val_loss: -0.8873 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6489 - val_loss: -0.9061 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6315 - val_loss: -0.9428 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6394 - val_loss: -0.9619 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6389 - val_loss: -0.9734 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6957 - val_loss: -0.9949 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6926 - val_loss: -0.9918 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7265 - val_loss: -1.0404 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7331 - val_loss: -1.0707 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7440 - val_loss: -1.0656 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8061 - val_loss: -1.1192 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7820 - val_loss: -1.0860 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7839 - val_loss: -1.1160 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7790 - val_loss: -1.1309 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7722 - val_loss: -1.1334 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8656 - val_loss: -1.1261 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8453 - val_loss: -1.1535 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8622 - val_loss: -1.1528 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8273 - val_loss: -1.1539 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8507 - val_loss: -1.1855 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8566 - val_loss: -1.1518 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9109 - val_loss: -1.1977 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8966 - val_loss: -1.2202 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9451 - val_loss: -1.2205 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9133 - val_loss: -1.2372 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9167 - val_loss: -1.2671 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9845 - val_loss: -1.2475 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9317 - val_loss: -1.2265 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9188 - val_loss: -1.2489 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9166 - val_loss: -1.2715 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9574 - val_loss: -1.2778 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9372 - val_loss: -1.2551 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9318 - val_loss: -1.2919 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9793 - val_loss: -1.2620 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9963 - val_loss: -1.2744 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0125 - val_loss: -1.2766 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9999 - val_loss: -1.2744 - learning_rate: 1.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0454 - val_loss: -1.2443 - learning_rate: 1.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -1.0033 - val_loss: -1.2848 - learning_rate: 5.0000e-05\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0351 - val_loss: -1.3026 - learning_rate: 5.0000e-05\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0695 - val_loss: -1.2762 - learning_rate: 5.0000e-05\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0363 - val_loss: -1.2982 - learning_rate: 5.0000e-05\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0396 - val_loss: -1.2914 - learning_rate: 5.0000e-05\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0188 - val_loss: -1.2943 - learning_rate: 5.0000e-05\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0462 - val_loss: -1.2938 - learning_rate: 5.0000e-05\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0321 - val_loss: -1.2843 - learning_rate: 2.5000e-05\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9766 - val_loss: -1.2952 - learning_rate: 2.5000e-05\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.1261 - val_loss: -1.2890 - learning_rate: 2.5000e-05\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9915 - val_loss: -1.2938 - learning_rate: 2.5000e-05\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9855 - val_loss: -1.2850 - learning_rate: 2.5000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 0.6108 - val_loss: 0.0089 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.3219 - val_loss: -0.0093 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.2522 - val_loss: -0.0227 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1702 - val_loss: -0.0202 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.1319 - val_loss: -0.0397 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0857 - val_loss: -0.0396 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0609 - val_loss: -0.0578 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0611 - val_loss: -0.0610 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0557 - val_loss: -0.0664 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0232 - val_loss: -0.0752 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0371 - val_loss: -0.0619 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0219 - val_loss: -0.0727 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0207 - val_loss: -0.0869 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: -0.0273 - val_loss: -0.0855 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0021 - val_loss: -0.0902 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0187 - val_loss: -0.0929 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0258 - val_loss: -0.0895 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0102 - val_loss: -0.0916 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0262 - val_loss: -0.1003 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0337 - val_loss: -0.0982 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0315 - val_loss: -0.1067 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0373 - val_loss: -0.1056 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0478 - val_loss: -0.1080 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0387 - val_loss: -0.1131 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0485 - val_loss: -0.1180 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.0425 - val_loss: -0.1182 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.0556 - val_loss: -0.1193 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0559 - val_loss: -0.1120 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0361 - val_loss: -0.1201 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.0654 - val_loss: -0.1205 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0602 - val_loss: -0.1062 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0620 - val_loss: -0.1170 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0680 - val_loss: -0.1145 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: -0.0777 - val_loss: -0.1073 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0603 - val_loss: -0.1121 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.0649 - val_loss: -0.1187 - learning_rate: 5.0000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0757 - val_loss: -0.1208 - learning_rate: 5.0000e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0879 - val_loss: -0.1208 - learning_rate: 5.0000e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0872 - val_loss: -0.1164 - learning_rate: 5.0000e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0619 - val_loss: -0.1172 - learning_rate: 5.0000e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0698 - val_loss: -0.1204 - learning_rate: 5.0000e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0695 - val_loss: -0.1185 - learning_rate: 5.0000e-05\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0820 - val_loss: -0.1215 - learning_rate: 2.5000e-05\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0733 - val_loss: -0.1218 - learning_rate: 2.5000e-05\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.0708 - val_loss: -0.1238 - learning_rate: 2.5000e-05\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.0824 - val_loss: -0.1232 - learning_rate: 2.5000e-05\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.0838 - val_loss: -0.1238 - learning_rate: 2.5000e-05\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.0681 - val_loss: -0.1229 - learning_rate: 2.5000e-05\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0930 - val_loss: -0.1231 - learning_rate: 2.5000e-05\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.0835 - val_loss: -0.1221 - learning_rate: 2.5000e-05\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0585 - val_loss: -0.1238 - learning_rate: 1.2500e-05\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.0690 - val_loss: -0.1238 - learning_rate: 1.2500e-05\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.0848 - val_loss: -0.1238 - learning_rate: 1.2500e-05\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0933 - val_loss: -0.1238 - learning_rate: 1.2500e-05\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0725 - val_loss: -0.1242 - learning_rate: 1.2500e-05\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0761 - val_loss: -0.1250 - learning_rate: 1.2500e-05\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0564 - val_loss: -0.1251 - learning_rate: 1.2500e-05\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: -0.0808 - val_loss: -0.1248 - learning_rate: 1.2500e-05\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: -0.0841 - val_loss: -0.1248 - learning_rate: 1.2500e-05\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0719 - val_loss: -0.1249 - learning_rate: 1.2500e-05\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0867 - val_loss: -0.1248 - learning_rate: 1.2500e-05\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0745 - val_loss: -0.1249 - learning_rate: 6.2500e-06\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0942 - val_loss: -0.1243 - learning_rate: 6.2500e-06\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0772 - val_loss: -0.1245 - learning_rate: 6.2500e-06\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0744 - val_loss: -0.1245 - learning_rate: 6.2500e-06\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: -0.0764 - val_loss: -0.1246 - learning_rate: 6.2500e-06\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.0828 - val_loss: -0.1246 - learning_rate: 3.1250e-06\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.7181 - val_loss: 0.0455 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.3766 - val_loss: -0.0023 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.2341 - val_loss: -0.0236 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1312 - val_loss: -0.0400 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1082 - val_loss: -0.0517 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0864 - val_loss: -0.0640 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0549 - val_loss: -0.0724 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0406 - val_loss: -0.0824 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.0071 - val_loss: -0.0964 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0129 - val_loss: -0.1122 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0038 - val_loss: -0.1258 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0507 - val_loss: -0.1372 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0400 - val_loss: -0.1617 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0533 - val_loss: -0.1848 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0743 - val_loss: -0.2052 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0870 - val_loss: -0.2234 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.1153 - val_loss: -0.2493 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.0948 - val_loss: -0.2721 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.1554 - val_loss: -0.2979 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.1650 - val_loss: -0.3218 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.1609 - val_loss: -0.3417 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.2024 - val_loss: -0.3852 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.2109 - val_loss: -0.4237 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.2629 - val_loss: -0.4464 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2780 - val_loss: -0.4841 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3130 - val_loss: -0.5153 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3197 - val_loss: -0.5495 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3668 - val_loss: -0.5922 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3746 - val_loss: -0.6190 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4183 - val_loss: -0.6639 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4390 - val_loss: -0.6905 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4756 - val_loss: -0.7205 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5046 - val_loss: -0.7512 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5069 - val_loss: -0.7951 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5549 - val_loss: -0.8351 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5787 - val_loss: -0.8667 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5589 - val_loss: -0.9077 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5785 - val_loss: -0.9187 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6632 - val_loss: -0.9409 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6362 - val_loss: -0.9577 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6706 - val_loss: -1.0046 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6488 - val_loss: -1.0145 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7489 - val_loss: -1.0277 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7355 - val_loss: -1.0661 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7392 - val_loss: -1.0757 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7396 - val_loss: -1.0912 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7764 - val_loss: -1.1069 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: -0.7500 - val_loss: -1.1251 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7994 - val_loss: -1.1411 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8003 - val_loss: -1.1512 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8194 - val_loss: -1.1634 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8067 - val_loss: -1.1364 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8114 - val_loss: -1.1654 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8435 - val_loss: -1.1907 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8981 - val_loss: -1.1905 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8410 - val_loss: -1.1919 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8914 - val_loss: -1.1906 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8902 - val_loss: -1.2051 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9244 - val_loss: -1.2312 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8539 - val_loss: -1.2193 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9383 - val_loss: -1.2192 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9069 - val_loss: -1.2362 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9231 - val_loss: -1.2525 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9599 - val_loss: -1.2521 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9257 - val_loss: -1.2355 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8980 - val_loss: -1.2280 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9284 - val_loss: -1.2348 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9521 - val_loss: -1.2462 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9283 - val_loss: -1.2552 - learning_rate: 5.0000e-05\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9713 - val_loss: -1.2563 - learning_rate: 5.0000e-05\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9933 - val_loss: -1.2689 - learning_rate: 5.0000e-05\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9246 - val_loss: -1.2678 - learning_rate: 5.0000e-05\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9891 - val_loss: -1.2822 - learning_rate: 5.0000e-05\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9796 - val_loss: -1.2664 - learning_rate: 5.0000e-05\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9749 - val_loss: -1.2711 - learning_rate: 5.0000e-05\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0012 - val_loss: -1.2724 - learning_rate: 5.0000e-05\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m661s\u001b[0m 3s/step - loss: -0.9846 - val_loss: -1.2579 - learning_rate: 5.0000e-05\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -1.0147 - val_loss: -1.2673 - learning_rate: 5.0000e-05\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.9471 - val_loss: -1.2830 - learning_rate: 2.5000e-05\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.9801 - val_loss: -1.2761 - learning_rate: 2.5000e-05\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9024 - val_loss: -1.2673 - learning_rate: 2.5000e-05\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9759 - val_loss: -1.2693 - learning_rate: 2.5000e-05\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0071 - val_loss: -1.2609 - learning_rate: 2.5000e-05\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0116 - val_loss: -1.2670 - learning_rate: 2.5000e-05\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0033 - val_loss: -1.2656 - learning_rate: 1.2500e-05\n",
      "Epoch 86/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.9878 - val_loss: -1.2630 - learning_rate: 1.2500e-05\n",
      "Epoch 87/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0351 - val_loss: -1.2764 - learning_rate: 1.2500e-05\n",
      "Epoch 88/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0214 - val_loss: -1.2740 - learning_rate: 1.2500e-05\n",
      "Epoch 89/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9656 - val_loss: -1.2839 - learning_rate: 1.2500e-05\n",
      "Epoch 90/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9947 - val_loss: -1.2772 - learning_rate: 1.2500e-05\n",
      "Epoch 91/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0372 - val_loss: -1.2721 - learning_rate: 1.2500e-05\n",
      "Epoch 92/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0356 - val_loss: -1.2710 - learning_rate: 1.2500e-05\n",
      "Epoch 93/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.9407 - val_loss: -1.2754 - learning_rate: 1.2500e-05\n",
      "Epoch 94/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -1.0249 - val_loss: -1.2713 - learning_rate: 1.2500e-05\n",
      "Epoch 95/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.9892 - val_loss: -1.2747 - learning_rate: 6.2500e-06\n",
      "Epoch 96/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -1.0349 - val_loss: -1.2757 - learning_rate: 6.2500e-06\n",
      "Epoch 97/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.9595 - val_loss: -1.2692 - learning_rate: 6.2500e-06\n",
      "Epoch 98/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9478 - val_loss: -1.2685 - learning_rate: 6.2500e-06\n",
      "Epoch 99/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -1.1276 - val_loss: -1.2723 - learning_rate: 6.2500e-06\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 0.7642 - val_loss: 0.0925 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.3748 - val_loss: 0.0527 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.2682 - val_loss: 0.0157 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.2062 - val_loss: 0.0213 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.1510 - val_loss: 0.0117 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.1309 - val_loss: 0.0090 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0831 - val_loss: 0.0092 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0862 - val_loss: 0.0147 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0627 - val_loss: 0.0058 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0596 - val_loss: 0.0065 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0635 - val_loss: 0.0070 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0559 - val_loss: 0.0082 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0452 - val_loss: 0.0044 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0323 - val_loss: 0.0021 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0291 - val_loss: 0.0027 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0434 - val_loss: 0.0046 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0292 - val_loss: 0.0042 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0469 - val_loss: 0.0069 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0258 - val_loss: 0.0038 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0334 - val_loss: 0.0028 - learning_rate: 5.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0364 - val_loss: 0.0083 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0334 - val_loss: 0.0028 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0212 - val_loss: 0.0086 - learning_rate: 5.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0320 - val_loss: 0.0022 - learning_rate: 5.0000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - loss: 0.8124 - val_loss: -0.0060 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.3519 - val_loss: -0.0176 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.2610 - val_loss: -0.0407 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.1645 - val_loss: -0.0427 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1160 - val_loss: -0.0478 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0792 - val_loss: -0.0737 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0514 - val_loss: -0.0917 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0196 - val_loss: -0.1109 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.0029 - val_loss: -0.1276 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.0263 - val_loss: -0.1621 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.0301 - val_loss: -0.1816 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.0656 - val_loss: -0.2133 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.1012 - val_loss: -0.2308 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.0840 - val_loss: -0.2477 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.1317 - val_loss: -0.2907 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.1361 - val_loss: -0.3113 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.1547 - val_loss: -0.3387 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.1666 - val_loss: -0.3482 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.1771 - val_loss: -0.3837 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.1995 - val_loss: -0.3977 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.2252 - val_loss: -0.4265 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2334 - val_loss: -0.4585 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2928 - val_loss: -0.4934 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.2699 - val_loss: -0.5169 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3458 - val_loss: -0.5529 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3263 - val_loss: -0.5865 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3790 - val_loss: -0.6337 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4060 - val_loss: -0.6728 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.4614 - val_loss: -0.7144 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.4623 - val_loss: -0.7504 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4736 - val_loss: -0.7842 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5176 - val_loss: -0.8107 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5285 - val_loss: -0.8364 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5509 - val_loss: -0.8650 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6305 - val_loss: -0.9179 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6512 - val_loss: -0.9377 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.6476 - val_loss: -0.9724 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7087 - val_loss: -0.9896 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.7195 - val_loss: -0.9891 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.6951 - val_loss: -1.0200 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7029 - val_loss: -1.0358 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7565 - val_loss: -1.0629 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7763 - val_loss: -1.0670 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7633 - val_loss: -1.0924 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8611 - val_loss: -1.0708 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8153 - val_loss: -1.0757 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8722 - val_loss: -1.1516 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8808 - val_loss: -1.1890 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.8203 - val_loss: -1.1491 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8538 - val_loss: -1.1806 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9520 - val_loss: -1.1497 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.9060 - val_loss: -1.1766 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8906 - val_loss: -1.1961 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.8975 - val_loss: -1.2106 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.9272 - val_loss: -1.2280 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9650 - val_loss: -1.2405 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -1.0435 - val_loss: -1.2459 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.9522 - val_loss: -1.2696 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9582 - val_loss: -1.2593 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9376 - val_loss: -1.2334 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9896 - val_loss: -1.2354 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.9565 - val_loss: -1.2686 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9844 - val_loss: -1.2783 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.9788 - val_loss: -1.3148 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0243 - val_loss: -1.2657 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9791 - val_loss: -1.2451 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0918 - val_loss: -1.3327 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9932 - val_loss: -1.2990 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.9651 - val_loss: -1.2607 - learning_rate: 1.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9305 - val_loss: -1.2961 - learning_rate: 1.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.9944 - val_loss: -1.3203 - learning_rate: 1.0000e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -1.0821 - val_loss: -1.3453 - learning_rate: 1.0000e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -1.0795 - val_loss: -1.3263 - learning_rate: 1.0000e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: -1.0524 - val_loss: -1.3081 - learning_rate: 1.0000e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0584 - val_loss: -1.3236 - learning_rate: 1.0000e-04\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -1.0576 - val_loss: -1.3180 - learning_rate: 1.0000e-04\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0245 - val_loss: -1.2741 - learning_rate: 1.0000e-04\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0514 - val_loss: -1.3139 - learning_rate: 5.0000e-05\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.1216 - val_loss: -1.3330 - learning_rate: 5.0000e-05\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0150 - val_loss: -1.3519 - learning_rate: 5.0000e-05\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0423 - val_loss: -1.3783 - learning_rate: 5.0000e-05\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -1.0808 - val_loss: -1.3152 - learning_rate: 5.0000e-05\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -1.0950 - val_loss: -1.3203 - learning_rate: 5.0000e-05\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -1.0724 - val_loss: -1.3449 - learning_rate: 5.0000e-05\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0777 - val_loss: -1.3564 - learning_rate: 5.0000e-05\n",
      "Epoch 86/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -1.0475 - val_loss: -1.3141 - learning_rate: 5.0000e-05\n",
      "Epoch 87/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0328 - val_loss: -1.3417 - learning_rate: 2.5000e-05\n",
      "Epoch 88/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0816 - val_loss: -1.3567 - learning_rate: 2.5000e-05\n",
      "Epoch 89/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.1037 - val_loss: -1.3594 - learning_rate: 2.5000e-05\n",
      "Epoch 90/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -1.0964 - val_loss: -1.3522 - learning_rate: 2.5000e-05\n",
      "Epoch 91/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0569 - val_loss: -1.3501 - learning_rate: 2.5000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.9957 - val_loss: 0.0636 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.5854 - val_loss: 0.0213 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.3798 - val_loss: 0.0213 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.2680 - val_loss: 0.0172 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.1953 - val_loss: 0.0142 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1559 - val_loss: 0.0069 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1205 - val_loss: 0.0111 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1296 - val_loss: 0.0096 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0973 - val_loss: 0.0038 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0581 - val_loss: 0.0094 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0855 - val_loss: 0.0075 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0617 - val_loss: 0.0190 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0682 - val_loss: 0.0045 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0542 - val_loss: 0.0084 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0465 - val_loss: 0.0055 - learning_rate: 5.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0458 - val_loss: 0.0064 - learning_rate: 5.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0479 - val_loss: 0.0028 - learning_rate: 5.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0305 - val_loss: 1.3976e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0483 - val_loss: 0.0049 - learning_rate: 5.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0357 - val_loss: 0.0013 - learning_rate: 5.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0449 - val_loss: 0.0019 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0311 - val_loss: 0.0045 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0352 - val_loss: 0.0033 - learning_rate: 5.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0390 - val_loss: 0.0052 - learning_rate: 2.5000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0277 - val_loss: 0.0038 - learning_rate: 2.5000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0347 - val_loss: 0.0056 - learning_rate: 2.5000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0427 - val_loss: 0.0014 - learning_rate: 2.5000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0373 - val_loss: 0.0034 - learning_rate: 2.5000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.7786 - val_loss: 0.0344 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.3877 - val_loss: -0.0113 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.3436 - val_loss: -0.0273 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1899 - val_loss: -0.0332 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1523 - val_loss: -0.0450 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1085 - val_loss: -0.0533 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0727 - val_loss: -0.0563 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0543 - val_loss: -0.0579 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0586 - val_loss: -0.0769 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0300 - val_loss: -0.0801 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0129 - val_loss: -0.0948 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0020 - val_loss: -0.1028 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.0199 - val_loss: -0.1250 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.0334 - val_loss: -0.1350 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.0480 - val_loss: -0.1621 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0731 - val_loss: -0.1928 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0772 - val_loss: -0.2188 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.1111 - val_loss: -0.2419 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.1443 - val_loss: -0.2640 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.1283 - val_loss: -0.2853 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.1768 - val_loss: -0.3053 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.1785 - val_loss: -0.3369 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.2122 - val_loss: -0.3546 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2372 - val_loss: -0.3834 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2364 - val_loss: -0.4071 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2826 - val_loss: -0.4289 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2924 - val_loss: -0.4514 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3160 - val_loss: -0.4930 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3164 - val_loss: -0.5190 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3525 - val_loss: -0.5605 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3796 - val_loss: -0.5959 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3674 - val_loss: -0.6386 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4393 - val_loss: -0.6710 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4668 - val_loss: -0.7121 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.4619 - val_loss: -0.7512 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4995 - val_loss: -0.7871 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5568 - val_loss: -0.8115 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5469 - val_loss: -0.8535 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5439 - val_loss: -0.8798 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5926 - val_loss: -0.8993 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6132 - val_loss: -0.9297 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6300 - val_loss: -0.9600 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6714 - val_loss: -0.9926 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6693 - val_loss: -1.0210 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6682 - val_loss: -1.0403 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6797 - val_loss: -1.0756 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7042 - val_loss: -1.0826 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7438 - val_loss: -1.0978 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7670 - val_loss: -1.1075 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7924 - val_loss: -1.1560 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7581 - val_loss: -1.1759 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7551 - val_loss: -1.2165 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8491 - val_loss: -1.2131 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7782 - val_loss: -1.2199 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.8276 - val_loss: -1.2509 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8357 - val_loss: -1.2436 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8338 - val_loss: -1.2772 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.8913 - val_loss: -1.2954 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8760 - val_loss: -1.2633 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8671 - val_loss: -1.2919 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8953 - val_loss: -1.2984 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.9250 - val_loss: -1.2850 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9110 - val_loss: -1.3600 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9507 - val_loss: -1.3388 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9563 - val_loss: -1.3806 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.9814 - val_loss: -1.3928 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9498 - val_loss: -1.3464 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0062 - val_loss: -1.3871 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0074 - val_loss: -1.4095 - learning_rate: 1.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0144 - val_loss: -1.4028 - learning_rate: 1.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9611 - val_loss: -1.3855 - learning_rate: 1.0000e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -1.0193 - val_loss: -1.4178 - learning_rate: 1.0000e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9528 - val_loss: -1.4431 - learning_rate: 1.0000e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0152 - val_loss: -1.4374 - learning_rate: 1.0000e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0330 - val_loss: -1.3945 - learning_rate: 1.0000e-04\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0255 - val_loss: -1.4352 - learning_rate: 1.0000e-04\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0440 - val_loss: -1.4494 - learning_rate: 1.0000e-04\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9706 - val_loss: -1.4461 - learning_rate: 1.0000e-04\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0308 - val_loss: -1.4483 - learning_rate: 1.0000e-04\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -1.0474 - val_loss: -1.4624 - learning_rate: 1.0000e-04\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -1.0297 - val_loss: -1.4897 - learning_rate: 1.0000e-04\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0732 - val_loss: -1.4536 - learning_rate: 1.0000e-04\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0458 - val_loss: -1.4725 - learning_rate: 1.0000e-04\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0762 - val_loss: -1.4777 - learning_rate: 1.0000e-04\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0351 - val_loss: -1.4783 - learning_rate: 1.0000e-04\n",
      "Epoch 86/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0530 - val_loss: -1.5107 - learning_rate: 1.0000e-04\n",
      "Epoch 87/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0776 - val_loss: -1.5006 - learning_rate: 1.0000e-04\n",
      "Epoch 88/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0776 - val_loss: -1.4885 - learning_rate: 1.0000e-04\n",
      "Epoch 89/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.1098 - val_loss: -1.4897 - learning_rate: 1.0000e-04\n",
      "Epoch 90/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.1214 - val_loss: -1.5214 - learning_rate: 1.0000e-04\n",
      "Epoch 91/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.1562 - val_loss: -1.5069 - learning_rate: 1.0000e-04\n",
      "Epoch 92/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.1135 - val_loss: -1.5313 - learning_rate: 1.0000e-04\n",
      "Epoch 93/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.1648 - val_loss: -1.5175 - learning_rate: 1.0000e-04\n",
      "Epoch 94/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0734 - val_loss: -1.4886 - learning_rate: 1.0000e-04\n",
      "Epoch 95/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0894 - val_loss: -1.5448 - learning_rate: 1.0000e-04\n",
      "Epoch 96/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -1.1348 - val_loss: -1.5134 - learning_rate: 1.0000e-04\n",
      "Epoch 97/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.1468 - val_loss: -1.5327 - learning_rate: 1.0000e-04\n",
      "Epoch 98/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.1212 - val_loss: -1.5281 - learning_rate: 1.0000e-04\n",
      "Epoch 99/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0574 - val_loss: -1.5504 - learning_rate: 1.0000e-04\n",
      "Epoch 100/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.1255 - val_loss: -1.5518 - learning_rate: 1.0000e-04\n",
      "Epoch 101/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -1.1248 - val_loss: -1.5541 - learning_rate: 1.0000e-04\n",
      "Epoch 102/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0425 - val_loss: -1.5018 - learning_rate: 1.0000e-04\n",
      "Epoch 103/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.1819 - val_loss: -1.5108 - learning_rate: 1.0000e-04\n",
      "Epoch 104/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.1718 - val_loss: -1.5310 - learning_rate: 1.0000e-04\n",
      "Epoch 105/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.1135 - val_loss: -1.5087 - learning_rate: 1.0000e-04\n",
      "Epoch 106/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.1494 - val_loss: -1.5433 - learning_rate: 1.0000e-04\n",
      "Epoch 107/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.1820 - val_loss: -1.5215 - learning_rate: 5.0000e-05\n",
      "Epoch 108/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -1.1744 - val_loss: -1.5331 - learning_rate: 5.0000e-05\n",
      "Epoch 109/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0541 - val_loss: -1.5468 - learning_rate: 5.0000e-05\n",
      "Epoch 110/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0742 - val_loss: -1.5344 - learning_rate: 5.0000e-05\n",
      "Epoch 111/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.1849 - val_loss: -1.5417 - learning_rate: 5.0000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.6506 - val_loss: 0.0215 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.3602 - val_loss: 0.0095 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.1960 - val_loss: 0.0100 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.2165 - val_loss: 0.0080 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.1524 - val_loss: 0.0039 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1344 - val_loss: 0.0078 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1079 - val_loss: 0.0077 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0875 - val_loss: 0.0033 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0784 - val_loss: 0.0041 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0740 - val_loss: 0.0113 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0661 - val_loss: 0.0040 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0369 - val_loss: 0.0049 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0506 - val_loss: 0.0103 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0381 - val_loss: 0.0056 - learning_rate: 5.0000e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0520 - val_loss: 0.0113 - learning_rate: 5.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0346 - val_loss: 0.0064 - learning_rate: 5.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0457 - val_loss: 0.0049 - learning_rate: 5.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0399 - val_loss: 0.0050 - learning_rate: 5.0000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.6327 - val_loss: 0.0537 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.3296 - val_loss: 0.0068 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.2256 - val_loss: -0.0164 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1666 - val_loss: -0.0303 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0948 - val_loss: -0.0369 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.1034 - val_loss: -0.0519 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0634 - val_loss: -0.0607 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0353 - val_loss: -0.0649 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0146 - val_loss: -0.0908 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0035 - val_loss: -0.1164 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.0250 - val_loss: -0.1439 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.0565 - val_loss: -0.1740 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0418 - val_loss: -0.1834 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0714 - val_loss: -0.2207 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0863 - val_loss: -0.2467 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.1248 - val_loss: -0.2710 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.1235 - val_loss: -0.2908 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.1357 - val_loss: -0.3084 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.1711 - val_loss: -0.3403 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.1818 - val_loss: -0.3667 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2210 - val_loss: -0.3857 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2400 - val_loss: -0.4141 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.2624 - val_loss: -0.4410 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2728 - val_loss: -0.4717 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3166 - val_loss: -0.5064 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3277 - val_loss: -0.5327 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: -0.3753 - val_loss: -0.5557 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3924 - val_loss: -0.5896 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4073 - val_loss: -0.6152 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4203 - val_loss: -0.6519 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4491 - val_loss: -0.6768 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4641 - val_loss: -0.7086 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4928 - val_loss: -0.7530 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4699 - val_loss: -0.7592 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5351 - val_loss: -0.8160 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5564 - val_loss: -0.8467 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5998 - val_loss: -0.8550 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5736 - val_loss: -0.8845 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6211 - val_loss: -0.9120 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6379 - val_loss: -0.9516 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6502 - val_loss: -0.9717 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6678 - val_loss: -1.0016 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6823 - val_loss: -1.0130 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7141 - val_loss: -1.0103 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7921 - val_loss: -1.0785 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7068 - val_loss: -1.1000 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7268 - val_loss: -1.1245 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8265 - val_loss: -1.1391 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7797 - val_loss: -1.1607 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8276 - val_loss: -1.1622 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7925 - val_loss: -1.1696 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.8603 - val_loss: -1.2322 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.8352 - val_loss: -1.2320 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8848 - val_loss: -1.2259 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8136 - val_loss: -1.2470 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.8453 - val_loss: -1.2528 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8851 - val_loss: -1.2658 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8628 - val_loss: -1.2919 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8853 - val_loss: -1.2876 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9134 - val_loss: -1.3032 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8399 - val_loss: -1.3153 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9721 - val_loss: -1.3340 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9162 - val_loss: -1.3143 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9239 - val_loss: -1.3381 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9193 - val_loss: -1.3672 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9694 - val_loss: -1.3708 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9315 - val_loss: -1.3480 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9630 - val_loss: -1.3722 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0093 - val_loss: -1.3837 - learning_rate: 1.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0318 - val_loss: -1.3668 - learning_rate: 1.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9337 - val_loss: -1.3683 - learning_rate: 1.0000e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9207 - val_loss: -1.3939 - learning_rate: 1.0000e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0236 - val_loss: -1.4118 - learning_rate: 1.0000e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9879 - val_loss: -1.4474 - learning_rate: 1.0000e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -1.0233 - val_loss: -1.4239 - learning_rate: 1.0000e-04\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0389 - val_loss: -1.4327 - learning_rate: 1.0000e-04\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0229 - val_loss: -1.3936 - learning_rate: 1.0000e-04\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0136 - val_loss: -1.4423 - learning_rate: 1.0000e-04\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0600 - val_loss: -1.4528 - learning_rate: 1.0000e-04\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0273 - val_loss: -1.4349 - learning_rate: 1.0000e-04\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.1065 - val_loss: -1.4433 - learning_rate: 1.0000e-04\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0519 - val_loss: -1.4432 - learning_rate: 1.0000e-04\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0742 - val_loss: -1.4347 - learning_rate: 1.0000e-04\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0506 - val_loss: -1.4301 - learning_rate: 1.0000e-04\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.1094 - val_loss: -1.4398 - learning_rate: 5.0000e-05\n",
      "Epoch 86/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0913 - val_loss: -1.4436 - learning_rate: 5.0000e-05\n",
      "Epoch 87/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0987 - val_loss: -1.4279 - learning_rate: 5.0000e-05\n",
      "Epoch 88/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -1.0501 - val_loss: -1.4395 - learning_rate: 5.0000e-05\n",
      "Epoch 89/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0879 - val_loss: -1.4261 - learning_rate: 5.0000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 1.1084 - val_loss: -0.0220 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.4085 - val_loss: -0.0420 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.2717 - val_loss: -0.0622 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.1530 - val_loss: -0.0719 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.1046 - val_loss: -0.0795 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0916 - val_loss: -0.0826 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0326 - val_loss: -0.0843 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0320 - val_loss: -0.0872 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0099 - val_loss: -0.0856 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0434 - val_loss: -0.0866 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0222 - val_loss: -0.0831 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0018 - val_loss: -0.0771 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0063 - val_loss: -0.0855 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0072 - val_loss: -0.0863 - learning_rate: 5.0000e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.0064 - val_loss: -0.0870 - learning_rate: 5.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0264 - val_loss: -0.0874 - learning_rate: 5.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0171 - val_loss: -0.0873 - learning_rate: 5.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0167 - val_loss: -0.0861 - learning_rate: 5.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0283 - val_loss: -0.0883 - learning_rate: 5.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0204 - val_loss: -0.0897 - learning_rate: 5.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0056 - val_loss: -0.0860 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0428 - val_loss: -0.0879 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0337 - val_loss: -0.0863 - learning_rate: 5.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0307 - val_loss: -0.0902 - learning_rate: 5.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.0245 - val_loss: -0.0902 - learning_rate: 5.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.0446 - val_loss: -0.0873 - learning_rate: 5.0000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.0347 - val_loss: -0.0880 - learning_rate: 5.0000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.0370 - val_loss: -0.0894 - learning_rate: 5.0000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0360 - val_loss: -0.0911 - learning_rate: 5.0000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0452 - val_loss: -0.0914 - learning_rate: 5.0000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0527 - val_loss: -0.0876 - learning_rate: 5.0000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0278 - val_loss: -0.0884 - learning_rate: 5.0000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0480 - val_loss: -0.0848 - learning_rate: 5.0000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0417 - val_loss: -0.0911 - learning_rate: 5.0000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0500 - val_loss: -0.0872 - learning_rate: 5.0000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0482 - val_loss: -0.0901 - learning_rate: 2.5000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.0427 - val_loss: -0.0898 - learning_rate: 2.5000e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0416 - val_loss: -0.0892 - learning_rate: 2.5000e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0424 - val_loss: -0.0888 - learning_rate: 2.5000e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0407 - val_loss: -0.0902 - learning_rate: 2.5000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.7195 - val_loss: 0.0210 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.3688 - val_loss: -0.0285 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.2376 - val_loss: -0.0438 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1640 - val_loss: -0.0595 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.1089 - val_loss: -0.0834 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0685 - val_loss: -0.0898 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0767 - val_loss: -0.1234 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0096 - val_loss: -0.1492 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0264 - val_loss: -0.1672 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0387 - val_loss: -0.1957 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0520 - val_loss: -0.2338 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0877 - val_loss: -0.2810 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.1240 - val_loss: -0.3218 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.1575 - val_loss: -0.3572 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.1726 - val_loss: -0.3961 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.1756 - val_loss: -0.4349 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2075 - val_loss: -0.4763 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.2549 - val_loss: -0.5097 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2645 - val_loss: -0.5482 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3138 - val_loss: -0.6024 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3230 - val_loss: -0.6434 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3948 - val_loss: -0.6793 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3651 - val_loss: -0.7282 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4563 - val_loss: -0.7727 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4495 - val_loss: -0.8079 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4857 - val_loss: -0.8585 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.4839 - val_loss: -0.8917 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5151 - val_loss: -0.9187 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5444 - val_loss: -0.9586 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6061 - val_loss: -0.9818 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5553 - val_loss: -1.0196 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6555 - val_loss: -1.0273 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.6766 - val_loss: -1.0740 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7134 - val_loss: -1.0916 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7064 - val_loss: -1.1093 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7129 - val_loss: -1.1542 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6965 - val_loss: -1.1476 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7188 - val_loss: -1.1786 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7923 - val_loss: -1.2144 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8389 - val_loss: -1.2311 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8254 - val_loss: -1.2450 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8235 - val_loss: -1.2557 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8409 - val_loss: -1.2579 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.8742 - val_loss: -1.2832 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7893 - val_loss: -1.2913 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8485 - val_loss: -1.3133 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8676 - val_loss: -1.3148 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.9448 - val_loss: -1.3482 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.8659 - val_loss: -1.3322 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9347 - val_loss: -1.3804 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9176 - val_loss: -1.3672 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8997 - val_loss: -1.3663 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9169 - val_loss: -1.3993 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.9339 - val_loss: -1.3951 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8878 - val_loss: -1.4040 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9836 - val_loss: -1.3672 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9176 - val_loss: -1.4134 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0240 - val_loss: -1.4281 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9960 - val_loss: -1.4245 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0120 - val_loss: -1.4400 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.9409 - val_loss: -1.4335 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9872 - val_loss: -1.4266 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0491 - val_loss: -1.4362 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0090 - val_loss: -1.4637 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9924 - val_loss: -1.4338 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0030 - val_loss: -1.4523 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0133 - val_loss: -1.4472 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -1.0608 - val_loss: -1.4478 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9939 - val_loss: -1.4515 - learning_rate: 1.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0749 - val_loss: -1.4742 - learning_rate: 5.0000e-05\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0305 - val_loss: -1.4498 - learning_rate: 5.0000e-05\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0370 - val_loss: -1.4459 - learning_rate: 5.0000e-05\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0502 - val_loss: -1.4747 - learning_rate: 5.0000e-05\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0388 - val_loss: -1.4681 - learning_rate: 5.0000e-05\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0312 - val_loss: -1.4620 - learning_rate: 5.0000e-05\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0397 - val_loss: -1.4792 - learning_rate: 5.0000e-05\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0957 - val_loss: -1.4638 - learning_rate: 5.0000e-05\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0275 - val_loss: -1.4701 - learning_rate: 5.0000e-05\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0961 - val_loss: -1.4781 - learning_rate: 5.0000e-05\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0370 - val_loss: -1.4821 - learning_rate: 5.0000e-05\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0895 - val_loss: -1.4825 - learning_rate: 5.0000e-05\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0697 - val_loss: -1.4829 - learning_rate: 5.0000e-05\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0448 - val_loss: -1.4642 - learning_rate: 5.0000e-05\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -1.0719 - val_loss: -1.4869 - learning_rate: 5.0000e-05\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0343 - val_loss: -1.4910 - learning_rate: 5.0000e-05\n",
      "Epoch 86/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.1259 - val_loss: -1.4872 - learning_rate: 5.0000e-05\n",
      "Epoch 87/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.1659 - val_loss: -1.4878 - learning_rate: 5.0000e-05\n",
      "Epoch 88/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.1219 - val_loss: -1.4770 - learning_rate: 5.0000e-05\n",
      "Epoch 89/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -1.0353 - val_loss: -1.4886 - learning_rate: 5.0000e-05\n",
      "Epoch 90/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.1488 - val_loss: -1.4449 - learning_rate: 5.0000e-05\n",
      "Epoch 91/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.1035 - val_loss: -1.4811 - learning_rate: 2.5000e-05\n",
      "Epoch 92/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0583 - val_loss: -1.4853 - learning_rate: 2.5000e-05\n",
      "Epoch 93/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.1010 - val_loss: -1.4945 - learning_rate: 2.5000e-05\n",
      "Epoch 94/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.1069 - val_loss: -1.4878 - learning_rate: 2.5000e-05\n",
      "Epoch 95/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.1143 - val_loss: -1.4932 - learning_rate: 2.5000e-05\n",
      "Epoch 96/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.1191 - val_loss: -1.4954 - learning_rate: 2.5000e-05\n",
      "Epoch 97/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.1014 - val_loss: -1.4854 - learning_rate: 2.5000e-05\n",
      "Epoch 98/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.1096 - val_loss: -1.4852 - learning_rate: 2.5000e-05\n",
      "Epoch 99/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0880 - val_loss: -1.4877 - learning_rate: 2.5000e-05\n",
      "Epoch 100/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0739 - val_loss: -1.4819 - learning_rate: 2.5000e-05\n",
      "Epoch 101/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.1756 - val_loss: -1.4937 - learning_rate: 2.5000e-05\n",
      "Epoch 102/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.1019 - val_loss: -1.4846 - learning_rate: 1.2500e-05\n",
      "Epoch 103/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -1.1042 - val_loss: -1.4888 - learning_rate: 1.2500e-05\n",
      "Epoch 104/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0825 - val_loss: -1.4901 - learning_rate: 1.2500e-05\n",
      "Epoch 105/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0172 - val_loss: -1.4898 - learning_rate: 1.2500e-05\n",
      "Epoch 106/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.2217 - val_loss: -1.4878 - learning_rate: 1.2500e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.6671 - val_loss: 0.0139 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.3982 - val_loss: 0.0209 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.2290 - val_loss: 0.0365 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1740 - val_loss: 0.0124 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1440 - val_loss: 0.0164 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1113 - val_loss: 0.0150 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1178 - val_loss: 0.0113 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0780 - val_loss: 0.0192 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0697 - val_loss: 0.0140 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0597 - val_loss: 0.0248 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0615 - val_loss: 0.0194 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0609 - val_loss: 0.0157 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0505 - val_loss: 0.0150 - learning_rate: 5.0000e-05\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0450 - val_loss: 0.0098 - learning_rate: 5.0000e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0426 - val_loss: 0.0182 - learning_rate: 5.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0638 - val_loss: 0.0076 - learning_rate: 5.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0438 - val_loss: 0.0114 - learning_rate: 5.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0442 - val_loss: 0.0078 - learning_rate: 5.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0330 - val_loss: 0.0116 - learning_rate: 5.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0413 - val_loss: 0.0093 - learning_rate: 5.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0334 - val_loss: 0.0071 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0343 - val_loss: 0.0112 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0247 - val_loss: 0.0069 - learning_rate: 5.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0331 - val_loss: 0.0088 - learning_rate: 5.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0246 - val_loss: 0.0178 - learning_rate: 5.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0269 - val_loss: 0.0125 - learning_rate: 5.0000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0369 - val_loss: 0.0040 - learning_rate: 5.0000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0293 - val_loss: 0.0084 - learning_rate: 5.0000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0216 - val_loss: 0.0082 - learning_rate: 5.0000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0275 - val_loss: 0.0086 - learning_rate: 5.0000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0247 - val_loss: 0.0042 - learning_rate: 5.0000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0186 - val_loss: 0.0046 - learning_rate: 5.0000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0144 - val_loss: 0.0061 - learning_rate: 2.5000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0288 - val_loss: 0.0040 - learning_rate: 2.5000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0261 - val_loss: 0.0038 - learning_rate: 2.5000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0319 - val_loss: 0.0067 - learning_rate: 2.5000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0261 - val_loss: 0.0066 - learning_rate: 2.5000e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0288 - val_loss: 0.0065 - learning_rate: 2.5000e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0156 - val_loss: 0.0041 - learning_rate: 2.5000e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0147 - val_loss: 0.0048 - learning_rate: 2.5000e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0226 - val_loss: 0.0045 - learning_rate: 1.2500e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0226 - val_loss: 0.0045 - learning_rate: 1.2500e-05\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0234 - val_loss: 0.0047 - learning_rate: 1.2500e-05\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0173 - val_loss: 0.0048 - learning_rate: 1.2500e-05\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0196 - val_loss: 0.0047 - learning_rate: 1.2500e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.4374 - val_loss: -0.0020 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.2876 - val_loss: -0.0227 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.1897 - val_loss: -0.0464 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.1031 - val_loss: -0.0632 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.1061 - val_loss: -0.0785 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0477 - val_loss: -0.0872 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0270 - val_loss: -0.1103 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0074 - val_loss: -0.1369 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0365 - val_loss: -0.1545 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0486 - val_loss: -0.1847 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.0727 - val_loss: -0.2070 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.1140 - val_loss: -0.2315 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.1175 - val_loss: -0.2617 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.1322 - val_loss: -0.2844 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.1558 - val_loss: -0.3107 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.1618 - val_loss: -0.3351 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.2120 - val_loss: -0.3628 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.1983 - val_loss: -0.3814 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.2136 - val_loss: -0.4133 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.2371 - val_loss: -0.4415 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.2935 - val_loss: -0.4837 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.3009 - val_loss: -0.5235 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3606 - val_loss: -0.5604 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.3506 - val_loss: -0.6005 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3805 - val_loss: -0.6236 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.3535 - val_loss: -0.6622 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4293 - val_loss: -0.6847 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4407 - val_loss: -0.7272 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4690 - val_loss: -0.7693 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5203 - val_loss: -0.7861 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5229 - val_loss: -0.8264 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5691 - val_loss: -0.8713 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5733 - val_loss: -0.8959 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5813 - val_loss: -0.8892 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6373 - val_loss: -0.9417 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6543 - val_loss: -0.9639 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6689 - val_loss: -0.9992 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7186 - val_loss: -1.0481 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7105 - val_loss: -1.0475 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7033 - val_loss: -1.0469 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7521 - val_loss: -1.1187 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8105 - val_loss: -1.1109 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7860 - val_loss: -1.1394 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7958 - val_loss: -1.1409 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7989 - val_loss: -1.1521 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8121 - val_loss: -1.1733 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8075 - val_loss: -1.1690 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8350 - val_loss: -1.1883 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8680 - val_loss: -1.2076 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9108 - val_loss: -1.1972 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8035 - val_loss: -1.2113 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8696 - val_loss: -1.2334 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9089 - val_loss: -1.2564 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9102 - val_loss: -1.2169 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8611 - val_loss: -1.2518 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9225 - val_loss: -1.2402 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.9226 - val_loss: -1.2564 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9287 - val_loss: -1.2716 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9537 - val_loss: -1.2985 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9473 - val_loss: -1.2651 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0138 - val_loss: -1.2889 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9638 - val_loss: -1.3254 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9522 - val_loss: -1.3209 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0283 - val_loss: -1.3217 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9797 - val_loss: -1.3067 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9616 - val_loss: -1.3304 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9972 - val_loss: -1.3434 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0192 - val_loss: -1.3391 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0085 - val_loss: -1.3626 - learning_rate: 1.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9783 - val_loss: -1.3256 - learning_rate: 1.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0200 - val_loss: -1.3260 - learning_rate: 1.0000e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9960 - val_loss: -1.3472 - learning_rate: 1.0000e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.1019 - val_loss: -1.3592 - learning_rate: 1.0000e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.9937 - val_loss: -1.3433 - learning_rate: 1.0000e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -1.0316 - val_loss: -1.3696 - learning_rate: 5.0000e-05\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -1.0262 - val_loss: -1.3604 - learning_rate: 5.0000e-05\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -1.0103 - val_loss: -1.3532 - learning_rate: 5.0000e-05\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.9894 - val_loss: -1.3470 - learning_rate: 5.0000e-05\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -1.0294 - val_loss: -1.3769 - learning_rate: 5.0000e-05\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -1.0594 - val_loss: -1.3781 - learning_rate: 5.0000e-05\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0679 - val_loss: -1.3557 - learning_rate: 5.0000e-05\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -1.0685 - val_loss: -1.3289 - learning_rate: 5.0000e-05\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.9896 - val_loss: -1.3304 - learning_rate: 5.0000e-05\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -1.0747 - val_loss: -1.3540 - learning_rate: 5.0000e-05\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0478 - val_loss: -1.3606 - learning_rate: 5.0000e-05\n",
      "Epoch 86/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0708 - val_loss: -1.3518 - learning_rate: 2.5000e-05\n",
      "Epoch 87/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0716 - val_loss: -1.3563 - learning_rate: 2.5000e-05\n",
      "Epoch 88/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0392 - val_loss: -1.3575 - learning_rate: 2.5000e-05\n",
      "Epoch 89/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9592 - val_loss: -1.3489 - learning_rate: 2.5000e-05\n",
      "Epoch 90/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.1238 - val_loss: -1.3387 - learning_rate: 2.5000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.6102 - val_loss: 0.0795 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.3445 - val_loss: 0.0430 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1868 - val_loss: 0.0332 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.2029 - val_loss: 0.0313 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.1386 - val_loss: 0.0204 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.1251 - val_loss: 0.0130 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1001 - val_loss: 0.0244 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0699 - val_loss: 0.0182 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0735 - val_loss: 0.0072 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0753 - val_loss: 0.0090 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0590 - val_loss: 0.0145 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0656 - val_loss: 0.0094 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0499 - val_loss: 0.0039 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0404 - val_loss: 0.0124 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0458 - val_loss: 0.0098 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0412 - val_loss: 0.0150 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0333 - val_loss: 0.0031 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0443 - val_loss: 0.0094 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0319 - val_loss: 0.0086 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0403 - val_loss: 0.0104 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0125 - val_loss: 0.0048 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0259 - val_loss: 0.0040 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0314 - val_loss: 0.0086 - learning_rate: 5.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0190 - val_loss: 0.0031 - learning_rate: 5.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0217 - val_loss: 0.0030 - learning_rate: 5.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0270 - val_loss: 0.0031 - learning_rate: 5.0000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0246 - val_loss: 0.0027 - learning_rate: 5.0000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0122 - val_loss: 0.0029 - learning_rate: 5.0000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0181 - val_loss: 0.0056 - learning_rate: 5.0000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0262 - val_loss: 0.0023 - learning_rate: 5.0000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0154 - val_loss: 0.0053 - learning_rate: 5.0000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0273 - val_loss: 0.0032 - learning_rate: 5.0000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0223 - val_loss: 0.0024 - learning_rate: 5.0000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0260 - val_loss: 0.0028 - learning_rate: 5.0000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0128 - val_loss: 0.0047 - learning_rate: 5.0000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0166 - val_loss: 0.0032 - learning_rate: 2.5000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0293 - val_loss: 0.0020 - learning_rate: 2.5000e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0172 - val_loss: 0.0028 - learning_rate: 2.5000e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0220 - val_loss: 0.0027 - learning_rate: 2.5000e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0167 - val_loss: 0.0025 - learning_rate: 2.5000e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0197 - val_loss: 0.0020 - learning_rate: 2.5000e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0248 - val_loss: 0.0027 - learning_rate: 2.5000e-05\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0178 - val_loss: 0.0023 - learning_rate: 1.2500e-05\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0161 - val_loss: 0.0025 - learning_rate: 1.2500e-05\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0135 - val_loss: 0.0024 - learning_rate: 1.2500e-05\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0220 - val_loss: 0.0018 - learning_rate: 1.2500e-05\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0204 - val_loss: 0.0017 - learning_rate: 1.2500e-05\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0188 - val_loss: 0.0030 - learning_rate: 1.2500e-05\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0174 - val_loss: 0.0024 - learning_rate: 1.2500e-05\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0110 - val_loss: 0.0020 - learning_rate: 1.2500e-05\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0118 - val_loss: 0.0019 - learning_rate: 1.2500e-05\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0126 - val_loss: 0.0019 - learning_rate: 6.2500e-06\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0146 - val_loss: 0.0023 - learning_rate: 6.2500e-06\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0090 - val_loss: 0.0017 - learning_rate: 6.2500e-06\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0157 - val_loss: 0.0019 - learning_rate: 6.2500e-06\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0159 - val_loss: 0.0019 - learning_rate: 6.2500e-06\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0196 - val_loss: 0.0020 - learning_rate: 3.1250e-06\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0168 - val_loss: 0.0019 - learning_rate: 3.1250e-06\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0166 - val_loss: 0.0014 - learning_rate: 3.1250e-06\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0170 - val_loss: 0.0019 - learning_rate: 3.1250e-06\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0110 - val_loss: 0.0019 - learning_rate: 3.1250e-06\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0147 - val_loss: 0.0023 - learning_rate: 3.1250e-06\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0050 - val_loss: 0.0018 - learning_rate: 3.1250e-06\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0133 - val_loss: 0.0016 - learning_rate: 3.1250e-06\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0148 - val_loss: 0.0018 - learning_rate: 1.5625e-06\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0167 - val_loss: 0.0022 - learning_rate: 1.5625e-06\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0161 - val_loss: 0.0021 - learning_rate: 1.5625e-06\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0104 - val_loss: 0.0020 - learning_rate: 1.5625e-06\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0185 - val_loss: 0.0016 - learning_rate: 1.5625e-06\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.4539 - val_loss: -0.0126 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.3082 - val_loss: -0.0480 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1603 - val_loss: -0.0824 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0902 - val_loss: -0.1097 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0423 - val_loss: -0.1430 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0361 - val_loss: -0.1673 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0025 - val_loss: -0.1973 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0408 - val_loss: -0.2155 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.0299 - val_loss: -0.2381 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0849 - val_loss: -0.2670 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.1297 - val_loss: -0.2954 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.1662 - val_loss: -0.3258 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.1906 - val_loss: -0.3623 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2156 - val_loss: -0.4049 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.2444 - val_loss: -0.4343 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2674 - val_loss: -0.4672 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.2813 - val_loss: -0.4901 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.3332 - val_loss: -0.5196 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3230 - val_loss: -0.5567 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3703 - val_loss: -0.5834 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3704 - val_loss: -0.6137 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.4131 - val_loss: -0.6485 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4306 - val_loss: -0.6905 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4854 - val_loss: -0.7227 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4893 - val_loss: -0.7650 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.5268 - val_loss: -0.8053 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5539 - val_loss: -0.8361 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5650 - val_loss: -0.8720 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5977 - val_loss: -0.9038 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5751 - val_loss: -0.9258 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6262 - val_loss: -0.9568 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6363 - val_loss: -0.9867 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6986 - val_loss: -1.0418 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7154 - val_loss: -1.0744 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7211 - val_loss: -1.0927 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7074 - val_loss: -1.1022 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7882 - val_loss: -1.1510 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7902 - val_loss: -1.1680 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7746 - val_loss: -1.1788 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8102 - val_loss: -1.2069 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8417 - val_loss: -1.2011 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8582 - val_loss: -1.2358 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9045 - val_loss: -1.2409 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8528 - val_loss: -1.2320 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8682 - val_loss: -1.2569 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9427 - val_loss: -1.2847 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8764 - val_loss: -1.2720 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9674 - val_loss: -1.3091 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8367 - val_loss: -1.3330 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9854 - val_loss: -1.3171 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9932 - val_loss: -1.3503 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.9175 - val_loss: -1.3501 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.9518 - val_loss: -1.3818 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.9971 - val_loss: -1.3819 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.9845 - val_loss: -1.3743 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0478 - val_loss: -1.3976 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0833 - val_loss: -1.3875 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.9918 - val_loss: -1.3839 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.9730 - val_loss: -1.4146 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0236 - val_loss: -1.4101 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -1.0036 - val_loss: -1.4170 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.9977 - val_loss: -1.4238 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0334 - val_loss: -1.4461 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: -1.0628 - val_loss: -1.4480 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0441 - val_loss: -1.4533 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0278 - val_loss: -1.4354 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0437 - val_loss: -1.4139 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0965 - val_loss: -1.4657 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.1206 - val_loss: -1.4376 - learning_rate: 1.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0823 - val_loss: -1.4578 - learning_rate: 1.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.1344 - val_loss: -1.4420 - learning_rate: 1.0000e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -1.0587 - val_loss: -1.4778 - learning_rate: 1.0000e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0813 - val_loss: -1.4743 - learning_rate: 1.0000e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.1322 - val_loss: -1.4795 - learning_rate: 1.0000e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0888 - val_loss: -1.4674 - learning_rate: 1.0000e-04\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0901 - val_loss: -1.4668 - learning_rate: 1.0000e-04\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -1.0851 - val_loss: -1.4737 - learning_rate: 1.0000e-04\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0168 - val_loss: -1.4742 - learning_rate: 1.0000e-04\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0835 - val_loss: -1.5110 - learning_rate: 1.0000e-04\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -1.1537 - val_loss: -1.5045 - learning_rate: 1.0000e-04\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.0755 - val_loss: -1.5147 - learning_rate: 1.0000e-04\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.2222 - val_loss: -1.5244 - learning_rate: 1.0000e-04\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0518 - val_loss: -1.5159 - learning_rate: 1.0000e-04\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.1001 - val_loss: -1.5144 - learning_rate: 1.0000e-04\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -1.0941 - val_loss: -1.5024 - learning_rate: 1.0000e-04\n",
      "Epoch 86/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.1044 - val_loss: -1.5124 - learning_rate: 1.0000e-04\n",
      "Epoch 87/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.1259 - val_loss: -1.5025 - learning_rate: 1.0000e-04\n",
      "Epoch 88/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.1886 - val_loss: -1.5129 - learning_rate: 5.0000e-05\n",
      "Epoch 89/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.1220 - val_loss: -1.4885 - learning_rate: 5.0000e-05\n",
      "Epoch 90/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.0885 - val_loss: -1.5146 - learning_rate: 5.0000e-05\n",
      "Epoch 91/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.1016 - val_loss: -1.5050 - learning_rate: 5.0000e-05\n",
      "Epoch 92/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -1.1488 - val_loss: -1.5039 - learning_rate: 5.0000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 14ms/step - loss: 0.6381 - val_loss: 0.0196 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.3528 - val_loss: 0.0074 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.2686 - val_loss: 0.0076 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1933 - val_loss: 0.0225 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1749 - val_loss: 0.0082 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1113 - val_loss: 0.0102 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0931 - val_loss: 0.0108 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.1135 - val_loss: 0.0121 - learning_rate: 5.0000e-05\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0765 - val_loss: 0.0092 - learning_rate: 5.0000e-05\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0836 - val_loss: 0.0130 - learning_rate: 5.0000e-05\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0898 - val_loss: 0.0088 - learning_rate: 5.0000e-05\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0705 - val_loss: 0.0101 - learning_rate: 5.0000e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 zmiennych na podstawie CMI: [ 1 12 16 20 18  8  5 11 19  2]\n",
      "Top 10 zmiennych na podstawie LASSO: [13  6 17  5 12  4  2  8  7 20]\n",
      "Liczba odwróconych par: 95\n",
      "Top 10 agreement score: 0.5\n",
      "Top 5 agreement score: 0.2\n"
     ]
    }
   ],
   "source": [
    "#est2\n",
    "\n",
    "cmi_scores = []\n",
    "for i in range(X.shape[1]):\n",
    "    # Zmienna Z to wszystkie cechy oprócz jednej\n",
    "    Z = np.delete(X, i, axis=1)\n",
    "    cmi_scores.append(est2(X[:, i].reshape(-1, 1), Y, Z))\n",
    "\n",
    "# Ranking zmiennych na podstawie CMI\n",
    "cmi_ranking = np.argsort(cmi_scores)[::-1]\n",
    "\n",
    "# Wizualizacja rankingów\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(range(1, n_features + 1), np.array(cmi_scores)[cmi_ranking], tick_label=cmi_ranking + 1)\n",
    "plt.title(\"CMI Ranking\")\n",
    "plt.xlabel(\"Feature Index\")\n",
    "plt.ylabel(\"Conditional Mutual Information\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(range(1, n_features + 1), np.array(lasso_importances)[lasso_ranking], tick_label=lasso_ranking + 1)\n",
    "plt.title(\"LASSO Ranking\")\n",
    "plt.xlabel(\"Feature Index\")\n",
    "plt.ylabel(\"LASSO Coefficients\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Wyświetlanie top 10 zmiennych\n",
    "print(\"Top 10 zmiennych na podstawie CMI:\", cmi_ranking[:10] + 1)\n",
    "print(\"Top 10 zmiennych na podstawie LASSO:\", lasso_ranking[:10] + 1)\n",
    "\n",
    "\n",
    "# Liczenie liczby odwróconych par\n",
    "inversions = count_inversions(cmi_ranking, lasso_ranking)\n",
    "print(f\"Liczba odwróconych par: {inversions}\")\n",
    "\n",
    "# Liczenie liczby przypadków, w których top 10 zmiennych się pokrywają\n",
    "top_k_agreement_10 = top_k_agreement(cmi_ranking, lasso_ranking, 10)\n",
    "top_k_agreement_5 = top_k_agreement(cmi_ranking, lasso_ranking, 5)\n",
    "\n",
    "print(f\"Top 10 agreement score: {top_k_agreement_10}\")\n",
    "print(f\"Top 5 agreement score: {top_k_agreement_5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I_XZY: 0.5533305174120713\n",
      "I_XY: 0\n",
      "I_XZY: 0.5533305174120713\n",
      "I_XY: 0.016527817036896764\n",
      "I_XZY: 0.5533305174120713\n",
      "I_XY: 0\n",
      "I_XZY: 0.5533305174120713\n",
      "I_XY: 0.022118706027732138\n",
      "I_XZY: 0.5533305174120713\n",
      "I_XY: 0.07695074422074022\n",
      "I_XZY: 0.5533305174120713\n",
      "I_XY: 0.12460468279635073\n",
      "I_XZY: 0.5533305174120713\n",
      "I_XY: 0.014830603117033547\n",
      "I_XZY: 0.5533305174120713\n",
      "I_XY: 0.007353375880041035\n",
      "I_XZY: 0.5533305174120713\n",
      "I_XY: 0\n",
      "I_XZY: 0.5533305174120713\n",
      "I_XY: 0\n",
      "I_XZY: 0.5533305174120713\n",
      "I_XY: 0\n",
      "I_XZY: 0.5533305174120713\n",
      "I_XY: 0.03464103228225124\n",
      "I_XZY: 0.5533305174120713\n",
      "I_XY: 0.14187779840545023\n",
      "I_XZY: 0.5533305174120713\n",
      "I_XY: 0.003362905142744843\n",
      "I_XZY: 0.5533305174120713\n",
      "I_XY: 0\n",
      "I_XZY: 0.5533305174120713\n",
      "I_XY: 0.005491157195736562\n",
      "I_XZY: 0.5533305174120713\n",
      "I_XY: 0.10393792529912105\n",
      "I_XZY: 0.5533305174120713\n",
      "I_XY: 0\n",
      "I_XZY: 0.5533305174120713\n",
      "I_XY: 0\n",
      "I_XZY: 0.5533305174120713\n",
      "I_XY: 0.0016337700079729345\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 zmiennych na podstawie CMI: [10 11  3  9 19  1 15 18 20 14]\n",
      "Top 10 zmiennych na podstawie LASSO: [13  6 17  5 12  4  2  8  7 20]\n",
      "Liczba odwróconych par: 106\n",
      "Top 10 agreement score: 0.1\n",
      "Top 5 agreement score: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmi_scores = []\n",
    "for i in range(X.shape[1]):\n",
    "    # Zmienna Z to wszystkie cechy oprócz jednej\n",
    "    Z = np.delete(X, i, axis=1)\n",
    "    cmi_scores.append(estimate_cmi(X[:, i].reshape(-1, 1), Y.ravel(), Z))\n",
    "\n",
    "# Ranking zmiennych na podstawie CMI\n",
    "cmi_ranking = np.argsort(cmi_scores)[::-1]\n",
    "\n",
    "# Wizualizacja rankingów\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(range(1, n_features + 1), np.array(cmi_scores)[cmi_ranking], tick_label=cmi_ranking + 1)\n",
    "plt.title(\"CMI Ranking\")\n",
    "plt.xlabel(\"Feature Index\")\n",
    "plt.ylabel(\"Conditional Mutual Information\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(range(1, n_features + 1), np.array(lasso_importances)[lasso_ranking], tick_label=lasso_ranking + 1)\n",
    "plt.title(\"LASSO Ranking\")\n",
    "plt.xlabel(\"Feature Index\")\n",
    "plt.ylabel(\"LASSO Coefficients\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Wyświetlanie top 10 zmiennych\n",
    "print(\"Top 10 zmiennych na podstawie CMI:\", cmi_ranking[:10] + 1)\n",
    "print(\"Top 10 zmiennych na podstawie LASSO:\", lasso_ranking[:10] + 1)\n",
    "\n",
    "# Liczenie liczby odwróconych par\n",
    "inversions = count_inversions(cmi_ranking, lasso_ranking)\n",
    "print(f\"Liczba odwróconych par: {inversions}\")\n",
    "\n",
    "# Liczenie liczby przypadków, w których top 10 zmiennych się pokrywają\n",
    "top_k_agreement_10 = top_k_agreement(cmi_ranking, lasso_ranking, 10)\n",
    "top_k_agreement_5 = top_k_agreement(cmi_ranking, lasso_ranking, 5)\n",
    "\n",
    "print(f\"Top 10 agreement score: {top_k_agreement_10}\")\n",
    "print(f\"Top 5 agreement score: {top_k_agreement_5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 przykład 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generowanie danych\n",
    "n_samples = 10000\n",
    "n_features = 20\n",
    "\n",
    "X = np.random.rand(n_samples, n_features)\n",
    "\n",
    "Y = (\n",
    "    3 * X[:, 0] +                    \n",
    "    2 * X[:, 1] ** 2 +               \n",
    "    4 * np.sin(2 * np.pi * X[:, 2]) + \n",
    "    X[:, 3] * X[:, 4] +              \n",
    "    np.random.normal(0, 0.1, n_samples) \n",
    ")\n",
    "\n",
    "\n",
    "X[:, 10:] += np.random.normal(0, 0.1, size=(n_samples, n_features - 10))\n",
    "\n",
    "# Generowanie modelu LassoCV i obliczanie ważności zmiennych\n",
    "lasso = LassoCV(cv=5).fit(X, Y)\n",
    "lasso_importances = np.abs(lasso.coef_)\n",
    "lasso_ranking = np.argsort(lasso_importances)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.6169 - val_loss: 0.0800 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3453 - val_loss: 0.0606 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2013 - val_loss: 0.0500 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1507 - val_loss: 0.0399 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1347 - val_loss: 0.0311 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0958 - val_loss: 0.0267 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0985 - val_loss: 0.0216 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0520 - val_loss: 0.0144 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0614 - val_loss: 0.0143 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0625 - val_loss: 0.0064 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0398 - val_loss: 0.0038 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0241 - val_loss: 0.0028 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0195 - val_loss: 0.0042 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0363 - val_loss: -9.9864e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0281 - val_loss: -0.0024 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0397 - val_loss: -0.0030 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0065 - val_loss: -0.0044 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0289 - val_loss: -0.0091 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0096 - val_loss: -0.0094 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0198 - val_loss: -0.0110 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.7013e-04 - val_loss: -0.0097 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0066 - val_loss: -0.0142 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0155 - val_loss: -0.0139 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0015 - val_loss: -0.0094 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -8.6340e-04 - val_loss: -0.0161 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0102 - val_loss: -0.0153 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0093 - val_loss: -0.0153 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0018 - val_loss: -0.0176 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0120 - val_loss: -0.0181 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0035 - val_loss: -0.0217 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0017 - val_loss: -0.0211 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0121 - val_loss: -0.0205 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0132 - val_loss: -0.0215 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0068 - val_loss: -0.0199 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0168 - val_loss: -0.0120 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 9.5691e-04 - val_loss: -0.0242 - learning_rate: 5.0000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0127 - val_loss: -0.0244 - learning_rate: 5.0000e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0043 - val_loss: -0.0241 - learning_rate: 5.0000e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0236 - val_loss: -0.0245 - learning_rate: 5.0000e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0137 - val_loss: -0.0249 - learning_rate: 5.0000e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0219 - val_loss: -0.0256 - learning_rate: 5.0000e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0219 - val_loss: -0.0250 - learning_rate: 5.0000e-05\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0249 - val_loss: -0.0249 - learning_rate: 5.0000e-05\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0301 - val_loss: -0.0263 - learning_rate: 5.0000e-05\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0222 - val_loss: -0.0271 - learning_rate: 5.0000e-05\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0126 - val_loss: -0.0270 - learning_rate: 5.0000e-05\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0130 - val_loss: -0.0269 - learning_rate: 5.0000e-05\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0138 - val_loss: -0.0286 - learning_rate: 5.0000e-05\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0176 - val_loss: -0.0288 - learning_rate: 5.0000e-05\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0262 - val_loss: -0.0304 - learning_rate: 5.0000e-05\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0335 - val_loss: -0.0307 - learning_rate: 5.0000e-05\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0286 - val_loss: -0.0309 - learning_rate: 5.0000e-05\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0346 - val_loss: -0.0320 - learning_rate: 5.0000e-05\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0427 - val_loss: -0.0323 - learning_rate: 5.0000e-05\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0205 - val_loss: -0.0324 - learning_rate: 5.0000e-05\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0226 - val_loss: -0.0324 - learning_rate: 5.0000e-05\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0200 - val_loss: -0.0336 - learning_rate: 5.0000e-05\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0345 - val_loss: -0.0345 - learning_rate: 5.0000e-05\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0284 - val_loss: -0.0353 - learning_rate: 5.0000e-05\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.0285 - val_loss: -0.0341 - learning_rate: 5.0000e-05\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.0289 - val_loss: -0.0354 - learning_rate: 5.0000e-05\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0272 - val_loss: -0.0352 - learning_rate: 5.0000e-05\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0353 - val_loss: -0.0359 - learning_rate: 5.0000e-05\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0406 - val_loss: -0.0360 - learning_rate: 5.0000e-05\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0392 - val_loss: -0.0350 - learning_rate: 5.0000e-05\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0315 - val_loss: -0.0361 - learning_rate: 5.0000e-05\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0195 - val_loss: -0.0356 - learning_rate: 5.0000e-05\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0393 - val_loss: -0.0346 - learning_rate: 5.0000e-05\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0316 - val_loss: -0.0359 - learning_rate: 5.0000e-05\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0297 - val_loss: -0.0363 - learning_rate: 2.5000e-05\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0302 - val_loss: -0.0371 - learning_rate: 2.5000e-05\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0353 - val_loss: -0.0367 - learning_rate: 2.5000e-05\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0202 - val_loss: -0.0374 - learning_rate: 2.5000e-05\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0411 - val_loss: -0.0383 - learning_rate: 2.5000e-05\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0478 - val_loss: -0.0382 - learning_rate: 2.5000e-05\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0295 - val_loss: -0.0387 - learning_rate: 2.5000e-05\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0264 - val_loss: -0.0382 - learning_rate: 2.5000e-05\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0303 - val_loss: -0.0385 - learning_rate: 2.5000e-05\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0333 - val_loss: -0.0380 - learning_rate: 2.5000e-05\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0337 - val_loss: -0.0384 - learning_rate: 2.5000e-05\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0413 - val_loss: -0.0382 - learning_rate: 2.5000e-05\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0345 - val_loss: -0.0383 - learning_rate: 1.2500e-05\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0384 - val_loss: -0.0394 - learning_rate: 1.2500e-05\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0328 - val_loss: -0.0392 - learning_rate: 1.2500e-05\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.0437 - val_loss: -0.0396 - learning_rate: 1.2500e-05\n",
      "Epoch 86/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0307 - val_loss: -0.0399 - learning_rate: 1.2500e-05\n",
      "Epoch 87/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0359 - val_loss: -0.0402 - learning_rate: 1.2500e-05\n",
      "Epoch 88/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0451 - val_loss: -0.0399 - learning_rate: 1.2500e-05\n",
      "Epoch 89/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0265 - val_loss: -0.0398 - learning_rate: 1.2500e-05\n",
      "Epoch 90/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0376 - val_loss: -0.0398 - learning_rate: 1.2500e-05\n",
      "Epoch 91/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0406 - val_loss: -0.0401 - learning_rate: 1.2500e-05\n",
      "Epoch 92/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0386 - val_loss: -0.0396 - learning_rate: 1.2500e-05\n",
      "Epoch 93/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0501 - val_loss: -0.0402 - learning_rate: 6.2500e-06\n",
      "Epoch 94/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.0346 - val_loss: -0.0400 - learning_rate: 6.2500e-06\n",
      "Epoch 95/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.0376 - val_loss: -0.0393 - learning_rate: 6.2500e-06\n",
      "Epoch 96/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0421 - val_loss: -0.0405 - learning_rate: 6.2500e-06\n",
      "Epoch 97/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0287 - val_loss: -0.0403 - learning_rate: 6.2500e-06\n",
      "Epoch 98/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0426 - val_loss: -0.0405 - learning_rate: 6.2500e-06\n",
      "Epoch 99/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0297 - val_loss: -0.0409 - learning_rate: 6.2500e-06\n",
      "Epoch 100/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0342 - val_loss: -0.0407 - learning_rate: 6.2500e-06\n",
      "Epoch 101/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0325 - val_loss: -0.0409 - learning_rate: 6.2500e-06\n",
      "Epoch 102/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0385 - val_loss: -0.0407 - learning_rate: 6.2500e-06\n",
      "Epoch 103/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0286 - val_loss: -0.0408 - learning_rate: 6.2500e-06\n",
      "Epoch 104/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0266 - val_loss: -0.0403 - learning_rate: 6.2500e-06\n",
      "Epoch 105/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0220 - val_loss: -0.0397 - learning_rate: 3.1250e-06\n",
      "Epoch 106/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0388 - val_loss: -0.0404 - learning_rate: 3.1250e-06\n",
      "Epoch 107/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0427 - val_loss: -0.0408 - learning_rate: 3.1250e-06\n",
      "Epoch 108/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0447 - val_loss: -0.0406 - learning_rate: 3.1250e-06\n",
      "Epoch 109/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0421 - val_loss: -0.0404 - learning_rate: 3.1250e-06\n",
      "Epoch 110/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.0352 - val_loss: -0.0407 - learning_rate: 1.5625e-06\n",
      "Epoch 111/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0396 - val_loss: -0.0407 - learning_rate: 1.5625e-06\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.6527 - val_loss: 0.0421 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3457 - val_loss: 0.0429 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2553 - val_loss: 0.0380 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1550 - val_loss: 0.0363 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1669 - val_loss: 0.0326 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1182 - val_loss: 0.0322 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1329 - val_loss: 0.0310 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0875 - val_loss: 0.0310 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0877 - val_loss: 0.0284 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0699 - val_loss: 0.0262 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0805 - val_loss: 0.0213 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0812 - val_loss: 0.0219 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0649 - val_loss: 0.0218 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0648 - val_loss: 0.0169 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0350 - val_loss: 0.0197 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0430 - val_loss: 0.0195 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0385 - val_loss: 0.0176 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0284 - val_loss: 0.0182 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0367 - val_loss: 0.0182 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0500 - val_loss: 0.0175 - learning_rate: 5.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0264 - val_loss: 0.0163 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0219 - val_loss: 0.0180 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0422 - val_loss: 0.0171 - learning_rate: 5.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0387 - val_loss: 0.0163 - learning_rate: 5.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0282 - val_loss: 0.0156 - learning_rate: 5.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0187 - val_loss: 0.0148 - learning_rate: 5.0000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0318 - val_loss: 0.0149 - learning_rate: 5.0000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0278 - val_loss: 0.0151 - learning_rate: 5.0000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0190 - val_loss: 0.0154 - learning_rate: 5.0000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0135 - val_loss: 0.0149 - learning_rate: 5.0000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0173 - val_loss: 0.0144 - learning_rate: 5.0000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0158 - val_loss: 0.0135 - learning_rate: 5.0000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0267 - val_loss: 0.0148 - learning_rate: 5.0000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0287 - val_loss: 0.0141 - learning_rate: 5.0000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0176 - val_loss: 0.0148 - learning_rate: 5.0000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0126 - val_loss: 0.0149 - learning_rate: 5.0000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0278 - val_loss: 0.0144 - learning_rate: 5.0000e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0272 - val_loss: 0.0144 - learning_rate: 2.5000e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0179 - val_loss: 0.0145 - learning_rate: 2.5000e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0217 - val_loss: 0.0145 - learning_rate: 2.5000e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0153 - val_loss: 0.0139 - learning_rate: 2.5000e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0123 - val_loss: 0.0141 - learning_rate: 2.5000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.6461 - val_loss: 0.0353 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3428 - val_loss: -0.0385 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1777 - val_loss: -0.0855 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1154 - val_loss: -0.1134 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0408 - val_loss: -0.1428 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.0025 - val_loss: -0.1551 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0093 - val_loss: -0.1738 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.0535 - val_loss: -0.1798 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.0546 - val_loss: -0.1964 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0590 - val_loss: -0.2054 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.0951 - val_loss: -0.2213 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.1143 - val_loss: -0.2206 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.1116 - val_loss: -0.2307 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.1060 - val_loss: -0.2369 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.1358 - val_loss: -0.2430 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.1619 - val_loss: -0.2513 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.1638 - val_loss: -0.2530 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.1629 - val_loss: -0.2538 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.1739 - val_loss: -0.2593 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.1706 - val_loss: -0.2652 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.1991 - val_loss: -0.2710 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.1840 - val_loss: -0.2796 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.1837 - val_loss: -0.2827 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.2071 - val_loss: -0.2893 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.2002 - val_loss: -0.2911 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.1988 - val_loss: -0.2937 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.2087 - val_loss: -0.2926 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.2437 - val_loss: -0.3016 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.2053 - val_loss: -0.2984 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.2158 - val_loss: -0.3074 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.2522 - val_loss: -0.3056 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.2287 - val_loss: -0.3105 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.2410 - val_loss: -0.3081 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.2943 - val_loss: -0.3182 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.2663 - val_loss: -0.3272 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.2804 - val_loss: -0.3252 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.2718 - val_loss: -0.3323 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.2675 - val_loss: -0.3369 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.2776 - val_loss: -0.3330 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.2999 - val_loss: -0.3391 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.2863 - val_loss: -0.3407 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.3172 - val_loss: -0.3416 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.3354 - val_loss: -0.3450 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.3069 - val_loss: -0.3477 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.2976 - val_loss: -0.3564 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.3003 - val_loss: -0.3606 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.3333 - val_loss: -0.3666 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.3248 - val_loss: -0.3698 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.3200 - val_loss: -0.3688 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.3475 - val_loss: -0.3830 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.3416 - val_loss: -0.3942 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.3375 - val_loss: -0.3878 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3397 - val_loss: -0.3986 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.3684 - val_loss: -0.4059 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.3393 - val_loss: -0.4078 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.3662 - val_loss: -0.4157 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.3669 - val_loss: -0.4175 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.4035 - val_loss: -0.4235 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.3982 - val_loss: -0.4231 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.3885 - val_loss: -0.4288 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.3764 - val_loss: -0.4354 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.4007 - val_loss: -0.4455 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.4047 - val_loss: -0.4538 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.3983 - val_loss: -0.4530 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.4181 - val_loss: -0.4541 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.4123 - val_loss: -0.4691 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.4269 - val_loss: -0.4711 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.4169 - val_loss: -0.4703 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.4513 - val_loss: -0.4857 - learning_rate: 1.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.4491 - val_loss: -0.4883 - learning_rate: 1.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.4514 - val_loss: -0.4911 - learning_rate: 1.0000e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.4768 - val_loss: -0.4941 - learning_rate: 1.0000e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.4703 - val_loss: -0.4998 - learning_rate: 1.0000e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.4279 - val_loss: -0.5111 - learning_rate: 1.0000e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.4465 - val_loss: -0.5166 - learning_rate: 1.0000e-04\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.4501 - val_loss: -0.5199 - learning_rate: 1.0000e-04\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.4782 - val_loss: -0.5266 - learning_rate: 1.0000e-04\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.4772 - val_loss: -0.5270 - learning_rate: 1.0000e-04\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.4854 - val_loss: -0.5396 - learning_rate: 1.0000e-04\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.4627 - val_loss: -0.5378 - learning_rate: 1.0000e-04\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.4821 - val_loss: -0.5510 - learning_rate: 1.0000e-04\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.4729 - val_loss: -0.5509 - learning_rate: 1.0000e-04\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.4874 - val_loss: -0.5593 - learning_rate: 1.0000e-04\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.5230 - val_loss: -0.5641 - learning_rate: 1.0000e-04\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.5191 - val_loss: -0.5611 - learning_rate: 1.0000e-04\n",
      "Epoch 86/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.5040 - val_loss: -0.5725 - learning_rate: 1.0000e-04\n",
      "Epoch 87/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.5327 - val_loss: -0.5763 - learning_rate: 1.0000e-04\n",
      "Epoch 88/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.4928 - val_loss: -0.5784 - learning_rate: 1.0000e-04\n",
      "Epoch 89/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.5245 - val_loss: -0.5881 - learning_rate: 1.0000e-04\n",
      "Epoch 90/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.5041 - val_loss: -0.5904 - learning_rate: 1.0000e-04\n",
      "Epoch 91/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.5631 - val_loss: -0.5919 - learning_rate: 1.0000e-04\n",
      "Epoch 92/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.5188 - val_loss: -0.5970 - learning_rate: 1.0000e-04\n",
      "Epoch 93/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.5166 - val_loss: -0.5934 - learning_rate: 1.0000e-04\n",
      "Epoch 94/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.5250 - val_loss: -0.6043 - learning_rate: 1.0000e-04\n",
      "Epoch 95/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.5213 - val_loss: -0.6044 - learning_rate: 1.0000e-04\n",
      "Epoch 96/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.5421 - val_loss: -0.6088 - learning_rate: 1.0000e-04\n",
      "Epoch 97/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.5384 - val_loss: -0.6135 - learning_rate: 1.0000e-04\n",
      "Epoch 98/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.5465 - val_loss: -0.6180 - learning_rate: 1.0000e-04\n",
      "Epoch 99/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.5274 - val_loss: -0.6197 - learning_rate: 1.0000e-04\n",
      "Epoch 100/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.5591 - val_loss: -0.6275 - learning_rate: 1.0000e-04\n",
      "Epoch 101/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.5822 - val_loss: -0.6341 - learning_rate: 1.0000e-04\n",
      "Epoch 102/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.5804 - val_loss: -0.6370 - learning_rate: 1.0000e-04\n",
      "Epoch 103/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.5646 - val_loss: -0.6369 - learning_rate: 1.0000e-04\n",
      "Epoch 104/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.5504 - val_loss: -0.6396 - learning_rate: 1.0000e-04\n",
      "Epoch 105/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.5743 - val_loss: -0.6472 - learning_rate: 1.0000e-04\n",
      "Epoch 106/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.5894 - val_loss: -0.6466 - learning_rate: 1.0000e-04\n",
      "Epoch 107/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.5962 - val_loss: -0.6514 - learning_rate: 1.0000e-04\n",
      "Epoch 108/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.5479 - val_loss: -0.6521 - learning_rate: 1.0000e-04\n",
      "Epoch 109/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.5446 - val_loss: -0.6577 - learning_rate: 1.0000e-04\n",
      "Epoch 110/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.5926 - val_loss: -0.6622 - learning_rate: 1.0000e-04\n",
      "Epoch 111/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.5669 - val_loss: -0.6609 - learning_rate: 1.0000e-04\n",
      "Epoch 112/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.5953 - val_loss: -0.6715 - learning_rate: 1.0000e-04\n",
      "Epoch 113/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.6049 - val_loss: -0.6702 - learning_rate: 1.0000e-04\n",
      "Epoch 114/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.5877 - val_loss: -0.6761 - learning_rate: 1.0000e-04\n",
      "Epoch 115/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.6182 - val_loss: -0.6816 - learning_rate: 1.0000e-04\n",
      "Epoch 116/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.6070 - val_loss: -0.6781 - learning_rate: 1.0000e-04\n",
      "Epoch 117/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.5885 - val_loss: -0.6895 - learning_rate: 1.0000e-04\n",
      "Epoch 118/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.5910 - val_loss: -0.6910 - learning_rate: 1.0000e-04\n",
      "Epoch 119/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.6192 - val_loss: -0.6942 - learning_rate: 1.0000e-04\n",
      "Epoch 120/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.6092 - val_loss: -0.6941 - learning_rate: 1.0000e-04\n",
      "Epoch 121/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.6070 - val_loss: -0.6989 - learning_rate: 1.0000e-04\n",
      "Epoch 122/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.6075 - val_loss: -0.6983 - learning_rate: 1.0000e-04\n",
      "Epoch 123/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.6190 - val_loss: -0.7085 - learning_rate: 1.0000e-04\n",
      "Epoch 124/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.6192 - val_loss: -0.7086 - learning_rate: 1.0000e-04\n",
      "Epoch 125/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.6377 - val_loss: -0.7132 - learning_rate: 1.0000e-04\n",
      "Epoch 126/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.6235 - val_loss: -0.7093 - learning_rate: 1.0000e-04\n",
      "Epoch 127/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.6327 - val_loss: -0.7163 - learning_rate: 1.0000e-04\n",
      "Epoch 128/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.6241 - val_loss: -0.7211 - learning_rate: 1.0000e-04\n",
      "Epoch 129/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.6333 - val_loss: -0.7232 - learning_rate: 1.0000e-04\n",
      "Epoch 130/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.6318 - val_loss: -0.7262 - learning_rate: 1.0000e-04\n",
      "Epoch 131/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.6296 - val_loss: -0.7326 - learning_rate: 1.0000e-04\n",
      "Epoch 132/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.6342 - val_loss: -0.7367 - learning_rate: 1.0000e-04\n",
      "Epoch 133/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.6366 - val_loss: -0.7413 - learning_rate: 1.0000e-04\n",
      "Epoch 134/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.6373 - val_loss: -0.7424 - learning_rate: 1.0000e-04\n",
      "Epoch 135/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.6726 - val_loss: -0.7462 - learning_rate: 1.0000e-04\n",
      "Epoch 136/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.6452 - val_loss: -0.7428 - learning_rate: 1.0000e-04\n",
      "Epoch 137/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.6480 - val_loss: -0.7488 - learning_rate: 1.0000e-04\n",
      "Epoch 138/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.6765 - val_loss: -0.7544 - learning_rate: 1.0000e-04\n",
      "Epoch 139/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.6367 - val_loss: -0.7578 - learning_rate: 1.0000e-04\n",
      "Epoch 140/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.6411 - val_loss: -0.7546 - learning_rate: 1.0000e-04\n",
      "Epoch 141/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.6877 - val_loss: -0.7627 - learning_rate: 1.0000e-04\n",
      "Epoch 142/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.6757 - val_loss: -0.7625 - learning_rate: 1.0000e-04\n",
      "Epoch 143/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.6569 - val_loss: -0.7692 - learning_rate: 1.0000e-04\n",
      "Epoch 144/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.6870 - val_loss: -0.7696 - learning_rate: 1.0000e-04\n",
      "Epoch 145/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.6707 - val_loss: -0.7701 - learning_rate: 1.0000e-04\n",
      "Epoch 146/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.6954 - val_loss: -0.7777 - learning_rate: 1.0000e-04\n",
      "Epoch 147/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.6553 - val_loss: -0.7816 - learning_rate: 1.0000e-04\n",
      "Epoch 148/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.6952 - val_loss: -0.7782 - learning_rate: 1.0000e-04\n",
      "Epoch 149/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.6468 - val_loss: -0.7784 - learning_rate: 1.0000e-04\n",
      "Epoch 150/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.7226 - val_loss: -0.7789 - learning_rate: 1.0000e-04\n",
      "Epoch 151/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.6922 - val_loss: -0.7890 - learning_rate: 1.0000e-04\n",
      "Epoch 152/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.6886 - val_loss: -0.7876 - learning_rate: 1.0000e-04\n",
      "Epoch 153/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.7223 - val_loss: -0.7877 - learning_rate: 1.0000e-04\n",
      "Epoch 154/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.6752 - val_loss: -0.7921 - learning_rate: 1.0000e-04\n",
      "Epoch 155/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.6985 - val_loss: -0.7987 - learning_rate: 1.0000e-04\n",
      "Epoch 156/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.6926 - val_loss: -0.8035 - learning_rate: 1.0000e-04\n",
      "Epoch 157/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.7094 - val_loss: -0.8040 - learning_rate: 1.0000e-04\n",
      "Epoch 158/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.6925 - val_loss: -0.8008 - learning_rate: 1.0000e-04\n",
      "Epoch 159/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.6998 - val_loss: -0.8079 - learning_rate: 1.0000e-04\n",
      "Epoch 160/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.7114 - val_loss: -0.8035 - learning_rate: 1.0000e-04\n",
      "Epoch 161/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.7262 - val_loss: -0.8137 - learning_rate: 1.0000e-04\n",
      "Epoch 162/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.7075 - val_loss: -0.8182 - learning_rate: 1.0000e-04\n",
      "Epoch 163/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.7414 - val_loss: -0.8245 - learning_rate: 1.0000e-04\n",
      "Epoch 164/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.7082 - val_loss: -0.8245 - learning_rate: 1.0000e-04\n",
      "Epoch 165/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.7135 - val_loss: -0.8255 - learning_rate: 1.0000e-04\n",
      "Epoch 166/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.7218 - val_loss: -0.8291 - learning_rate: 1.0000e-04\n",
      "Epoch 167/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.7336 - val_loss: -0.8326 - learning_rate: 1.0000e-04\n",
      "Epoch 168/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.7349 - val_loss: -0.8348 - learning_rate: 1.0000e-04\n",
      "Epoch 169/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.7421 - val_loss: -0.8376 - learning_rate: 1.0000e-04\n",
      "Epoch 170/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.7225 - val_loss: -0.8407 - learning_rate: 1.0000e-04\n",
      "Epoch 171/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.7330 - val_loss: -0.8421 - learning_rate: 1.0000e-04\n",
      "Epoch 172/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.7392 - val_loss: -0.8457 - learning_rate: 1.0000e-04\n",
      "Epoch 173/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.7514 - val_loss: -0.8498 - learning_rate: 1.0000e-04\n",
      "Epoch 174/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.7523 - val_loss: -0.8543 - learning_rate: 1.0000e-04\n",
      "Epoch 175/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.7579 - val_loss: -0.8560 - learning_rate: 1.0000e-04\n",
      "Epoch 176/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.7194 - val_loss: -0.8568 - learning_rate: 1.0000e-04\n",
      "Epoch 177/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.7202 - val_loss: -0.8614 - learning_rate: 1.0000e-04\n",
      "Epoch 178/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.7456 - val_loss: -0.8636 - learning_rate: 1.0000e-04\n",
      "Epoch 179/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.7790 - val_loss: -0.8639 - learning_rate: 1.0000e-04\n",
      "Epoch 180/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.7382 - val_loss: -0.8704 - learning_rate: 1.0000e-04\n",
      "Epoch 181/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.7368 - val_loss: -0.8698 - learning_rate: 1.0000e-04\n",
      "Epoch 182/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.7840 - val_loss: -0.8673 - learning_rate: 1.0000e-04\n",
      "Epoch 183/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.7550 - val_loss: -0.8779 - learning_rate: 1.0000e-04\n",
      "Epoch 184/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.7626 - val_loss: -0.8766 - learning_rate: 1.0000e-04\n",
      "Epoch 185/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.7565 - val_loss: -0.8776 - learning_rate: 1.0000e-04\n",
      "Epoch 186/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.7700 - val_loss: -0.8822 - learning_rate: 1.0000e-04\n",
      "Epoch 187/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.7195 - val_loss: -0.8736 - learning_rate: 1.0000e-04\n",
      "Epoch 188/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.7975 - val_loss: -0.8872 - learning_rate: 1.0000e-04\n",
      "Epoch 189/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.7937 - val_loss: -0.8905 - learning_rate: 1.0000e-04\n",
      "Epoch 190/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.7239 - val_loss: -0.8838 - learning_rate: 1.0000e-04\n",
      "Epoch 191/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.7517 - val_loss: -0.8942 - learning_rate: 1.0000e-04\n",
      "Epoch 192/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.7757 - val_loss: -0.9011 - learning_rate: 1.0000e-04\n",
      "Epoch 193/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.7598 - val_loss: -0.9007 - learning_rate: 1.0000e-04\n",
      "Epoch 194/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.7832 - val_loss: -0.8967 - learning_rate: 1.0000e-04\n",
      "Epoch 195/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.6962 - val_loss: -0.9032 - learning_rate: 1.0000e-04\n",
      "Epoch 196/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.7974 - val_loss: -0.9128 - learning_rate: 1.0000e-04\n",
      "Epoch 197/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.7757 - val_loss: -0.9133 - learning_rate: 1.0000e-04\n",
      "Epoch 198/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.7770 - val_loss: -0.9194 - learning_rate: 1.0000e-04\n",
      "Epoch 199/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.7927 - val_loss: -0.9191 - learning_rate: 1.0000e-04\n",
      "Epoch 200/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.8072 - val_loss: -0.9223 - learning_rate: 1.0000e-04\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.5385 - val_loss: 0.0540 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3353 - val_loss: 0.0543 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2454 - val_loss: 0.0512 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1807 - val_loss: 0.0446 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1626 - val_loss: 0.0440 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1455 - val_loss: 0.0426 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1154 - val_loss: 0.0401 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1043 - val_loss: 0.0361 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0866 - val_loss: 0.0344 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0945 - val_loss: 0.0356 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0861 - val_loss: 0.0396 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0811 - val_loss: 0.0302 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0634 - val_loss: 0.0305 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0555 - val_loss: 0.0275 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0547 - val_loss: 0.0276 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0501 - val_loss: 0.0273 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0534 - val_loss: 0.0266 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0537 - val_loss: 0.0355 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0771 - val_loss: 0.0282 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0412 - val_loss: 0.0286 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0380 - val_loss: 0.0302 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0356 - val_loss: 0.0280 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0351 - val_loss: 0.0280 - learning_rate: 5.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0351 - val_loss: 0.0258 - learning_rate: 5.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0324 - val_loss: 0.0276 - learning_rate: 5.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0281 - val_loss: 0.0255 - learning_rate: 5.0000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0267 - val_loss: 0.0235 - learning_rate: 5.0000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0323 - val_loss: 0.0244 - learning_rate: 5.0000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0251 - val_loss: 0.0227 - learning_rate: 5.0000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0270 - val_loss: 0.0235 - learning_rate: 5.0000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0267 - val_loss: 0.0235 - learning_rate: 5.0000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0115 - val_loss: 0.0229 - learning_rate: 5.0000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0316 - val_loss: 0.0232 - learning_rate: 5.0000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0207 - val_loss: 0.0247 - learning_rate: 5.0000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0252 - val_loss: 0.0252 - learning_rate: 2.5000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0146 - val_loss: 0.0249 - learning_rate: 2.5000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0173 - val_loss: 0.0242 - learning_rate: 2.5000e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0228 - val_loss: 0.0250 - learning_rate: 2.5000e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0131 - val_loss: 0.0256 - learning_rate: 2.5000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.5987 - val_loss: 0.0742 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3333 - val_loss: 0.0665 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2384 - val_loss: 0.0539 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2029 - val_loss: 0.0602 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1739 - val_loss: 0.0418 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1442 - val_loss: 0.0380 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1356 - val_loss: 0.0349 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1161 - val_loss: 0.0319 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1039 - val_loss: 0.0343 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1004 - val_loss: 0.0269 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0874 - val_loss: 0.0263 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0824 - val_loss: 0.0301 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0746 - val_loss: 0.0298 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0652 - val_loss: 0.0248 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0660 - val_loss: 0.0295 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0732 - val_loss: 0.0265 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0738 - val_loss: 0.0268 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0653 - val_loss: 0.0259 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0465 - val_loss: 0.0266 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0451 - val_loss: 0.0250 - learning_rate: 5.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0487 - val_loss: 0.0269 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0293 - val_loss: 0.0256 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0429 - val_loss: 0.0230 - learning_rate: 5.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0389 - val_loss: 0.0236 - learning_rate: 5.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0284 - val_loss: 0.0240 - learning_rate: 5.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0389 - val_loss: 0.0247 - learning_rate: 5.0000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0341 - val_loss: 0.0235 - learning_rate: 5.0000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0326 - val_loss: 0.0235 - learning_rate: 5.0000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0282 - val_loss: 0.0232 - learning_rate: 2.5000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0309 - val_loss: 0.0237 - learning_rate: 2.5000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0299 - val_loss: 0.0233 - learning_rate: 2.5000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0380 - val_loss: 0.0229 - learning_rate: 2.5000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0268 - val_loss: 0.0231 - learning_rate: 2.5000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0346 - val_loss: 0.0221 - learning_rate: 2.5000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0238 - val_loss: 0.0222 - learning_rate: 2.5000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0327 - val_loss: 0.0234 - learning_rate: 2.5000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0272 - val_loss: 0.0233 - learning_rate: 2.5000e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0298 - val_loss: 0.0235 - learning_rate: 2.5000e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0244 - val_loss: 0.0235 - learning_rate: 2.5000e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0243 - val_loss: 0.0244 - learning_rate: 1.2500e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0313 - val_loss: 0.0233 - learning_rate: 1.2500e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0201 - val_loss: 0.0230 - learning_rate: 1.2500e-05\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0304 - val_loss: 0.0235 - learning_rate: 1.2500e-05\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0307 - val_loss: 0.0231 - learning_rate: 1.2500e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.8087 - val_loss: 0.0939 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4111 - val_loss: 0.0786 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2449 - val_loss: 0.0647 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1938 - val_loss: 0.0528 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1539 - val_loss: 0.0489 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1370 - val_loss: 0.0467 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1148 - val_loss: 0.0386 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1181 - val_loss: 0.0385 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0791 - val_loss: 0.0401 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0869 - val_loss: 0.0359 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0766 - val_loss: 0.0371 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0854 - val_loss: 0.0401 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0815 - val_loss: 0.0355 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0546 - val_loss: 0.0293 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0594 - val_loss: 0.0315 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0519 - val_loss: 0.0331 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0509 - val_loss: 0.0269 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0474 - val_loss: 0.0298 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0357 - val_loss: 0.0284 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0384 - val_loss: 0.0323 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0383 - val_loss: 0.0293 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0447 - val_loss: 0.0281 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0383 - val_loss: 0.0291 - learning_rate: 5.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0484 - val_loss: 0.0293 - learning_rate: 5.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0269 - val_loss: 0.0287 - learning_rate: 5.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0305 - val_loss: 0.0296 - learning_rate: 5.0000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0163 - val_loss: 0.0299 - learning_rate: 5.0000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.5254 - val_loss: 0.0563 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3125 - val_loss: 0.0634 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2326 - val_loss: 0.0580 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1732 - val_loss: 0.0505 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1302 - val_loss: 0.0492 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1054 - val_loss: 0.0441 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1073 - val_loss: 0.0459 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0888 - val_loss: 0.0400 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0894 - val_loss: 0.0393 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0958 - val_loss: 0.0384 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0751 - val_loss: 0.0408 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0823 - val_loss: 0.0430 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0561 - val_loss: 0.0358 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0567 - val_loss: 0.0364 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0583 - val_loss: 0.0379 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0670 - val_loss: 0.0340 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0423 - val_loss: 0.0397 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0453 - val_loss: 0.0377 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0322 - val_loss: 0.0352 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0340 - val_loss: 0.0349 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0399 - val_loss: 0.0325 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0397 - val_loss: 0.0333 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0402 - val_loss: 0.0338 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0338 - val_loss: 0.0345 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0273 - val_loss: 0.0318 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0399 - val_loss: 0.0360 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0269 - val_loss: 0.0298 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0371 - val_loss: 0.0334 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0135 - val_loss: 0.0334 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0280 - val_loss: 0.0343 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0310 - val_loss: 0.0323 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0260 - val_loss: 0.0314 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0305 - val_loss: 0.0318 - learning_rate: 5.0000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0177 - val_loss: 0.0327 - learning_rate: 5.0000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0189 - val_loss: 0.0300 - learning_rate: 5.0000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0207 - val_loss: 0.0302 - learning_rate: 5.0000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0123 - val_loss: 0.0295 - learning_rate: 5.0000e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0170 - val_loss: 0.0307 - learning_rate: 5.0000e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0139 - val_loss: 0.0294 - learning_rate: 5.0000e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0117 - val_loss: 0.0311 - learning_rate: 5.0000e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0242 - val_loss: 0.0298 - learning_rate: 5.0000e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0142 - val_loss: 0.0299 - learning_rate: 5.0000e-05\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0157 - val_loss: 0.0296 - learning_rate: 2.5000e-05\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0174 - val_loss: 0.0294 - learning_rate: 2.5000e-05\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0129 - val_loss: 0.0293 - learning_rate: 2.5000e-05\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0062 - val_loss: 0.0294 - learning_rate: 2.5000e-05\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0301 - learning_rate: 2.5000e-05\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0192 - val_loss: 0.0287 - learning_rate: 2.5000e-05\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0138 - val_loss: 0.0286 - learning_rate: 2.5000e-05\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0114 - val_loss: 0.0286 - learning_rate: 2.5000e-05\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0089 - val_loss: 0.0293 - learning_rate: 2.5000e-05\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0017 - val_loss: 0.0293 - learning_rate: 2.5000e-05\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0146 - val_loss: 0.0304 - learning_rate: 2.5000e-05\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0162 - val_loss: 0.0304 - learning_rate: 2.5000e-05\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0147 - val_loss: 0.0301 - learning_rate: 1.2500e-05\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0059 - val_loss: 0.0297 - learning_rate: 1.2500e-05\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0175 - val_loss: 0.0301 - learning_rate: 1.2500e-05\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0014 - val_loss: 0.0299 - learning_rate: 1.2500e-05\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0298 - learning_rate: 1.2500e-05\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0296 - learning_rate: 6.2500e-06\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.6728 - val_loss: 0.0739 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4354 - val_loss: 0.0808 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2940 - val_loss: 0.0728 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2348 - val_loss: 0.0681 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1752 - val_loss: 0.0609 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1776 - val_loss: 0.0562 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1423 - val_loss: 0.0556 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1286 - val_loss: 0.0562 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1329 - val_loss: 0.0567 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1156 - val_loss: 0.0506 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1089 - val_loss: 0.0453 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0904 - val_loss: 0.0452 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0979 - val_loss: 0.0470 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0848 - val_loss: 0.0460 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0774 - val_loss: 0.0462 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0800 - val_loss: 0.0417 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0664 - val_loss: 0.0440 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0738 - val_loss: 0.0416 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0691 - val_loss: 0.0400 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0696 - val_loss: 0.0380 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0601 - val_loss: 0.0364 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0539 - val_loss: 0.0381 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0543 - val_loss: 0.0366 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0332 - val_loss: 0.0364 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0421 - val_loss: 0.0353 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0420 - val_loss: 0.0350 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0437 - val_loss: 0.0350 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0378 - val_loss: 0.0343 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0354 - val_loss: 0.0323 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0416 - val_loss: 0.0318 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0250 - val_loss: 0.0321 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0289 - val_loss: 0.0360 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0333 - val_loss: 0.0323 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0303 - val_loss: 0.0302 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0165 - val_loss: 0.0304 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0287 - val_loss: 0.0326 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0375 - val_loss: 0.0303 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0300 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0156 - val_loss: 0.0296 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0278 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0201 - val_loss: 0.0290 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0220 - val_loss: 0.0284 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0143 - val_loss: 0.0265 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0196 - val_loss: 0.0274 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0178 - val_loss: 0.0302 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0163 - val_loss: 0.0289 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0089 - val_loss: 0.0288 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0061 - val_loss: 0.0288 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0134 - val_loss: 0.0271 - learning_rate: 5.0000e-05\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0156 - val_loss: 0.0293 - learning_rate: 5.0000e-05\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0120 - val_loss: 0.0281 - learning_rate: 5.0000e-05\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0138 - val_loss: 0.0284 - learning_rate: 5.0000e-05\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0155 - val_loss: 0.0285 - learning_rate: 5.0000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.7575 - val_loss: 0.0570 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3848 - val_loss: 0.0545 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2810 - val_loss: 0.0447 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1995 - val_loss: 0.0480 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1979 - val_loss: 0.0360 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1261 - val_loss: 0.0363 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1302 - val_loss: 0.0350 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1020 - val_loss: 0.0394 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1123 - val_loss: 0.0348 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0843 - val_loss: 0.0317 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0850 - val_loss: 0.0296 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1017 - val_loss: 0.0314 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0749 - val_loss: 0.0303 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0762 - val_loss: 0.0315 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0692 - val_loss: 0.0328 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0446 - val_loss: 0.0309 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0396 - val_loss: 0.0296 - learning_rate: 5.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0366 - val_loss: 0.0309 - learning_rate: 5.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0610 - val_loss: 0.0300 - learning_rate: 5.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0530 - val_loss: 0.0308 - learning_rate: 5.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0468 - val_loss: 0.0286 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0515 - val_loss: 0.0290 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0473 - val_loss: 0.0290 - learning_rate: 5.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0455 - val_loss: 0.0304 - learning_rate: 5.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0407 - val_loss: 0.0303 - learning_rate: 5.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0437 - val_loss: 0.0300 - learning_rate: 5.0000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0486 - val_loss: 0.0300 - learning_rate: 2.5000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0403 - val_loss: 0.0294 - learning_rate: 2.5000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0518 - val_loss: 0.0293 - learning_rate: 2.5000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0442 - val_loss: 0.0291 - learning_rate: 2.5000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0442 - val_loss: 0.0297 - learning_rate: 2.5000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.9531 - val_loss: 0.0861 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3922 - val_loss: 0.0779 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2810 - val_loss: 0.0529 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2037 - val_loss: 0.0481 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1995 - val_loss: 0.0296 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1367 - val_loss: 0.0280 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1050 - val_loss: 0.0244 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0944 - val_loss: 0.0235 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1092 - val_loss: 0.0216 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1092 - val_loss: 0.0218 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0931 - val_loss: 0.0187 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0639 - val_loss: 0.0210 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0713 - val_loss: 0.0228 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0808 - val_loss: 0.0203 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0733 - val_loss: 0.0224 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0570 - val_loss: 0.0174 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0646 - val_loss: 0.0147 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0502 - val_loss: 0.0168 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0430 - val_loss: 0.0157 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0364 - val_loss: 0.0170 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0442 - val_loss: 0.0195 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0306 - val_loss: 0.0145 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0353 - val_loss: 0.0209 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0283 - val_loss: 0.0156 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0330 - val_loss: 0.0190 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0351 - val_loss: 0.0173 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0293 - val_loss: 0.0243 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0324 - val_loss: 0.0167 - learning_rate: 5.0000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0235 - val_loss: 0.0193 - learning_rate: 5.0000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0256 - val_loss: 0.0201 - learning_rate: 5.0000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0292 - val_loss: 0.0206 - learning_rate: 5.0000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0243 - val_loss: 0.0217 - learning_rate: 5.0000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.7364 - val_loss: 0.0688 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3576 - val_loss: 0.0677 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2555 - val_loss: 0.0612 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1894 - val_loss: 0.0514 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1543 - val_loss: 0.0509 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1372 - val_loss: 0.0464 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1269 - val_loss: 0.0545 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1011 - val_loss: 0.0404 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1091 - val_loss: 0.0421 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0770 - val_loss: 0.0391 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0700 - val_loss: 0.0360 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0668 - val_loss: 0.0346 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0886 - val_loss: 0.0344 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0664 - val_loss: 0.0309 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0530 - val_loss: 0.0311 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0472 - val_loss: 0.0305 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0623 - val_loss: 0.0314 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0648 - val_loss: 0.0289 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0408 - val_loss: 0.0292 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0359 - val_loss: 0.0285 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0375 - val_loss: 0.0293 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0357 - val_loss: 0.0279 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0439 - val_loss: 0.0317 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0356 - val_loss: 0.0279 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0299 - val_loss: 0.0275 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0226 - val_loss: 0.0247 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0224 - val_loss: 0.0282 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0196 - val_loss: 0.0290 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0345 - val_loss: 0.0245 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0318 - val_loss: 0.0240 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0244 - val_loss: 0.0270 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0207 - val_loss: 0.0230 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0258 - val_loss: 0.0219 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0231 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0204 - val_loss: 0.0201 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0212 - val_loss: 0.0207 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0154 - val_loss: 0.0226 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0158 - val_loss: 0.0233 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0118 - val_loss: 0.0221 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0307 - val_loss: 0.0222 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0122 - val_loss: 0.0217 - learning_rate: 5.0000e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0100 - val_loss: 0.0216 - learning_rate: 5.0000e-05\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4.5775e-04 - val_loss: 0.0204 - learning_rate: 5.0000e-05\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0063 - val_loss: 0.0212 - learning_rate: 5.0000e-05\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0165 - val_loss: 0.0214 - learning_rate: 5.0000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.6806 - val_loss: 0.0759 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3103 - val_loss: 0.0655 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1893 - val_loss: 0.0574 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1558 - val_loss: 0.0530 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1401 - val_loss: 0.0460 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1202 - val_loss: 0.0413 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1157 - val_loss: 0.0428 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1100 - val_loss: 0.0412 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1060 - val_loss: 0.0427 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0919 - val_loss: 0.0383 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0787 - val_loss: 0.0396 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0788 - val_loss: 0.0371 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0713 - val_loss: 0.0351 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0708 - val_loss: 0.0376 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0614 - val_loss: 0.0301 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0614 - val_loss: 0.0344 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0390 - val_loss: 0.0282 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0478 - val_loss: 0.0281 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0296 - val_loss: 0.0353 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0420 - val_loss: 0.0275 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0385 - val_loss: 0.0312 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0358 - val_loss: 0.0287 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0353 - val_loss: 0.0314 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0421 - val_loss: 0.0288 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0370 - val_loss: 0.0287 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0327 - val_loss: 0.0251 - learning_rate: 5.0000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0259 - val_loss: 0.0274 - learning_rate: 5.0000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0277 - val_loss: 0.0281 - learning_rate: 5.0000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0372 - val_loss: 0.0259 - learning_rate: 5.0000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0253 - val_loss: 0.0261 - learning_rate: 5.0000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0040 - val_loss: 0.0276 - learning_rate: 5.0000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0285 - val_loss: 0.0263 - learning_rate: 2.5000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0270 - val_loss: 0.0252 - learning_rate: 2.5000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0197 - val_loss: 0.0262 - learning_rate: 2.5000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0243 - val_loss: 0.0254 - learning_rate: 2.5000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0243 - val_loss: 0.0256 - learning_rate: 2.5000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.7694 - val_loss: 0.0637 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3718 - val_loss: 0.0635 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2788 - val_loss: 0.0537 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2404 - val_loss: 0.0554 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1663 - val_loss: 0.0509 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1574 - val_loss: 0.0529 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1172 - val_loss: 0.0574 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1278 - val_loss: 0.0469 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0891 - val_loss: 0.0482 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1149 - val_loss: 0.0426 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0902 - val_loss: 0.0450 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0900 - val_loss: 0.0625 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0900 - val_loss: 0.0435 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0778 - val_loss: 0.0487 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0657 - val_loss: 0.0360 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0446 - val_loss: 0.0348 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0662 - val_loss: 0.0376 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0639 - val_loss: 0.0346 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0558 - val_loss: 0.0329 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0367 - val_loss: 0.0324 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0487 - val_loss: 0.0412 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0441 - val_loss: 0.0322 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0285 - val_loss: 0.0312 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0354 - val_loss: 0.0277 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0304 - val_loss: 0.0382 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0276 - val_loss: 0.0280 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0401 - val_loss: 0.0330 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0213 - val_loss: 0.0309 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0353 - val_loss: 0.0375 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0297 - val_loss: 0.0326 - learning_rate: 5.0000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0324 - val_loss: 0.0341 - learning_rate: 5.0000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0203 - val_loss: 0.0308 - learning_rate: 5.0000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0235 - val_loss: 0.0332 - learning_rate: 5.0000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0261 - val_loss: 0.0350 - learning_rate: 5.0000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.6866 - val_loss: 0.0575 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3519 - val_loss: 0.0603 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2557 - val_loss: 0.0520 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2184 - val_loss: 0.0489 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1472 - val_loss: 0.0460 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1310 - val_loss: 0.0449 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1412 - val_loss: 0.0418 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.1221 - val_loss: 0.0403 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1085 - val_loss: 0.0392 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1076 - val_loss: 0.0369 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0705 - val_loss: 0.0354 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0657 - val_loss: 0.0340 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0779 - val_loss: 0.0312 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0683 - val_loss: 0.0355 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0567 - val_loss: 0.0297 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0570 - val_loss: 0.0300 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0519 - val_loss: 0.0298 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0382 - val_loss: 0.0266 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0585 - val_loss: 0.0254 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0614 - val_loss: 0.0250 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0443 - val_loss: 0.0250 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0448 - val_loss: 0.0254 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0417 - val_loss: 0.0252 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0432 - val_loss: 0.0250 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0355 - val_loss: 0.0233 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0246 - val_loss: 0.0235 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0224 - val_loss: 0.0239 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0250 - val_loss: 0.0250 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0262 - val_loss: 0.0232 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0307 - val_loss: 0.0244 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0175 - val_loss: 0.0232 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0284 - val_loss: 0.0235 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0198 - val_loss: 0.0231 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0255 - val_loss: 0.0219 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0211 - val_loss: 0.0211 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0138 - val_loss: 0.0225 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0172 - val_loss: 0.0221 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0217 - val_loss: 0.0227 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0196 - val_loss: 0.0233 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0186 - val_loss: 0.0215 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0186 - val_loss: 0.0216 - learning_rate: 5.0000e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0161 - val_loss: 0.0220 - learning_rate: 5.0000e-05\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0062 - val_loss: 0.0219 - learning_rate: 5.0000e-05\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0159 - val_loss: 0.0207 - learning_rate: 5.0000e-05\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0140 - val_loss: 0.0207 - learning_rate: 5.0000e-05\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0133 - val_loss: 0.0213 - learning_rate: 5.0000e-05\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0091 - val_loss: 0.0211 - learning_rate: 5.0000e-05\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0155 - val_loss: 0.0212 - learning_rate: 5.0000e-05\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0090 - val_loss: 0.0207 - learning_rate: 5.0000e-05\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0203 - learning_rate: 2.5000e-05\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0105 - val_loss: 0.0202 - learning_rate: 2.5000e-05\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0099 - val_loss: 0.0197 - learning_rate: 2.5000e-05\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0085 - val_loss: 0.0205 - learning_rate: 2.5000e-05\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0126 - val_loss: 0.0198 - learning_rate: 2.5000e-05\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0151 - val_loss: 0.0199 - learning_rate: 2.5000e-05\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0064 - val_loss: 0.0202 - learning_rate: 2.5000e-05\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0087 - val_loss: 0.0207 - learning_rate: 2.5000e-05\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0116 - val_loss: 0.0206 - learning_rate: 1.2500e-05\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0075 - val_loss: 0.0204 - learning_rate: 1.2500e-05\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0133 - val_loss: 0.0203 - learning_rate: 1.2500e-05\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0088 - val_loss: 0.0203 - learning_rate: 1.2500e-05\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0103 - val_loss: 0.0202 - learning_rate: 1.2500e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.6720 - val_loss: 0.0486 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3010 - val_loss: 0.0573 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2092 - val_loss: 0.0552 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1634 - val_loss: 0.0513 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1209 - val_loss: 0.0476 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1185 - val_loss: 0.0465 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1180 - val_loss: 0.0503 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0965 - val_loss: 0.0406 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0929 - val_loss: 0.0430 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0709 - val_loss: 0.0401 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0757 - val_loss: 0.0353 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0456 - val_loss: 0.0414 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0424 - val_loss: 0.0399 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0696 - val_loss: 0.0406 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0659 - val_loss: 0.0386 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0578 - val_loss: 0.0371 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0459 - val_loss: 0.0379 - learning_rate: 5.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0398 - val_loss: 0.0373 - learning_rate: 5.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0346 - val_loss: 0.0412 - learning_rate: 5.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0577 - val_loss: 0.0356 - learning_rate: 5.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0419 - val_loss: 0.0350 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0426 - val_loss: 0.0363 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0470 - val_loss: 0.0337 - learning_rate: 5.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0390 - val_loss: 0.0371 - learning_rate: 5.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0333 - val_loss: 0.0340 - learning_rate: 5.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0421 - val_loss: 0.0341 - learning_rate: 5.0000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0346 - val_loss: 0.0363 - learning_rate: 5.0000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0322 - val_loss: 0.0367 - learning_rate: 5.0000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0268 - val_loss: 0.0364 - learning_rate: 2.5000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0315 - val_loss: 0.0357 - learning_rate: 2.5000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0313 - val_loss: 0.0344 - learning_rate: 2.5000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0305 - val_loss: 0.0340 - learning_rate: 2.5000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0321 - val_loss: 0.0335 - learning_rate: 2.5000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0325 - val_loss: 0.0345 - learning_rate: 2.5000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0314 - val_loss: 0.0338 - learning_rate: 2.5000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0273 - val_loss: 0.0346 - learning_rate: 2.5000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0274 - val_loss: 0.0335 - learning_rate: 2.5000e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0203 - val_loss: 0.0333 - learning_rate: 2.5000e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0235 - val_loss: 0.0331 - learning_rate: 2.5000e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0333 - val_loss: 0.0332 - learning_rate: 2.5000e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0267 - val_loss: 0.0334 - learning_rate: 2.5000e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0285 - val_loss: 0.0324 - learning_rate: 2.5000e-05\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0191 - val_loss: 0.0329 - learning_rate: 2.5000e-05\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0309 - val_loss: 0.0336 - learning_rate: 2.5000e-05\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0305 - val_loss: 0.0328 - learning_rate: 2.5000e-05\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0199 - val_loss: 0.0348 - learning_rate: 2.5000e-05\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0234 - val_loss: 0.0339 - learning_rate: 2.5000e-05\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0174 - val_loss: 0.0335 - learning_rate: 1.2500e-05\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0257 - val_loss: 0.0330 - learning_rate: 1.2500e-05\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0171 - val_loss: 0.0334 - learning_rate: 1.2500e-05\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0259 - val_loss: 0.0335 - learning_rate: 1.2500e-05\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0269 - val_loss: 0.0330 - learning_rate: 1.2500e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 1.1443 - val_loss: 0.0747 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.3860 - val_loss: 0.0727 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2401 - val_loss: 0.0647 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1872 - val_loss: 0.0515 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1366 - val_loss: 0.0485 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1123 - val_loss: 0.0398 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1055 - val_loss: 0.0368 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1036 - val_loss: 0.0370 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0959 - val_loss: 0.0345 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0669 - val_loss: 0.0357 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0607 - val_loss: 0.0296 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0747 - val_loss: 0.0274 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0481 - val_loss: 0.0344 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0532 - val_loss: 0.0270 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0588 - val_loss: 0.0293 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0596 - val_loss: 0.0296 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0512 - val_loss: 0.0259 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0516 - val_loss: 0.0254 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0348 - val_loss: 0.0317 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0355 - val_loss: 0.0284 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0390 - val_loss: 0.0255 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0347 - val_loss: 0.0268 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0272 - val_loss: 0.0290 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0254 - val_loss: 0.0263 - learning_rate: 5.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0269 - val_loss: 0.0266 - learning_rate: 5.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0221 - val_loss: 0.0257 - learning_rate: 5.0000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0304 - val_loss: 0.0256 - learning_rate: 5.0000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0278 - val_loss: 0.0245 - learning_rate: 5.0000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183 - val_loss: 0.0233 - learning_rate: 5.0000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0355 - val_loss: 0.0241 - learning_rate: 5.0000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0203 - val_loss: 0.0227 - learning_rate: 5.0000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0201 - val_loss: 0.0249 - learning_rate: 5.0000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0271 - val_loss: 0.0219 - learning_rate: 5.0000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0217 - val_loss: 0.0215 - learning_rate: 5.0000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0275 - val_loss: 0.0219 - learning_rate: 5.0000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0210 - val_loss: 0.0220 - learning_rate: 5.0000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0186 - val_loss: 0.0218 - learning_rate: 5.0000e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0169 - val_loss: 0.0232 - learning_rate: 5.0000e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0204 - val_loss: 0.0223 - learning_rate: 5.0000e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0132 - val_loss: 0.0212 - learning_rate: 2.5000e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0094 - val_loss: 0.0209 - learning_rate: 2.5000e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0180 - val_loss: 0.0214 - learning_rate: 2.5000e-05\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0059 - val_loss: 0.0216 - learning_rate: 2.5000e-05\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0206 - val_loss: 0.0220 - learning_rate: 2.5000e-05\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0178 - val_loss: 0.0212 - learning_rate: 2.5000e-05\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0115 - val_loss: 0.0212 - learning_rate: 2.5000e-05\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0100 - val_loss: 0.0210 - learning_rate: 1.2500e-05\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0153 - val_loss: 0.0215 - learning_rate: 1.2500e-05\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0131 - val_loss: 0.0212 - learning_rate: 1.2500e-05\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0054 - val_loss: 0.0210 - learning_rate: 1.2500e-05\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0073 - val_loss: 0.0206 - learning_rate: 1.2500e-05\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0107 - val_loss: 0.0207 - learning_rate: 1.2500e-05\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0137 - val_loss: 0.0207 - learning_rate: 1.2500e-05\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0124 - val_loss: 0.0206 - learning_rate: 1.2500e-05\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0099 - val_loss: 0.0201 - learning_rate: 1.2500e-05\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0172 - val_loss: 0.0204 - learning_rate: 1.2500e-05\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0067 - val_loss: 0.0204 - learning_rate: 1.2500e-05\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0123 - val_loss: 0.0206 - learning_rate: 1.2500e-05\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1211s\u001b[0m 5s/step - loss: 0.0165 - val_loss: 0.0204 - learning_rate: 1.2500e-05\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4356s\u001b[0m 17s/step - loss: 0.0142 - val_loss: 0.0211 - learning_rate: 1.2500e-05\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0259 - val_loss: 0.0212 - learning_rate: 6.2500e-06\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0140 - val_loss: 0.0204 - learning_rate: 6.2500e-06\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0143 - val_loss: 0.0208 - learning_rate: 6.2500e-06\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0073 - val_loss: 0.0205 - learning_rate: 6.2500e-06\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0132 - val_loss: 0.0202 - learning_rate: 6.2500e-06\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.6007 - val_loss: 0.0602 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3626 - val_loss: 0.0527 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2163 - val_loss: 0.0438 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1870 - val_loss: 0.0374 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.1640 - val_loss: 0.0295 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1153 - val_loss: 0.0280 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1058 - val_loss: 0.0275 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1007 - val_loss: 0.0251 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0769 - val_loss: 0.0233 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0717 - val_loss: 0.0259 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0730 - val_loss: 0.0261 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0727 - val_loss: 0.0235 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0460 - val_loss: 0.0252 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0662 - val_loss: 0.0240 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0592 - val_loss: 0.0225 - learning_rate: 5.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0499 - val_loss: 0.0225 - learning_rate: 5.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0549 - val_loss: 0.0212 - learning_rate: 5.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0516 - val_loss: 0.0220 - learning_rate: 5.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0450 - val_loss: 0.0222 - learning_rate: 5.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0429 - val_loss: 0.0223 - learning_rate: 5.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0379 - val_loss: 0.0214 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0452 - val_loss: 0.0214 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0422 - val_loss: 0.0213 - learning_rate: 2.5000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0319 - val_loss: 0.0210 - learning_rate: 2.5000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0325 - val_loss: 0.0210 - learning_rate: 2.5000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0380 - val_loss: 0.0211 - learning_rate: 2.5000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0402 - val_loss: 0.0210 - learning_rate: 2.5000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0366 - val_loss: 0.0210 - learning_rate: 2.5000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0391 - val_loss: 0.0207 - learning_rate: 2.5000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0415 - val_loss: 0.0199 - learning_rate: 2.5000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0226 - val_loss: 0.0199 - learning_rate: 2.5000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0227 - val_loss: 0.0196 - learning_rate: 2.5000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0318 - val_loss: 0.0189 - learning_rate: 2.5000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0379 - val_loss: 0.0186 - learning_rate: 2.5000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0279 - val_loss: 0.0188 - learning_rate: 2.5000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0165 - val_loss: 0.0188 - learning_rate: 2.5000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0202 - val_loss: 0.0183 - learning_rate: 2.5000e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0297 - val_loss: 0.0188 - learning_rate: 2.5000e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0189 - val_loss: 0.0190 - learning_rate: 2.5000e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0262 - val_loss: 0.0193 - learning_rate: 2.5000e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0258 - val_loss: 0.0188 - learning_rate: 2.5000e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0338 - val_loss: 0.0197 - learning_rate: 2.5000e-05\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0176 - val_loss: 0.0192 - learning_rate: 1.2500e-05\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0228 - val_loss: 0.0191 - learning_rate: 1.2500e-05\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0301 - val_loss: 0.0193 - learning_rate: 1.2500e-05\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0190 - val_loss: 0.0191 - learning_rate: 1.2500e-05\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0274 - val_loss: 0.0190 - learning_rate: 1.2500e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.6969 - val_loss: 0.0646 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3626 - val_loss: 0.0752 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.1892 - val_loss: 0.0669 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.1807 - val_loss: 0.0567 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1475 - val_loss: 0.0567 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1012 - val_loss: 0.0522 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1003 - val_loss: 0.0468 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1088 - val_loss: 0.0473 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0846 - val_loss: 0.0450 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0626 - val_loss: 0.0423 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0864 - val_loss: 0.0467 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0586 - val_loss: 0.0397 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0686 - val_loss: 0.0326 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0521 - val_loss: 0.0354 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0716 - val_loss: 0.0358 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0622 - val_loss: 0.0349 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0432 - val_loss: 0.0326 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0532 - val_loss: 0.0331 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0435 - val_loss: 0.0331 - learning_rate: 5.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0433 - val_loss: 0.0326 - learning_rate: 5.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0398 - val_loss: 0.0317 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0323 - val_loss: 0.0349 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0379 - val_loss: 0.0376 - learning_rate: 5.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0362 - val_loss: 0.0327 - learning_rate: 5.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0314 - val_loss: 0.0286 - learning_rate: 5.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0294 - val_loss: 0.0291 - learning_rate: 5.0000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0300 - val_loss: 0.0294 - learning_rate: 5.0000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0271 - val_loss: 0.0300 - learning_rate: 5.0000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0246 - val_loss: 0.0296 - learning_rate: 5.0000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0200 - val_loss: 0.0301 - learning_rate: 5.0000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0287 - val_loss: 0.0307 - learning_rate: 2.5000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0301 - val_loss: 0.0291 - learning_rate: 2.5000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0252 - val_loss: 0.0287 - learning_rate: 2.5000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0255 - val_loss: 0.0278 - learning_rate: 2.5000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0260 - val_loss: 0.0278 - learning_rate: 2.5000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0324 - val_loss: 0.0278 - learning_rate: 2.5000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0378 - val_loss: 0.0274 - learning_rate: 2.5000e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0282 - val_loss: 0.0270 - learning_rate: 2.5000e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0233 - val_loss: 0.0274 - learning_rate: 2.5000e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0329 - val_loss: 0.0284 - learning_rate: 2.5000e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0233 - val_loss: 0.0290 - learning_rate: 2.5000e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0282 - val_loss: 0.0293 - learning_rate: 2.5000e-05\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0227 - val_loss: 0.0278 - learning_rate: 2.5000e-05\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0260 - val_loss: 0.0277 - learning_rate: 1.2500e-05\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0197 - val_loss: 0.0277 - learning_rate: 1.2500e-05\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0265 - val_loss: 0.0273 - learning_rate: 1.2500e-05\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0196 - val_loss: 0.0274 - learning_rate: 1.2500e-05\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0163 - val_loss: 0.0281 - learning_rate: 1.2500e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.5887 - val_loss: 0.0998 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3869 - val_loss: 0.0915 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2440 - val_loss: 0.0781 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1992 - val_loss: 0.0684 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1644 - val_loss: 0.0636 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1301 - val_loss: 0.0586 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0968 - val_loss: 0.0624 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1066 - val_loss: 0.0579 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1017 - val_loss: 0.0590 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0914 - val_loss: 0.0531 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0669 - val_loss: 0.0557 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0653 - val_loss: 0.0554 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0683 - val_loss: 0.0500 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0670 - val_loss: 0.0493 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0572 - val_loss: 0.0503 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0517 - val_loss: 0.0474 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0597 - val_loss: 0.0467 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0418 - val_loss: 0.0409 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0565 - val_loss: 0.0436 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0459 - val_loss: 0.0451 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0492 - val_loss: 0.0390 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0379 - val_loss: 0.0488 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0230 - val_loss: 0.0414 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0467 - val_loss: 0.0455 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0425 - val_loss: 0.0389 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0313 - val_loss: 0.0403 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0309 - val_loss: 0.0390 - learning_rate: 5.0000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0403 - val_loss: 0.0376 - learning_rate: 5.0000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0356 - val_loss: 0.0388 - learning_rate: 5.0000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0284 - val_loss: 0.0382 - learning_rate: 5.0000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0273 - val_loss: 0.0380 - learning_rate: 5.0000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0153 - val_loss: 0.0364 - learning_rate: 5.0000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0243 - val_loss: 0.0361 - learning_rate: 5.0000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0311 - val_loss: 0.0371 - learning_rate: 5.0000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0197 - val_loss: 0.0388 - learning_rate: 5.0000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0317 - val_loss: 0.0367 - learning_rate: 5.0000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0351 - val_loss: 0.0391 - learning_rate: 5.0000e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0213 - val_loss: 0.0378 - learning_rate: 5.0000e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0261 - val_loss: 0.0375 - learning_rate: 2.5000e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0180 - val_loss: 0.0370 - learning_rate: 2.5000e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 0.0369 - learning_rate: 2.5000e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0142 - val_loss: 0.0374 - learning_rate: 2.5000e-05\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0161 - val_loss: 0.0381 - learning_rate: 2.5000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.7338 - val_loss: 0.0837 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.3477 - val_loss: 0.0963 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2955 - val_loss: 0.0843 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1969 - val_loss: 0.0744 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1769 - val_loss: 0.0626 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1230 - val_loss: 0.0660 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1093 - val_loss: 0.0562 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0995 - val_loss: 0.0527 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1016 - val_loss: 0.0524 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0838 - val_loss: 0.0447 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0892 - val_loss: 0.0458 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0740 - val_loss: 0.0433 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0700 - val_loss: 0.0407 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0767 - val_loss: 0.0416 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0614 - val_loss: 0.0408 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0558 - val_loss: 0.0438 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0576 - val_loss: 0.0450 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0420 - val_loss: 0.0413 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0495 - val_loss: 0.0394 - learning_rate: 5.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0437 - val_loss: 0.0392 - learning_rate: 5.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0463 - val_loss: 0.0384 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0479 - val_loss: 0.0389 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0459 - val_loss: 0.0367 - learning_rate: 5.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0648 - val_loss: 0.0357 - learning_rate: 5.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0263 - val_loss: 0.0361 - learning_rate: 5.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0375 - val_loss: 0.0380 - learning_rate: 5.0000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0384 - val_loss: 0.0359 - learning_rate: 5.0000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0246 - val_loss: 0.0348 - learning_rate: 5.0000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0412 - val_loss: 0.0360 - learning_rate: 5.0000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0326 - val_loss: 0.0357 - learning_rate: 5.0000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0311 - val_loss: 0.0348 - learning_rate: 5.0000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0222 - val_loss: 0.0356 - learning_rate: 5.0000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0147 - val_loss: 0.0349 - learning_rate: 5.0000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0307 - val_loss: 0.0348 - learning_rate: 2.5000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0325 - val_loss: 0.0350 - learning_rate: 2.5000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0210 - val_loss: 0.0343 - learning_rate: 2.5000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0286 - val_loss: 0.0346 - learning_rate: 2.5000e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0458 - val_loss: 0.0347 - learning_rate: 2.5000e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0303 - val_loss: 0.0357 - learning_rate: 2.5000e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0225 - val_loss: 0.0350 - learning_rate: 2.5000e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0253 - val_loss: 0.0350 - learning_rate: 2.5000e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0213 - val_loss: 0.0353 - learning_rate: 1.2500e-05\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0246 - val_loss: 0.0349 - learning_rate: 1.2500e-05\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0220 - val_loss: 0.0354 - learning_rate: 1.2500e-05\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0235 - val_loss: 0.0343 - learning_rate: 1.2500e-05\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0289 - val_loss: 0.0345 - learning_rate: 1.2500e-05\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0166 - val_loss: 0.0345 - learning_rate: 6.2500e-06\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0233 - val_loss: 0.0345 - learning_rate: 6.2500e-06\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0246 - val_loss: 0.0343 - learning_rate: 6.2500e-06\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0208 - val_loss: 0.0342 - learning_rate: 6.2500e-06\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0276 - val_loss: 0.0342 - learning_rate: 6.2500e-06\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0249 - val_loss: 0.0345 - learning_rate: 6.2500e-06\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0238 - val_loss: 0.0341 - learning_rate: 6.2500e-06\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0226 - val_loss: 0.0338 - learning_rate: 6.2500e-06\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0205 - val_loss: 0.0341 - learning_rate: 6.2500e-06\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0247 - val_loss: 0.0342 - learning_rate: 6.2500e-06\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0177 - val_loss: 0.0341 - learning_rate: 6.2500e-06\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0215 - val_loss: 0.0340 - learning_rate: 6.2500e-06\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0218 - val_loss: 0.0335 - learning_rate: 6.2500e-06\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0272 - val_loss: 0.0336 - learning_rate: 6.2500e-06\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0189 - val_loss: 0.0338 - learning_rate: 6.2500e-06\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0190 - val_loss: 0.0333 - learning_rate: 6.2500e-06\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0317 - val_loss: 0.0335 - learning_rate: 6.2500e-06\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0302 - val_loss: 0.0334 - learning_rate: 6.2500e-06\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0271 - val_loss: 0.0334 - learning_rate: 6.2500e-06\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0236 - val_loss: 0.0335 - learning_rate: 6.2500e-06\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0216 - val_loss: 0.0334 - learning_rate: 6.2500e-06\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0245 - val_loss: 0.0337 - learning_rate: 3.1250e-06\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0224 - val_loss: 0.0338 - learning_rate: 3.1250e-06\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0199 - val_loss: 0.0337 - learning_rate: 3.1250e-06\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0200 - val_loss: 0.0333 - learning_rate: 3.1250e-06\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0175 - val_loss: 0.0335 - learning_rate: 3.1250e-06\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0210 - val_loss: 0.0334 - learning_rate: 1.5625e-06\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0228 - val_loss: 0.0335 - learning_rate: 1.5625e-06\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0292 - val_loss: 0.0333 - learning_rate: 1.5625e-06\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0193 - val_loss: 0.0334 - learning_rate: 1.5625e-06\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0226 - val_loss: 0.0332 - learning_rate: 1.5625e-06\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0257 - val_loss: 0.0335 - learning_rate: 1.0000e-06\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0279 - val_loss: 0.0329 - learning_rate: 1.0000e-06\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0150 - val_loss: 0.0334 - learning_rate: 1.0000e-06\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0189 - val_loss: 0.0336 - learning_rate: 1.0000e-06\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0232 - val_loss: 0.0333 - learning_rate: 1.0000e-06\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0241 - val_loss: 0.0337 - learning_rate: 1.0000e-06\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0214 - val_loss: 0.0335 - learning_rate: 1.0000e-06\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0208 - val_loss: 0.0338 - learning_rate: 1.0000e-06\n",
      "Epoch 86/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0220 - val_loss: 0.0334 - learning_rate: 1.0000e-06\n",
      "Epoch 87/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0133 - val_loss: 0.0332 - learning_rate: 1.0000e-06\n",
      "Epoch 88/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0244 - val_loss: 0.0334 - learning_rate: 1.0000e-06\n",
      "Epoch 89/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0252 - val_loss: 0.0332 - learning_rate: 1.0000e-06\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 zmiennych na podstawie CMI: [ 3  1 19  2  4  5  6  7  8  9]\n",
      "Top 10 zmiennych na podstawie LASSO: [ 3  1  2  4  5 18  6 11 19 12]\n",
      "Liczba odwróconych par: 75\n",
      "Top 10 agreement score: 0.7\n",
      "Top 5 agreement score: 0.8\n"
     ]
    }
   ],
   "source": [
    "#est1\n",
    "\n",
    "cmi_scores = []\n",
    "for i in range(X.shape[1]):\n",
    "    Z = np.delete(X, i, axis=1) \n",
    "    cmi_scores.append(est1(X[:, i].reshape(-1, 1), Y.reshape(-1, 1), Z))\n",
    "\n",
    "\n",
    "cmi_ranking = np.argsort(cmi_scores)[::-1]\n",
    "\n",
    "# Wizualizacja rankingów\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(range(1, n_features + 1), np.array(cmi_scores)[cmi_ranking], tick_label=cmi_ranking + 1)\n",
    "plt.title(\"CMI Ranking\")\n",
    "plt.xlabel(\"Feature Index\")\n",
    "plt.ylabel(\"Conditional Mutual Information\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(range(1, n_features + 1), lasso_importances[lasso_ranking], tick_label=lasso_ranking + 1)\n",
    "plt.title(\"LASSO Ranking\")\n",
    "plt.xlabel(\"Feature Index\")\n",
    "plt.ylabel(\"LASSO Coefficients\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Wyświetlamy top 10 zmiennych\n",
    "print(\"Top 10 zmiennych na podstawie CMI:\", cmi_ranking[:10] + 1)\n",
    "print(\"Top 10 zmiennych na podstawie LASSO:\", lasso_ranking[:10] + 1)\n",
    "\n",
    "\n",
    "\n",
    "# Liczenie liczby odwróconych par\n",
    "inversions = count_inversions(cmi_ranking, lasso_ranking)\n",
    "print(f\"Liczba odwróconych par: {inversions}\")\n",
    "\n",
    "# Liczenie liczby przypadków, w których top 10 zmiennych się pokrywają\n",
    "top_k_agreement_10 = top_k_agreement(cmi_ranking, lasso_ranking, 10)\n",
    "top_k_agreement_5 = top_k_agreement(cmi_ranking, lasso_ranking, 5)\n",
    "\n",
    "print(f\"Top 10 agreement score: {top_k_agreement_10}\")\n",
    "print(f\"Top 5 agreement score: {top_k_agreement_5}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.6704 - val_loss: 0.0115 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.3222 - val_loss: -0.1004 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1268 - val_loss: -0.1585 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0783 - val_loss: -0.2003 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0238 - val_loss: -0.2336 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.0368 - val_loss: -0.2643 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.0903 - val_loss: -0.2854 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.1077 - val_loss: -0.3027 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.0687 - val_loss: -0.3211 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.1487 - val_loss: -0.3313 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.1294 - val_loss: -0.3459 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.1520 - val_loss: -0.3566 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.2182 - val_loss: -0.3635 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.2091 - val_loss: -0.3715 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.2254 - val_loss: -0.3809 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.2333 - val_loss: -0.3890 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.2308 - val_loss: -0.3944 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.2263 - val_loss: -0.3991 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.2521 - val_loss: -0.4087 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.2757 - val_loss: -0.4127 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.2516 - val_loss: -0.4179 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.3306 - val_loss: -0.4236 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.2800 - val_loss: -0.4295 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.3061 - val_loss: -0.4364 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.2683 - val_loss: -0.4452 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.2818 - val_loss: -0.4516 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.2882 - val_loss: -0.4573 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.3234 - val_loss: -0.4625 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.3133 - val_loss: -0.4686 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.2855 - val_loss: -0.4763 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.3340 - val_loss: -0.4793 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3499 - val_loss: -0.4866 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3633 - val_loss: -0.4907 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3211 - val_loss: -0.4948 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3520 - val_loss: -0.5016 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4099 - val_loss: -0.5073 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.3990 - val_loss: -0.5105 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3528 - val_loss: -0.5179 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3925 - val_loss: -0.5237 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4187 - val_loss: -0.5340 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4141 - val_loss: -0.5373 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3984 - val_loss: -0.5387 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4386 - val_loss: -0.5447 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.4374 - val_loss: -0.5593 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4242 - val_loss: -0.5628 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4173 - val_loss: -0.5678 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.4423 - val_loss: -0.5777 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.4795 - val_loss: -0.5768 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.4546 - val_loss: -0.5845 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4448 - val_loss: -0.5883 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4490 - val_loss: -0.5899 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4796 - val_loss: -0.5941 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.4518 - val_loss: -0.5969 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.4740 - val_loss: -0.6047 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4717 - val_loss: -0.6112 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5147 - val_loss: -0.6111 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4816 - val_loss: -0.6146 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5058 - val_loss: -0.6234 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4973 - val_loss: -0.6285 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5204 - val_loss: -0.6326 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5109 - val_loss: -0.6328 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4905 - val_loss: -0.6421 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5227 - val_loss: -0.6418 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5432 - val_loss: -0.6429 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5318 - val_loss: -0.6472 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5508 - val_loss: -0.6538 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5389 - val_loss: -0.6543 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5410 - val_loss: -0.6717 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5325 - val_loss: -0.6634 - learning_rate: 1.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5722 - val_loss: -0.6718 - learning_rate: 1.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5656 - val_loss: -0.6749 - learning_rate: 1.0000e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5285 - val_loss: -0.6820 - learning_rate: 1.0000e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5492 - val_loss: -0.6845 - learning_rate: 1.0000e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5900 - val_loss: -0.6837 - learning_rate: 1.0000e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5758 - val_loss: -0.6851 - learning_rate: 1.0000e-04\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5858 - val_loss: -0.6945 - learning_rate: 1.0000e-04\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5744 - val_loss: -0.7023 - learning_rate: 1.0000e-04\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5779 - val_loss: -0.7013 - learning_rate: 1.0000e-04\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5995 - val_loss: -0.7018 - learning_rate: 1.0000e-04\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5504 - val_loss: -0.7004 - learning_rate: 1.0000e-04\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5947 - val_loss: -0.7098 - learning_rate: 1.0000e-04\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.6080 - val_loss: -0.7183 - learning_rate: 1.0000e-04\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5849 - val_loss: -0.7134 - learning_rate: 1.0000e-04\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5963 - val_loss: -0.7268 - learning_rate: 1.0000e-04\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5803 - val_loss: -0.7275 - learning_rate: 1.0000e-04\n",
      "Epoch 86/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6108 - val_loss: -0.7264 - learning_rate: 1.0000e-04\n",
      "Epoch 87/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5854 - val_loss: -0.7270 - learning_rate: 1.0000e-04\n",
      "Epoch 88/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5843 - val_loss: -0.7137 - learning_rate: 1.0000e-04\n",
      "Epoch 89/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6253 - val_loss: -0.7353 - learning_rate: 1.0000e-04\n",
      "Epoch 90/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6203 - val_loss: -0.7381 - learning_rate: 1.0000e-04\n",
      "Epoch 91/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6220 - val_loss: -0.7381 - learning_rate: 1.0000e-04\n",
      "Epoch 92/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6305 - val_loss: -0.7450 - learning_rate: 1.0000e-04\n",
      "Epoch 93/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6349 - val_loss: -0.7577 - learning_rate: 1.0000e-04\n",
      "Epoch 94/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6198 - val_loss: -0.7551 - learning_rate: 1.0000e-04\n",
      "Epoch 95/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6611 - val_loss: -0.7624 - learning_rate: 1.0000e-04\n",
      "Epoch 96/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6422 - val_loss: -0.7561 - learning_rate: 1.0000e-04\n",
      "Epoch 97/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6459 - val_loss: -0.7637 - learning_rate: 1.0000e-04\n",
      "Epoch 98/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6572 - val_loss: -0.7650 - learning_rate: 1.0000e-04\n",
      "Epoch 99/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6578 - val_loss: -0.7722 - learning_rate: 1.0000e-04\n",
      "Epoch 100/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6521 - val_loss: -0.7691 - learning_rate: 1.0000e-04\n",
      "Epoch 101/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6421 - val_loss: -0.7725 - learning_rate: 1.0000e-04\n",
      "Epoch 102/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6888 - val_loss: -0.7761 - learning_rate: 1.0000e-04\n",
      "Epoch 103/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6635 - val_loss: -0.7792 - learning_rate: 1.0000e-04\n",
      "Epoch 104/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6314 - val_loss: -0.7853 - learning_rate: 1.0000e-04\n",
      "Epoch 105/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6351 - val_loss: -0.7813 - learning_rate: 1.0000e-04\n",
      "Epoch 106/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6769 - val_loss: -0.8022 - learning_rate: 1.0000e-04\n",
      "Epoch 107/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6689 - val_loss: -0.8012 - learning_rate: 1.0000e-04\n",
      "Epoch 108/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7199 - val_loss: -0.7994 - learning_rate: 1.0000e-04\n",
      "Epoch 109/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7271 - val_loss: -0.8007 - learning_rate: 1.0000e-04\n",
      "Epoch 110/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7198 - val_loss: -0.8028 - learning_rate: 1.0000e-04\n",
      "Epoch 111/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7071 - val_loss: -0.8118 - learning_rate: 1.0000e-04\n",
      "Epoch 112/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6951 - val_loss: -0.8096 - learning_rate: 1.0000e-04\n",
      "Epoch 113/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6623 - val_loss: -0.8185 - learning_rate: 1.0000e-04\n",
      "Epoch 114/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7466 - val_loss: -0.8216 - learning_rate: 1.0000e-04\n",
      "Epoch 115/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7445 - val_loss: -0.8184 - learning_rate: 1.0000e-04\n",
      "Epoch 116/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7084 - val_loss: -0.8202 - learning_rate: 1.0000e-04\n",
      "Epoch 117/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6843 - val_loss: -0.8319 - learning_rate: 1.0000e-04\n",
      "Epoch 118/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7025 - val_loss: -0.8285 - learning_rate: 1.0000e-04\n",
      "Epoch 119/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7141 - val_loss: -0.8427 - learning_rate: 1.0000e-04\n",
      "Epoch 120/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7682 - val_loss: -0.8417 - learning_rate: 1.0000e-04\n",
      "Epoch 121/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6935 - val_loss: -0.8382 - learning_rate: 1.0000e-04\n",
      "Epoch 122/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7028 - val_loss: -0.8513 - learning_rate: 1.0000e-04\n",
      "Epoch 123/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7232 - val_loss: -0.8481 - learning_rate: 1.0000e-04\n",
      "Epoch 124/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7258 - val_loss: -0.8518 - learning_rate: 1.0000e-04\n",
      "Epoch 125/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7861 - val_loss: -0.8484 - learning_rate: 1.0000e-04\n",
      "Epoch 126/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7526 - val_loss: -0.8673 - learning_rate: 1.0000e-04\n",
      "Epoch 127/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7394 - val_loss: -0.8617 - learning_rate: 1.0000e-04\n",
      "Epoch 128/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7050 - val_loss: -0.8682 - learning_rate: 1.0000e-04\n",
      "Epoch 129/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7726 - val_loss: -0.8687 - learning_rate: 1.0000e-04\n",
      "Epoch 130/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7555 - val_loss: -0.8762 - learning_rate: 1.0000e-04\n",
      "Epoch 131/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7011 - val_loss: -0.8745 - learning_rate: 1.0000e-04\n",
      "Epoch 132/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7654 - val_loss: -0.8774 - learning_rate: 1.0000e-04\n",
      "Epoch 133/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7838 - val_loss: -0.8786 - learning_rate: 1.0000e-04\n",
      "Epoch 134/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7092 - val_loss: -0.8813 - learning_rate: 1.0000e-04\n",
      "Epoch 135/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7623 - val_loss: -0.8750 - learning_rate: 1.0000e-04\n",
      "Epoch 136/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7561 - val_loss: -0.8732 - learning_rate: 1.0000e-04\n",
      "Epoch 137/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7726 - val_loss: -0.8797 - learning_rate: 1.0000e-04\n",
      "Epoch 138/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7923 - val_loss: -0.8933 - learning_rate: 1.0000e-04\n",
      "Epoch 139/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7655 - val_loss: -0.8905 - learning_rate: 1.0000e-04\n",
      "Epoch 140/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7240 - val_loss: -0.8940 - learning_rate: 1.0000e-04\n",
      "Epoch 141/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7279 - val_loss: -0.8859 - learning_rate: 1.0000e-04\n",
      "Epoch 142/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8359 - val_loss: -0.8819 - learning_rate: 1.0000e-04\n",
      "Epoch 143/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8545 - val_loss: -0.8952 - learning_rate: 1.0000e-04\n",
      "Epoch 144/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7899 - val_loss: -0.9009 - learning_rate: 1.0000e-04\n",
      "Epoch 145/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7587 - val_loss: -0.9067 - learning_rate: 1.0000e-04\n",
      "Epoch 146/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8156 - val_loss: -0.9018 - learning_rate: 1.0000e-04\n",
      "Epoch 147/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8445 - val_loss: -0.9099 - learning_rate: 1.0000e-04\n",
      "Epoch 148/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8509 - val_loss: -0.9239 - learning_rate: 1.0000e-04\n",
      "Epoch 149/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8427 - val_loss: -0.9170 - learning_rate: 1.0000e-04\n",
      "Epoch 150/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7763 - val_loss: -0.9153 - learning_rate: 1.0000e-04\n",
      "Epoch 151/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8157 - val_loss: -0.9170 - learning_rate: 1.0000e-04\n",
      "Epoch 152/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7114 - val_loss: -0.9038 - learning_rate: 1.0000e-04\n",
      "Epoch 153/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7762 - val_loss: -0.9094 - learning_rate: 1.0000e-04\n",
      "Epoch 154/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8398 - val_loss: -0.9208 - learning_rate: 5.0000e-05\n",
      "Epoch 155/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.8277 - val_loss: -0.9177 - learning_rate: 5.0000e-05\n",
      "Epoch 156/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8232 - val_loss: -0.9167 - learning_rate: 5.0000e-05\n",
      "Epoch 157/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7958 - val_loss: -0.9127 - learning_rate: 5.0000e-05\n",
      "Epoch 158/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8121 - val_loss: -0.9188 - learning_rate: 5.0000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - loss: 0.9951 - val_loss: 8.9321e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.4014 - val_loss: -0.0061 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.2258 - val_loss: -0.0383 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1160 - val_loss: -0.0457 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1344 - val_loss: -0.0565 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0889 - val_loss: -0.0556 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0740 - val_loss: -0.0647 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0375 - val_loss: -0.0631 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0424 - val_loss: -0.0611 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0471 - val_loss: -0.0626 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0176 - val_loss: -0.0640 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0198 - val_loss: -0.0629 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0244 - val_loss: -0.0664 - learning_rate: 5.0000e-05\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0067 - val_loss: -0.0668 - learning_rate: 5.0000e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0017 - val_loss: -0.0686 - learning_rate: 5.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 3.8896e-04 - val_loss: -0.0704 - learning_rate: 5.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0089 - val_loss: -0.0671 - learning_rate: 5.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -4.9508e-06 - val_loss: -0.0671 - learning_rate: 5.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0056 - val_loss: -0.0710 - learning_rate: 5.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0070 - val_loss: -0.0692 - learning_rate: 5.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0126 - val_loss: -0.0689 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0021 - val_loss: -0.0692 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.0019 - val_loss: -0.0669 - learning_rate: 5.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0088 - val_loss: -0.0696 - learning_rate: 5.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0280 - val_loss: -0.0706 - learning_rate: 2.5000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0044 - val_loss: -0.0706 - learning_rate: 2.5000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.0361 - val_loss: -0.0712 - learning_rate: 2.5000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0076 - val_loss: -0.0720 - learning_rate: 2.5000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0233 - val_loss: -0.0726 - learning_rate: 2.5000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0248 - val_loss: -0.0728 - learning_rate: 2.5000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0018 - val_loss: -0.0714 - learning_rate: 2.5000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0184 - val_loss: -0.0726 - learning_rate: 2.5000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0201 - val_loss: -0.0699 - learning_rate: 2.5000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0098 - val_loss: -0.0723 - learning_rate: 2.5000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0256 - val_loss: -0.0732 - learning_rate: 2.5000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0198 - val_loss: -0.0732 - learning_rate: 2.5000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0344 - val_loss: -0.0725 - learning_rate: 2.5000e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0192 - val_loss: -0.0729 - learning_rate: 2.5000e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0191 - val_loss: -0.0738 - learning_rate: 2.5000e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0269 - val_loss: -0.0726 - learning_rate: 2.5000e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0141 - val_loss: -0.0735 - learning_rate: 2.5000e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0122 - val_loss: -0.0739 - learning_rate: 2.5000e-05\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0033 - val_loss: -0.0746 - learning_rate: 2.5000e-05\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.0166 - val_loss: -0.0746 - learning_rate: 2.5000e-05\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.0303 - val_loss: -0.0746 - learning_rate: 2.5000e-05\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0310 - val_loss: -0.0762 - learning_rate: 2.5000e-05\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0245 - val_loss: -0.0765 - learning_rate: 2.5000e-05\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0237 - val_loss: -0.0773 - learning_rate: 2.5000e-05\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0219 - val_loss: -0.0765 - learning_rate: 2.5000e-05\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0237 - val_loss: -0.0764 - learning_rate: 2.5000e-05\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0115 - val_loss: -0.0759 - learning_rate: 2.5000e-05\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0331 - val_loss: -0.0767 - learning_rate: 2.5000e-05\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0438 - val_loss: -0.0767 - learning_rate: 2.5000e-05\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0228 - val_loss: -0.0773 - learning_rate: 1.2500e-05\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0179 - val_loss: -0.0765 - learning_rate: 1.2500e-05\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0310 - val_loss: -0.0763 - learning_rate: 1.2500e-05\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0353 - val_loss: -0.0768 - learning_rate: 1.2500e-05\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0381 - val_loss: -0.0768 - learning_rate: 1.2500e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.7203 - val_loss: -0.0093 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.3037 - val_loss: -0.0877 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1380 - val_loss: -0.1439 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0640 - val_loss: -0.1778 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0026 - val_loss: -0.2000 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.0705 - val_loss: -0.2212 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.0628 - val_loss: -0.2432 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0959 - val_loss: -0.2573 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.1506 - val_loss: -0.2750 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.1315 - val_loss: -0.2862 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.1507 - val_loss: -0.2969 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.1277 - val_loss: -0.2960 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.1810 - val_loss: -0.3159 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.1804 - val_loss: -0.3232 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.1855 - val_loss: -0.3338 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.1831 - val_loss: -0.3477 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2223 - val_loss: -0.3578 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2187 - val_loss: -0.3636 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2357 - val_loss: -0.3716 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2574 - val_loss: -0.3743 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2418 - val_loss: -0.3823 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2840 - val_loss: -0.3917 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2757 - val_loss: -0.3980 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2508 - val_loss: -0.4016 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2707 - val_loss: -0.4058 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2820 - val_loss: -0.4153 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3069 - val_loss: -0.4223 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.2840 - val_loss: -0.4293 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2814 - val_loss: -0.4349 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3254 - val_loss: -0.4423 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3541 - val_loss: -0.4491 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3327 - val_loss: -0.4591 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3308 - val_loss: -0.4692 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3355 - val_loss: -0.4747 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3458 - val_loss: -0.4764 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3305 - val_loss: -0.4811 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3767 - val_loss: -0.4931 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3859 - val_loss: -0.4929 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4080 - val_loss: -0.4985 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4145 - val_loss: -0.5002 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3906 - val_loss: -0.5155 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3970 - val_loss: -0.5187 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4088 - val_loss: -0.5248 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3814 - val_loss: -0.5237 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4417 - val_loss: -0.5288 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4040 - val_loss: -0.5376 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4468 - val_loss: -0.5432 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4620 - val_loss: -0.5485 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4156 - val_loss: -0.5514 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4377 - val_loss: -0.5566 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4240 - val_loss: -0.5552 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4275 - val_loss: -0.5648 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4718 - val_loss: -0.5740 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4584 - val_loss: -0.5761 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4714 - val_loss: -0.5784 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4626 - val_loss: -0.5729 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5127 - val_loss: -0.5791 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5191 - val_loss: -0.5878 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5012 - val_loss: -0.5865 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4859 - val_loss: -0.5962 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4908 - val_loss: -0.6042 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5034 - val_loss: -0.6100 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4696 - val_loss: -0.6038 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5062 - val_loss: -0.6106 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4888 - val_loss: -0.6140 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5058 - val_loss: -0.6156 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5426 - val_loss: -0.6222 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4931 - val_loss: -0.6188 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4913 - val_loss: -0.6213 - learning_rate: 1.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5276 - val_loss: -0.6281 - learning_rate: 1.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5230 - val_loss: -0.6344 - learning_rate: 1.0000e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5713 - val_loss: -0.6446 - learning_rate: 1.0000e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5144 - val_loss: -0.6428 - learning_rate: 1.0000e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5426 - val_loss: -0.6499 - learning_rate: 1.0000e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5287 - val_loss: -0.6534 - learning_rate: 1.0000e-04\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5762 - val_loss: -0.6417 - learning_rate: 1.0000e-04\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5628 - val_loss: -0.6546 - learning_rate: 1.0000e-04\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5655 - val_loss: -0.6453 - learning_rate: 1.0000e-04\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5698 - val_loss: -0.6537 - learning_rate: 1.0000e-04\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5652 - val_loss: -0.6534 - learning_rate: 1.0000e-04\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5877 - val_loss: -0.6649 - learning_rate: 1.0000e-04\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5617 - val_loss: -0.6665 - learning_rate: 1.0000e-04\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5603 - val_loss: -0.6687 - learning_rate: 1.0000e-04\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5589 - val_loss: -0.6695 - learning_rate: 1.0000e-04\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5815 - val_loss: -0.6824 - learning_rate: 1.0000e-04\n",
      "Epoch 86/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6228 - val_loss: -0.6793 - learning_rate: 1.0000e-04\n",
      "Epoch 87/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6168 - val_loss: -0.6828 - learning_rate: 1.0000e-04\n",
      "Epoch 88/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6297 - val_loss: -0.6735 - learning_rate: 1.0000e-04\n",
      "Epoch 89/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6148 - val_loss: -0.6927 - learning_rate: 1.0000e-04\n",
      "Epoch 90/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5973 - val_loss: -0.6930 - learning_rate: 1.0000e-04\n",
      "Epoch 91/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6401 - val_loss: -0.6966 - learning_rate: 1.0000e-04\n",
      "Epoch 92/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6121 - val_loss: -0.6950 - learning_rate: 1.0000e-04\n",
      "Epoch 93/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6167 - val_loss: -0.7066 - learning_rate: 1.0000e-04\n",
      "Epoch 94/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6292 - val_loss: -0.7080 - learning_rate: 1.0000e-04\n",
      "Epoch 95/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6200 - val_loss: -0.7150 - learning_rate: 1.0000e-04\n",
      "Epoch 96/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6366 - val_loss: -0.7086 - learning_rate: 1.0000e-04\n",
      "Epoch 97/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6385 - val_loss: -0.7228 - learning_rate: 1.0000e-04\n",
      "Epoch 98/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6267 - val_loss: -0.7199 - learning_rate: 1.0000e-04\n",
      "Epoch 99/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6434 - val_loss: -0.7192 - learning_rate: 1.0000e-04\n",
      "Epoch 100/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6248 - val_loss: -0.7127 - learning_rate: 1.0000e-04\n",
      "Epoch 101/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6162 - val_loss: -0.7244 - learning_rate: 1.0000e-04\n",
      "Epoch 102/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6273 - val_loss: -0.7205 - learning_rate: 1.0000e-04\n",
      "Epoch 103/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6093 - val_loss: -0.7319 - learning_rate: 1.0000e-04\n",
      "Epoch 104/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6602 - val_loss: -0.7432 - learning_rate: 1.0000e-04\n",
      "Epoch 105/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6599 - val_loss: -0.7444 - learning_rate: 1.0000e-04\n",
      "Epoch 106/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6555 - val_loss: -0.7550 - learning_rate: 1.0000e-04\n",
      "Epoch 107/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6585 - val_loss: -0.7405 - learning_rate: 1.0000e-04\n",
      "Epoch 108/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6546 - val_loss: -0.7601 - learning_rate: 1.0000e-04\n",
      "Epoch 109/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6334 - val_loss: -0.7537 - learning_rate: 1.0000e-04\n",
      "Epoch 110/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6950 - val_loss: -0.7550 - learning_rate: 1.0000e-04\n",
      "Epoch 111/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6894 - val_loss: -0.7445 - learning_rate: 1.0000e-04\n",
      "Epoch 112/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6744 - val_loss: -0.7610 - learning_rate: 1.0000e-04\n",
      "Epoch 113/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6933 - val_loss: -0.7602 - learning_rate: 1.0000e-04\n",
      "Epoch 114/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6833 - val_loss: -0.7642 - learning_rate: 1.0000e-04\n",
      "Epoch 115/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6380 - val_loss: -0.7610 - learning_rate: 1.0000e-04\n",
      "Epoch 116/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6724 - val_loss: -0.7535 - learning_rate: 1.0000e-04\n",
      "Epoch 117/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6963 - val_loss: -0.7549 - learning_rate: 1.0000e-04\n",
      "Epoch 118/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6566 - val_loss: -0.7841 - learning_rate: 1.0000e-04\n",
      "Epoch 119/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7185 - val_loss: -0.7866 - learning_rate: 1.0000e-04\n",
      "Epoch 120/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7263 - val_loss: -0.7776 - learning_rate: 1.0000e-04\n",
      "Epoch 121/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7362 - val_loss: -0.7884 - learning_rate: 1.0000e-04\n",
      "Epoch 122/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6956 - val_loss: -0.7807 - learning_rate: 1.0000e-04\n",
      "Epoch 123/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7080 - val_loss: -0.7943 - learning_rate: 1.0000e-04\n",
      "Epoch 124/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6822 - val_loss: -0.7555 - learning_rate: 1.0000e-04\n",
      "Epoch 125/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6942 - val_loss: -0.7868 - learning_rate: 1.0000e-04\n",
      "Epoch 126/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7107 - val_loss: -0.8060 - learning_rate: 1.0000e-04\n",
      "Epoch 127/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7432 - val_loss: -0.8017 - learning_rate: 1.0000e-04\n",
      "Epoch 128/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7378 - val_loss: -0.7827 - learning_rate: 1.0000e-04\n",
      "Epoch 129/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7384 - val_loss: -0.8043 - learning_rate: 1.0000e-04\n",
      "Epoch 130/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7325 - val_loss: -0.8054 - learning_rate: 1.0000e-04\n",
      "Epoch 131/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7289 - val_loss: -0.8350 - learning_rate: 1.0000e-04\n",
      "Epoch 132/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7398 - val_loss: -0.7877 - learning_rate: 1.0000e-04\n",
      "Epoch 133/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7476 - val_loss: -0.8187 - learning_rate: 1.0000e-04\n",
      "Epoch 134/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7970 - val_loss: -0.8356 - learning_rate: 1.0000e-04\n",
      "Epoch 135/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.7579 - val_loss: -0.8169 - learning_rate: 1.0000e-04\n",
      "Epoch 136/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7249 - val_loss: -0.8219 - learning_rate: 1.0000e-04\n",
      "Epoch 137/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7037 - val_loss: -0.8328 - learning_rate: 1.0000e-04\n",
      "Epoch 138/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7303 - val_loss: -0.8317 - learning_rate: 1.0000e-04\n",
      "Epoch 139/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7642 - val_loss: -0.8497 - learning_rate: 1.0000e-04\n",
      "Epoch 140/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7886 - val_loss: -0.8538 - learning_rate: 1.0000e-04\n",
      "Epoch 141/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7351 - val_loss: -0.8197 - learning_rate: 1.0000e-04\n",
      "Epoch 142/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7679 - val_loss: -0.8349 - learning_rate: 1.0000e-04\n",
      "Epoch 143/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7277 - val_loss: -0.8612 - learning_rate: 1.0000e-04\n",
      "Epoch 144/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8062 - val_loss: -0.8672 - learning_rate: 1.0000e-04\n",
      "Epoch 145/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8139 - val_loss: -0.8459 - learning_rate: 1.0000e-04\n",
      "Epoch 146/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7266 - val_loss: -0.8352 - learning_rate: 1.0000e-04\n",
      "Epoch 147/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7584 - val_loss: -0.8453 - learning_rate: 1.0000e-04\n",
      "Epoch 148/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7773 - val_loss: -0.8283 - learning_rate: 1.0000e-04\n",
      "Epoch 149/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7589 - val_loss: -0.8536 - learning_rate: 1.0000e-04\n",
      "Epoch 150/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8099 - val_loss: -0.8237 - learning_rate: 5.0000e-05\n",
      "Epoch 151/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6779 - val_loss: -0.8511 - learning_rate: 5.0000e-05\n",
      "Epoch 152/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8316 - val_loss: -0.8497 - learning_rate: 5.0000e-05\n",
      "Epoch 153/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7444 - val_loss: -0.8450 - learning_rate: 5.0000e-05\n",
      "Epoch 154/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7127 - val_loss: -0.8628 - learning_rate: 5.0000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.7217 - val_loss: 0.0045 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.3270 - val_loss: 0.0092 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.2244 - val_loss: 0.0111 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1761 - val_loss: 0.0050 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1266 - val_loss: 0.0126 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1152 - val_loss: 0.0082 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1064 - val_loss: 0.0025 - learning_rate: 5.0000e-05\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0692 - val_loss: -0.0015 - learning_rate: 5.0000e-05\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0654 - val_loss: -0.0029 - learning_rate: 5.0000e-05\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0734 - val_loss: -0.0032 - learning_rate: 5.0000e-05\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0601 - val_loss: 0.0071 - learning_rate: 5.0000e-05\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0599 - val_loss: -9.2032e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0554 - val_loss: -0.0011 - learning_rate: 5.0000e-05\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0475 - val_loss: -0.0036 - learning_rate: 5.0000e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0707 - val_loss: -0.0036 - learning_rate: 5.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0379 - val_loss: -0.0070 - learning_rate: 5.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0315 - val_loss: -0.0032 - learning_rate: 5.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0493 - val_loss: -0.0033 - learning_rate: 5.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0260 - val_loss: -0.0064 - learning_rate: 5.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0252 - val_loss: -0.0070 - learning_rate: 5.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0175 - val_loss: -0.0071 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0267 - val_loss: -0.0072 - learning_rate: 2.5000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0300 - val_loss: -0.0083 - learning_rate: 2.5000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0361 - val_loss: -0.0076 - learning_rate: 2.5000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0206 - val_loss: -0.0063 - learning_rate: 2.5000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0219 - val_loss: -0.0070 - learning_rate: 2.5000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0201 - val_loss: -0.0097 - learning_rate: 2.5000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0268 - val_loss: -0.0096 - learning_rate: 2.5000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0317 - val_loss: -0.0093 - learning_rate: 2.5000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0226 - val_loss: -0.0085 - learning_rate: 2.5000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0155 - val_loss: -0.0095 - learning_rate: 2.5000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0256 - val_loss: -0.0104 - learning_rate: 2.5000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0212 - val_loss: -0.0099 - learning_rate: 2.5000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0319 - val_loss: -0.0100 - learning_rate: 2.5000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0074 - val_loss: -0.0100 - learning_rate: 2.5000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0050 - val_loss: -0.0078 - learning_rate: 2.5000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0129 - val_loss: -0.0094 - learning_rate: 2.5000e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0280 - val_loss: -0.0098 - learning_rate: 1.2500e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0087 - val_loss: -0.0080 - learning_rate: 1.2500e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0318 - val_loss: -0.0092 - learning_rate: 1.2500e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0332 - val_loss: -0.0098 - learning_rate: 1.2500e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0171 - val_loss: -0.0089 - learning_rate: 1.2500e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.7406 - val_loss: 0.0170 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.3270 - val_loss: -0.0689 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1544 - val_loss: -0.1252 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0789 - val_loss: -0.1643 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0266 - val_loss: -0.1927 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0272 - val_loss: -0.2088 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0428 - val_loss: -0.2359 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0578 - val_loss: -0.2523 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0598 - val_loss: -0.2659 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.1484 - val_loss: -0.2738 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.1495 - val_loss: -0.2809 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.1460 - val_loss: -0.2957 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.1601 - val_loss: -0.2997 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.1823 - val_loss: -0.3106 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2299 - val_loss: -0.3151 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.1554 - val_loss: -0.3261 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.1699 - val_loss: -0.3286 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2248 - val_loss: -0.3295 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.2551 - val_loss: -0.3447 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2117 - val_loss: -0.3521 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.2542 - val_loss: -0.3520 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.2389 - val_loss: -0.3602 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.2651 - val_loss: -0.3635 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.2528 - val_loss: -0.3725 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.2855 - val_loss: -0.3764 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.2912 - val_loss: -0.3788 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.2944 - val_loss: -0.3855 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.2991 - val_loss: -0.3998 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.3009 - val_loss: -0.3994 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3263 - val_loss: -0.4012 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3236 - val_loss: -0.4119 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3502 - val_loss: -0.4115 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.3339 - val_loss: -0.4217 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3627 - val_loss: -0.4235 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3455 - val_loss: -0.4297 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3722 - val_loss: -0.4400 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3972 - val_loss: -0.4512 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3760 - val_loss: -0.4535 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3661 - val_loss: -0.4561 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.3793 - val_loss: -0.4584 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4005 - val_loss: -0.4670 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.3815 - val_loss: -0.4744 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3976 - val_loss: -0.4770 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4178 - val_loss: -0.4756 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4266 - val_loss: -0.4841 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3922 - val_loss: -0.4846 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4032 - val_loss: -0.4863 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4163 - val_loss: -0.5023 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4421 - val_loss: -0.5121 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4324 - val_loss: -0.5173 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.4315 - val_loss: -0.5224 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4214 - val_loss: -0.5191 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4547 - val_loss: -0.5227 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4355 - val_loss: -0.5284 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4419 - val_loss: -0.5220 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4704 - val_loss: -0.5340 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4210 - val_loss: -0.5344 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4417 - val_loss: -0.5434 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4514 - val_loss: -0.5495 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4760 - val_loss: -0.5453 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4659 - val_loss: -0.5526 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4833 - val_loss: -0.5514 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.4600 - val_loss: -0.5626 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4933 - val_loss: -0.5688 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4918 - val_loss: -0.5618 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5266 - val_loss: -0.5729 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5012 - val_loss: -0.5731 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.4807 - val_loss: -0.5790 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4902 - val_loss: -0.5857 - learning_rate: 1.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4887 - val_loss: -0.5845 - learning_rate: 1.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5383 - val_loss: -0.5950 - learning_rate: 1.0000e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5291 - val_loss: -0.5940 - learning_rate: 1.0000e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5413 - val_loss: -0.6046 - learning_rate: 1.0000e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5227 - val_loss: -0.5977 - learning_rate: 1.0000e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5475 - val_loss: -0.6097 - learning_rate: 1.0000e-04\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5302 - val_loss: -0.6121 - learning_rate: 1.0000e-04\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5134 - val_loss: -0.6091 - learning_rate: 1.0000e-04\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5575 - val_loss: -0.6171 - learning_rate: 1.0000e-04\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5433 - val_loss: -0.6222 - learning_rate: 1.0000e-04\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5494 - val_loss: -0.6318 - learning_rate: 1.0000e-04\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5582 - val_loss: -0.6387 - learning_rate: 1.0000e-04\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5870 - val_loss: -0.6465 - learning_rate: 1.0000e-04\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5415 - val_loss: -0.6332 - learning_rate: 1.0000e-04\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5214 - val_loss: -0.6429 - learning_rate: 1.0000e-04\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5718 - val_loss: -0.6402 - learning_rate: 1.0000e-04\n",
      "Epoch 86/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5786 - val_loss: -0.6562 - learning_rate: 1.0000e-04\n",
      "Epoch 87/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5661 - val_loss: -0.6557 - learning_rate: 1.0000e-04\n",
      "Epoch 88/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5950 - val_loss: -0.6681 - learning_rate: 1.0000e-04\n",
      "Epoch 89/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5721 - val_loss: -0.6659 - learning_rate: 1.0000e-04\n",
      "Epoch 90/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5994 - val_loss: -0.6762 - learning_rate: 1.0000e-04\n",
      "Epoch 91/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6037 - val_loss: -0.6807 - learning_rate: 1.0000e-04\n",
      "Epoch 92/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5656 - val_loss: -0.6783 - learning_rate: 1.0000e-04\n",
      "Epoch 93/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6045 - val_loss: -0.6829 - learning_rate: 1.0000e-04\n",
      "Epoch 94/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5925 - val_loss: -0.6847 - learning_rate: 1.0000e-04\n",
      "Epoch 95/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5952 - val_loss: -0.6814 - learning_rate: 1.0000e-04\n",
      "Epoch 96/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5908 - val_loss: -0.6977 - learning_rate: 1.0000e-04\n",
      "Epoch 97/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6072 - val_loss: -0.7020 - learning_rate: 1.0000e-04\n",
      "Epoch 98/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5931 - val_loss: -0.6971 - learning_rate: 1.0000e-04\n",
      "Epoch 99/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6071 - val_loss: -0.7035 - learning_rate: 1.0000e-04\n",
      "Epoch 100/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6117 - val_loss: -0.7192 - learning_rate: 1.0000e-04\n",
      "Epoch 101/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6710 - val_loss: -0.7138 - learning_rate: 1.0000e-04\n",
      "Epoch 102/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6253 - val_loss: -0.7258 - learning_rate: 1.0000e-04\n",
      "Epoch 103/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6377 - val_loss: -0.7263 - learning_rate: 1.0000e-04\n",
      "Epoch 104/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6368 - val_loss: -0.7307 - learning_rate: 1.0000e-04\n",
      "Epoch 105/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6394 - val_loss: -0.7302 - learning_rate: 1.0000e-04\n",
      "Epoch 106/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6609 - val_loss: -0.7350 - learning_rate: 1.0000e-04\n",
      "Epoch 107/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6643 - val_loss: -0.7408 - learning_rate: 1.0000e-04\n",
      "Epoch 108/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6561 - val_loss: -0.7359 - learning_rate: 1.0000e-04\n",
      "Epoch 109/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6403 - val_loss: -0.7349 - learning_rate: 1.0000e-04\n",
      "Epoch 110/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6226 - val_loss: -0.7482 - learning_rate: 1.0000e-04\n",
      "Epoch 111/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6060 - val_loss: -0.7546 - learning_rate: 1.0000e-04\n",
      "Epoch 112/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6690 - val_loss: -0.7595 - learning_rate: 1.0000e-04\n",
      "Epoch 113/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6538 - val_loss: -0.7494 - learning_rate: 1.0000e-04\n",
      "Epoch 114/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6747 - val_loss: -0.7603 - learning_rate: 1.0000e-04\n",
      "Epoch 115/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6944 - val_loss: -0.7535 - learning_rate: 1.0000e-04\n",
      "Epoch 116/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6887 - val_loss: -0.7692 - learning_rate: 1.0000e-04\n",
      "Epoch 117/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6408 - val_loss: -0.7738 - learning_rate: 1.0000e-04\n",
      "Epoch 118/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6866 - val_loss: -0.7710 - learning_rate: 1.0000e-04\n",
      "Epoch 119/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7024 - val_loss: -0.7849 - learning_rate: 1.0000e-04\n",
      "Epoch 120/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6980 - val_loss: -0.7842 - learning_rate: 1.0000e-04\n",
      "Epoch 121/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6644 - val_loss: -0.7821 - learning_rate: 1.0000e-04\n",
      "Epoch 122/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6995 - val_loss: -0.7893 - learning_rate: 1.0000e-04\n",
      "Epoch 123/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6870 - val_loss: -0.7949 - learning_rate: 1.0000e-04\n",
      "Epoch 124/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7069 - val_loss: -0.7980 - learning_rate: 1.0000e-04\n",
      "Epoch 125/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6937 - val_loss: -0.8035 - learning_rate: 1.0000e-04\n",
      "Epoch 126/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6942 - val_loss: -0.8029 - learning_rate: 1.0000e-04\n",
      "Epoch 127/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6917 - val_loss: -0.8157 - learning_rate: 1.0000e-04\n",
      "Epoch 128/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6807 - val_loss: -0.8168 - learning_rate: 1.0000e-04\n",
      "Epoch 129/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7048 - val_loss: -0.8171 - learning_rate: 1.0000e-04\n",
      "Epoch 130/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7057 - val_loss: -0.8331 - learning_rate: 1.0000e-04\n",
      "Epoch 131/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7325 - val_loss: -0.8313 - learning_rate: 1.0000e-04\n",
      "Epoch 132/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7294 - val_loss: -0.8380 - learning_rate: 1.0000e-04\n",
      "Epoch 133/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7509 - val_loss: -0.8361 - learning_rate: 1.0000e-04\n",
      "Epoch 134/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.7310 - val_loss: -0.8456 - learning_rate: 1.0000e-04\n",
      "Epoch 135/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.7490 - val_loss: -0.8460 - learning_rate: 1.0000e-04\n",
      "Epoch 136/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7587 - val_loss: -0.8428 - learning_rate: 1.0000e-04\n",
      "Epoch 137/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7420 - val_loss: -0.8443 - learning_rate: 1.0000e-04\n",
      "Epoch 138/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.7300 - val_loss: -0.8431 - learning_rate: 1.0000e-04\n",
      "Epoch 139/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7638 - val_loss: -0.8415 - learning_rate: 1.0000e-04\n",
      "Epoch 140/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7480 - val_loss: -0.8534 - learning_rate: 1.0000e-04\n",
      "Epoch 141/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.7825 - val_loss: -0.8658 - learning_rate: 1.0000e-04\n",
      "Epoch 142/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7071 - val_loss: -0.8638 - learning_rate: 1.0000e-04\n",
      "Epoch 143/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.7488 - val_loss: -0.8601 - learning_rate: 1.0000e-04\n",
      "Epoch 144/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7819 - val_loss: -0.8719 - learning_rate: 1.0000e-04\n",
      "Epoch 145/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7309 - val_loss: -0.8656 - learning_rate: 1.0000e-04\n",
      "Epoch 146/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7408 - val_loss: -0.8668 - learning_rate: 1.0000e-04\n",
      "Epoch 147/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.7779 - val_loss: -0.8853 - learning_rate: 1.0000e-04\n",
      "Epoch 148/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7453 - val_loss: -0.8804 - learning_rate: 1.0000e-04\n",
      "Epoch 149/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.8007 - val_loss: -0.8808 - learning_rate: 1.0000e-04\n",
      "Epoch 150/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7633 - val_loss: -0.8823 - learning_rate: 1.0000e-04\n",
      "Epoch 151/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.8090 - val_loss: -0.8868 - learning_rate: 1.0000e-04\n",
      "Epoch 152/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7556 - val_loss: -0.8938 - learning_rate: 1.0000e-04\n",
      "Epoch 153/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7515 - val_loss: -0.8896 - learning_rate: 1.0000e-04\n",
      "Epoch 154/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.8220 - val_loss: -0.8924 - learning_rate: 1.0000e-04\n",
      "Epoch 155/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7884 - val_loss: -0.9065 - learning_rate: 1.0000e-04\n",
      "Epoch 156/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7819 - val_loss: -0.9005 - learning_rate: 1.0000e-04\n",
      "Epoch 157/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.7375 - val_loss: -0.9233 - learning_rate: 1.0000e-04\n",
      "Epoch 158/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.8009 - val_loss: -0.9134 - learning_rate: 1.0000e-04\n",
      "Epoch 159/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.8344 - val_loss: -0.9074 - learning_rate: 1.0000e-04\n",
      "Epoch 160/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.8209 - val_loss: -0.9038 - learning_rate: 1.0000e-04\n",
      "Epoch 161/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.8320 - val_loss: -0.9021 - learning_rate: 1.0000e-04\n",
      "Epoch 162/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.8381 - val_loss: -0.8703 - learning_rate: 1.0000e-04\n",
      "Epoch 163/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7906 - val_loss: -0.8988 - learning_rate: 5.0000e-05\n",
      "Epoch 164/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8506 - val_loss: -0.9170 - learning_rate: 5.0000e-05\n",
      "Epoch 165/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7978 - val_loss: -0.9195 - learning_rate: 5.0000e-05\n",
      "Epoch 166/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.8441 - val_loss: -0.9198 - learning_rate: 5.0000e-05\n",
      "Epoch 167/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.8222 - val_loss: -0.9103 - learning_rate: 5.0000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - loss: 0.4161 - val_loss: -0.1839 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0517 - val_loss: -0.2894 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.0264 - val_loss: -0.3231 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.0738 - val_loss: -0.3307 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.1536 - val_loss: -0.3328 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.2183 - val_loss: -0.3463 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.1999 - val_loss: -0.3488 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.2096 - val_loss: -0.3633 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.2291 - val_loss: -0.3544 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.2555 - val_loss: -0.3549 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2534 - val_loss: -0.3730 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2786 - val_loss: -0.3782 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2935 - val_loss: -0.3794 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2904 - val_loss: -0.4016 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2979 - val_loss: -0.3963 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3110 - val_loss: -0.4023 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3033 - val_loss: -0.4162 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: -0.3298 - val_loss: -0.4340 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3339 - val_loss: -0.4178 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3441 - val_loss: -0.4335 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.3813 - val_loss: -0.4510 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3512 - val_loss: -0.4470 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3485 - val_loss: -0.4405 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4254 - val_loss: -0.4470 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3814 - val_loss: -0.4676 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3665 - val_loss: -0.4819 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4219 - val_loss: -0.4823 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3939 - val_loss: -0.4808 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.4141 - val_loss: -0.4902 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4040 - val_loss: -0.4909 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4014 - val_loss: -0.5081 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4427 - val_loss: -0.4999 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4212 - val_loss: -0.5092 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4179 - val_loss: -0.5230 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4386 - val_loss: -0.4961 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4186 - val_loss: -0.5079 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4471 - val_loss: -0.5182 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4192 - val_loss: -0.5198 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4686 - val_loss: -0.5396 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4532 - val_loss: -0.5539 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4670 - val_loss: -0.5550 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4301 - val_loss: -0.5443 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4621 - val_loss: -0.5428 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4671 - val_loss: -0.5553 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4525 - val_loss: -0.5466 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4691 - val_loss: -0.5486 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4520 - val_loss: -0.5616 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4910 - val_loss: -0.5684 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4979 - val_loss: -0.5695 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5068 - val_loss: -0.5521 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4738 - val_loss: -0.5765 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4796 - val_loss: -0.5690 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4781 - val_loss: -0.5952 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5139 - val_loss: -0.5936 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5016 - val_loss: -0.5942 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5356 - val_loss: -0.6023 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4884 - val_loss: -0.6036 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5226 - val_loss: -0.6113 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5480 - val_loss: -0.6185 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5249 - val_loss: -0.6089 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5568 - val_loss: -0.6221 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5682 - val_loss: -0.6252 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5367 - val_loss: -0.6255 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5494 - val_loss: -0.6317 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5527 - val_loss: -0.6214 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5497 - val_loss: -0.6257 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5680 - val_loss: -0.6396 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5435 - val_loss: -0.6377 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5401 - val_loss: -0.6361 - learning_rate: 1.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: -0.5309 - val_loss: -0.6526 - learning_rate: 1.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5847 - val_loss: -0.6412 - learning_rate: 1.0000e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5749 - val_loss: -0.6498 - learning_rate: 1.0000e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5985 - val_loss: -0.6712 - learning_rate: 1.0000e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5900 - val_loss: -0.6636 - learning_rate: 1.0000e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: -0.5675 - val_loss: -0.6748 - learning_rate: 1.0000e-04\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5440 - val_loss: -0.6715 - learning_rate: 1.0000e-04\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5675 - val_loss: -0.6736 - learning_rate: 1.0000e-04\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5908 - val_loss: -0.6819 - learning_rate: 1.0000e-04\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5956 - val_loss: -0.6849 - learning_rate: 1.0000e-04\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5626 - val_loss: -0.6817 - learning_rate: 1.0000e-04\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5889 - val_loss: -0.6946 - learning_rate: 1.0000e-04\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5762 - val_loss: -0.6905 - learning_rate: 1.0000e-04\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.5943 - val_loss: -0.7026 - learning_rate: 1.0000e-04\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.5962 - val_loss: -0.7076 - learning_rate: 1.0000e-04\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5770 - val_loss: -0.7088 - learning_rate: 1.0000e-04\n",
      "Epoch 86/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6093 - val_loss: -0.7050 - learning_rate: 1.0000e-04\n",
      "Epoch 87/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6069 - val_loss: -0.7120 - learning_rate: 1.0000e-04\n",
      "Epoch 88/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5876 - val_loss: -0.7141 - learning_rate: 1.0000e-04\n",
      "Epoch 89/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6142 - val_loss: -0.7160 - learning_rate: 1.0000e-04\n",
      "Epoch 90/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6172 - val_loss: -0.7184 - learning_rate: 1.0000e-04\n",
      "Epoch 91/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6194 - val_loss: -0.7238 - learning_rate: 1.0000e-04\n",
      "Epoch 92/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6067 - val_loss: -0.7239 - learning_rate: 1.0000e-04\n",
      "Epoch 93/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5950 - val_loss: -0.7267 - learning_rate: 1.0000e-04\n",
      "Epoch 94/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6363 - val_loss: -0.7294 - learning_rate: 1.0000e-04\n",
      "Epoch 95/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.6162 - val_loss: -0.7352 - learning_rate: 1.0000e-04\n",
      "Epoch 96/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.6407 - val_loss: -0.7393 - learning_rate: 1.0000e-04\n",
      "Epoch 97/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6071 - val_loss: -0.7439 - learning_rate: 1.0000e-04\n",
      "Epoch 98/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6109 - val_loss: -0.7475 - learning_rate: 1.0000e-04\n",
      "Epoch 99/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.6529 - val_loss: -0.7422 - learning_rate: 1.0000e-04\n",
      "Epoch 100/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6189 - val_loss: -0.7423 - learning_rate: 1.0000e-04\n",
      "Epoch 101/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6304 - val_loss: -0.7539 - learning_rate: 1.0000e-04\n",
      "Epoch 102/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6335 - val_loss: -0.7609 - learning_rate: 1.0000e-04\n",
      "Epoch 103/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6653 - val_loss: -0.7503 - learning_rate: 1.0000e-04\n",
      "Epoch 104/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6330 - val_loss: -0.7541 - learning_rate: 1.0000e-04\n",
      "Epoch 105/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6131 - val_loss: -0.7593 - learning_rate: 1.0000e-04\n",
      "Epoch 106/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6412 - val_loss: -0.7614 - learning_rate: 1.0000e-04\n",
      "Epoch 107/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6395 - val_loss: -0.7633 - learning_rate: 1.0000e-04\n",
      "Epoch 108/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6487 - val_loss: -0.7741 - learning_rate: 1.0000e-04\n",
      "Epoch 109/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6528 - val_loss: -0.7724 - learning_rate: 1.0000e-04\n",
      "Epoch 110/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6246 - val_loss: -0.7727 - learning_rate: 1.0000e-04\n",
      "Epoch 111/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6535 - val_loss: -0.7731 - learning_rate: 1.0000e-04\n",
      "Epoch 112/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6787 - val_loss: -0.7794 - learning_rate: 1.0000e-04\n",
      "Epoch 113/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6740 - val_loss: -0.7879 - learning_rate: 1.0000e-04\n",
      "Epoch 114/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6649 - val_loss: -0.7904 - learning_rate: 1.0000e-04\n",
      "Epoch 115/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6530 - val_loss: -0.7931 - learning_rate: 1.0000e-04\n",
      "Epoch 116/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6426 - val_loss: -0.7867 - learning_rate: 1.0000e-04\n",
      "Epoch 117/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.6588 - val_loss: -0.7992 - learning_rate: 1.0000e-04\n",
      "Epoch 118/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6841 - val_loss: -0.7908 - learning_rate: 1.0000e-04\n",
      "Epoch 119/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6540 - val_loss: -0.7941 - learning_rate: 1.0000e-04\n",
      "Epoch 120/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6744 - val_loss: -0.7998 - learning_rate: 1.0000e-04\n",
      "Epoch 121/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6429 - val_loss: -0.7970 - learning_rate: 1.0000e-04\n",
      "Epoch 122/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6639 - val_loss: -0.7972 - learning_rate: 1.0000e-04\n",
      "Epoch 123/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6970 - val_loss: -0.8032 - learning_rate: 1.0000e-04\n",
      "Epoch 124/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.6605 - val_loss: -0.8056 - learning_rate: 1.0000e-04\n",
      "Epoch 125/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.6779 - val_loss: -0.8121 - learning_rate: 1.0000e-04\n",
      "Epoch 126/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.6904 - val_loss: -0.8131 - learning_rate: 1.0000e-04\n",
      "Epoch 127/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7264 - val_loss: -0.8161 - learning_rate: 1.0000e-04\n",
      "Epoch 128/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6825 - val_loss: -0.8178 - learning_rate: 1.0000e-04\n",
      "Epoch 129/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6810 - val_loss: -0.8215 - learning_rate: 1.0000e-04\n",
      "Epoch 130/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.7044 - val_loss: -0.8236 - learning_rate: 1.0000e-04\n",
      "Epoch 131/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6944 - val_loss: -0.8221 - learning_rate: 1.0000e-04\n",
      "Epoch 132/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: -0.6866 - val_loss: -0.8215 - learning_rate: 1.0000e-04\n",
      "Epoch 133/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.6893 - val_loss: -0.8192 - learning_rate: 1.0000e-04\n",
      "Epoch 134/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.6714 - val_loss: -0.8229 - learning_rate: 1.0000e-04\n",
      "Epoch 135/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6922 - val_loss: -0.8233 - learning_rate: 1.0000e-04\n",
      "Epoch 136/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6791 - val_loss: -0.8240 - learning_rate: 5.0000e-05\n",
      "Epoch 137/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7076 - val_loss: -0.8261 - learning_rate: 5.0000e-05\n",
      "Epoch 138/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7115 - val_loss: -0.8269 - learning_rate: 5.0000e-05\n",
      "Epoch 139/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.6742 - val_loss: -0.8214 - learning_rate: 5.0000e-05\n",
      "Epoch 140/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7115 - val_loss: -0.8295 - learning_rate: 5.0000e-05\n",
      "Epoch 141/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6610 - val_loss: -0.8277 - learning_rate: 5.0000e-05\n",
      "Epoch 142/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.7110 - val_loss: -0.8314 - learning_rate: 5.0000e-05\n",
      "Epoch 143/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.6722 - val_loss: -0.8330 - learning_rate: 5.0000e-05\n",
      "Epoch 144/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7161 - val_loss: -0.8319 - learning_rate: 5.0000e-05\n",
      "Epoch 145/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7076 - val_loss: -0.8310 - learning_rate: 5.0000e-05\n",
      "Epoch 146/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7257 - val_loss: -0.8307 - learning_rate: 5.0000e-05\n",
      "Epoch 147/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6946 - val_loss: -0.8331 - learning_rate: 5.0000e-05\n",
      "Epoch 148/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7229 - val_loss: -0.8348 - learning_rate: 5.0000e-05\n",
      "Epoch 149/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6949 - val_loss: -0.8372 - learning_rate: 5.0000e-05\n",
      "Epoch 150/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: -0.6833 - val_loss: -0.8360 - learning_rate: 5.0000e-05\n",
      "Epoch 151/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7231 - val_loss: -0.8360 - learning_rate: 5.0000e-05\n",
      "Epoch 152/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7257 - val_loss: -0.8401 - learning_rate: 5.0000e-05\n",
      "Epoch 153/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7137 - val_loss: -0.8367 - learning_rate: 5.0000e-05\n",
      "Epoch 154/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: -0.6989 - val_loss: -0.8393 - learning_rate: 5.0000e-05\n",
      "Epoch 155/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7186 - val_loss: -0.8401 - learning_rate: 5.0000e-05\n",
      "Epoch 156/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7301 - val_loss: -0.8413 - learning_rate: 5.0000e-05\n",
      "Epoch 157/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6944 - val_loss: -0.8410 - learning_rate: 5.0000e-05\n",
      "Epoch 158/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7251 - val_loss: -0.8432 - learning_rate: 5.0000e-05\n",
      "Epoch 159/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6978 - val_loss: -0.8431 - learning_rate: 5.0000e-05\n",
      "Epoch 160/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7091 - val_loss: -0.8450 - learning_rate: 5.0000e-05\n",
      "Epoch 161/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7212 - val_loss: -0.8446 - learning_rate: 5.0000e-05\n",
      "Epoch 162/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7451 - val_loss: -0.8405 - learning_rate: 5.0000e-05\n",
      "Epoch 163/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7195 - val_loss: -0.8432 - learning_rate: 5.0000e-05\n",
      "Epoch 164/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7085 - val_loss: -0.8471 - learning_rate: 5.0000e-05\n",
      "Epoch 165/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7480 - val_loss: -0.8471 - learning_rate: 5.0000e-05\n",
      "Epoch 166/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7032 - val_loss: -0.8431 - learning_rate: 5.0000e-05\n",
      "Epoch 167/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6866 - val_loss: -0.8445 - learning_rate: 5.0000e-05\n",
      "Epoch 168/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7374 - val_loss: -0.8479 - learning_rate: 5.0000e-05\n",
      "Epoch 169/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7318 - val_loss: -0.8465 - learning_rate: 5.0000e-05\n",
      "Epoch 170/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7222 - val_loss: -0.8475 - learning_rate: 5.0000e-05\n",
      "Epoch 171/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: -0.7463 - val_loss: -0.8507 - learning_rate: 5.0000e-05\n",
      "Epoch 172/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7468 - val_loss: -0.8496 - learning_rate: 5.0000e-05\n",
      "Epoch 173/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7306 - val_loss: -0.8491 - learning_rate: 5.0000e-05\n",
      "Epoch 174/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.7505 - val_loss: -0.8513 - learning_rate: 5.0000e-05\n",
      "Epoch 175/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7473 - val_loss: -0.8517 - learning_rate: 5.0000e-05\n",
      "Epoch 176/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7093 - val_loss: -0.8523 - learning_rate: 5.0000e-05\n",
      "Epoch 177/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.7289 - val_loss: -0.8514 - learning_rate: 5.0000e-05\n",
      "Epoch 178/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7551 - val_loss: -0.8527 - learning_rate: 5.0000e-05\n",
      "Epoch 179/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7414 - val_loss: -0.8530 - learning_rate: 5.0000e-05\n",
      "Epoch 180/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.6993 - val_loss: -0.8553 - learning_rate: 5.0000e-05\n",
      "Epoch 181/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7303 - val_loss: -0.8517 - learning_rate: 5.0000e-05\n",
      "Epoch 182/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7506 - val_loss: -0.8535 - learning_rate: 5.0000e-05\n",
      "Epoch 183/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.7253 - val_loss: -0.8568 - learning_rate: 5.0000e-05\n",
      "Epoch 184/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: -0.7452 - val_loss: -0.8558 - learning_rate: 5.0000e-05\n",
      "Epoch 185/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.7464 - val_loss: -0.8580 - learning_rate: 5.0000e-05\n",
      "Epoch 186/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.7588 - val_loss: -0.8610 - learning_rate: 5.0000e-05\n",
      "Epoch 187/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7177 - val_loss: -0.8590 - learning_rate: 5.0000e-05\n",
      "Epoch 188/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7366 - val_loss: -0.8602 - learning_rate: 5.0000e-05\n",
      "Epoch 189/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.7133 - val_loss: -0.8577 - learning_rate: 5.0000e-05\n",
      "Epoch 190/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7737 - val_loss: -0.8613 - learning_rate: 5.0000e-05\n",
      "Epoch 191/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6948 - val_loss: -0.8567 - learning_rate: 5.0000e-05\n",
      "Epoch 192/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.7343 - val_loss: -0.8595 - learning_rate: 5.0000e-05\n",
      "Epoch 193/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7190 - val_loss: -0.8586 - learning_rate: 5.0000e-05\n",
      "Epoch 194/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.7144 - val_loss: -0.8584 - learning_rate: 5.0000e-05\n",
      "Epoch 195/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7131 - val_loss: -0.8581 - learning_rate: 5.0000e-05\n",
      "Epoch 196/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7416 - val_loss: -0.8597 - learning_rate: 2.5000e-05\n",
      "Epoch 197/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7426 - val_loss: -0.8600 - learning_rate: 2.5000e-05\n",
      "Epoch 198/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7472 - val_loss: -0.8613 - learning_rate: 2.5000e-05\n",
      "Epoch 199/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.7279 - val_loss: -0.8601 - learning_rate: 2.5000e-05\n",
      "Epoch 200/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7676 - val_loss: -0.8590 - learning_rate: 2.5000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.8453 - val_loss: 0.0131 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.3367 - val_loss: -0.0859 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.1953 - val_loss: -0.1450 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0984 - val_loss: -0.1901 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0668 - val_loss: -0.2233 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0113 - val_loss: -0.2404 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0392 - val_loss: -0.2644 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 80ms/step - loss: -0.0309 - val_loss: -0.2850 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0745 - val_loss: -0.2994 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.0912 - val_loss: -0.3150 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.1109 - val_loss: -0.3317 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.1297 - val_loss: -0.3410 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.1225 - val_loss: -0.3498 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.1649 - val_loss: -0.3625 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.1751 - val_loss: -0.3633 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.1710 - val_loss: -0.3711 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.1926 - val_loss: -0.3743 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.1794 - val_loss: -0.3806 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.1951 - val_loss: -0.3886 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.1860 - val_loss: -0.3912 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2082 - val_loss: -0.4048 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2078 - val_loss: -0.4123 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2445 - val_loss: -0.4159 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2593 - val_loss: -0.4197 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2482 - val_loss: -0.4240 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2601 - val_loss: -0.4300 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2589 - val_loss: -0.4311 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2675 - val_loss: -0.4392 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.2905 - val_loss: -0.4406 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2900 - val_loss: -0.4486 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.2990 - val_loss: -0.4588 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2763 - val_loss: -0.4692 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3281 - val_loss: -0.4723 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3054 - val_loss: -0.4826 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3471 - val_loss: -0.4889 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3318 - val_loss: -0.4840 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.3394 - val_loss: -0.4993 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3622 - val_loss: -0.5034 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3410 - val_loss: -0.5011 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3300 - val_loss: -0.5146 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3529 - val_loss: -0.5215 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3892 - val_loss: -0.5271 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3799 - val_loss: -0.5336 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3597 - val_loss: -0.5403 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3874 - val_loss: -0.5433 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4117 - val_loss: -0.5448 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3819 - val_loss: -0.5512 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3841 - val_loss: -0.5581 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4106 - val_loss: -0.5638 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4248 - val_loss: -0.5643 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4152 - val_loss: -0.5710 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4279 - val_loss: -0.5742 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4000 - val_loss: -0.5793 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4359 - val_loss: -0.5859 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4745 - val_loss: -0.5921 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4821 - val_loss: -0.5972 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4448 - val_loss: -0.6005 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4972 - val_loss: -0.6036 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4812 - val_loss: -0.6091 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4696 - val_loss: -0.6142 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4345 - val_loss: -0.6169 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4793 - val_loss: -0.6163 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4525 - val_loss: -0.6211 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4945 - val_loss: -0.6333 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4999 - val_loss: -0.6354 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4531 - val_loss: -0.6411 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4915 - val_loss: -0.6468 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5030 - val_loss: -0.6445 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: -0.5385 - val_loss: -0.6556 - learning_rate: 1.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5289 - val_loss: -0.6526 - learning_rate: 1.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5100 - val_loss: -0.6585 - learning_rate: 1.0000e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4907 - val_loss: -0.6666 - learning_rate: 1.0000e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5400 - val_loss: -0.6691 - learning_rate: 1.0000e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5224 - val_loss: -0.6770 - learning_rate: 1.0000e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4998 - val_loss: -0.6808 - learning_rate: 1.0000e-04\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5227 - val_loss: -0.6819 - learning_rate: 1.0000e-04\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5400 - val_loss: -0.6827 - learning_rate: 1.0000e-04\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5093 - val_loss: -0.6924 - learning_rate: 1.0000e-04\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5391 - val_loss: -0.6936 - learning_rate: 1.0000e-04\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5299 - val_loss: -0.6997 - learning_rate: 1.0000e-04\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5462 - val_loss: -0.7015 - learning_rate: 1.0000e-04\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5307 - val_loss: -0.7025 - learning_rate: 1.0000e-04\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5597 - val_loss: -0.7116 - learning_rate: 1.0000e-04\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5341 - val_loss: -0.7185 - learning_rate: 1.0000e-04\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5569 - val_loss: -0.7213 - learning_rate: 1.0000e-04\n",
      "Epoch 86/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5665 - val_loss: -0.7322 - learning_rate: 1.0000e-04\n",
      "Epoch 87/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5848 - val_loss: -0.7346 - learning_rate: 1.0000e-04\n",
      "Epoch 88/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6077 - val_loss: -0.7415 - learning_rate: 1.0000e-04\n",
      "Epoch 89/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6195 - val_loss: -0.7483 - learning_rate: 1.0000e-04\n",
      "Epoch 90/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5900 - val_loss: -0.7533 - learning_rate: 1.0000e-04\n",
      "Epoch 91/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5674 - val_loss: -0.7532 - learning_rate: 1.0000e-04\n",
      "Epoch 92/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6059 - val_loss: -0.7654 - learning_rate: 1.0000e-04\n",
      "Epoch 93/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.5822 - val_loss: -0.7611 - learning_rate: 1.0000e-04\n",
      "Epoch 94/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6187 - val_loss: -0.7660 - learning_rate: 1.0000e-04\n",
      "Epoch 95/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6188 - val_loss: -0.7694 - learning_rate: 1.0000e-04\n",
      "Epoch 96/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6329 - val_loss: -0.7694 - learning_rate: 1.0000e-04\n",
      "Epoch 97/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6194 - val_loss: -0.7802 - learning_rate: 1.0000e-04\n",
      "Epoch 98/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6427 - val_loss: -0.7833 - learning_rate: 1.0000e-04\n",
      "Epoch 99/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.5618 - val_loss: -0.7848 - learning_rate: 1.0000e-04\n",
      "Epoch 100/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6148 - val_loss: -0.7878 - learning_rate: 1.0000e-04\n",
      "Epoch 101/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6529 - val_loss: -0.7849 - learning_rate: 1.0000e-04\n",
      "Epoch 102/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6319 - val_loss: -0.7937 - learning_rate: 1.0000e-04\n",
      "Epoch 103/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6363 - val_loss: -0.7990 - learning_rate: 1.0000e-04\n",
      "Epoch 104/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6638 - val_loss: -0.7976 - learning_rate: 1.0000e-04\n",
      "Epoch 105/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6942 - val_loss: -0.8054 - learning_rate: 1.0000e-04\n",
      "Epoch 106/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6399 - val_loss: -0.8077 - learning_rate: 1.0000e-04\n",
      "Epoch 107/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6226 - val_loss: -0.8210 - learning_rate: 1.0000e-04\n",
      "Epoch 108/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6672 - val_loss: -0.8168 - learning_rate: 1.0000e-04\n",
      "Epoch 109/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6507 - val_loss: -0.8283 - learning_rate: 1.0000e-04\n",
      "Epoch 110/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6557 - val_loss: -0.8282 - learning_rate: 1.0000e-04\n",
      "Epoch 111/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6519 - val_loss: -0.8241 - learning_rate: 1.0000e-04\n",
      "Epoch 112/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6495 - val_loss: -0.8235 - learning_rate: 1.0000e-04\n",
      "Epoch 113/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6632 - val_loss: -0.8365 - learning_rate: 1.0000e-04\n",
      "Epoch 114/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6448 - val_loss: -0.8404 - learning_rate: 1.0000e-04\n",
      "Epoch 115/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6993 - val_loss: -0.8472 - learning_rate: 1.0000e-04\n",
      "Epoch 116/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6997 - val_loss: -0.8506 - learning_rate: 1.0000e-04\n",
      "Epoch 117/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6835 - val_loss: -0.8563 - learning_rate: 1.0000e-04\n",
      "Epoch 118/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6818 - val_loss: -0.8542 - learning_rate: 1.0000e-04\n",
      "Epoch 119/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6997 - val_loss: -0.8547 - learning_rate: 1.0000e-04\n",
      "Epoch 120/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6632 - val_loss: -0.8582 - learning_rate: 1.0000e-04\n",
      "Epoch 121/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6859 - val_loss: -0.8686 - learning_rate: 1.0000e-04\n",
      "Epoch 122/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7070 - val_loss: -0.8692 - learning_rate: 1.0000e-04\n",
      "Epoch 123/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6695 - val_loss: -0.8595 - learning_rate: 1.0000e-04\n",
      "Epoch 124/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7194 - val_loss: -0.8745 - learning_rate: 1.0000e-04\n",
      "Epoch 125/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7141 - val_loss: -0.8845 - learning_rate: 1.0000e-04\n",
      "Epoch 126/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7088 - val_loss: -0.8900 - learning_rate: 1.0000e-04\n",
      "Epoch 127/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7566 - val_loss: -0.8921 - learning_rate: 1.0000e-04\n",
      "Epoch 128/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7377 - val_loss: -0.8900 - learning_rate: 1.0000e-04\n",
      "Epoch 129/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7196 - val_loss: -0.8999 - learning_rate: 1.0000e-04\n",
      "Epoch 130/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7781 - val_loss: -0.8997 - learning_rate: 1.0000e-04\n",
      "Epoch 131/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7320 - val_loss: -0.8977 - learning_rate: 1.0000e-04\n",
      "Epoch 132/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7402 - val_loss: -0.9085 - learning_rate: 1.0000e-04\n",
      "Epoch 133/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7247 - val_loss: -0.9173 - learning_rate: 1.0000e-04\n",
      "Epoch 134/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7473 - val_loss: -0.9168 - learning_rate: 1.0000e-04\n",
      "Epoch 135/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7577 - val_loss: -0.9142 - learning_rate: 1.0000e-04\n",
      "Epoch 136/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7380 - val_loss: -0.9237 - learning_rate: 1.0000e-04\n",
      "Epoch 137/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7756 - val_loss: -0.9283 - learning_rate: 1.0000e-04\n",
      "Epoch 138/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7526 - val_loss: -0.9250 - learning_rate: 1.0000e-04\n",
      "Epoch 139/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7462 - val_loss: -0.9385 - learning_rate: 1.0000e-04\n",
      "Epoch 140/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7513 - val_loss: -0.9347 - learning_rate: 1.0000e-04\n",
      "Epoch 141/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7709 - val_loss: -0.9476 - learning_rate: 1.0000e-04\n",
      "Epoch 142/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7811 - val_loss: -0.9414 - learning_rate: 1.0000e-04\n",
      "Epoch 143/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7756 - val_loss: -0.9496 - learning_rate: 1.0000e-04\n",
      "Epoch 144/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8034 - val_loss: -0.9430 - learning_rate: 1.0000e-04\n",
      "Epoch 145/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8197 - val_loss: -0.9562 - learning_rate: 1.0000e-04\n",
      "Epoch 146/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8363 - val_loss: -0.9646 - learning_rate: 1.0000e-04\n",
      "Epoch 147/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8137 - val_loss: -0.9619 - learning_rate: 1.0000e-04\n",
      "Epoch 148/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7995 - val_loss: -0.9722 - learning_rate: 1.0000e-04\n",
      "Epoch 149/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8055 - val_loss: -0.9738 - learning_rate: 1.0000e-04\n",
      "Epoch 150/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8085 - val_loss: -0.9712 - learning_rate: 1.0000e-04\n",
      "Epoch 151/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7873 - val_loss: -0.9729 - learning_rate: 1.0000e-04\n",
      "Epoch 152/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8269 - val_loss: -0.9684 - learning_rate: 1.0000e-04\n",
      "Epoch 153/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7972 - val_loss: -0.9745 - learning_rate: 1.0000e-04\n",
      "Epoch 154/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8207 - val_loss: -0.9759 - learning_rate: 1.0000e-04\n",
      "Epoch 155/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8073 - val_loss: -0.9835 - learning_rate: 1.0000e-04\n",
      "Epoch 156/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8202 - val_loss: -0.9806 - learning_rate: 1.0000e-04\n",
      "Epoch 157/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8046 - val_loss: -0.9898 - learning_rate: 1.0000e-04\n",
      "Epoch 158/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8259 - val_loss: -0.9933 - learning_rate: 1.0000e-04\n",
      "Epoch 159/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8372 - val_loss: -0.9920 - learning_rate: 1.0000e-04\n",
      "Epoch 160/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8177 - val_loss: -1.0003 - learning_rate: 1.0000e-04\n",
      "Epoch 161/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.8378 - val_loss: -1.0020 - learning_rate: 1.0000e-04\n",
      "Epoch 162/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.8268 - val_loss: -0.9979 - learning_rate: 1.0000e-04\n",
      "Epoch 163/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8652 - val_loss: -0.9872 - learning_rate: 1.0000e-04\n",
      "Epoch 164/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8180 - val_loss: -1.0083 - learning_rate: 1.0000e-04\n",
      "Epoch 165/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8364 - val_loss: -1.0078 - learning_rate: 1.0000e-04\n",
      "Epoch 166/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8857 - val_loss: -0.9956 - learning_rate: 1.0000e-04\n",
      "Epoch 167/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8425 - val_loss: -1.0117 - learning_rate: 1.0000e-04\n",
      "Epoch 168/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8552 - val_loss: -1.0123 - learning_rate: 1.0000e-04\n",
      "Epoch 169/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8767 - val_loss: -1.0186 - learning_rate: 1.0000e-04\n",
      "Epoch 170/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9082 - val_loss: -1.0114 - learning_rate: 1.0000e-04\n",
      "Epoch 171/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.8139 - val_loss: -1.0142 - learning_rate: 1.0000e-04\n",
      "Epoch 172/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8836 - val_loss: -1.0205 - learning_rate: 1.0000e-04\n",
      "Epoch 173/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8970 - val_loss: -1.0271 - learning_rate: 1.0000e-04\n",
      "Epoch 174/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8163 - val_loss: -1.0217 - learning_rate: 1.0000e-04\n",
      "Epoch 175/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8833 - val_loss: -1.0236 - learning_rate: 1.0000e-04\n",
      "Epoch 176/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8514 - val_loss: -1.0185 - learning_rate: 1.0000e-04\n",
      "Epoch 177/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9013 - val_loss: -1.0316 - learning_rate: 1.0000e-04\n",
      "Epoch 178/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9133 - val_loss: -1.0413 - learning_rate: 1.0000e-04\n",
      "Epoch 179/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8590 - val_loss: -1.0296 - learning_rate: 1.0000e-04\n",
      "Epoch 180/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8959 - val_loss: -1.0325 - learning_rate: 1.0000e-04\n",
      "Epoch 181/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.9208 - val_loss: -1.0505 - learning_rate: 1.0000e-04\n",
      "Epoch 182/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.8740 - val_loss: -1.0447 - learning_rate: 1.0000e-04\n",
      "Epoch 183/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8798 - val_loss: -1.0454 - learning_rate: 1.0000e-04\n",
      "Epoch 184/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.9541 - val_loss: -1.0487 - learning_rate: 1.0000e-04\n",
      "Epoch 185/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9197 - val_loss: -1.0380 - learning_rate: 1.0000e-04\n",
      "Epoch 186/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9277 - val_loss: -1.0587 - learning_rate: 1.0000e-04\n",
      "Epoch 187/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9076 - val_loss: -1.0503 - learning_rate: 1.0000e-04\n",
      "Epoch 188/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: -0.8678 - val_loss: -1.0510 - learning_rate: 1.0000e-04\n",
      "Epoch 189/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9136 - val_loss: -1.0511 - learning_rate: 1.0000e-04\n",
      "Epoch 190/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8814 - val_loss: -1.0589 - learning_rate: 1.0000e-04\n",
      "Epoch 191/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9686 - val_loss: -1.0745 - learning_rate: 1.0000e-04\n",
      "Epoch 192/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8939 - val_loss: -1.0685 - learning_rate: 1.0000e-04\n",
      "Epoch 193/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9570 - val_loss: -1.0700 - learning_rate: 1.0000e-04\n",
      "Epoch 194/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8960 - val_loss: -1.0708 - learning_rate: 1.0000e-04\n",
      "Epoch 195/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9379 - val_loss: -1.0805 - learning_rate: 1.0000e-04\n",
      "Epoch 196/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9355 - val_loss: -1.0659 - learning_rate: 1.0000e-04\n",
      "Epoch 197/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9836 - val_loss: -1.0609 - learning_rate: 1.0000e-04\n",
      "Epoch 198/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.9189 - val_loss: -1.0689 - learning_rate: 1.0000e-04\n",
      "Epoch 199/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.9280 - val_loss: -1.0710 - learning_rate: 1.0000e-04\n",
      "Epoch 200/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.9349 - val_loss: -1.0646 - learning_rate: 1.0000e-04\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - loss: 1.1331 - val_loss: 0.0427 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.4710 - val_loss: 0.0467 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.3188 - val_loss: 0.0220 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.2593 - val_loss: 0.0155 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.1736 - val_loss: 0.0044 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.1197 - val_loss: 0.0103 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.1085 - val_loss: 0.0061 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0917 - val_loss: 0.0130 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0870 - val_loss: 0.0039 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0904 - val_loss: -4.9273e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0755 - val_loss: -0.0021 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0613 - val_loss: -0.0013 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0664 - val_loss: 3.5736e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0406 - val_loss: 0.0087 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0356 - val_loss: 0.0021 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0454 - val_loss: -0.0011 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0475 - val_loss: -0.0011 - learning_rate: 5.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0358 - val_loss: -0.0012 - learning_rate: 5.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0434 - val_loss: -0.0038 - learning_rate: 5.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0436 - val_loss: -0.0015 - learning_rate: 5.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0338 - val_loss: -0.0023 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0253 - val_loss: -0.0035 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0239 - val_loss: 5.8924e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0240 - val_loss: -0.0036 - learning_rate: 5.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0297 - val_loss: -0.0034 - learning_rate: 2.5000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0440 - val_loss: -0.0030 - learning_rate: 2.5000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0251 - val_loss: -0.0011 - learning_rate: 2.5000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0251 - val_loss: -0.0023 - learning_rate: 2.5000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0241 - val_loss: -0.0023 - learning_rate: 2.5000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.4962 - val_loss: -0.0462 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.2336 - val_loss: -0.1233 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.1498 - val_loss: -0.1740 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0138 - val_loss: -0.2082 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.0024 - val_loss: -0.2406 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.0716 - val_loss: -0.2635 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.0777 - val_loss: -0.2822 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.0964 - val_loss: -0.2972 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.1169 - val_loss: -0.3136 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.1454 - val_loss: -0.3301 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.1508 - val_loss: -0.3437 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.1406 - val_loss: -0.3545 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.1888 - val_loss: -0.3664 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.1992 - val_loss: -0.3703 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.1881 - val_loss: -0.3772 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.2213 - val_loss: -0.3918 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.2445 - val_loss: -0.3965 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.2407 - val_loss: -0.4030 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.2518 - val_loss: -0.3998 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.2134 - val_loss: -0.4170 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.2573 - val_loss: -0.4225 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.2615 - val_loss: -0.4244 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.2210 - val_loss: -0.4280 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.2613 - val_loss: -0.4350 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.2721 - val_loss: -0.4411 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.3005 - val_loss: -0.4499 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.2780 - val_loss: -0.4563 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.2991 - val_loss: -0.4628 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.2233 - val_loss: -0.4667 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.3298 - val_loss: -0.4720 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.3040 - val_loss: -0.4806 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.3440 - val_loss: -0.4869 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.3224 - val_loss: -0.4964 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.3403 - val_loss: -0.5028 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.3673 - val_loss: -0.5020 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.3648 - val_loss: -0.5080 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.3792 - val_loss: -0.5126 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.3528 - val_loss: -0.5288 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.3865 - val_loss: -0.5338 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.3800 - val_loss: -0.5412 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4036 - val_loss: -0.5435 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.3792 - val_loss: -0.5448 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.4050 - val_loss: -0.5507 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4061 - val_loss: -0.5618 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.3984 - val_loss: -0.5601 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4102 - val_loss: -0.5658 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4003 - val_loss: -0.5744 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4283 - val_loss: -0.5775 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4328 - val_loss: -0.5838 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4455 - val_loss: -0.5829 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4615 - val_loss: -0.5905 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4426 - val_loss: -0.5901 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4729 - val_loss: -0.5983 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.3820 - val_loss: -0.5987 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4467 - val_loss: -0.6107 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4957 - val_loss: -0.6148 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.4564 - val_loss: -0.6066 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5062 - val_loss: -0.6192 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4705 - val_loss: -0.6200 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.4822 - val_loss: -0.6320 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.4801 - val_loss: -0.6162 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4921 - val_loss: -0.6213 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4577 - val_loss: -0.6455 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5029 - val_loss: -0.6395 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4506 - val_loss: -0.6500 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.4535 - val_loss: -0.6568 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4786 - val_loss: -0.6499 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.4872 - val_loss: -0.6533 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4645 - val_loss: -0.6579 - learning_rate: 1.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5189 - val_loss: -0.6561 - learning_rate: 1.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5135 - val_loss: -0.6699 - learning_rate: 1.0000e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4871 - val_loss: -0.6744 - learning_rate: 1.0000e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5199 - val_loss: -0.6833 - learning_rate: 1.0000e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4889 - val_loss: -0.6788 - learning_rate: 1.0000e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5134 - val_loss: -0.6955 - learning_rate: 1.0000e-04\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5233 - val_loss: -0.6869 - learning_rate: 1.0000e-04\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5251 - val_loss: -0.6980 - learning_rate: 1.0000e-04\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5472 - val_loss: -0.6993 - learning_rate: 1.0000e-04\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5018 - val_loss: -0.6988 - learning_rate: 1.0000e-04\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.5198 - val_loss: -0.7107 - learning_rate: 1.0000e-04\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5938 - val_loss: -0.7161 - learning_rate: 1.0000e-04\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5175 - val_loss: -0.7266 - learning_rate: 1.0000e-04\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5391 - val_loss: -0.7365 - learning_rate: 1.0000e-04\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4908 - val_loss: -0.7328 - learning_rate: 1.0000e-04\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5145 - val_loss: -0.7332 - learning_rate: 1.0000e-04\n",
      "Epoch 86/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5381 - val_loss: -0.7448 - learning_rate: 1.0000e-04\n",
      "Epoch 87/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5430 - val_loss: -0.7371 - learning_rate: 1.0000e-04\n",
      "Epoch 88/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5510 - val_loss: -0.7533 - learning_rate: 1.0000e-04\n",
      "Epoch 89/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6130 - val_loss: -0.7553 - learning_rate: 1.0000e-04\n",
      "Epoch 90/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5747 - val_loss: -0.7588 - learning_rate: 1.0000e-04\n",
      "Epoch 91/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5540 - val_loss: -0.7642 - learning_rate: 1.0000e-04\n",
      "Epoch 92/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5538 - val_loss: -0.7674 - learning_rate: 1.0000e-04\n",
      "Epoch 93/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5659 - val_loss: -0.7622 - learning_rate: 1.0000e-04\n",
      "Epoch 94/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5099 - val_loss: -0.7843 - learning_rate: 1.0000e-04\n",
      "Epoch 95/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5588 - val_loss: -0.7934 - learning_rate: 1.0000e-04\n",
      "Epoch 96/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6074 - val_loss: -0.7908 - learning_rate: 1.0000e-04\n",
      "Epoch 97/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6025 - val_loss: -0.7882 - learning_rate: 1.0000e-04\n",
      "Epoch 98/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.5768 - val_loss: -0.7958 - learning_rate: 1.0000e-04\n",
      "Epoch 99/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6052 - val_loss: -0.7966 - learning_rate: 1.0000e-04\n",
      "Epoch 100/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6228 - val_loss: -0.8059 - learning_rate: 1.0000e-04\n",
      "Epoch 101/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5612 - val_loss: -0.8038 - learning_rate: 1.0000e-04\n",
      "Epoch 102/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5847 - val_loss: -0.8099 - learning_rate: 1.0000e-04\n",
      "Epoch 103/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5610 - val_loss: -0.8208 - learning_rate: 1.0000e-04\n",
      "Epoch 104/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5792 - val_loss: -0.8178 - learning_rate: 1.0000e-04\n",
      "Epoch 105/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6263 - val_loss: -0.8355 - learning_rate: 1.0000e-04\n",
      "Epoch 106/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6154 - val_loss: -0.8431 - learning_rate: 1.0000e-04\n",
      "Epoch 107/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6180 - val_loss: -0.8412 - learning_rate: 1.0000e-04\n",
      "Epoch 108/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6389 - val_loss: -0.8376 - learning_rate: 1.0000e-04\n",
      "Epoch 109/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6392 - val_loss: -0.8407 - learning_rate: 1.0000e-04\n",
      "Epoch 110/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5900 - val_loss: -0.8581 - learning_rate: 1.0000e-04\n",
      "Epoch 111/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5305 - val_loss: -0.8465 - learning_rate: 1.0000e-04\n",
      "Epoch 112/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6544 - val_loss: -0.8517 - learning_rate: 1.0000e-04\n",
      "Epoch 113/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6563 - val_loss: -0.8729 - learning_rate: 1.0000e-04\n",
      "Epoch 114/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6354 - val_loss: -0.8651 - learning_rate: 1.0000e-04\n",
      "Epoch 115/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6312 - val_loss: -0.8750 - learning_rate: 1.0000e-04\n",
      "Epoch 116/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6887 - val_loss: -0.8699 - learning_rate: 1.0000e-04\n",
      "Epoch 117/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.6680 - val_loss: -0.8819 - learning_rate: 1.0000e-04\n",
      "Epoch 118/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6359 - val_loss: -0.8966 - learning_rate: 1.0000e-04\n",
      "Epoch 119/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6295 - val_loss: -0.8892 - learning_rate: 1.0000e-04\n",
      "Epoch 120/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6594 - val_loss: -0.8771 - learning_rate: 1.0000e-04\n",
      "Epoch 121/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6162 - val_loss: -0.8938 - learning_rate: 1.0000e-04\n",
      "Epoch 122/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5801 - val_loss: -0.8873 - learning_rate: 1.0000e-04\n",
      "Epoch 123/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6938 - val_loss: -0.8911 - learning_rate: 1.0000e-04\n",
      "Epoch 124/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6506 - val_loss: -0.8985 - learning_rate: 5.0000e-05\n",
      "Epoch 125/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7007 - val_loss: -0.8929 - learning_rate: 5.0000e-05\n",
      "Epoch 126/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5683 - val_loss: -0.9070 - learning_rate: 5.0000e-05\n",
      "Epoch 127/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6920 - val_loss: -0.9135 - learning_rate: 5.0000e-05\n",
      "Epoch 128/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6188 - val_loss: -0.9085 - learning_rate: 5.0000e-05\n",
      "Epoch 129/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6322 - val_loss: -0.9195 - learning_rate: 5.0000e-05\n",
      "Epoch 130/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6410 - val_loss: -0.9189 - learning_rate: 5.0000e-05\n",
      "Epoch 131/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6429 - val_loss: -0.9152 - learning_rate: 5.0000e-05\n",
      "Epoch 132/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5592 - val_loss: -0.9198 - learning_rate: 5.0000e-05\n",
      "Epoch 133/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6161 - val_loss: -0.9209 - learning_rate: 5.0000e-05\n",
      "Epoch 134/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6741 - val_loss: -0.9222 - learning_rate: 5.0000e-05\n",
      "Epoch 135/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7166 - val_loss: -0.9272 - learning_rate: 5.0000e-05\n",
      "Epoch 136/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.6053 - val_loss: -0.9216 - learning_rate: 5.0000e-05\n",
      "Epoch 137/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6853 - val_loss: -0.9264 - learning_rate: 5.0000e-05\n",
      "Epoch 138/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6552 - val_loss: -0.9303 - learning_rate: 5.0000e-05\n",
      "Epoch 139/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5540 - val_loss: -0.9196 - learning_rate: 5.0000e-05\n",
      "Epoch 140/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5513 - val_loss: -0.9242 - learning_rate: 5.0000e-05\n",
      "Epoch 141/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6301 - val_loss: -0.9282 - learning_rate: 5.0000e-05\n",
      "Epoch 142/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6115 - val_loss: -0.9317 - learning_rate: 5.0000e-05\n",
      "Epoch 143/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7208 - val_loss: -0.9384 - learning_rate: 5.0000e-05\n",
      "Epoch 144/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5770 - val_loss: -0.9400 - learning_rate: 5.0000e-05\n",
      "Epoch 145/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6529 - val_loss: -0.9394 - learning_rate: 5.0000e-05\n",
      "Epoch 146/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6879 - val_loss: -0.9615 - learning_rate: 5.0000e-05\n",
      "Epoch 147/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6854 - val_loss: -0.9553 - learning_rate: 5.0000e-05\n",
      "Epoch 148/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6381 - val_loss: -0.9658 - learning_rate: 5.0000e-05\n",
      "Epoch 149/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.7051 - val_loss: -0.9562 - learning_rate: 5.0000e-05\n",
      "Epoch 150/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6921 - val_loss: -0.9613 - learning_rate: 5.0000e-05\n",
      "Epoch 151/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6734 - val_loss: -0.9526 - learning_rate: 5.0000e-05\n",
      "Epoch 152/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7028 - val_loss: -0.9642 - learning_rate: 5.0000e-05\n",
      "Epoch 153/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6222 - val_loss: -0.9678 - learning_rate: 5.0000e-05\n",
      "Epoch 154/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.6907 - val_loss: -0.9734 - learning_rate: 5.0000e-05\n",
      "Epoch 155/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.6147 - val_loss: -0.9789 - learning_rate: 5.0000e-05\n",
      "Epoch 156/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6481 - val_loss: -0.9738 - learning_rate: 5.0000e-05\n",
      "Epoch 157/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7056 - val_loss: -0.9686 - learning_rate: 5.0000e-05\n",
      "Epoch 158/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7177 - val_loss: -0.9754 - learning_rate: 5.0000e-05\n",
      "Epoch 159/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7368 - val_loss: -0.9756 - learning_rate: 5.0000e-05\n",
      "Epoch 160/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7249 - val_loss: -0.9785 - learning_rate: 5.0000e-05\n",
      "Epoch 161/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6597 - val_loss: -0.9863 - learning_rate: 2.5000e-05\n",
      "Epoch 162/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6946 - val_loss: -0.9839 - learning_rate: 2.5000e-05\n",
      "Epoch 163/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7180 - val_loss: -0.9846 - learning_rate: 2.5000e-05\n",
      "Epoch 164/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6101 - val_loss: -0.9858 - learning_rate: 2.5000e-05\n",
      "Epoch 165/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7576 - val_loss: -0.9839 - learning_rate: 2.5000e-05\n",
      "Epoch 166/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7187 - val_loss: -0.9942 - learning_rate: 2.5000e-05\n",
      "Epoch 167/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7705 - val_loss: -0.9894 - learning_rate: 2.5000e-05\n",
      "Epoch 168/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.7051 - val_loss: -0.9935 - learning_rate: 2.5000e-05\n",
      "Epoch 169/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6687 - val_loss: -0.9872 - learning_rate: 2.5000e-05\n",
      "Epoch 170/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.7224 - val_loss: -0.9884 - learning_rate: 2.5000e-05\n",
      "Epoch 171/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7589 - val_loss: -0.9913 - learning_rate: 2.5000e-05\n",
      "Epoch 172/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.7499 - val_loss: -0.9956 - learning_rate: 1.2500e-05\n",
      "Epoch 173/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.7427 - val_loss: -0.9975 - learning_rate: 1.2500e-05\n",
      "Epoch 174/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6837 - val_loss: -1.0007 - learning_rate: 1.2500e-05\n",
      "Epoch 175/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6965 - val_loss: -0.9927 - learning_rate: 1.2500e-05\n",
      "Epoch 176/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7676 - val_loss: -0.9989 - learning_rate: 1.2500e-05\n",
      "Epoch 177/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6997 - val_loss: -0.9945 - learning_rate: 1.2500e-05\n",
      "Epoch 178/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7958 - val_loss: -0.9961 - learning_rate: 1.2500e-05\n",
      "Epoch 179/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7717 - val_loss: -0.9929 - learning_rate: 1.2500e-05\n",
      "Epoch 180/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7406 - val_loss: -0.9964 - learning_rate: 6.2500e-06\n",
      "Epoch 181/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6696 - val_loss: -1.0015 - learning_rate: 6.2500e-06\n",
      "Epoch 182/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7432 - val_loss: -0.9943 - learning_rate: 6.2500e-06\n",
      "Epoch 183/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.7442 - val_loss: -0.9946 - learning_rate: 6.2500e-06\n",
      "Epoch 184/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7004 - val_loss: -0.9995 - learning_rate: 6.2500e-06\n",
      "Epoch 185/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.7795 - val_loss: -0.9965 - learning_rate: 6.2500e-06\n",
      "Epoch 186/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7291 - val_loss: -0.9998 - learning_rate: 6.2500e-06\n",
      "Epoch 187/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6428 - val_loss: -1.0009 - learning_rate: 3.1250e-06\n",
      "Epoch 188/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7000 - val_loss: -1.0025 - learning_rate: 3.1250e-06\n",
      "Epoch 189/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7653 - val_loss: -0.9986 - learning_rate: 3.1250e-06\n",
      "Epoch 190/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7712 - val_loss: -1.0002 - learning_rate: 3.1250e-06\n",
      "Epoch 191/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6905 - val_loss: -0.9981 - learning_rate: 3.1250e-06\n",
      "Epoch 192/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.8007 - val_loss: -1.0037 - learning_rate: 3.1250e-06\n",
      "Epoch 193/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7189 - val_loss: -1.0014 - learning_rate: 3.1250e-06\n",
      "Epoch 194/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4911 - val_loss: -0.9978 - learning_rate: 3.1250e-06\n",
      "Epoch 195/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.8069 - val_loss: -1.0022 - learning_rate: 3.1250e-06\n",
      "Epoch 196/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.7274 - val_loss: -1.0033 - learning_rate: 3.1250e-06\n",
      "Epoch 197/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.7775 - val_loss: -0.9961 - learning_rate: 3.1250e-06\n",
      "Epoch 198/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.7570 - val_loss: -1.0038 - learning_rate: 1.5625e-06\n",
      "Epoch 199/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.8135 - val_loss: -0.9916 - learning_rate: 1.5625e-06\n",
      "Epoch 200/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7101 - val_loss: -1.0046 - learning_rate: 1.5625e-06\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - loss: 0.4965 - val_loss: 0.0430 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.3230 - val_loss: 0.0278 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.2037 - val_loss: 0.0325 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.1690 - val_loss: 0.0150 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.1429 - val_loss: 0.0152 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.1350 - val_loss: 0.0145 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0758 - val_loss: 0.0126 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0706 - val_loss: 0.0111 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0663 - val_loss: 0.0123 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0658 - val_loss: 0.0083 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0737 - val_loss: 0.0094 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0610 - val_loss: 0.0099 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0446 - val_loss: 0.0062 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0517 - val_loss: 0.0056 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0355 - val_loss: 0.0058 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0314 - val_loss: 0.0061 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0395 - val_loss: 0.0064 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0307 - val_loss: 0.0068 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0319 - val_loss: 0.0020 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0393 - val_loss: 0.0018 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0241 - val_loss: 0.0073 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0351 - val_loss: 0.0039 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0223 - val_loss: 0.0045 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0270 - val_loss: 0.0047 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0217 - val_loss: 0.0059 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0204 - val_loss: 0.0014 - learning_rate: 5.0000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0236 - val_loss: 0.0017 - learning_rate: 5.0000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0249 - val_loss: 0.0052 - learning_rate: 5.0000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0206 - val_loss: 0.0045 - learning_rate: 5.0000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0184 - val_loss: 8.7347e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0231 - val_loss: 0.0036 - learning_rate: 5.0000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0209 - val_loss: 6.8649e-05 - learning_rate: 5.0000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0142 - val_loss: -5.0256e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0201 - val_loss: -9.4218e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0134 - val_loss: -5.8816e-05 - learning_rate: 5.0000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0159 - val_loss: 1.1949e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0167 - val_loss: 6.0260e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0200 - val_loss: 2.1374e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0144 - val_loss: 9.3952e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0173 - val_loss: 8.5791e-04 - learning_rate: 2.5000e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0126 - val_loss: -6.1277e-04 - learning_rate: 2.5000e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0096 - val_loss: -4.8398e-04 - learning_rate: 2.5000e-05\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0135 - val_loss: -2.8279e-04 - learning_rate: 2.5000e-05\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0198 - val_loss: -6.3522e-05 - learning_rate: 2.5000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - loss: 0.6404 - val_loss: -0.0436 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.2618 - val_loss: -0.1399 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.1062 - val_loss: -0.1810 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0209 - val_loss: -0.2043 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.0454 - val_loss: -0.2263 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.1156 - val_loss: -0.2454 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.1217 - val_loss: -0.2570 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.1382 - val_loss: -0.2689 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.0932 - val_loss: -0.2762 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.1869 - val_loss: -0.2812 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.1941 - val_loss: -0.2977 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.2356 - val_loss: -0.3019 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.2452 - val_loss: -0.3028 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.2416 - val_loss: -0.3087 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.2166 - val_loss: -0.3177 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.2403 - val_loss: -0.3228 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.2649 - val_loss: -0.3247 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.2645 - val_loss: -0.3293 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - loss: -0.2699 - val_loss: -0.3369 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.2844 - val_loss: -0.3373 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.2655 - val_loss: -0.3451 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.2846 - val_loss: -0.3509 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.3227 - val_loss: -0.3588 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.3438 - val_loss: -0.3562 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.3099 - val_loss: -0.3654 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.3018 - val_loss: -0.3662 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.3479 - val_loss: -0.3702 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.3676 - val_loss: -0.3744 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.3439 - val_loss: -0.3736 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.3788 - val_loss: -0.3805 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.3813 - val_loss: -0.3809 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.3684 - val_loss: -0.3822 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.3968 - val_loss: -0.3973 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.3755 - val_loss: -0.3835 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.4016 - val_loss: -0.3968 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.3900 - val_loss: -0.4073 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.4118 - val_loss: -0.4042 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.4205 - val_loss: -0.4122 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4364 - val_loss: -0.4039 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: -0.4209 - val_loss: -0.4070 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.4488 - val_loss: -0.4035 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - loss: -0.4367 - val_loss: -0.4125 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m940s\u001b[0m 4s/step - loss: -0.4378 - val_loss: -0.4190 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.4009 - val_loss: -0.4158 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.4287 - val_loss: -0.4257 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4170 - val_loss: -0.4186 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4155 - val_loss: -0.4186 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.4538 - val_loss: -0.4344 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.4674 - val_loss: -0.4369 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4474 - val_loss: -0.4360 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4468 - val_loss: -0.4251 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.5039 - val_loss: -0.4359 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.4784 - val_loss: -0.4339 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4831 - val_loss: -0.4475 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4881 - val_loss: -0.4419 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.4571 - val_loss: -0.4455 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4605 - val_loss: -0.4616 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5021 - val_loss: -0.4432 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4663 - val_loss: -0.4690 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.5089 - val_loss: -0.4494 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4799 - val_loss: -0.4614 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.5020 - val_loss: -0.4716 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.4631 - val_loss: -0.4686 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4946 - val_loss: -0.4614 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5006 - val_loss: -0.4667 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5077 - val_loss: -0.4919 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5076 - val_loss: -0.4847 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5270 - val_loss: -0.4956 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.5452 - val_loss: -0.4976 - learning_rate: 1.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.5274 - val_loss: -0.4988 - learning_rate: 1.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5273 - val_loss: -0.5007 - learning_rate: 1.0000e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5177 - val_loss: -0.5061 - learning_rate: 1.0000e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5562 - val_loss: -0.4935 - learning_rate: 1.0000e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5802 - val_loss: -0.5044 - learning_rate: 1.0000e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5426 - val_loss: -0.5145 - learning_rate: 1.0000e-04\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5471 - val_loss: -0.5154 - learning_rate: 1.0000e-04\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5260 - val_loss: -0.5061 - learning_rate: 1.0000e-04\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5785 - val_loss: -0.5041 - learning_rate: 1.0000e-04\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5658 - val_loss: -0.5058 - learning_rate: 1.0000e-04\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5558 - val_loss: -0.4926 - learning_rate: 1.0000e-04\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5559 - val_loss: -0.5102 - learning_rate: 1.0000e-04\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5726 - val_loss: -0.5208 - learning_rate: 5.0000e-05\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.5171 - val_loss: -0.5191 - learning_rate: 5.0000e-05\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5794 - val_loss: -0.5345 - learning_rate: 5.0000e-05\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5546 - val_loss: -0.5244 - learning_rate: 5.0000e-05\n",
      "Epoch 86/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5658 - val_loss: -0.5397 - learning_rate: 5.0000e-05\n",
      "Epoch 87/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.5969 - val_loss: -0.5347 - learning_rate: 5.0000e-05\n",
      "Epoch 88/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5969 - val_loss: -0.5302 - learning_rate: 5.0000e-05\n",
      "Epoch 89/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5642 - val_loss: -0.5414 - learning_rate: 5.0000e-05\n",
      "Epoch 90/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5878 - val_loss: -0.5411 - learning_rate: 5.0000e-05\n",
      "Epoch 91/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.5701 - val_loss: -0.5431 - learning_rate: 5.0000e-05\n",
      "Epoch 92/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5746 - val_loss: -0.5355 - learning_rate: 5.0000e-05\n",
      "Epoch 93/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6024 - val_loss: -0.5476 - learning_rate: 5.0000e-05\n",
      "Epoch 94/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5944 - val_loss: -0.5342 - learning_rate: 5.0000e-05\n",
      "Epoch 95/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.5913 - val_loss: -0.5483 - learning_rate: 5.0000e-05\n",
      "Epoch 96/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.5714 - val_loss: -0.5532 - learning_rate: 5.0000e-05\n",
      "Epoch 97/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.6042 - val_loss: -0.5500 - learning_rate: 5.0000e-05\n",
      "Epoch 98/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5917 - val_loss: -0.5596 - learning_rate: 5.0000e-05\n",
      "Epoch 99/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.6141 - val_loss: -0.5659 - learning_rate: 5.0000e-05\n",
      "Epoch 100/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.6049 - val_loss: -0.5633 - learning_rate: 5.0000e-05\n",
      "Epoch 101/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.6137 - val_loss: -0.5635 - learning_rate: 5.0000e-05\n",
      "Epoch 102/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6283 - val_loss: -0.5667 - learning_rate: 5.0000e-05\n",
      "Epoch 103/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.6104 - val_loss: -0.5549 - learning_rate: 5.0000e-05\n",
      "Epoch 104/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6166 - val_loss: -0.5607 - learning_rate: 5.0000e-05\n",
      "Epoch 105/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5751 - val_loss: -0.5647 - learning_rate: 5.0000e-05\n",
      "Epoch 106/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5951 - val_loss: -0.5742 - learning_rate: 5.0000e-05\n",
      "Epoch 107/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5746 - val_loss: -0.5710 - learning_rate: 5.0000e-05\n",
      "Epoch 108/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5781 - val_loss: -0.5776 - learning_rate: 5.0000e-05\n",
      "Epoch 109/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5897 - val_loss: -0.5611 - learning_rate: 5.0000e-05\n",
      "Epoch 110/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5780 - val_loss: -0.5740 - learning_rate: 5.0000e-05\n",
      "Epoch 111/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6032 - val_loss: -0.5757 - learning_rate: 5.0000e-05\n",
      "Epoch 112/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6195 - val_loss: -0.5749 - learning_rate: 5.0000e-05\n",
      "Epoch 113/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.6165 - val_loss: -0.5964 - learning_rate: 5.0000e-05\n",
      "Epoch 114/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5983 - val_loss: -0.5927 - learning_rate: 5.0000e-05\n",
      "Epoch 115/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6205 - val_loss: -0.5867 - learning_rate: 5.0000e-05\n",
      "Epoch 116/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5742 - val_loss: -0.5890 - learning_rate: 5.0000e-05\n",
      "Epoch 117/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.6265 - val_loss: -0.5848 - learning_rate: 5.0000e-05\n",
      "Epoch 118/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6379 - val_loss: -0.5816 - learning_rate: 5.0000e-05\n",
      "Epoch 119/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5842 - val_loss: -0.5888 - learning_rate: 2.5000e-05\n",
      "Epoch 120/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.6901 - val_loss: -0.5950 - learning_rate: 2.5000e-05\n",
      "Epoch 121/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.6373 - val_loss: -0.5871 - learning_rate: 2.5000e-05\n",
      "Epoch 122/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5952 - val_loss: -0.5940 - learning_rate: 2.5000e-05\n",
      "Epoch 123/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6681 - val_loss: -0.5875 - learning_rate: 2.5000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.6295 - val_loss: 0.0099 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.3398 - val_loss: 0.0076 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.2189 - val_loss: 0.0111 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.1584 - val_loss: 0.0107 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.1256 - val_loss: 0.0076 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.1308 - val_loss: 0.0111 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0989 - val_loss: 0.0085 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0868 - val_loss: 0.0096 - learning_rate: 5.0000e-05\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0758 - val_loss: 0.0078 - learning_rate: 5.0000e-05\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0686 - val_loss: 0.0115 - learning_rate: 5.0000e-05\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0661 - val_loss: 0.0091 - learning_rate: 5.0000e-05\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0590 - val_loss: 0.0098 - learning_rate: 5.0000e-05\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0514 - val_loss: 0.0073 - learning_rate: 2.5000e-05\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0702 - val_loss: 0.0099 - learning_rate: 2.5000e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0536 - val_loss: 0.0072 - learning_rate: 2.5000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0562 - val_loss: 0.0114 - learning_rate: 2.5000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0382 - val_loss: 0.0067 - learning_rate: 2.5000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0566 - val_loss: 0.0066 - learning_rate: 2.5000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0459 - val_loss: 0.0110 - learning_rate: 2.5000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0600 - val_loss: 0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0355 - val_loss: 0.0061 - learning_rate: 2.5000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0397 - val_loss: 0.0112 - learning_rate: 2.5000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0533 - val_loss: 0.0091 - learning_rate: 2.5000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0489 - val_loss: 0.0084 - learning_rate: 2.5000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0412 - val_loss: 0.0062 - learning_rate: 2.5000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0366 - val_loss: 0.0063 - learning_rate: 2.5000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0442 - val_loss: 0.0064 - learning_rate: 1.2500e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0433 - val_loss: 0.0067 - learning_rate: 1.2500e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0502 - val_loss: 0.0067 - learning_rate: 1.2500e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0425 - val_loss: 0.0064 - learning_rate: 1.2500e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0322 - val_loss: 0.0071 - learning_rate: 1.2500e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 0.6726 - val_loss: -0.0128 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.3391 - val_loss: -0.0910 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.1870 - val_loss: -0.1447 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0667 - val_loss: -0.1834 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -1.2434e-05 - val_loss: -0.2079 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.0390 - val_loss: -0.2269 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.0522 - val_loss: -0.2474 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - loss: -0.0934 - val_loss: -0.2609 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.0843 - val_loss: -0.2721 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.1206 - val_loss: -0.2895 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.1173 - val_loss: -0.2972 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.1560 - val_loss: -0.3117 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.1835 - val_loss: -0.3212 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.1670 - val_loss: -0.3262 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.1493 - val_loss: -0.3399 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.1645 - val_loss: -0.3434 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.1997 - val_loss: -0.3478 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.1846 - val_loss: -0.3543 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.2335 - val_loss: -0.3614 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.2363 - val_loss: -0.3674 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.2564 - val_loss: -0.3755 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.2536 - val_loss: -0.3762 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.2499 - val_loss: -0.3868 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.2770 - val_loss: -0.3789 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.2705 - val_loss: -0.3958 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.2650 - val_loss: -0.4033 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.2697 - val_loss: -0.4056 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3103 - val_loss: -0.4155 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.2955 - val_loss: -0.4137 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3043 - val_loss: -0.4186 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3122 - val_loss: -0.4243 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3264 - val_loss: -0.4263 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3503 - val_loss: -0.4354 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3175 - val_loss: -0.4406 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3321 - val_loss: -0.4472 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3562 - val_loss: -0.4540 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3659 - val_loss: -0.4552 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3770 - val_loss: -0.4615 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3575 - val_loss: -0.4677 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.3707 - val_loss: -0.4657 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.3793 - val_loss: -0.4710 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4129 - val_loss: -0.4772 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3518 - val_loss: -0.4826 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4009 - val_loss: -0.4818 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4056 - val_loss: -0.4859 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4028 - val_loss: -0.4868 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3982 - val_loss: -0.4859 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3965 - val_loss: -0.5013 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.4335 - val_loss: -0.5002 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4276 - val_loss: -0.5064 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4184 - val_loss: -0.5017 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4217 - val_loss: -0.5179 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.4232 - val_loss: -0.5119 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.4451 - val_loss: -0.5136 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.4438 - val_loss: -0.5206 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4579 - val_loss: -0.5293 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4545 - val_loss: -0.5277 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4142 - val_loss: -0.5448 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.4036 - val_loss: -0.5413 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4674 - val_loss: -0.5382 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.4644 - val_loss: -0.5469 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4754 - val_loss: -0.5482 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4803 - val_loss: -0.5522 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.4496 - val_loss: -0.5476 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4490 - val_loss: -0.5589 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.4619 - val_loss: -0.5579 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4479 - val_loss: -0.5619 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.4649 - val_loss: -0.5710 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4606 - val_loss: -0.5696 - learning_rate: 1.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5103 - val_loss: -0.5777 - learning_rate: 1.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.4544 - val_loss: -0.5823 - learning_rate: 1.0000e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.4879 - val_loss: -0.5914 - learning_rate: 1.0000e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5253 - val_loss: -0.5987 - learning_rate: 1.0000e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.4892 - val_loss: -0.5914 - learning_rate: 1.0000e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4856 - val_loss: -0.6061 - learning_rate: 1.0000e-04\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5308 - val_loss: -0.6077 - learning_rate: 1.0000e-04\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4964 - val_loss: -0.6036 - learning_rate: 1.0000e-04\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5285 - val_loss: -0.6148 - learning_rate: 1.0000e-04\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5164 - val_loss: -0.6042 - learning_rate: 1.0000e-04\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5411 - val_loss: -0.6231 - learning_rate: 1.0000e-04\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5041 - val_loss: -0.6321 - learning_rate: 1.0000e-04\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5706 - val_loss: -0.6155 - learning_rate: 1.0000e-04\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5581 - val_loss: -0.6333 - learning_rate: 1.0000e-04\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5065 - val_loss: -0.6303 - learning_rate: 1.0000e-04\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5445 - val_loss: -0.6348 - learning_rate: 1.0000e-04\n",
      "Epoch 86/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5095 - val_loss: -0.6310 - learning_rate: 1.0000e-04\n",
      "Epoch 87/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5501 - val_loss: -0.6383 - learning_rate: 1.0000e-04\n",
      "Epoch 88/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5822 - val_loss: -0.6381 - learning_rate: 1.0000e-04\n",
      "Epoch 89/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5107 - val_loss: -0.6496 - learning_rate: 1.0000e-04\n",
      "Epoch 90/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5358 - val_loss: -0.6541 - learning_rate: 1.0000e-04\n",
      "Epoch 91/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5529 - val_loss: -0.6645 - learning_rate: 1.0000e-04\n",
      "Epoch 92/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5756 - val_loss: -0.6531 - learning_rate: 1.0000e-04\n",
      "Epoch 93/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - loss: -0.5825 - val_loss: -0.6631 - learning_rate: 1.0000e-04\n",
      "Epoch 94/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.6205 - val_loss: -0.6795 - learning_rate: 1.0000e-04\n",
      "Epoch 95/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.5874 - val_loss: -0.6823 - learning_rate: 1.0000e-04\n",
      "Epoch 96/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5748 - val_loss: -0.6628 - learning_rate: 1.0000e-04\n",
      "Epoch 97/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5939 - val_loss: -0.6688 - learning_rate: 1.0000e-04\n",
      "Epoch 98/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5617 - val_loss: -0.6866 - learning_rate: 1.0000e-04\n",
      "Epoch 99/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5826 - val_loss: -0.6784 - learning_rate: 1.0000e-04\n",
      "Epoch 100/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5733 - val_loss: -0.6788 - learning_rate: 1.0000e-04\n",
      "Epoch 101/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: -0.5521 - val_loss: -0.6888 - learning_rate: 1.0000e-04\n",
      "Epoch 102/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6086 - val_loss: -0.6874 - learning_rate: 1.0000e-04\n",
      "Epoch 103/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.5885 - val_loss: -0.6832 - learning_rate: 1.0000e-04\n",
      "Epoch 104/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6076 - val_loss: -0.6882 - learning_rate: 1.0000e-04\n",
      "Epoch 105/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5450 - val_loss: -0.6907 - learning_rate: 1.0000e-04\n",
      "Epoch 106/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6205 - val_loss: -0.7005 - learning_rate: 1.0000e-04\n",
      "Epoch 107/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: -0.6048 - val_loss: -0.7145 - learning_rate: 1.0000e-04\n",
      "Epoch 108/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - loss: -0.6202 - val_loss: -0.7123 - learning_rate: 1.0000e-04\n",
      "Epoch 109/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - loss: -0.5911 - val_loss: -0.7209 - learning_rate: 1.0000e-04\n",
      "Epoch 110/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6187 - val_loss: -0.7222 - learning_rate: 1.0000e-04\n",
      "Epoch 111/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.6109 - val_loss: -0.7002 - learning_rate: 1.0000e-04\n",
      "Epoch 112/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.5944 - val_loss: -0.7331 - learning_rate: 1.0000e-04\n",
      "Epoch 113/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.6165 - val_loss: -0.7354 - learning_rate: 1.0000e-04\n",
      "Epoch 114/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.6246 - val_loss: -0.7459 - learning_rate: 1.0000e-04\n",
      "Epoch 115/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.6414 - val_loss: -0.7358 - learning_rate: 1.0000e-04\n",
      "Epoch 116/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.6381 - val_loss: -0.7394 - learning_rate: 1.0000e-04\n",
      "Epoch 117/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.6449 - val_loss: -0.7218 - learning_rate: 1.0000e-04\n",
      "Epoch 118/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6673 - val_loss: -0.7086 - learning_rate: 1.0000e-04\n",
      "Epoch 119/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6080 - val_loss: -0.7278 - learning_rate: 1.0000e-04\n",
      "Epoch 120/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6530 - val_loss: -0.7382 - learning_rate: 5.0000e-05\n",
      "Epoch 121/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6759 - val_loss: -0.7426 - learning_rate: 5.0000e-05\n",
      "Epoch 122/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6790 - val_loss: -0.7394 - learning_rate: 5.0000e-05\n",
      "Epoch 123/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6554 - val_loss: -0.7399 - learning_rate: 5.0000e-05\n",
      "Epoch 124/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6657 - val_loss: -0.7403 - learning_rate: 5.0000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.4546 - val_loss: 0.0305 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.3420 - val_loss: 0.0305 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.2432 - val_loss: 0.0147 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1547 - val_loss: 0.0077 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1316 - val_loss: 0.0114 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1198 - val_loss: 0.0062 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0829 - val_loss: 0.0030 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0726 - val_loss: 1.3937e-05 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0843 - val_loss: 0.0026 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0765 - val_loss: 0.0015 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0615 - val_loss: 0.0026 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0705 - val_loss: 0.0020 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0553 - val_loss: 0.0149 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0497 - val_loss: 0.0056 - learning_rate: 5.0000e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0433 - val_loss: 0.0064 - learning_rate: 5.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0439 - val_loss: 0.0018 - learning_rate: 5.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0544 - val_loss: 0.0035 - learning_rate: 5.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0424 - val_loss: 0.0041 - learning_rate: 5.0000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.6112 - val_loss: -0.0043 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.2393 - val_loss: -0.0773 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.1090 - val_loss: -0.1240 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0358 - val_loss: -0.1553 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.0090 - val_loss: -0.1806 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.0139 - val_loss: -0.2012 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.0736 - val_loss: -0.2185 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.1182 - val_loss: -0.2355 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.0955 - val_loss: -0.2505 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.1634 - val_loss: -0.2556 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.1555 - val_loss: -0.2777 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.1509 - val_loss: -0.2857 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.1428 - val_loss: -0.2959 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.1761 - val_loss: -0.3041 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.1994 - val_loss: -0.3124 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.2219 - val_loss: -0.3183 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.2197 - val_loss: -0.3297 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.2057 - val_loss: -0.3206 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.2257 - val_loss: -0.3470 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.2201 - val_loss: -0.3513 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.2613 - val_loss: -0.3558 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.2545 - val_loss: -0.3640 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.3117 - val_loss: -0.3709 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.2905 - val_loss: -0.3769 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2944 - val_loss: -0.3853 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3103 - val_loss: -0.3791 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.2893 - val_loss: -0.3949 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.3064 - val_loss: -0.3940 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3279 - val_loss: -0.3955 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2904 - val_loss: -0.4057 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3408 - val_loss: -0.4174 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3411 - val_loss: -0.4223 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3443 - val_loss: -0.4349 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3565 - val_loss: -0.4331 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3444 - val_loss: -0.4375 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3612 - val_loss: -0.4473 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.3910 - val_loss: -0.4522 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3722 - val_loss: -0.4669 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3261 - val_loss: -0.4740 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3859 - val_loss: -0.4740 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3691 - val_loss: -0.4639 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.3761 - val_loss: -0.4660 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4056 - val_loss: -0.4803 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4388 - val_loss: -0.4946 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4180 - val_loss: -0.4890 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4261 - val_loss: -0.4937 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4120 - val_loss: -0.4941 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4226 - val_loss: -0.5024 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4268 - val_loss: -0.5075 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.3941 - val_loss: -0.5202 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4295 - val_loss: -0.5135 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4213 - val_loss: -0.5282 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4716 - val_loss: -0.5267 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4579 - val_loss: -0.5352 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.4489 - val_loss: -0.5238 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4449 - val_loss: -0.5424 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4570 - val_loss: -0.5435 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4848 - val_loss: -0.5552 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.4681 - val_loss: -0.5585 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.4900 - val_loss: -0.5556 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.4737 - val_loss: -0.5573 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4797 - val_loss: -0.5646 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.4698 - val_loss: -0.5732 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.4940 - val_loss: -0.5731 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4759 - val_loss: -0.5693 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.4690 - val_loss: -0.5687 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5099 - val_loss: -0.5796 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.4736 - val_loss: -0.5806 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.4682 - val_loss: -0.5776 - learning_rate: 1.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5377 - val_loss: -0.5896 - learning_rate: 1.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5371 - val_loss: -0.5734 - learning_rate: 1.0000e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5061 - val_loss: -0.6015 - learning_rate: 1.0000e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5430 - val_loss: -0.6038 - learning_rate: 1.0000e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.4999 - val_loss: -0.6194 - learning_rate: 1.0000e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5745 - val_loss: -0.6117 - learning_rate: 1.0000e-04\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5073 - val_loss: -0.6103 - learning_rate: 1.0000e-04\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5347 - val_loss: -0.6107 - learning_rate: 1.0000e-04\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5949 - val_loss: -0.6246 - learning_rate: 1.0000e-04\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.4856 - val_loss: -0.6277 - learning_rate: 1.0000e-04\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5441 - val_loss: -0.6308 - learning_rate: 1.0000e-04\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5518 - val_loss: -0.6100 - learning_rate: 1.0000e-04\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.4846 - val_loss: -0.6315 - learning_rate: 1.0000e-04\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5667 - val_loss: -0.6268 - learning_rate: 1.0000e-04\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5190 - val_loss: -0.6475 - learning_rate: 1.0000e-04\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5584 - val_loss: -0.6625 - learning_rate: 1.0000e-04\n",
      "Epoch 86/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.5735 - val_loss: -0.6665 - learning_rate: 1.0000e-04\n",
      "Epoch 87/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.5627 - val_loss: -0.6573 - learning_rate: 1.0000e-04\n",
      "Epoch 88/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5318 - val_loss: -0.6703 - learning_rate: 1.0000e-04\n",
      "Epoch 89/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5801 - val_loss: -0.6453 - learning_rate: 1.0000e-04\n",
      "Epoch 90/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.5951 - val_loss: -0.6733 - learning_rate: 1.0000e-04\n",
      "Epoch 91/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5953 - val_loss: -0.6571 - learning_rate: 1.0000e-04\n",
      "Epoch 92/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5488 - val_loss: -0.6793 - learning_rate: 1.0000e-04\n",
      "Epoch 93/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5813 - val_loss: -0.6708 - learning_rate: 1.0000e-04\n",
      "Epoch 94/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5480 - val_loss: -0.6646 - learning_rate: 1.0000e-04\n",
      "Epoch 95/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.5709 - val_loss: -0.6944 - learning_rate: 1.0000e-04\n",
      "Epoch 96/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6149 - val_loss: -0.7097 - learning_rate: 1.0000e-04\n",
      "Epoch 97/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6204 - val_loss: -0.7092 - learning_rate: 1.0000e-04\n",
      "Epoch 98/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6226 - val_loss: -0.7160 - learning_rate: 1.0000e-04\n",
      "Epoch 99/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6203 - val_loss: -0.7211 - learning_rate: 1.0000e-04\n",
      "Epoch 100/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6609 - val_loss: -0.7152 - learning_rate: 1.0000e-04\n",
      "Epoch 101/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6067 - val_loss: -0.6987 - learning_rate: 1.0000e-04\n",
      "Epoch 102/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6050 - val_loss: -0.7284 - learning_rate: 1.0000e-04\n",
      "Epoch 103/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6763 - val_loss: -0.7439 - learning_rate: 1.0000e-04\n",
      "Epoch 104/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6393 - val_loss: -0.7305 - learning_rate: 1.0000e-04\n",
      "Epoch 105/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.6381 - val_loss: -0.7420 - learning_rate: 1.0000e-04\n",
      "Epoch 106/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6407 - val_loss: -0.7410 - learning_rate: 1.0000e-04\n",
      "Epoch 107/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6105 - val_loss: -0.7558 - learning_rate: 1.0000e-04\n",
      "Epoch 108/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6342 - val_loss: -0.7492 - learning_rate: 1.0000e-04\n",
      "Epoch 109/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6357 - val_loss: -0.7525 - learning_rate: 1.0000e-04\n",
      "Epoch 110/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6703 - val_loss: -0.7646 - learning_rate: 1.0000e-04\n",
      "Epoch 111/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6904 - val_loss: -0.7590 - learning_rate: 1.0000e-04\n",
      "Epoch 112/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.7265 - val_loss: -0.7763 - learning_rate: 1.0000e-04\n",
      "Epoch 113/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6718 - val_loss: -0.7731 - learning_rate: 1.0000e-04\n",
      "Epoch 114/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6035 - val_loss: -0.7622 - learning_rate: 1.0000e-04\n",
      "Epoch 115/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6536 - val_loss: -0.7541 - learning_rate: 1.0000e-04\n",
      "Epoch 116/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6714 - val_loss: -0.7630 - learning_rate: 1.0000e-04\n",
      "Epoch 117/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6444 - val_loss: -0.7920 - learning_rate: 1.0000e-04\n",
      "Epoch 118/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.6750 - val_loss: -0.7543 - learning_rate: 1.0000e-04\n",
      "Epoch 119/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.7109 - val_loss: -0.7744 - learning_rate: 1.0000e-04\n",
      "Epoch 120/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.7186 - val_loss: -0.7750 - learning_rate: 1.0000e-04\n",
      "Epoch 121/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6545 - val_loss: -0.7944 - learning_rate: 1.0000e-04\n",
      "Epoch 122/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7104 - val_loss: -0.8025 - learning_rate: 1.0000e-04\n",
      "Epoch 123/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7146 - val_loss: -0.8036 - learning_rate: 1.0000e-04\n",
      "Epoch 124/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.7354 - val_loss: -0.8227 - learning_rate: 1.0000e-04\n",
      "Epoch 125/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7080 - val_loss: -0.8203 - learning_rate: 1.0000e-04\n",
      "Epoch 126/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7250 - val_loss: -0.7926 - learning_rate: 1.0000e-04\n",
      "Epoch 127/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.6935 - val_loss: -0.8031 - learning_rate: 1.0000e-04\n",
      "Epoch 128/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.7132 - val_loss: -0.8249 - learning_rate: 1.0000e-04\n",
      "Epoch 129/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.7110 - val_loss: -0.8096 - learning_rate: 1.0000e-04\n",
      "Epoch 130/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7005 - val_loss: -0.8378 - learning_rate: 1.0000e-04\n",
      "Epoch 131/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7273 - val_loss: -0.8377 - learning_rate: 1.0000e-04\n",
      "Epoch 132/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.6730 - val_loss: -0.8494 - learning_rate: 1.0000e-04\n",
      "Epoch 133/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.6974 - val_loss: -0.8661 - learning_rate: 1.0000e-04\n",
      "Epoch 134/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7563 - val_loss: -0.8492 - learning_rate: 1.0000e-04\n",
      "Epoch 135/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.7490 - val_loss: -0.8782 - learning_rate: 1.0000e-04\n",
      "Epoch 136/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.8076 - val_loss: -0.8428 - learning_rate: 1.0000e-04\n",
      "Epoch 137/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.8007 - val_loss: -0.8445 - learning_rate: 1.0000e-04\n",
      "Epoch 138/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7454 - val_loss: -0.8767 - learning_rate: 1.0000e-04\n",
      "Epoch 139/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7869 - val_loss: -0.8709 - learning_rate: 1.0000e-04\n",
      "Epoch 140/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7673 - val_loss: -0.8779 - learning_rate: 1.0000e-04\n",
      "Epoch 141/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7733 - val_loss: -0.8769 - learning_rate: 5.0000e-05\n",
      "Epoch 142/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7763 - val_loss: -0.8783 - learning_rate: 5.0000e-05\n",
      "Epoch 143/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.8136 - val_loss: -0.8749 - learning_rate: 5.0000e-05\n",
      "Epoch 144/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7743 - val_loss: -0.8958 - learning_rate: 5.0000e-05\n",
      "Epoch 145/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7954 - val_loss: -0.9065 - learning_rate: 5.0000e-05\n",
      "Epoch 146/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7647 - val_loss: -0.8954 - learning_rate: 5.0000e-05\n",
      "Epoch 147/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.8252 - val_loss: -0.8935 - learning_rate: 5.0000e-05\n",
      "Epoch 148/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7920 - val_loss: -0.8906 - learning_rate: 5.0000e-05\n",
      "Epoch 149/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7923 - val_loss: -0.8866 - learning_rate: 5.0000e-05\n",
      "Epoch 150/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7618 - val_loss: -0.8715 - learning_rate: 5.0000e-05\n",
      "Epoch 151/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.7859 - val_loss: -0.8826 - learning_rate: 2.5000e-05\n",
      "Epoch 152/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.7993 - val_loss: -0.8926 - learning_rate: 2.5000e-05\n",
      "Epoch 153/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8302 - val_loss: -0.8869 - learning_rate: 2.5000e-05\n",
      "Epoch 154/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.7932 - val_loss: -0.8853 - learning_rate: 2.5000e-05\n",
      "Epoch 155/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.8418 - val_loss: -0.8761 - learning_rate: 2.5000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - loss: 0.6136 - val_loss: 0.0472 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.3786 - val_loss: 0.0336 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.2347 - val_loss: 0.0149 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.2017 - val_loss: 0.0061 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.1438 - val_loss: 0.0064 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.1187 - val_loss: 0.0092 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.1173 - val_loss: 0.0156 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0983 - val_loss: 0.0016 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0744 - val_loss: 0.0056 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0846 - val_loss: 0.0038 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0558 - val_loss: 0.0040 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0410 - val_loss: 0.0067 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0539 - val_loss: 0.0051 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0494 - val_loss: 0.0049 - learning_rate: 5.0000e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0454 - val_loss: 0.0044 - learning_rate: 5.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0599 - val_loss: 0.0016 - learning_rate: 5.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0440 - val_loss: 0.0018 - learning_rate: 5.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0306 - val_loss: 0.0041 - learning_rate: 5.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0356 - val_loss: 0.0054 - learning_rate: 2.5000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0330 - val_loss: 0.0044 - learning_rate: 2.5000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0391 - val_loss: 0.0029 - learning_rate: 2.5000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0281 - val_loss: 0.0049 - learning_rate: 2.5000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0307 - val_loss: 0.0065 - learning_rate: 2.5000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0450 - val_loss: 0.0033 - learning_rate: 1.2500e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0350 - val_loss: 0.0041 - learning_rate: 1.2500e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0348 - val_loss: 0.0039 - learning_rate: 1.2500e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.6715 - val_loss: -0.0662 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.3156 - val_loss: -0.1573 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.1226 - val_loss: -0.1990 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0515 - val_loss: -0.2365 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0417 - val_loss: -0.2560 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0107 - val_loss: -0.2785 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.0404 - val_loss: -0.2923 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.0658 - val_loss: -0.3049 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.0715 - val_loss: -0.3164 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.1135 - val_loss: -0.3269 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: -0.1226 - val_loss: -0.3318 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.1194 - val_loss: -0.3420 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.1553 - val_loss: -0.3513 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.1489 - val_loss: -0.3589 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.1543 - val_loss: -0.3621 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: -0.2005 - val_loss: -0.3772 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.2207 - val_loss: -0.3815 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2071 - val_loss: -0.3861 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.2269 - val_loss: -0.3915 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2354 - val_loss: -0.3938 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: -0.2740 - val_loss: -0.4017 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.2839 - val_loss: -0.4071 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: -0.2929 - val_loss: -0.4089 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: -0.2529 - val_loss: -0.4162 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.2605 - val_loss: -0.4253 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.2975 - val_loss: -0.4287 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.2726 - val_loss: -0.4338 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.3151 - val_loss: -0.4406 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.2795 - val_loss: -0.4441 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.2910 - val_loss: -0.4459 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.3283 - val_loss: -0.4571 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.3218 - val_loss: -0.4637 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.3105 - val_loss: -0.4697 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.3443 - val_loss: -0.4567 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.3474 - val_loss: -0.4695 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.3326 - val_loss: -0.4816 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.3484 - val_loss: -0.4822 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.3687 - val_loss: -0.4819 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.3791 - val_loss: -0.4812 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.3588 - val_loss: -0.4957 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.3690 - val_loss: -0.4920 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.3668 - val_loss: -0.5034 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.3706 - val_loss: -0.4981 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.3389 - val_loss: -0.5075 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.3861 - val_loss: -0.5055 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.3536 - val_loss: -0.5145 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.4033 - val_loss: -0.5223 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.4192 - val_loss: -0.5266 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.3840 - val_loss: -0.5212 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.4172 - val_loss: -0.5310 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.4207 - val_loss: -0.5309 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.4108 - val_loss: -0.5341 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.4388 - val_loss: -0.5355 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.4176 - val_loss: -0.5441 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.4368 - val_loss: -0.5405 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.4434 - val_loss: -0.5507 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.4041 - val_loss: -0.5515 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.4770 - val_loss: -0.5485 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.4284 - val_loss: -0.5585 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.4461 - val_loss: -0.5521 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.4721 - val_loss: -0.5659 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.4371 - val_loss: -0.5676 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.5099 - val_loss: -0.5667 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.4833 - val_loss: -0.5850 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.4733 - val_loss: -0.5726 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.4461 - val_loss: -0.5882 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.4860 - val_loss: -0.5996 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.5396 - val_loss: -0.6035 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.4775 - val_loss: -0.5921 - learning_rate: 1.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.4986 - val_loss: -0.6069 - learning_rate: 1.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5299 - val_loss: -0.5955 - learning_rate: 1.0000e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.5217 - val_loss: -0.6012 - learning_rate: 1.0000e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5379 - val_loss: -0.5969 - learning_rate: 1.0000e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5180 - val_loss: -0.6086 - learning_rate: 1.0000e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5207 - val_loss: -0.6079 - learning_rate: 1.0000e-04\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5068 - val_loss: -0.6205 - learning_rate: 1.0000e-04\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5149 - val_loss: -0.6258 - learning_rate: 1.0000e-04\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.5529 - val_loss: -0.6063 - learning_rate: 1.0000e-04\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5383 - val_loss: -0.6311 - learning_rate: 1.0000e-04\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.5628 - val_loss: -0.6399 - learning_rate: 1.0000e-04\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.5548 - val_loss: -0.6399 - learning_rate: 1.0000e-04\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.5669 - val_loss: -0.6408 - learning_rate: 1.0000e-04\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5340 - val_loss: -0.6465 - learning_rate: 1.0000e-04\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.5571 - val_loss: -0.6488 - learning_rate: 1.0000e-04\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5851 - val_loss: -0.6416 - learning_rate: 1.0000e-04\n",
      "Epoch 86/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5712 - val_loss: -0.6483 - learning_rate: 1.0000e-04\n",
      "Epoch 87/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5388 - val_loss: -0.6506 - learning_rate: 1.0000e-04\n",
      "Epoch 88/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5424 - val_loss: -0.6565 - learning_rate: 1.0000e-04\n",
      "Epoch 89/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.5788 - val_loss: -0.6683 - learning_rate: 1.0000e-04\n",
      "Epoch 90/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.5938 - val_loss: -0.6670 - learning_rate: 1.0000e-04\n",
      "Epoch 91/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5548 - val_loss: -0.6693 - learning_rate: 1.0000e-04\n",
      "Epoch 92/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.6331 - val_loss: -0.6823 - learning_rate: 1.0000e-04\n",
      "Epoch 93/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5444 - val_loss: -0.6808 - learning_rate: 1.0000e-04\n",
      "Epoch 94/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5576 - val_loss: -0.6889 - learning_rate: 1.0000e-04\n",
      "Epoch 95/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5826 - val_loss: -0.6847 - learning_rate: 1.0000e-04\n",
      "Epoch 96/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6168 - val_loss: -0.6962 - learning_rate: 1.0000e-04\n",
      "Epoch 97/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5990 - val_loss: -0.6943 - learning_rate: 1.0000e-04\n",
      "Epoch 98/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.5533 - val_loss: -0.7034 - learning_rate: 1.0000e-04\n",
      "Epoch 99/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6236 - val_loss: -0.7058 - learning_rate: 1.0000e-04\n",
      "Epoch 100/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.6118 - val_loss: -0.6946 - learning_rate: 1.0000e-04\n",
      "Epoch 101/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5834 - val_loss: -0.6916 - learning_rate: 1.0000e-04\n",
      "Epoch 102/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.5972 - val_loss: -0.7254 - learning_rate: 1.0000e-04\n",
      "Epoch 103/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.6003 - val_loss: -0.7271 - learning_rate: 1.0000e-04\n",
      "Epoch 104/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6265 - val_loss: -0.7159 - learning_rate: 1.0000e-04\n",
      "Epoch 105/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6346 - val_loss: -0.7203 - learning_rate: 1.0000e-04\n",
      "Epoch 106/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6224 - val_loss: -0.7397 - learning_rate: 1.0000e-04\n",
      "Epoch 107/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.6303 - val_loss: -0.7386 - learning_rate: 1.0000e-04\n",
      "Epoch 108/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6532 - val_loss: -0.7423 - learning_rate: 1.0000e-04\n",
      "Epoch 109/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5937 - val_loss: -0.7527 - learning_rate: 1.0000e-04\n",
      "Epoch 110/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7003 - val_loss: -0.7461 - learning_rate: 1.0000e-04\n",
      "Epoch 111/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.6565 - val_loss: -0.7569 - learning_rate: 1.0000e-04\n",
      "Epoch 112/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.6823 - val_loss: -0.7376 - learning_rate: 1.0000e-04\n",
      "Epoch 113/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.6352 - val_loss: -0.7730 - learning_rate: 1.0000e-04\n",
      "Epoch 114/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.7045 - val_loss: -0.7660 - learning_rate: 1.0000e-04\n",
      "Epoch 115/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7328 - val_loss: -0.7560 - learning_rate: 1.0000e-04\n",
      "Epoch 116/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6356 - val_loss: -0.7614 - learning_rate: 1.0000e-04\n",
      "Epoch 117/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.6788 - val_loss: -0.7754 - learning_rate: 1.0000e-04\n",
      "Epoch 118/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6437 - val_loss: -0.7945 - learning_rate: 1.0000e-04\n",
      "Epoch 119/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.6929 - val_loss: -0.7952 - learning_rate: 1.0000e-04\n",
      "Epoch 120/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.6303 - val_loss: -0.7688 - learning_rate: 1.0000e-04\n",
      "Epoch 121/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.6725 - val_loss: -0.7813 - learning_rate: 1.0000e-04\n",
      "Epoch 122/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.6768 - val_loss: -0.8133 - learning_rate: 1.0000e-04\n",
      "Epoch 123/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.7056 - val_loss: -0.7801 - learning_rate: 1.0000e-04\n",
      "Epoch 124/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.7643 - val_loss: -0.7918 - learning_rate: 1.0000e-04\n",
      "Epoch 125/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.7193 - val_loss: -0.7787 - learning_rate: 1.0000e-04\n",
      "Epoch 126/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.7494 - val_loss: -0.7869 - learning_rate: 1.0000e-04\n",
      "Epoch 127/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6946 - val_loss: -0.8212 - learning_rate: 1.0000e-04\n",
      "Epoch 128/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.7198 - val_loss: -0.8310 - learning_rate: 1.0000e-04\n",
      "Epoch 129/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7241 - val_loss: -0.8077 - learning_rate: 1.0000e-04\n",
      "Epoch 130/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.7911 - val_loss: -0.8416 - learning_rate: 1.0000e-04\n",
      "Epoch 131/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7312 - val_loss: -0.8410 - learning_rate: 1.0000e-04\n",
      "Epoch 132/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7380 - val_loss: -0.8404 - learning_rate: 1.0000e-04\n",
      "Epoch 133/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7359 - val_loss: -0.8143 - learning_rate: 1.0000e-04\n",
      "Epoch 134/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.6008 - val_loss: -0.8207 - learning_rate: 1.0000e-04\n",
      "Epoch 135/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6892 - val_loss: -0.8278 - learning_rate: 1.0000e-04\n",
      "Epoch 136/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7086 - val_loss: -0.8310 - learning_rate: 5.0000e-05\n",
      "Epoch 137/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.7132 - val_loss: -0.8275 - learning_rate: 5.0000e-05\n",
      "Epoch 138/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7007 - val_loss: -0.8554 - learning_rate: 5.0000e-05\n",
      "Epoch 139/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7007 - val_loss: -0.8332 - learning_rate: 5.0000e-05\n",
      "Epoch 140/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.7053 - val_loss: -0.8464 - learning_rate: 5.0000e-05\n",
      "Epoch 141/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7360 - val_loss: -0.8309 - learning_rate: 5.0000e-05\n",
      "Epoch 142/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7297 - val_loss: -0.8344 - learning_rate: 5.0000e-05\n",
      "Epoch 143/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.7916 - val_loss: -0.8238 - learning_rate: 5.0000e-05\n",
      "Epoch 144/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7344 - val_loss: -0.8389 - learning_rate: 2.5000e-05\n",
      "Epoch 145/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.6482 - val_loss: -0.8390 - learning_rate: 2.5000e-05\n",
      "Epoch 146/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7203 - val_loss: -0.8396 - learning_rate: 2.5000e-05\n",
      "Epoch 147/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6553 - val_loss: -0.8408 - learning_rate: 2.5000e-05\n",
      "Epoch 148/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6992 - val_loss: -0.8438 - learning_rate: 2.5000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.6400 - val_loss: 0.0329 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.3830 - val_loss: 0.0116 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.2656 - val_loss: 0.0151 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.2040 - val_loss: 0.0125 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1580 - val_loss: 0.0128 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.1196 - val_loss: 0.0113 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0897 - val_loss: 0.0120 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0863 - val_loss: 0.0145 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0741 - val_loss: 0.0095 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0798 - val_loss: 0.0116 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0743 - val_loss: 0.0112 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0507 - val_loss: 0.0077 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0542 - val_loss: 0.0075 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0439 - val_loss: 0.0063 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0492 - val_loss: 0.0085 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0327 - val_loss: 0.0134 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0512 - val_loss: 0.0095 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0545 - val_loss: 0.0067 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0390 - val_loss: 0.0037 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0401 - val_loss: 0.0069 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0228 - val_loss: 0.0046 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0278 - val_loss: 0.0070 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0346 - val_loss: 0.0061 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0182 - val_loss: 0.0060 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0338 - val_loss: 0.0040 - learning_rate: 5.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0273 - val_loss: 0.0055 - learning_rate: 5.0000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0237 - val_loss: 0.0033 - learning_rate: 5.0000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0147 - val_loss: 0.0032 - learning_rate: 5.0000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0200 - val_loss: 0.0047 - learning_rate: 5.0000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0175 - val_loss: 0.0061 - learning_rate: 5.0000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0134 - val_loss: 0.0028 - learning_rate: 5.0000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0175 - val_loss: 0.0038 - learning_rate: 5.0000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0174 - val_loss: 0.0036 - learning_rate: 5.0000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0119 - val_loss: 0.0044 - learning_rate: 5.0000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0208 - val_loss: 0.0034 - learning_rate: 5.0000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0200 - val_loss: 0.0030 - learning_rate: 5.0000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0202 - val_loss: 0.0035 - learning_rate: 2.5000e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0125 - val_loss: 0.0034 - learning_rate: 2.5000e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0161 - val_loss: 0.0036 - learning_rate: 2.5000e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0143 - val_loss: 0.0039 - learning_rate: 2.5000e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0129 - val_loss: 0.0061 - learning_rate: 2.5000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.7373 - val_loss: 0.0590 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.3275 - val_loss: -0.0737 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0976 - val_loss: -0.1450 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0253 - val_loss: -0.1954 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.0289 - val_loss: -0.2303 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.0828 - val_loss: -0.2545 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.1270 - val_loss: -0.2763 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.1252 - val_loss: -0.2998 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.1232 - val_loss: -0.3193 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.1776 - val_loss: -0.3346 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.1661 - val_loss: -0.3452 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.2009 - val_loss: -0.3595 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.2395 - val_loss: -0.3630 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.2175 - val_loss: -0.3773 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.2273 - val_loss: -0.3920 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.2724 - val_loss: -0.3929 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.2758 - val_loss: -0.4126 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.2466 - val_loss: -0.4189 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.2673 - val_loss: -0.4269 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.2438 - val_loss: -0.4330 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.2995 - val_loss: -0.4420 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.2917 - val_loss: -0.4443 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.3127 - val_loss: -0.4551 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.2821 - val_loss: -0.4654 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.3171 - val_loss: -0.4713 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.3170 - val_loss: -0.4765 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.3251 - val_loss: -0.4864 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.3039 - val_loss: -0.4921 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.3513 - val_loss: -0.4989 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.3616 - val_loss: -0.5055 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.3449 - val_loss: -0.5115 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.4108 - val_loss: -0.5089 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.3304 - val_loss: -0.5222 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.3610 - val_loss: -0.5216 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.3989 - val_loss: -0.5252 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.3680 - val_loss: -0.5290 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.3897 - val_loss: -0.5428 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.3995 - val_loss: -0.5452 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.4586 - val_loss: -0.5527 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.3915 - val_loss: -0.5540 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.3838 - val_loss: -0.5531 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.4226 - val_loss: -0.5652 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.4244 - val_loss: -0.5659 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.4392 - val_loss: -0.5644 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.4612 - val_loss: -0.5729 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.4066 - val_loss: -0.5749 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.4187 - val_loss: -0.5792 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.4304 - val_loss: -0.5840 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.4553 - val_loss: -0.5785 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.4608 - val_loss: -0.5876 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.4162 - val_loss: -0.5924 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.4587 - val_loss: -0.5971 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.4699 - val_loss: -0.5999 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.4384 - val_loss: -0.6061 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.4752 - val_loss: -0.6026 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.4533 - val_loss: -0.6143 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.4529 - val_loss: -0.6205 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.4664 - val_loss: -0.6211 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.4537 - val_loss: -0.6287 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.4848 - val_loss: -0.6334 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5118 - val_loss: -0.6332 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.5282 - val_loss: -0.6394 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5118 - val_loss: -0.6428 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.4767 - val_loss: -0.6496 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5139 - val_loss: -0.6476 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.4613 - val_loss: -0.6503 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5130 - val_loss: -0.6542 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5316 - val_loss: -0.6572 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5611 - val_loss: -0.6599 - learning_rate: 1.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5120 - val_loss: -0.6671 - learning_rate: 1.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5442 - val_loss: -0.6755 - learning_rate: 1.0000e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5214 - val_loss: -0.6775 - learning_rate: 1.0000e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5720 - val_loss: -0.6789 - learning_rate: 1.0000e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5441 - val_loss: -0.6834 - learning_rate: 1.0000e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5811 - val_loss: -0.6885 - learning_rate: 1.0000e-04\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5649 - val_loss: -0.6915 - learning_rate: 1.0000e-04\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5866 - val_loss: -0.6916 - learning_rate: 1.0000e-04\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5654 - val_loss: -0.6990 - learning_rate: 1.0000e-04\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.5749 - val_loss: -0.7038 - learning_rate: 1.0000e-04\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6106 - val_loss: -0.7038 - learning_rate: 1.0000e-04\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.6171 - val_loss: -0.7107 - learning_rate: 1.0000e-04\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5826 - val_loss: -0.7111 - learning_rate: 1.0000e-04\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5810 - val_loss: -0.7242 - learning_rate: 1.0000e-04\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.5682 - val_loss: -0.7252 - learning_rate: 1.0000e-04\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5738 - val_loss: -0.7293 - learning_rate: 1.0000e-04\n",
      "Epoch 86/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5888 - val_loss: -0.7334 - learning_rate: 1.0000e-04\n",
      "Epoch 87/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6049 - val_loss: -0.7362 - learning_rate: 1.0000e-04\n",
      "Epoch 88/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5646 - val_loss: -0.7370 - learning_rate: 1.0000e-04\n",
      "Epoch 89/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6205 - val_loss: -0.7399 - learning_rate: 1.0000e-04\n",
      "Epoch 90/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6144 - val_loss: -0.7452 - learning_rate: 1.0000e-04\n",
      "Epoch 91/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6050 - val_loss: -0.7521 - learning_rate: 1.0000e-04\n",
      "Epoch 92/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.6685 - val_loss: -0.7498 - learning_rate: 1.0000e-04\n",
      "Epoch 93/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.6051 - val_loss: -0.7549 - learning_rate: 1.0000e-04\n",
      "Epoch 94/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6579 - val_loss: -0.7622 - learning_rate: 1.0000e-04\n",
      "Epoch 95/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.6383 - val_loss: -0.7601 - learning_rate: 1.0000e-04\n",
      "Epoch 96/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6351 - val_loss: -0.7645 - learning_rate: 1.0000e-04\n",
      "Epoch 97/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6531 - val_loss: -0.7737 - learning_rate: 1.0000e-04\n",
      "Epoch 98/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6172 - val_loss: -0.7747 - learning_rate: 1.0000e-04\n",
      "Epoch 99/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6465 - val_loss: -0.7701 - learning_rate: 1.0000e-04\n",
      "Epoch 100/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6347 - val_loss: -0.7845 - learning_rate: 1.0000e-04\n",
      "Epoch 101/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6735 - val_loss: -0.7747 - learning_rate: 1.0000e-04\n",
      "Epoch 102/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6116 - val_loss: -0.7865 - learning_rate: 1.0000e-04\n",
      "Epoch 103/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6173 - val_loss: -0.7925 - learning_rate: 1.0000e-04\n",
      "Epoch 104/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6476 - val_loss: -0.7923 - learning_rate: 1.0000e-04\n",
      "Epoch 105/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6638 - val_loss: -0.7965 - learning_rate: 1.0000e-04\n",
      "Epoch 106/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6582 - val_loss: -0.8043 - learning_rate: 1.0000e-04\n",
      "Epoch 107/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7242 - val_loss: -0.7929 - learning_rate: 1.0000e-04\n",
      "Epoch 108/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5778 - val_loss: -0.8088 - learning_rate: 1.0000e-04\n",
      "Epoch 109/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6624 - val_loss: -0.8183 - learning_rate: 1.0000e-04\n",
      "Epoch 110/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6769 - val_loss: -0.8145 - learning_rate: 1.0000e-04\n",
      "Epoch 111/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6633 - val_loss: -0.8288 - learning_rate: 1.0000e-04\n",
      "Epoch 112/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6957 - val_loss: -0.8306 - learning_rate: 1.0000e-04\n",
      "Epoch 113/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6957 - val_loss: -0.8438 - learning_rate: 1.0000e-04\n",
      "Epoch 114/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6950 - val_loss: -0.8391 - learning_rate: 1.0000e-04\n",
      "Epoch 115/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6182 - val_loss: -0.8402 - learning_rate: 1.0000e-04\n",
      "Epoch 116/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7133 - val_loss: -0.8454 - learning_rate: 1.0000e-04\n",
      "Epoch 117/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6787 - val_loss: -0.8555 - learning_rate: 1.0000e-04\n",
      "Epoch 118/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7138 - val_loss: -0.8534 - learning_rate: 1.0000e-04\n",
      "Epoch 119/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7153 - val_loss: -0.8419 - learning_rate: 1.0000e-04\n",
      "Epoch 120/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7026 - val_loss: -0.8632 - learning_rate: 1.0000e-04\n",
      "Epoch 121/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6999 - val_loss: -0.8597 - learning_rate: 1.0000e-04\n",
      "Epoch 122/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7346 - val_loss: -0.8553 - learning_rate: 1.0000e-04\n",
      "Epoch 123/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.7070 - val_loss: -0.8626 - learning_rate: 1.0000e-04\n",
      "Epoch 124/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7340 - val_loss: -0.8667 - learning_rate: 1.0000e-04\n",
      "Epoch 125/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7137 - val_loss: -0.8672 - learning_rate: 1.0000e-04\n",
      "Epoch 126/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7119 - val_loss: -0.8778 - learning_rate: 1.0000e-04\n",
      "Epoch 127/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7141 - val_loss: -0.8802 - learning_rate: 1.0000e-04\n",
      "Epoch 128/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7066 - val_loss: -0.8790 - learning_rate: 1.0000e-04\n",
      "Epoch 129/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7703 - val_loss: -0.8715 - learning_rate: 1.0000e-04\n",
      "Epoch 130/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7597 - val_loss: -0.8777 - learning_rate: 1.0000e-04\n",
      "Epoch 131/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.7013 - val_loss: -0.8743 - learning_rate: 1.0000e-04\n",
      "Epoch 132/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7375 - val_loss: -0.8931 - learning_rate: 1.0000e-04\n",
      "Epoch 133/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7214 - val_loss: -0.8862 - learning_rate: 1.0000e-04\n",
      "Epoch 134/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7052 - val_loss: -0.8987 - learning_rate: 1.0000e-04\n",
      "Epoch 135/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7143 - val_loss: -0.8931 - learning_rate: 1.0000e-04\n",
      "Epoch 136/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7129 - val_loss: -0.8950 - learning_rate: 1.0000e-04\n",
      "Epoch 137/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7495 - val_loss: -0.8896 - learning_rate: 1.0000e-04\n",
      "Epoch 138/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7638 - val_loss: -0.9019 - learning_rate: 1.0000e-04\n",
      "Epoch 139/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7658 - val_loss: -0.8984 - learning_rate: 1.0000e-04\n",
      "Epoch 140/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.7367 - val_loss: -0.9064 - learning_rate: 1.0000e-04\n",
      "Epoch 141/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.7969 - val_loss: -0.9127 - learning_rate: 1.0000e-04\n",
      "Epoch 142/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7388 - val_loss: -0.9084 - learning_rate: 1.0000e-04\n",
      "Epoch 143/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.8371 - val_loss: -0.9140 - learning_rate: 1.0000e-04\n",
      "Epoch 144/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7648 - val_loss: -0.9286 - learning_rate: 1.0000e-04\n",
      "Epoch 145/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7470 - val_loss: -0.9359 - learning_rate: 1.0000e-04\n",
      "Epoch 146/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.7805 - val_loss: -0.9306 - learning_rate: 1.0000e-04\n",
      "Epoch 147/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.8325 - val_loss: -0.9191 - learning_rate: 1.0000e-04\n",
      "Epoch 148/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.7672 - val_loss: -0.9354 - learning_rate: 1.0000e-04\n",
      "Epoch 149/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.8129 - val_loss: -0.9313 - learning_rate: 1.0000e-04\n",
      "Epoch 150/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.8393 - val_loss: -0.9321 - learning_rate: 1.0000e-04\n",
      "Epoch 151/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.7970 - val_loss: -0.9315 - learning_rate: 5.0000e-05\n",
      "Epoch 152/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7985 - val_loss: -0.9367 - learning_rate: 5.0000e-05\n",
      "Epoch 153/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.8401 - val_loss: -0.9313 - learning_rate: 5.0000e-05\n",
      "Epoch 154/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.8422 - val_loss: -0.9276 - learning_rate: 5.0000e-05\n",
      "Epoch 155/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7952 - val_loss: -0.9398 - learning_rate: 5.0000e-05\n",
      "Epoch 156/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.7820 - val_loss: -0.9309 - learning_rate: 5.0000e-05\n",
      "Epoch 157/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.8066 - val_loss: -0.9396 - learning_rate: 5.0000e-05\n",
      "Epoch 158/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.8240 - val_loss: -0.9470 - learning_rate: 5.0000e-05\n",
      "Epoch 159/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7988 - val_loss: -0.9388 - learning_rate: 5.0000e-05\n",
      "Epoch 160/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7840 - val_loss: -0.9369 - learning_rate: 5.0000e-05\n",
      "Epoch 161/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7888 - val_loss: -0.9399 - learning_rate: 5.0000e-05\n",
      "Epoch 162/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7854 - val_loss: -0.9528 - learning_rate: 5.0000e-05\n",
      "Epoch 163/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.8275 - val_loss: -0.9397 - learning_rate: 5.0000e-05\n",
      "Epoch 164/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.8196 - val_loss: -0.9456 - learning_rate: 5.0000e-05\n",
      "Epoch 165/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7589 - val_loss: -0.9557 - learning_rate: 5.0000e-05\n",
      "Epoch 166/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7988 - val_loss: -0.9585 - learning_rate: 5.0000e-05\n",
      "Epoch 167/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7661 - val_loss: -0.9530 - learning_rate: 5.0000e-05\n",
      "Epoch 168/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.8224 - val_loss: -0.9426 - learning_rate: 5.0000e-05\n",
      "Epoch 169/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7856 - val_loss: -0.9456 - learning_rate: 5.0000e-05\n",
      "Epoch 170/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6987 - val_loss: -0.9500 - learning_rate: 5.0000e-05\n",
      "Epoch 171/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.8401 - val_loss: -0.9503 - learning_rate: 5.0000e-05\n",
      "Epoch 172/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7195 - val_loss: -0.9496 - learning_rate: 2.5000e-05\n",
      "Epoch 173/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.8358 - val_loss: -0.9553 - learning_rate: 2.5000e-05\n",
      "Epoch 174/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.9464 - val_loss: -0.9598 - learning_rate: 2.5000e-05\n",
      "Epoch 175/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.8393 - val_loss: -0.9541 - learning_rate: 2.5000e-05\n",
      "Epoch 176/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.9032 - val_loss: -0.9535 - learning_rate: 2.5000e-05\n",
      "Epoch 177/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.8469 - val_loss: -0.9618 - learning_rate: 2.5000e-05\n",
      "Epoch 178/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7954 - val_loss: -0.9579 - learning_rate: 2.5000e-05\n",
      "Epoch 179/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7926 - val_loss: -0.9581 - learning_rate: 2.5000e-05\n",
      "Epoch 180/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.7088 - val_loss: -0.9620 - learning_rate: 2.5000e-05\n",
      "Epoch 181/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.8475 - val_loss: -0.9596 - learning_rate: 2.5000e-05\n",
      "Epoch 182/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.8401 - val_loss: -0.9599 - learning_rate: 2.5000e-05\n",
      "Epoch 183/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.9238 - val_loss: -0.9557 - learning_rate: 2.5000e-05\n",
      "Epoch 184/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.8777 - val_loss: -0.9659 - learning_rate: 2.5000e-05\n",
      "Epoch 185/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.8238 - val_loss: -0.9596 - learning_rate: 2.5000e-05\n",
      "Epoch 186/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.8469 - val_loss: -0.9663 - learning_rate: 2.5000e-05\n",
      "Epoch 187/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.8015 - val_loss: -0.9663 - learning_rate: 2.5000e-05\n",
      "Epoch 188/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.9021 - val_loss: -0.9581 - learning_rate: 2.5000e-05\n",
      "Epoch 189/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.8232 - val_loss: -0.9651 - learning_rate: 2.5000e-05\n",
      "Epoch 190/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.8397 - val_loss: -0.9598 - learning_rate: 2.5000e-05\n",
      "Epoch 191/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.7916 - val_loss: -0.9680 - learning_rate: 2.5000e-05\n",
      "Epoch 192/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.8118 - val_loss: -0.9675 - learning_rate: 2.5000e-05\n",
      "Epoch 193/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.8879 - val_loss: -0.9761 - learning_rate: 2.5000e-05\n",
      "Epoch 194/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.8641 - val_loss: -0.9710 - learning_rate: 2.5000e-05\n",
      "Epoch 195/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.7818 - val_loss: -0.9718 - learning_rate: 2.5000e-05\n",
      "Epoch 196/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.8145 - val_loss: -0.9661 - learning_rate: 2.5000e-05\n",
      "Epoch 197/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7875 - val_loss: -0.9697 - learning_rate: 2.5000e-05\n",
      "Epoch 198/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.8716 - val_loss: -0.9628 - learning_rate: 2.5000e-05\n",
      "Epoch 199/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.8497 - val_loss: -0.9704 - learning_rate: 1.2500e-05\n",
      "Epoch 200/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.8355 - val_loss: -0.9698 - learning_rate: 1.2500e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.6396 - val_loss: 0.0210 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.4536 - val_loss: 0.0221 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.2213 - val_loss: 0.0108 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.2107 - val_loss: 0.0156 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.1499 - val_loss: 0.0223 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.1372 - val_loss: 0.0145 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.1033 - val_loss: 0.0127 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0893 - val_loss: 0.0136 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0841 - val_loss: 0.0105 - learning_rate: 5.0000e-05\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0637 - val_loss: 0.0114 - learning_rate: 5.0000e-05\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0610 - val_loss: 0.0096 - learning_rate: 5.0000e-05\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0565 - val_loss: 0.0088 - learning_rate: 5.0000e-05\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0623 - val_loss: 0.0098 - learning_rate: 5.0000e-05\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0476 - val_loss: 0.0084 - learning_rate: 5.0000e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0525 - val_loss: 0.0111 - learning_rate: 5.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0489 - val_loss: 0.0087 - learning_rate: 5.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0483 - val_loss: 0.0086 - learning_rate: 5.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0603 - val_loss: 0.0085 - learning_rate: 5.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0508 - val_loss: 0.0081 - learning_rate: 5.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0541 - val_loss: 0.0083 - learning_rate: 5.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0479 - val_loss: 0.0080 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0238 - val_loss: 0.0080 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0409 - val_loss: 0.0067 - learning_rate: 5.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0338 - val_loss: 0.0077 - learning_rate: 5.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0261 - val_loss: 0.0073 - learning_rate: 5.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0352 - val_loss: 0.0075 - learning_rate: 5.0000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0358 - val_loss: 0.0084 - learning_rate: 5.0000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0413 - val_loss: 0.0073 - learning_rate: 5.0000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0338 - val_loss: 0.0071 - learning_rate: 2.5000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0353 - val_loss: 0.0072 - learning_rate: 2.5000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0327 - val_loss: 0.0065 - learning_rate: 2.5000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0291 - val_loss: 0.0063 - learning_rate: 2.5000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0260 - val_loss: 0.0064 - learning_rate: 2.5000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0299 - val_loss: 0.0067 - learning_rate: 2.5000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0224 - val_loss: 0.0064 - learning_rate: 2.5000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0293 - val_loss: 0.0066 - learning_rate: 2.5000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0243 - val_loss: 0.0065 - learning_rate: 2.5000e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0349 - val_loss: 0.0066 - learning_rate: 1.2500e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0320 - val_loss: 0.0067 - learning_rate: 1.2500e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0233 - val_loss: 0.0063 - learning_rate: 1.2500e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0303 - val_loss: 0.0059 - learning_rate: 1.2500e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0321 - val_loss: 0.0057 - learning_rate: 1.2500e-05\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0184 - val_loss: 0.0061 - learning_rate: 1.2500e-05\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0247 - val_loss: 0.0062 - learning_rate: 1.2500e-05\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0269 - val_loss: 0.0062 - learning_rate: 1.2500e-05\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0369 - val_loss: 0.0059 - learning_rate: 1.2500e-05\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0267 - val_loss: 0.0063 - learning_rate: 1.2500e-05\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0304 - val_loss: 0.0062 - learning_rate: 6.2500e-06\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0252 - val_loss: 0.0064 - learning_rate: 6.2500e-06\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0242 - val_loss: 0.0064 - learning_rate: 6.2500e-06\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0313 - val_loss: 0.0061 - learning_rate: 6.2500e-06\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0277 - val_loss: 0.0060 - learning_rate: 6.2500e-06\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - loss: 0.8306 - val_loss: -0.0440 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.3217 - val_loss: -0.1383 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1550 - val_loss: -0.1969 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0575 - val_loss: -0.2447 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0037 - val_loss: -0.2737 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.0656 - val_loss: -0.2831 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.0599 - val_loss: -0.3181 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.1393 - val_loss: -0.3300 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.1032 - val_loss: -0.3488 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.1550 - val_loss: -0.3649 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.1471 - val_loss: -0.3594 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2088 - val_loss: -0.3861 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.1709 - val_loss: -0.3883 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2068 - val_loss: -0.3994 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.2115 - val_loss: -0.4087 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2057 - val_loss: -0.4190 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2422 - val_loss: -0.4222 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2148 - val_loss: -0.4291 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2602 - val_loss: -0.4378 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2399 - val_loss: -0.4419 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2781 - val_loss: -0.4473 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2646 - val_loss: -0.4527 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2765 - val_loss: -0.4630 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2848 - val_loss: -0.4644 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.2730 - val_loss: -0.4613 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3047 - val_loss: -0.4724 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2988 - val_loss: -0.4747 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2749 - val_loss: -0.4800 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3282 - val_loss: -0.4910 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3403 - val_loss: -0.4947 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3606 - val_loss: -0.4802 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3271 - val_loss: -0.5041 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3764 - val_loss: -0.4995 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.3796 - val_loss: -0.5023 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3299 - val_loss: -0.5107 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3339 - val_loss: -0.5083 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3499 - val_loss: -0.5170 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3729 - val_loss: -0.5237 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3720 - val_loss: -0.5309 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3891 - val_loss: -0.5294 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3901 - val_loss: -0.5384 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3835 - val_loss: -0.5317 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3552 - val_loss: -0.5411 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3928 - val_loss: -0.5433 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3748 - val_loss: -0.5431 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4110 - val_loss: -0.5445 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4089 - val_loss: -0.5573 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4204 - val_loss: -0.5640 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4328 - val_loss: -0.5503 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4349 - val_loss: -0.5618 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4650 - val_loss: -0.5512 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4157 - val_loss: -0.5723 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4522 - val_loss: -0.5766 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4604 - val_loss: -0.5681 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4603 - val_loss: -0.5801 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4626 - val_loss: -0.5813 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4654 - val_loss: -0.5889 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4454 - val_loss: -0.5925 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4380 - val_loss: -0.6006 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4511 - val_loss: -0.5950 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4625 - val_loss: -0.6001 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4451 - val_loss: -0.6009 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4569 - val_loss: -0.6129 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5125 - val_loss: -0.6067 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4985 - val_loss: -0.6078 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4915 - val_loss: -0.6090 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4742 - val_loss: -0.6066 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5297 - val_loss: -0.6212 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4882 - val_loss: -0.6283 - learning_rate: 1.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4742 - val_loss: -0.6320 - learning_rate: 1.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4775 - val_loss: -0.6394 - learning_rate: 1.0000e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5041 - val_loss: -0.6382 - learning_rate: 1.0000e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5152 - val_loss: -0.6310 - learning_rate: 1.0000e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4971 - val_loss: -0.6388 - learning_rate: 1.0000e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5371 - val_loss: -0.6303 - learning_rate: 1.0000e-04\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5019 - val_loss: -0.6455 - learning_rate: 1.0000e-04\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5142 - val_loss: -0.6571 - learning_rate: 1.0000e-04\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5466 - val_loss: -0.6371 - learning_rate: 1.0000e-04\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5162 - val_loss: -0.6422 - learning_rate: 1.0000e-04\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5351 - val_loss: -0.6570 - learning_rate: 1.0000e-04\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5492 - val_loss: -0.6584 - learning_rate: 1.0000e-04\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5083 - val_loss: -0.6629 - learning_rate: 1.0000e-04\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5302 - val_loss: -0.6755 - learning_rate: 1.0000e-04\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5819 - val_loss: -0.6670 - learning_rate: 1.0000e-04\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5170 - val_loss: -0.6732 - learning_rate: 1.0000e-04\n",
      "Epoch 86/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5605 - val_loss: -0.6755 - learning_rate: 1.0000e-04\n",
      "Epoch 87/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5790 - val_loss: -0.6708 - learning_rate: 1.0000e-04\n",
      "Epoch 88/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5663 - val_loss: -0.6736 - learning_rate: 1.0000e-04\n",
      "Epoch 89/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5582 - val_loss: -0.6860 - learning_rate: 5.0000e-05\n",
      "Epoch 90/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5760 - val_loss: -0.6809 - learning_rate: 5.0000e-05\n",
      "Epoch 91/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5240 - val_loss: -0.6901 - learning_rate: 5.0000e-05\n",
      "Epoch 92/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5678 - val_loss: -0.6880 - learning_rate: 5.0000e-05\n",
      "Epoch 93/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5702 - val_loss: -0.6820 - learning_rate: 5.0000e-05\n",
      "Epoch 94/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5940 - val_loss: -0.6930 - learning_rate: 5.0000e-05\n",
      "Epoch 95/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5571 - val_loss: -0.6937 - learning_rate: 5.0000e-05\n",
      "Epoch 96/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5957 - val_loss: -0.6879 - learning_rate: 5.0000e-05\n",
      "Epoch 97/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5567 - val_loss: -0.6929 - learning_rate: 5.0000e-05\n",
      "Epoch 98/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6285 - val_loss: -0.7064 - learning_rate: 5.0000e-05\n",
      "Epoch 99/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5934 - val_loss: -0.6962 - learning_rate: 5.0000e-05\n",
      "Epoch 100/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5915 - val_loss: -0.7057 - learning_rate: 5.0000e-05\n",
      "Epoch 101/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6078 - val_loss: -0.6917 - learning_rate: 5.0000e-05\n",
      "Epoch 102/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5821 - val_loss: -0.7030 - learning_rate: 5.0000e-05\n",
      "Epoch 103/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5972 - val_loss: -0.7007 - learning_rate: 5.0000e-05\n",
      "Epoch 104/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5770 - val_loss: -0.7031 - learning_rate: 2.5000e-05\n",
      "Epoch 105/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5699 - val_loss: -0.7073 - learning_rate: 2.5000e-05\n",
      "Epoch 106/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6108 - val_loss: -0.7070 - learning_rate: 2.5000e-05\n",
      "Epoch 107/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6187 - val_loss: -0.7119 - learning_rate: 2.5000e-05\n",
      "Epoch 108/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6201 - val_loss: -0.7111 - learning_rate: 2.5000e-05\n",
      "Epoch 109/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5780 - val_loss: -0.7066 - learning_rate: 2.5000e-05\n",
      "Epoch 110/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5993 - val_loss: -0.7027 - learning_rate: 2.5000e-05\n",
      "Epoch 111/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5760 - val_loss: -0.7118 - learning_rate: 2.5000e-05\n",
      "Epoch 112/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6161 - val_loss: -0.7106 - learning_rate: 2.5000e-05\n",
      "Epoch 113/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6069 - val_loss: -0.7107 - learning_rate: 1.2500e-05\n",
      "Epoch 114/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6059 - val_loss: -0.7156 - learning_rate: 1.2500e-05\n",
      "Epoch 115/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6195 - val_loss: -0.7077 - learning_rate: 1.2500e-05\n",
      "Epoch 116/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6299 - val_loss: -0.7050 - learning_rate: 1.2500e-05\n",
      "Epoch 117/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6173 - val_loss: -0.7162 - learning_rate: 1.2500e-05\n",
      "Epoch 118/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.6125 - val_loss: -0.7101 - learning_rate: 1.2500e-05\n",
      "Epoch 119/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6550 - val_loss: -0.7141 - learning_rate: 1.2500e-05\n",
      "Epoch 120/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6026 - val_loss: -0.7152 - learning_rate: 1.2500e-05\n",
      "Epoch 121/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5757 - val_loss: -0.7186 - learning_rate: 1.2500e-05\n",
      "Epoch 122/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5998 - val_loss: -0.7186 - learning_rate: 1.2500e-05\n",
      "Epoch 123/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5550 - val_loss: -0.7165 - learning_rate: 1.2500e-05\n",
      "Epoch 124/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6036 - val_loss: -0.7182 - learning_rate: 1.2500e-05\n",
      "Epoch 125/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6072 - val_loss: -0.7171 - learning_rate: 1.2500e-05\n",
      "Epoch 126/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6391 - val_loss: -0.7159 - learning_rate: 1.2500e-05\n",
      "Epoch 127/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5918 - val_loss: -0.7191 - learning_rate: 6.2500e-06\n",
      "Epoch 128/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6063 - val_loss: -0.7220 - learning_rate: 6.2500e-06\n",
      "Epoch 129/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5862 - val_loss: -0.7157 - learning_rate: 6.2500e-06\n",
      "Epoch 130/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6134 - val_loss: -0.7161 - learning_rate: 6.2500e-06\n",
      "Epoch 131/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5838 - val_loss: -0.7174 - learning_rate: 6.2500e-06\n",
      "Epoch 132/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6315 - val_loss: -0.7206 - learning_rate: 6.2500e-06\n",
      "Epoch 133/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6456 - val_loss: -0.7183 - learning_rate: 6.2500e-06\n",
      "Epoch 134/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5988 - val_loss: -0.7191 - learning_rate: 3.1250e-06\n",
      "Epoch 135/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5928 - val_loss: -0.7218 - learning_rate: 3.1250e-06\n",
      "Epoch 136/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6191 - val_loss: -0.7194 - learning_rate: 3.1250e-06\n",
      "Epoch 137/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5934 - val_loss: -0.7164 - learning_rate: 3.1250e-06\n",
      "Epoch 138/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6078 - val_loss: -0.7224 - learning_rate: 3.1250e-06\n",
      "Epoch 139/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6090 - val_loss: -0.7183 - learning_rate: 3.1250e-06\n",
      "Epoch 140/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6501 - val_loss: -0.7186 - learning_rate: 3.1250e-06\n",
      "Epoch 141/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6308 - val_loss: -0.7163 - learning_rate: 3.1250e-06\n",
      "Epoch 142/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6202 - val_loss: -0.7173 - learning_rate: 3.1250e-06\n",
      "Epoch 143/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6328 - val_loss: -0.7205 - learning_rate: 3.1250e-06\n",
      "Epoch 144/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5726 - val_loss: -0.7215 - learning_rate: 1.5625e-06\n",
      "Epoch 145/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6536 - val_loss: -0.7207 - learning_rate: 1.5625e-06\n",
      "Epoch 146/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6392 - val_loss: -0.7192 - learning_rate: 1.5625e-06\n",
      "Epoch 147/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6695 - val_loss: -0.7241 - learning_rate: 1.5625e-06\n",
      "Epoch 148/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6182 - val_loss: -0.7196 - learning_rate: 1.5625e-06\n",
      "Epoch 149/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6036 - val_loss: -0.7196 - learning_rate: 1.5625e-06\n",
      "Epoch 150/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6139 - val_loss: -0.7217 - learning_rate: 1.5625e-06\n",
      "Epoch 151/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5777 - val_loss: -0.7223 - learning_rate: 1.5625e-06\n",
      "Epoch 152/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6385 - val_loss: -0.7171 - learning_rate: 1.5625e-06\n",
      "Epoch 153/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6242 - val_loss: -0.7220 - learning_rate: 1.0000e-06\n",
      "Epoch 154/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6045 - val_loss: -0.7165 - learning_rate: 1.0000e-06\n",
      "Epoch 155/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5997 - val_loss: -0.7181 - learning_rate: 1.0000e-06\n",
      "Epoch 156/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6103 - val_loss: -0.7231 - learning_rate: 1.0000e-06\n",
      "Epoch 157/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6171 - val_loss: -0.7138 - learning_rate: 1.0000e-06\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.6973 - val_loss: 0.0505 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.3446 - val_loss: 0.0270 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.2179 - val_loss: 0.0138 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1543 - val_loss: 0.0110 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1666 - val_loss: 0.0098 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1178 - val_loss: 0.0110 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1067 - val_loss: 0.0137 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1062 - val_loss: 0.0084 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0801 - val_loss: 0.0072 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0660 - val_loss: 0.0139 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0710 - val_loss: 0.0066 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0594 - val_loss: 0.0100 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0534 - val_loss: 0.0089 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0405 - val_loss: 0.0098 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0529 - val_loss: 0.0066 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0338 - val_loss: 0.0090 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0319 - val_loss: 0.0079 - learning_rate: 5.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0331 - val_loss: 0.0090 - learning_rate: 5.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0347 - val_loss: 0.0082 - learning_rate: 5.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0228 - val_loss: 0.0070 - learning_rate: 5.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0249 - val_loss: 0.0071 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0180 - val_loss: 0.0072 - learning_rate: 2.5000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0350 - val_loss: 0.0071 - learning_rate: 2.5000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0170 - val_loss: 0.0073 - learning_rate: 2.5000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0341 - val_loss: 0.0073 - learning_rate: 2.5000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.8050 - val_loss: -0.0124 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.2511 - val_loss: -0.1339 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0560 - val_loss: -0.1971 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0186 - val_loss: -0.2351 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.0174 - val_loss: -0.2614 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.0492 - val_loss: -0.2839 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -0.0946 - val_loss: -0.3016 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.1131 - val_loss: -0.3120 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.1323 - val_loss: -0.3275 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.1298 - val_loss: -0.3402 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.1383 - val_loss: -0.3474 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.1498 - val_loss: -0.3554 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2036 - val_loss: -0.3626 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2050 - val_loss: -0.3706 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2186 - val_loss: -0.3777 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2089 - val_loss: -0.3861 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2464 - val_loss: -0.3868 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2415 - val_loss: -0.3983 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.2131 - val_loss: -0.4086 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.2425 - val_loss: -0.4153 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2270 - val_loss: -0.4189 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2432 - val_loss: -0.4222 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2713 - val_loss: -0.4292 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2595 - val_loss: -0.4338 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2723 - val_loss: -0.4384 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2461 - val_loss: -0.4458 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2972 - val_loss: -0.4521 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3018 - val_loss: -0.4587 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3028 - val_loss: -0.4670 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3165 - val_loss: -0.4770 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3377 - val_loss: -0.4800 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3069 - val_loss: -0.4864 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3271 - val_loss: -0.4963 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3391 - val_loss: -0.4924 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3611 - val_loss: -0.5006 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3512 - val_loss: -0.5097 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3966 - val_loss: -0.5060 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3834 - val_loss: -0.5095 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3443 - val_loss: -0.5164 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3926 - val_loss: -0.5269 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3700 - val_loss: -0.5311 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3541 - val_loss: -0.5327 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4083 - val_loss: -0.5352 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3899 - val_loss: -0.5391 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3759 - val_loss: -0.5502 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3848 - val_loss: -0.5536 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3726 - val_loss: -0.5610 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.4212 - val_loss: -0.5662 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4312 - val_loss: -0.5692 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4309 - val_loss: -0.5678 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4364 - val_loss: -0.5753 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4395 - val_loss: -0.5893 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4214 - val_loss: -0.5881 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4565 - val_loss: -0.5942 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4122 - val_loss: -0.6025 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4357 - val_loss: -0.6053 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4679 - val_loss: -0.6153 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4695 - val_loss: -0.6179 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4397 - val_loss: -0.6124 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4613 - val_loss: -0.6155 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4762 - val_loss: -0.6180 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4797 - val_loss: -0.6212 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4893 - val_loss: -0.6274 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4840 - val_loss: -0.6283 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4915 - val_loss: -0.6341 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4689 - val_loss: -0.6250 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4480 - val_loss: -0.6254 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5055 - val_loss: -0.6147 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4888 - val_loss: -0.6232 - learning_rate: 1.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5049 - val_loss: -0.6277 - learning_rate: 1.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5342 - val_loss: -0.6334 - learning_rate: 5.0000e-05\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4834 - val_loss: -0.6384 - learning_rate: 5.0000e-05\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4823 - val_loss: -0.6309 - learning_rate: 5.0000e-05\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5171 - val_loss: -0.6304 - learning_rate: 5.0000e-05\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5102 - val_loss: -0.6372 - learning_rate: 5.0000e-05\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5291 - val_loss: -0.6404 - learning_rate: 5.0000e-05\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5341 - val_loss: -0.6337 - learning_rate: 5.0000e-05\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5325 - val_loss: -0.6284 - learning_rate: 5.0000e-05\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5162 - val_loss: -0.6321 - learning_rate: 5.0000e-05\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5137 - val_loss: -0.6413 - learning_rate: 5.0000e-05\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5315 - val_loss: -0.6431 - learning_rate: 5.0000e-05\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5513 - val_loss: -0.6451 - learning_rate: 5.0000e-05\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5430 - val_loss: -0.6491 - learning_rate: 5.0000e-05\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5304 - val_loss: -0.6488 - learning_rate: 5.0000e-05\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.5675 - val_loss: -0.6606 - learning_rate: 5.0000e-05\n",
      "Epoch 86/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.5700 - val_loss: -0.6473 - learning_rate: 5.0000e-05\n",
      "Epoch 87/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5551 - val_loss: -0.6515 - learning_rate: 5.0000e-05\n",
      "Epoch 88/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5329 - val_loss: -0.6583 - learning_rate: 5.0000e-05\n",
      "Epoch 89/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5216 - val_loss: -0.6556 - learning_rate: 5.0000e-05\n",
      "Epoch 90/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5602 - val_loss: -0.6598 - learning_rate: 5.0000e-05\n",
      "Epoch 91/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5530 - val_loss: -0.6527 - learning_rate: 2.5000e-05\n",
      "Epoch 92/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5334 - val_loss: -0.6526 - learning_rate: 2.5000e-05\n",
      "Epoch 93/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5561 - val_loss: -0.6544 - learning_rate: 2.5000e-05\n",
      "Epoch 94/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5717 - val_loss: -0.6564 - learning_rate: 2.5000e-05\n",
      "Epoch 95/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5135 - val_loss: -0.6574 - learning_rate: 2.5000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.6397 - val_loss: 0.0255 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.3977 - val_loss: 0.0118 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.2008 - val_loss: 0.0086 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.2186 - val_loss: 0.0071 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1456 - val_loss: 0.0109 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1012 - val_loss: 0.0060 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0757 - val_loss: 0.0054 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0898 - val_loss: 0.0057 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0942 - val_loss: 0.0042 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0680 - val_loss: 0.0014 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0682 - val_loss: 0.0011 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0552 - val_loss: -4.6867e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0578 - val_loss: -0.0012 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0421 - val_loss: 0.0043 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0526 - val_loss: -4.5398e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0376 - val_loss: -0.0014 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0409 - val_loss: -0.0017 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0434 - val_loss: 0.0013 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0419 - val_loss: -0.0017 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0236 - val_loss: -0.0025 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0336 - val_loss: -0.0013 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0255 - val_loss: -2.8502e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0181 - val_loss: 1.1663e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0135 - val_loss: 0.0059 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0284 - val_loss: 1.1229e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0310 - val_loss: 0.0025 - learning_rate: 5.0000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0219 - val_loss: 3.6155e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0200 - val_loss: -3.3243e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0301 - val_loss: -9.2332e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0149 - val_loss: -6.9957e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.4876 - val_loss: -0.0813 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1907 - val_loss: -0.1764 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0688 - val_loss: -0.2303 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.0036 - val_loss: -0.2625 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.0690 - val_loss: -0.2836 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.0674 - val_loss: -0.2983 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.1024 - val_loss: -0.3175 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.1178 - val_loss: -0.3311 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.1612 - val_loss: -0.3416 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.1601 - val_loss: -0.3457 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.1990 - val_loss: -0.3563 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.1866 - val_loss: -0.3678 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2148 - val_loss: -0.3739 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2263 - val_loss: -0.3808 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2123 - val_loss: -0.3869 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2218 - val_loss: -0.3977 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2341 - val_loss: -0.3968 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2821 - val_loss: -0.4023 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2494 - val_loss: -0.4067 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2316 - val_loss: -0.4152 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2538 - val_loss: -0.4069 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2758 - val_loss: -0.4203 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2941 - val_loss: -0.4255 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2720 - val_loss: -0.4406 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2759 - val_loss: -0.4373 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3083 - val_loss: -0.4405 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3272 - val_loss: -0.4458 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3166 - val_loss: -0.4485 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3190 - val_loss: -0.4556 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3472 - val_loss: -0.4573 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3477 - val_loss: -0.4602 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.3598 - val_loss: -0.4646 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3549 - val_loss: -0.4725 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3788 - val_loss: -0.4669 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3838 - val_loss: -0.4784 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3865 - val_loss: -0.4850 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4146 - val_loss: -0.4881 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4264 - val_loss: -0.4800 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3957 - val_loss: -0.4873 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3919 - val_loss: -0.4953 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4081 - val_loss: -0.5047 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4308 - val_loss: -0.5012 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4239 - val_loss: -0.5119 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4303 - val_loss: -0.5136 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4699 - val_loss: -0.5095 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4395 - val_loss: -0.5153 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4605 - val_loss: -0.5146 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4509 - val_loss: -0.5187 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4644 - val_loss: -0.5280 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4510 - val_loss: -0.5324 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4384 - val_loss: -0.5320 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3999 - val_loss: -0.5367 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4597 - val_loss: -0.5230 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4724 - val_loss: -0.5377 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4792 - val_loss: -0.5217 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5000 - val_loss: -0.5193 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4778 - val_loss: -0.5365 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4696 - val_loss: -0.5577 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4927 - val_loss: -0.5448 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4798 - val_loss: -0.5670 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5303 - val_loss: -0.5557 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5118 - val_loss: -0.5569 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5196 - val_loss: -0.5752 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5380 - val_loss: -0.5650 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5475 - val_loss: -0.5684 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5567 - val_loss: -0.5748 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5202 - val_loss: -0.5571 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5512 - val_loss: -0.5844 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.5660 - val_loss: -0.5633 - learning_rate: 1.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4859 - val_loss: -0.5773 - learning_rate: 1.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5108 - val_loss: -0.5900 - learning_rate: 1.0000e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5771 - val_loss: -0.5799 - learning_rate: 1.0000e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5609 - val_loss: -0.5766 - learning_rate: 1.0000e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5139 - val_loss: -0.5866 - learning_rate: 1.0000e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5399 - val_loss: -0.5979 - learning_rate: 1.0000e-04\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5639 - val_loss: -0.5943 - learning_rate: 1.0000e-04\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5599 - val_loss: -0.5638 - learning_rate: 1.0000e-04\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5945 - val_loss: -0.5907 - learning_rate: 1.0000e-04\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5924 - val_loss: -0.5957 - learning_rate: 1.0000e-04\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5663 - val_loss: -0.5977 - learning_rate: 1.0000e-04\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5567 - val_loss: -0.5902 - learning_rate: 5.0000e-05\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5854 - val_loss: -0.5929 - learning_rate: 5.0000e-05\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6045 - val_loss: -0.6002 - learning_rate: 5.0000e-05\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5288 - val_loss: -0.5968 - learning_rate: 5.0000e-05\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5473 - val_loss: -0.5926 - learning_rate: 5.0000e-05\n",
      "Epoch 86/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6033 - val_loss: -0.6007 - learning_rate: 5.0000e-05\n",
      "Epoch 87/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5637 - val_loss: -0.6114 - learning_rate: 5.0000e-05\n",
      "Epoch 88/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6443 - val_loss: -0.5921 - learning_rate: 5.0000e-05\n",
      "Epoch 89/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6277 - val_loss: -0.5906 - learning_rate: 5.0000e-05\n",
      "Epoch 90/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5757 - val_loss: -0.6078 - learning_rate: 5.0000e-05\n",
      "Epoch 91/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5685 - val_loss: -0.6133 - learning_rate: 5.0000e-05\n",
      "Epoch 92/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6018 - val_loss: -0.6224 - learning_rate: 5.0000e-05\n",
      "Epoch 93/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6212 - val_loss: -0.6218 - learning_rate: 5.0000e-05\n",
      "Epoch 94/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5668 - val_loss: -0.6177 - learning_rate: 5.0000e-05\n",
      "Epoch 95/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5856 - val_loss: -0.6251 - learning_rate: 5.0000e-05\n",
      "Epoch 96/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6220 - val_loss: -0.6079 - learning_rate: 5.0000e-05\n",
      "Epoch 97/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5889 - val_loss: -0.6194 - learning_rate: 5.0000e-05\n",
      "Epoch 98/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5930 - val_loss: -0.6236 - learning_rate: 5.0000e-05\n",
      "Epoch 99/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6054 - val_loss: -0.6201 - learning_rate: 5.0000e-05\n",
      "Epoch 100/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6215 - val_loss: -0.6237 - learning_rate: 5.0000e-05\n",
      "Epoch 101/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6289 - val_loss: -0.6228 - learning_rate: 2.5000e-05\n",
      "Epoch 102/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6004 - val_loss: -0.6220 - learning_rate: 2.5000e-05\n",
      "Epoch 103/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6129 - val_loss: -0.6258 - learning_rate: 2.5000e-05\n",
      "Epoch 104/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5766 - val_loss: -0.6229 - learning_rate: 2.5000e-05\n",
      "Epoch 105/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6700 - val_loss: -0.6233 - learning_rate: 2.5000e-05\n",
      "Epoch 106/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.5917 - val_loss: -0.6201 - learning_rate: 2.5000e-05\n",
      "Epoch 107/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5992 - val_loss: -0.6285 - learning_rate: 2.5000e-05\n",
      "Epoch 108/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6275 - val_loss: -0.6350 - learning_rate: 2.5000e-05\n",
      "Epoch 109/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6414 - val_loss: -0.6329 - learning_rate: 2.5000e-05\n",
      "Epoch 110/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6411 - val_loss: -0.6217 - learning_rate: 2.5000e-05\n",
      "Epoch 111/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6117 - val_loss: -0.6194 - learning_rate: 2.5000e-05\n",
      "Epoch 112/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6219 - val_loss: -0.6365 - learning_rate: 2.5000e-05\n",
      "Epoch 113/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6261 - val_loss: -0.6302 - learning_rate: 2.5000e-05\n",
      "Epoch 114/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6455 - val_loss: -0.6284 - learning_rate: 2.5000e-05\n",
      "Epoch 115/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6386 - val_loss: -0.6272 - learning_rate: 2.5000e-05\n",
      "Epoch 116/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5774 - val_loss: -0.6243 - learning_rate: 2.5000e-05\n",
      "Epoch 117/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6059 - val_loss: -0.6387 - learning_rate: 2.5000e-05\n",
      "Epoch 118/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6175 - val_loss: -0.6361 - learning_rate: 2.5000e-05\n",
      "Epoch 119/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6063 - val_loss: -0.6356 - learning_rate: 2.5000e-05\n",
      "Epoch 120/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6179 - val_loss: -0.6427 - learning_rate: 2.5000e-05\n",
      "Epoch 121/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6426 - val_loss: -0.6282 - learning_rate: 2.5000e-05\n",
      "Epoch 122/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6975 - val_loss: -0.6266 - learning_rate: 2.5000e-05\n",
      "Epoch 123/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6658 - val_loss: -0.6192 - learning_rate: 2.5000e-05\n",
      "Epoch 124/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6313 - val_loss: -0.6301 - learning_rate: 2.5000e-05\n",
      "Epoch 125/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6269 - val_loss: -0.6308 - learning_rate: 2.5000e-05\n",
      "Epoch 126/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6844 - val_loss: -0.6291 - learning_rate: 1.2500e-05\n",
      "Epoch 127/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5950 - val_loss: -0.6359 - learning_rate: 1.2500e-05\n",
      "Epoch 128/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6602 - val_loss: -0.6198 - learning_rate: 1.2500e-05\n",
      "Epoch 129/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6556 - val_loss: -0.6286 - learning_rate: 1.2500e-05\n",
      "Epoch 130/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6329 - val_loss: -0.6309 - learning_rate: 1.2500e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.8842 - val_loss: 0.0223 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.4627 - val_loss: 0.0182 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.3618 - val_loss: 0.0169 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.2563 - val_loss: 0.0212 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1997 - val_loss: 0.0044 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1496 - val_loss: 0.0046 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1262 - val_loss: 0.0035 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1080 - val_loss: 0.0034 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1162 - val_loss: 0.0040 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0916 - val_loss: 0.0055 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0733 - val_loss: 0.0034 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0754 - val_loss: 0.0096 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0831 - val_loss: 0.0026 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0554 - val_loss: 0.0027 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0475 - val_loss: 0.0031 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0462 - val_loss: 0.0026 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0660 - val_loss: 0.0015 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0576 - val_loss: 3.3516e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0443 - val_loss: 0.0026 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0332 - val_loss: 0.0097 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0282 - val_loss: 0.0134 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0334 - val_loss: 0.0055 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0360 - val_loss: 0.0011 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0290 - val_loss: 0.0013 - learning_rate: 5.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0344 - val_loss: 0.0031 - learning_rate: 5.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0297 - val_loss: 0.0026 - learning_rate: 5.0000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0304 - val_loss: 0.0012 - learning_rate: 5.0000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0238 - val_loss: 0.0023 - learning_rate: 5.0000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.6972 - val_loss: -0.0363 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.2999 - val_loss: -0.1324 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1353 - val_loss: -0.1900 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0498 - val_loss: -0.2290 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0343 - val_loss: -0.2475 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.0220 - val_loss: -0.2593 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.0614 - val_loss: -0.2747 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.0879 - val_loss: -0.2974 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.0876 - val_loss: -0.3071 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.1027 - val_loss: -0.3094 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.1306 - val_loss: -0.3178 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.1301 - val_loss: -0.3276 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.1546 - val_loss: -0.3295 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.1619 - val_loss: -0.3417 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.1643 - val_loss: -0.3510 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.1749 - val_loss: -0.3664 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.1828 - val_loss: -0.3720 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2209 - val_loss: -0.3815 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.1988 - val_loss: -0.3927 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2041 - val_loss: -0.3979 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2113 - val_loss: -0.4004 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.1986 - val_loss: -0.4007 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2538 - val_loss: -0.4056 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2400 - val_loss: -0.4130 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2395 - val_loss: -0.4210 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2448 - val_loss: -0.4281 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2581 - val_loss: -0.4298 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2840 - val_loss: -0.4430 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2917 - val_loss: -0.4515 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2470 - val_loss: -0.4536 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2926 - val_loss: -0.4610 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2918 - val_loss: -0.4641 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2983 - val_loss: -0.4646 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2878 - val_loss: -0.4788 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3332 - val_loss: -0.4814 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3356 - val_loss: -0.4894 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2819 - val_loss: -0.4928 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3364 - val_loss: -0.4966 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3124 - val_loss: -0.5045 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3642 - val_loss: -0.5104 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2903 - val_loss: -0.5173 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3517 - val_loss: -0.5229 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3403 - val_loss: -0.5279 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3898 - val_loss: -0.5329 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3879 - val_loss: -0.5441 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3847 - val_loss: -0.5497 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3630 - val_loss: -0.5560 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4104 - val_loss: -0.5586 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3725 - val_loss: -0.5643 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3826 - val_loss: -0.5745 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4242 - val_loss: -0.5786 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4029 - val_loss: -0.5861 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3739 - val_loss: -0.5911 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4241 - val_loss: -0.5952 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3900 - val_loss: -0.6010 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.4397 - val_loss: -0.6059 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.4354 - val_loss: -0.6190 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4434 - val_loss: -0.6145 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4197 - val_loss: -0.6248 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4244 - val_loss: -0.6325 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4410 - val_loss: -0.6381 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4419 - val_loss: -0.6474 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4814 - val_loss: -0.6521 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4528 - val_loss: -0.6604 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4648 - val_loss: -0.6626 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4816 - val_loss: -0.6697 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4842 - val_loss: -0.6761 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4922 - val_loss: -0.6774 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4673 - val_loss: -0.6848 - learning_rate: 1.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4868 - val_loss: -0.6891 - learning_rate: 1.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5190 - val_loss: -0.6985 - learning_rate: 1.0000e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4823 - val_loss: -0.7007 - learning_rate: 1.0000e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4785 - val_loss: -0.7052 - learning_rate: 1.0000e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5046 - val_loss: -0.7158 - learning_rate: 1.0000e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4284 - val_loss: -0.7216 - learning_rate: 1.0000e-04\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5458 - val_loss: -0.7262 - learning_rate: 1.0000e-04\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5363 - val_loss: -0.7312 - learning_rate: 1.0000e-04\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5040 - val_loss: -0.7328 - learning_rate: 1.0000e-04\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4768 - val_loss: -0.7418 - learning_rate: 1.0000e-04\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5591 - val_loss: -0.7441 - learning_rate: 1.0000e-04\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5246 - val_loss: -0.7450 - learning_rate: 1.0000e-04\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5281 - val_loss: -0.7428 - learning_rate: 1.0000e-04\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5209 - val_loss: -0.7519 - learning_rate: 1.0000e-04\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5182 - val_loss: -0.7520 - learning_rate: 1.0000e-04\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5689 - val_loss: -0.7586 - learning_rate: 1.0000e-04\n",
      "Epoch 86/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5293 - val_loss: -0.7652 - learning_rate: 1.0000e-04\n",
      "Epoch 87/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5417 - val_loss: -0.7726 - learning_rate: 1.0000e-04\n",
      "Epoch 88/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5645 - val_loss: -0.7785 - learning_rate: 1.0000e-04\n",
      "Epoch 89/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5446 - val_loss: -0.7862 - learning_rate: 1.0000e-04\n",
      "Epoch 90/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5731 - val_loss: -0.7930 - learning_rate: 1.0000e-04\n",
      "Epoch 91/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5315 - val_loss: -0.7890 - learning_rate: 1.0000e-04\n",
      "Epoch 92/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5635 - val_loss: -0.7912 - learning_rate: 1.0000e-04\n",
      "Epoch 93/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5715 - val_loss: -0.8033 - learning_rate: 1.0000e-04\n",
      "Epoch 94/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.5625 - val_loss: -0.8097 - learning_rate: 1.0000e-04\n",
      "Epoch 95/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5862 - val_loss: -0.8148 - learning_rate: 1.0000e-04\n",
      "Epoch 96/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5879 - val_loss: -0.8120 - learning_rate: 1.0000e-04\n",
      "Epoch 97/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5588 - val_loss: -0.8255 - learning_rate: 1.0000e-04\n",
      "Epoch 98/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5957 - val_loss: -0.8274 - learning_rate: 1.0000e-04\n",
      "Epoch 99/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5895 - val_loss: -0.8265 - learning_rate: 1.0000e-04\n",
      "Epoch 100/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5838 - val_loss: -0.8329 - learning_rate: 1.0000e-04\n",
      "Epoch 101/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6150 - val_loss: -0.8385 - learning_rate: 1.0000e-04\n",
      "Epoch 102/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5749 - val_loss: -0.8493 - learning_rate: 1.0000e-04\n",
      "Epoch 103/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6026 - val_loss: -0.8536 - learning_rate: 1.0000e-04\n",
      "Epoch 104/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5787 - val_loss: -0.8575 - learning_rate: 1.0000e-04\n",
      "Epoch 105/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6376 - val_loss: -0.8523 - learning_rate: 1.0000e-04\n",
      "Epoch 106/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6089 - val_loss: -0.8569 - learning_rate: 1.0000e-04\n",
      "Epoch 107/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6408 - val_loss: -0.8619 - learning_rate: 1.0000e-04\n",
      "Epoch 108/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6174 - val_loss: -0.8642 - learning_rate: 1.0000e-04\n",
      "Epoch 109/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5996 - val_loss: -0.8666 - learning_rate: 1.0000e-04\n",
      "Epoch 110/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6202 - val_loss: -0.8668 - learning_rate: 1.0000e-04\n",
      "Epoch 111/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6892 - val_loss: -0.8764 - learning_rate: 1.0000e-04\n",
      "Epoch 112/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6250 - val_loss: -0.8837 - learning_rate: 1.0000e-04\n",
      "Epoch 113/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6218 - val_loss: -0.8832 - learning_rate: 1.0000e-04\n",
      "Epoch 114/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6103 - val_loss: -0.8925 - learning_rate: 1.0000e-04\n",
      "Epoch 115/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5967 - val_loss: -0.8853 - learning_rate: 1.0000e-04\n",
      "Epoch 116/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6402 - val_loss: -0.8953 - learning_rate: 1.0000e-04\n",
      "Epoch 117/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5875 - val_loss: -0.8932 - learning_rate: 1.0000e-04\n",
      "Epoch 118/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6800 - val_loss: -0.9089 - learning_rate: 1.0000e-04\n",
      "Epoch 119/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6262 - val_loss: -0.9103 - learning_rate: 1.0000e-04\n",
      "Epoch 120/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6888 - val_loss: -0.9148 - learning_rate: 1.0000e-04\n",
      "Epoch 121/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6928 - val_loss: -0.9108 - learning_rate: 1.0000e-04\n",
      "Epoch 122/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6164 - val_loss: -0.9145 - learning_rate: 1.0000e-04\n",
      "Epoch 123/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6203 - val_loss: -0.9218 - learning_rate: 1.0000e-04\n",
      "Epoch 124/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6247 - val_loss: -0.9249 - learning_rate: 1.0000e-04\n",
      "Epoch 125/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6666 - val_loss: -0.9201 - learning_rate: 1.0000e-04\n",
      "Epoch 126/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6875 - val_loss: -0.9326 - learning_rate: 1.0000e-04\n",
      "Epoch 127/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7193 - val_loss: -0.9421 - learning_rate: 1.0000e-04\n",
      "Epoch 128/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6388 - val_loss: -0.9366 - learning_rate: 1.0000e-04\n",
      "Epoch 129/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6915 - val_loss: -0.9450 - learning_rate: 1.0000e-04\n",
      "Epoch 130/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6338 - val_loss: -0.9539 - learning_rate: 1.0000e-04\n",
      "Epoch 131/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.7271 - val_loss: -0.9595 - learning_rate: 1.0000e-04\n",
      "Epoch 132/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7160 - val_loss: -0.9553 - learning_rate: 1.0000e-04\n",
      "Epoch 133/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6778 - val_loss: -0.9623 - learning_rate: 1.0000e-04\n",
      "Epoch 134/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6772 - val_loss: -0.9645 - learning_rate: 1.0000e-04\n",
      "Epoch 135/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5975 - val_loss: -0.9740 - learning_rate: 1.0000e-04\n",
      "Epoch 136/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7244 - val_loss: -0.9805 - learning_rate: 1.0000e-04\n",
      "Epoch 137/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7113 - val_loss: -0.9912 - learning_rate: 1.0000e-04\n",
      "Epoch 138/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7189 - val_loss: -0.9922 - learning_rate: 1.0000e-04\n",
      "Epoch 139/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6790 - val_loss: -1.0009 - learning_rate: 1.0000e-04\n",
      "Epoch 140/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7035 - val_loss: -0.9980 - learning_rate: 1.0000e-04\n",
      "Epoch 141/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7634 - val_loss: -1.0012 - learning_rate: 1.0000e-04\n",
      "Epoch 142/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7047 - val_loss: -1.0042 - learning_rate: 1.0000e-04\n",
      "Epoch 143/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7479 - val_loss: -1.0154 - learning_rate: 1.0000e-04\n",
      "Epoch 144/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6990 - val_loss: -1.0162 - learning_rate: 1.0000e-04\n",
      "Epoch 145/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6848 - val_loss: -1.0203 - learning_rate: 1.0000e-04\n",
      "Epoch 146/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6638 - val_loss: -1.0113 - learning_rate: 1.0000e-04\n",
      "Epoch 147/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7545 - val_loss: -1.0167 - learning_rate: 1.0000e-04\n",
      "Epoch 148/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7400 - val_loss: -1.0205 - learning_rate: 1.0000e-04\n",
      "Epoch 149/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7521 - val_loss: -1.0199 - learning_rate: 1.0000e-04\n",
      "Epoch 150/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.8041 - val_loss: -1.0285 - learning_rate: 1.0000e-04\n",
      "Epoch 151/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7330 - val_loss: -1.0223 - learning_rate: 1.0000e-04\n",
      "Epoch 152/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7634 - val_loss: -1.0299 - learning_rate: 1.0000e-04\n",
      "Epoch 153/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7620 - val_loss: -1.0377 - learning_rate: 1.0000e-04\n",
      "Epoch 154/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7734 - val_loss: -1.0337 - learning_rate: 1.0000e-04\n",
      "Epoch 155/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7841 - val_loss: -1.0466 - learning_rate: 1.0000e-04\n",
      "Epoch 156/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7747 - val_loss: -1.0364 - learning_rate: 1.0000e-04\n",
      "Epoch 157/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7350 - val_loss: -1.0463 - learning_rate: 1.0000e-04\n",
      "Epoch 158/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6978 - val_loss: -1.0434 - learning_rate: 1.0000e-04\n",
      "Epoch 159/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7336 - val_loss: -1.0582 - learning_rate: 1.0000e-04\n",
      "Epoch 160/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7869 - val_loss: -1.0734 - learning_rate: 1.0000e-04\n",
      "Epoch 161/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7076 - val_loss: -1.0706 - learning_rate: 1.0000e-04\n",
      "Epoch 162/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7838 - val_loss: -1.0675 - learning_rate: 1.0000e-04\n",
      "Epoch 163/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.8212 - val_loss: -1.0722 - learning_rate: 1.0000e-04\n",
      "Epoch 164/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.8222 - val_loss: -1.0807 - learning_rate: 1.0000e-04\n",
      "Epoch 165/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7845 - val_loss: -1.0832 - learning_rate: 1.0000e-04\n",
      "Epoch 166/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.8308 - val_loss: -1.0879 - learning_rate: 1.0000e-04\n",
      "Epoch 167/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.8147 - val_loss: -1.0952 - learning_rate: 1.0000e-04\n",
      "Epoch 168/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.7801 - val_loss: -1.0996 - learning_rate: 1.0000e-04\n",
      "Epoch 169/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7877 - val_loss: -1.1000 - learning_rate: 1.0000e-04\n",
      "Epoch 170/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.8209 - val_loss: -1.1132 - learning_rate: 1.0000e-04\n",
      "Epoch 171/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7406 - val_loss: -1.1156 - learning_rate: 1.0000e-04\n",
      "Epoch 172/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7272 - val_loss: -1.1178 - learning_rate: 1.0000e-04\n",
      "Epoch 173/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7620 - val_loss: -1.1296 - learning_rate: 1.0000e-04\n",
      "Epoch 174/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7966 - val_loss: -1.1292 - learning_rate: 1.0000e-04\n",
      "Epoch 175/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.8271 - val_loss: -1.1272 - learning_rate: 1.0000e-04\n",
      "Epoch 176/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7932 - val_loss: -1.1332 - learning_rate: 1.0000e-04\n",
      "Epoch 177/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.8517 - val_loss: -1.1283 - learning_rate: 1.0000e-04\n",
      "Epoch 178/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.8559 - val_loss: -1.1332 - learning_rate: 1.0000e-04\n",
      "Epoch 179/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.8363 - val_loss: -1.1418 - learning_rate: 1.0000e-04\n",
      "Epoch 180/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.8466 - val_loss: -1.1517 - learning_rate: 1.0000e-04\n",
      "Epoch 181/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.8548 - val_loss: -1.1419 - learning_rate: 1.0000e-04\n",
      "Epoch 182/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.8063 - val_loss: -1.1567 - learning_rate: 1.0000e-04\n",
      "Epoch 183/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.8602 - val_loss: -1.1513 - learning_rate: 1.0000e-04\n",
      "Epoch 184/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.8640 - val_loss: -1.1623 - learning_rate: 1.0000e-04\n",
      "Epoch 185/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.8231 - val_loss: -1.1688 - learning_rate: 1.0000e-04\n",
      "Epoch 186/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.8704 - val_loss: -1.1728 - learning_rate: 1.0000e-04\n",
      "Epoch 187/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.7941 - val_loss: -1.1764 - learning_rate: 1.0000e-04\n",
      "Epoch 188/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.8637 - val_loss: -1.1752 - learning_rate: 1.0000e-04\n",
      "Epoch 189/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.8586 - val_loss: -1.1829 - learning_rate: 1.0000e-04\n",
      "Epoch 190/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.8702 - val_loss: -1.2017 - learning_rate: 1.0000e-04\n",
      "Epoch 191/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.8712 - val_loss: -1.1943 - learning_rate: 1.0000e-04\n",
      "Epoch 192/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.8693 - val_loss: -1.2023 - learning_rate: 1.0000e-04\n",
      "Epoch 193/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.8682 - val_loss: -1.2034 - learning_rate: 1.0000e-04\n",
      "Epoch 194/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.9023 - val_loss: -1.2019 - learning_rate: 1.0000e-04\n",
      "Epoch 195/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.8537 - val_loss: -1.2077 - learning_rate: 1.0000e-04\n",
      "Epoch 196/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.8815 - val_loss: -1.2073 - learning_rate: 1.0000e-04\n",
      "Epoch 197/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.8487 - val_loss: -1.2028 - learning_rate: 1.0000e-04\n",
      "Epoch 198/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.9219 - val_loss: -1.2265 - learning_rate: 1.0000e-04\n",
      "Epoch 199/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.8572 - val_loss: -1.2269 - learning_rate: 1.0000e-04\n",
      "Epoch 200/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.8445 - val_loss: -1.2330 - learning_rate: 1.0000e-04\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.9147 - val_loss: 0.0582 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.3751 - val_loss: 0.0337 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.2784 - val_loss: 0.0212 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.2211 - val_loss: 0.0194 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1326 - val_loss: 0.0158 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1145 - val_loss: 0.0091 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1006 - val_loss: 0.0091 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0693 - val_loss: 0.0048 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0791 - val_loss: 0.0059 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0549 - val_loss: 0.0050 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0706 - val_loss: 0.0075 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0602 - val_loss: 0.0085 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0546 - val_loss: 0.0071 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0451 - val_loss: 0.0099 - learning_rate: 5.0000e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0526 - val_loss: 0.0074 - learning_rate: 5.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0526 - val_loss: 0.0096 - learning_rate: 5.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0414 - val_loss: 0.0091 - learning_rate: 5.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0295 - val_loss: 0.0061 - learning_rate: 5.0000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.7639 - val_loss: 0.0015 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.3354 - val_loss: -0.0756 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1729 - val_loss: -0.1387 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1101 - val_loss: -0.1735 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0452 - val_loss: -0.1972 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0120 - val_loss: -0.2159 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.0219 - val_loss: -0.2275 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.0537 - val_loss: -0.2452 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.0679 - val_loss: -0.2611 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.0818 - val_loss: -0.2686 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.1070 - val_loss: -0.2765 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.1105 - val_loss: -0.2832 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.1417 - val_loss: -0.2985 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.1277 - val_loss: -0.3038 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.1504 - val_loss: -0.3116 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.1859 - val_loss: -0.3164 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.1818 - val_loss: -0.3295 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.1881 - val_loss: -0.3267 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2030 - val_loss: -0.3403 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.1777 - val_loss: -0.3430 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2100 - val_loss: -0.3389 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.2053 - val_loss: -0.3493 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.2264 - val_loss: -0.3652 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.2088 - val_loss: -0.3651 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.2453 - val_loss: -0.3722 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.2290 - val_loss: -0.3734 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.2397 - val_loss: -0.3776 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.2508 - val_loss: -0.3826 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.2787 - val_loss: -0.3943 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.2770 - val_loss: -0.3911 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.2701 - val_loss: -0.3810 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3182 - val_loss: -0.3776 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3154 - val_loss: -0.3991 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3207 - val_loss: -0.3966 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.2978 - val_loss: -0.4110 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3518 - val_loss: -0.4107 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3352 - val_loss: -0.4235 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3449 - val_loss: -0.4152 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3332 - val_loss: -0.4295 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3808 - val_loss: -0.4431 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3268 - val_loss: -0.4387 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3605 - val_loss: -0.4426 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3524 - val_loss: -0.4571 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4158 - val_loss: -0.4502 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3769 - val_loss: -0.4662 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3880 - val_loss: -0.4664 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3790 - val_loss: -0.4659 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3730 - val_loss: -0.4748 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3993 - val_loss: -0.4565 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3819 - val_loss: -0.4871 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4174 - val_loss: -0.5064 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3954 - val_loss: -0.4850 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4208 - val_loss: -0.4858 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4559 - val_loss: -0.4792 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4504 - val_loss: -0.4850 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4238 - val_loss: -0.5068 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4455 - val_loss: -0.4990 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4381 - val_loss: -0.5215 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4558 - val_loss: -0.4939 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4488 - val_loss: -0.4776 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4456 - val_loss: -0.5138 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4604 - val_loss: -0.5022 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4475 - val_loss: -0.5025 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4390 - val_loss: -0.5138 - learning_rate: 5.0000e-05\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4733 - val_loss: -0.5107 - learning_rate: 5.0000e-05\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4482 - val_loss: -0.5077 - learning_rate: 5.0000e-05\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4236 - val_loss: -0.5101 - learning_rate: 5.0000e-05\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4562 - val_loss: -0.5149 - learning_rate: 5.0000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.5314 - val_loss: 0.0292 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.3500 - val_loss: 0.0134 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.2391 - val_loss: 0.0190 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1895 - val_loss: 0.0098 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1620 - val_loss: 0.0087 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1510 - val_loss: 0.0139 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0843 - val_loss: 0.0098 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0961 - val_loss: 0.0143 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0724 - val_loss: 0.0099 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0928 - val_loss: 0.0089 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0712 - val_loss: 0.0093 - learning_rate: 5.0000e-05\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0714 - val_loss: 0.0088 - learning_rate: 5.0000e-05\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0548 - val_loss: 0.0064 - learning_rate: 5.0000e-05\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0673 - val_loss: 0.0058 - learning_rate: 5.0000e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0731 - val_loss: 0.0045 - learning_rate: 5.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0510 - val_loss: 0.0050 - learning_rate: 5.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0532 - val_loss: 0.0051 - learning_rate: 5.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0724 - val_loss: 0.0036 - learning_rate: 5.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0433 - val_loss: 0.0046 - learning_rate: 5.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0442 - val_loss: 0.0035 - learning_rate: 5.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0517 - val_loss: 0.0051 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0401 - val_loss: 0.0035 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0373 - val_loss: 0.0027 - learning_rate: 5.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0403 - val_loss: 0.0023 - learning_rate: 5.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0420 - val_loss: 0.0026 - learning_rate: 5.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0433 - val_loss: 0.0042 - learning_rate: 5.0000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0342 - val_loss: 0.0012 - learning_rate: 5.0000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0288 - val_loss: 0.0028 - learning_rate: 5.0000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0253 - val_loss: 0.0026 - learning_rate: 5.0000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0331 - val_loss: 0.0021 - learning_rate: 5.0000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0298 - val_loss: 0.0020 - learning_rate: 5.0000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0349 - val_loss: 0.0016 - learning_rate: 5.0000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0292 - val_loss: 0.0020 - learning_rate: 2.5000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0321 - val_loss: 0.0028 - learning_rate: 2.5000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0292 - val_loss: 0.0029 - learning_rate: 2.5000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0208 - val_loss: 0.0031 - learning_rate: 2.5000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0298 - val_loss: 0.0025 - learning_rate: 2.5000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.0109 - val_loss: 0.0389 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.4085 - val_loss: -0.0977 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1826 - val_loss: -0.1784 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0384 - val_loss: -0.2382 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.0443 - val_loss: -0.2681 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.0515 - val_loss: -0.2837 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.0849 - val_loss: -0.3104 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.1186 - val_loss: -0.3185 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.0966 - val_loss: -0.3287 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.1243 - val_loss: -0.3377 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.1598 - val_loss: -0.3349 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.1843 - val_loss: -0.3613 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.1623 - val_loss: -0.3526 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.1738 - val_loss: -0.3764 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.1984 - val_loss: -0.3792 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2317 - val_loss: -0.3925 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2266 - val_loss: -0.3926 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2367 - val_loss: -0.4011 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2370 - val_loss: -0.4059 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2566 - val_loss: -0.3996 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.2468 - val_loss: -0.4187 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.2630 - val_loss: -0.4137 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.2515 - val_loss: -0.4153 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.2706 - val_loss: -0.4269 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.2913 - val_loss: -0.4398 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.2901 - val_loss: -0.4340 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3017 - val_loss: -0.4433 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.2964 - val_loss: -0.4426 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3087 - val_loss: -0.4556 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3574 - val_loss: -0.4584 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3454 - val_loss: -0.4604 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3564 - val_loss: -0.4609 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3635 - val_loss: -0.4769 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3823 - val_loss: -0.4875 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3444 - val_loss: -0.4847 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3868 - val_loss: -0.4906 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3771 - val_loss: -0.4929 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3551 - val_loss: -0.4987 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3755 - val_loss: -0.5069 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3643 - val_loss: -0.5063 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4039 - val_loss: -0.5101 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4085 - val_loss: -0.5162 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4204 - val_loss: -0.5293 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3800 - val_loss: -0.5330 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3898 - val_loss: -0.5349 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4031 - val_loss: -0.5371 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4508 - val_loss: -0.5364 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4329 - val_loss: -0.5396 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4450 - val_loss: -0.5463 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4353 - val_loss: -0.5556 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4459 - val_loss: -0.5550 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4616 - val_loss: -0.5613 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4526 - val_loss: -0.5659 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4435 - val_loss: -0.5661 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4864 - val_loss: -0.5780 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.4839 - val_loss: -0.5837 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.4752 - val_loss: -0.5843 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4963 - val_loss: -0.5822 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.4459 - val_loss: -0.5908 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4953 - val_loss: -0.5956 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4822 - val_loss: -0.5954 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.4940 - val_loss: -0.5898 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.5153 - val_loss: -0.6121 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5045 - val_loss: -0.6101 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.5027 - val_loss: -0.6142 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.4940 - val_loss: -0.6154 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5011 - val_loss: -0.6305 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.5129 - val_loss: -0.6192 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.4975 - val_loss: -0.6346 - learning_rate: 1.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5464 - val_loss: -0.6363 - learning_rate: 1.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.5435 - val_loss: -0.6341 - learning_rate: 1.0000e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.5578 - val_loss: -0.6519 - learning_rate: 1.0000e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.5415 - val_loss: -0.6470 - learning_rate: 1.0000e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.5700 - val_loss: -0.6589 - learning_rate: 1.0000e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5821 - val_loss: -0.6557 - learning_rate: 1.0000e-04\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5250 - val_loss: -0.6618 - learning_rate: 1.0000e-04\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.5734 - val_loss: -0.6531 - learning_rate: 1.0000e-04\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.5770 - val_loss: -0.6572 - learning_rate: 1.0000e-04\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5754 - val_loss: -0.6680 - learning_rate: 1.0000e-04\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5799 - val_loss: -0.6614 - learning_rate: 1.0000e-04\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.6028 - val_loss: -0.6783 - learning_rate: 1.0000e-04\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.5727 - val_loss: -0.6803 - learning_rate: 1.0000e-04\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5983 - val_loss: -0.6923 - learning_rate: 1.0000e-04\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5647 - val_loss: -0.6789 - learning_rate: 1.0000e-04\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.6017 - val_loss: -0.7003 - learning_rate: 1.0000e-04\n",
      "Epoch 86/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5882 - val_loss: -0.7011 - learning_rate: 1.0000e-04\n",
      "Epoch 87/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5887 - val_loss: -0.6900 - learning_rate: 1.0000e-04\n",
      "Epoch 88/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.5787 - val_loss: -0.7066 - learning_rate: 1.0000e-04\n",
      "Epoch 89/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.6130 - val_loss: -0.6977 - learning_rate: 1.0000e-04\n",
      "Epoch 90/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.6184 - val_loss: -0.7147 - learning_rate: 1.0000e-04\n",
      "Epoch 91/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.6051 - val_loss: -0.7146 - learning_rate: 1.0000e-04\n",
      "Epoch 92/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6266 - val_loss: -0.7376 - learning_rate: 1.0000e-04\n",
      "Epoch 93/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.6252 - val_loss: -0.7299 - learning_rate: 1.0000e-04\n",
      "Epoch 94/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.6291 - val_loss: -0.7329 - learning_rate: 1.0000e-04\n",
      "Epoch 95/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.6291 - val_loss: -0.7361 - learning_rate: 1.0000e-04\n",
      "Epoch 96/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.6140 - val_loss: -0.7472 - learning_rate: 1.0000e-04\n",
      "Epoch 97/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.6308 - val_loss: -0.7405 - learning_rate: 1.0000e-04\n",
      "Epoch 98/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.6125 - val_loss: -0.7594 - learning_rate: 1.0000e-04\n",
      "Epoch 99/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.6531 - val_loss: -0.7554 - learning_rate: 1.0000e-04\n",
      "Epoch 100/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.6165 - val_loss: -0.7641 - learning_rate: 1.0000e-04\n",
      "Epoch 101/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.6235 - val_loss: -0.7698 - learning_rate: 1.0000e-04\n",
      "Epoch 102/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.6724 - val_loss: -0.7756 - learning_rate: 1.0000e-04\n",
      "Epoch 103/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6341 - val_loss: -0.7667 - learning_rate: 1.0000e-04\n",
      "Epoch 104/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.6387 - val_loss: -0.7793 - learning_rate: 1.0000e-04\n",
      "Epoch 105/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.6676 - val_loss: -0.7757 - learning_rate: 1.0000e-04\n",
      "Epoch 106/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.6971 - val_loss: -0.7945 - learning_rate: 1.0000e-04\n",
      "Epoch 107/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.6621 - val_loss: -0.7873 - learning_rate: 1.0000e-04\n",
      "Epoch 108/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.6730 - val_loss: -0.7855 - learning_rate: 1.0000e-04\n",
      "Epoch 109/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.6261 - val_loss: -0.8049 - learning_rate: 1.0000e-04\n",
      "Epoch 110/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.6940 - val_loss: -0.8046 - learning_rate: 1.0000e-04\n",
      "Epoch 111/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.7128 - val_loss: -0.8070 - learning_rate: 1.0000e-04\n",
      "Epoch 112/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.7201 - val_loss: -0.8183 - learning_rate: 1.0000e-04\n",
      "Epoch 113/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.6502 - val_loss: -0.8204 - learning_rate: 1.0000e-04\n",
      "Epoch 114/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.6868 - val_loss: -0.8280 - learning_rate: 1.0000e-04\n",
      "Epoch 115/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.6825 - val_loss: -0.8317 - learning_rate: 1.0000e-04\n",
      "Epoch 116/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.6898 - val_loss: -0.8147 - learning_rate: 1.0000e-04\n",
      "Epoch 117/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.7117 - val_loss: -0.8199 - learning_rate: 1.0000e-04\n",
      "Epoch 118/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.7554 - val_loss: -0.8392 - learning_rate: 1.0000e-04\n",
      "Epoch 119/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.7248 - val_loss: -0.8378 - learning_rate: 1.0000e-04\n",
      "Epoch 120/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.7222 - val_loss: -0.8345 - learning_rate: 1.0000e-04\n",
      "Epoch 121/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.7375 - val_loss: -0.8557 - learning_rate: 1.0000e-04\n",
      "Epoch 122/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.6694 - val_loss: -0.8438 - learning_rate: 1.0000e-04\n",
      "Epoch 123/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.6714 - val_loss: -0.8450 - learning_rate: 1.0000e-04\n",
      "Epoch 124/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.7404 - val_loss: -0.8534 - learning_rate: 1.0000e-04\n",
      "Epoch 125/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.7414 - val_loss: -0.8505 - learning_rate: 1.0000e-04\n",
      "Epoch 126/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.7484 - val_loss: -0.8634 - learning_rate: 1.0000e-04\n",
      "Epoch 127/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.7979 - val_loss: -0.8637 - learning_rate: 1.0000e-04\n",
      "Epoch 128/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.7374 - val_loss: -0.8652 - learning_rate: 1.0000e-04\n",
      "Epoch 129/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.7754 - val_loss: -0.8704 - learning_rate: 1.0000e-04\n",
      "Epoch 130/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.7744 - val_loss: -0.8858 - learning_rate: 1.0000e-04\n",
      "Epoch 131/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7439 - val_loss: -0.8754 - learning_rate: 1.0000e-04\n",
      "Epoch 132/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.7653 - val_loss: -0.8899 - learning_rate: 1.0000e-04\n",
      "Epoch 133/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.7498 - val_loss: -0.8883 - learning_rate: 1.0000e-04\n",
      "Epoch 134/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.7330 - val_loss: -0.8781 - learning_rate: 1.0000e-04\n",
      "Epoch 135/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.7912 - val_loss: -0.8936 - learning_rate: 1.0000e-04\n",
      "Epoch 136/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.7315 - val_loss: -0.8882 - learning_rate: 1.0000e-04\n",
      "Epoch 137/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.7736 - val_loss: -0.9068 - learning_rate: 1.0000e-04\n",
      "Epoch 138/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.7794 - val_loss: -0.8907 - learning_rate: 1.0000e-04\n",
      "Epoch 139/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.7755 - val_loss: -0.9062 - learning_rate: 1.0000e-04\n",
      "Epoch 140/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.7937 - val_loss: -0.9091 - learning_rate: 1.0000e-04\n",
      "Epoch 141/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.7849 - val_loss: -0.9247 - learning_rate: 1.0000e-04\n",
      "Epoch 142/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.7355 - val_loss: -0.9260 - learning_rate: 1.0000e-04\n",
      "Epoch 143/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.7757 - val_loss: -0.9151 - learning_rate: 1.0000e-04\n",
      "Epoch 144/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.7942 - val_loss: -0.9256 - learning_rate: 1.0000e-04\n",
      "Epoch 145/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.7895 - val_loss: -0.9321 - learning_rate: 1.0000e-04\n",
      "Epoch 146/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7702 - val_loss: -0.9342 - learning_rate: 1.0000e-04\n",
      "Epoch 147/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.7748 - val_loss: -0.9436 - learning_rate: 1.0000e-04\n",
      "Epoch 148/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.7635 - val_loss: -0.9435 - learning_rate: 1.0000e-04\n",
      "Epoch 149/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.8277 - val_loss: -0.9327 - learning_rate: 1.0000e-04\n",
      "Epoch 150/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.8171 - val_loss: -0.9490 - learning_rate: 1.0000e-04\n",
      "Epoch 151/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.7546 - val_loss: -0.9435 - learning_rate: 1.0000e-04\n",
      "Epoch 152/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.7970 - val_loss: -0.9307 - learning_rate: 1.0000e-04\n",
      "Epoch 153/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.8279 - val_loss: -0.9503 - learning_rate: 1.0000e-04\n",
      "Epoch 154/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.8101 - val_loss: -0.9747 - learning_rate: 1.0000e-04\n",
      "Epoch 155/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.7552 - val_loss: -0.9602 - learning_rate: 1.0000e-04\n",
      "Epoch 156/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.7753 - val_loss: -0.9541 - learning_rate: 1.0000e-04\n",
      "Epoch 157/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.8197 - val_loss: -0.9729 - learning_rate: 1.0000e-04\n",
      "Epoch 158/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.7768 - val_loss: -0.9661 - learning_rate: 1.0000e-04\n",
      "Epoch 159/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.8678 - val_loss: -0.9731 - learning_rate: 1.0000e-04\n",
      "Epoch 160/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.8717 - val_loss: -0.9815 - learning_rate: 5.0000e-05\n",
      "Epoch 161/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.8491 - val_loss: -0.9787 - learning_rate: 5.0000e-05\n",
      "Epoch 162/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.8212 - val_loss: -0.9842 - learning_rate: 5.0000e-05\n",
      "Epoch 163/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.7951 - val_loss: -0.9837 - learning_rate: 5.0000e-05\n",
      "Epoch 164/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.8425 - val_loss: -0.9830 - learning_rate: 5.0000e-05\n",
      "Epoch 165/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.8035 - val_loss: -0.9971 - learning_rate: 5.0000e-05\n",
      "Epoch 166/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.8307 - val_loss: -0.9916 - learning_rate: 5.0000e-05\n",
      "Epoch 167/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.8970 - val_loss: -0.9856 - learning_rate: 5.0000e-05\n",
      "Epoch 168/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.8001 - val_loss: -0.9926 - learning_rate: 5.0000e-05\n",
      "Epoch 169/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.8551 - val_loss: -0.9930 - learning_rate: 5.0000e-05\n",
      "Epoch 170/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.8706 - val_loss: -0.9914 - learning_rate: 5.0000e-05\n",
      "Epoch 171/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.8715 - val_loss: -0.9996 - learning_rate: 2.5000e-05\n",
      "Epoch 172/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.8103 - val_loss: -1.0039 - learning_rate: 2.5000e-05\n",
      "Epoch 173/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.9092 - val_loss: -1.0050 - learning_rate: 2.5000e-05\n",
      "Epoch 174/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.8457 - val_loss: -1.0032 - learning_rate: 2.5000e-05\n",
      "Epoch 175/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.7946 - val_loss: -1.0031 - learning_rate: 2.5000e-05\n",
      "Epoch 176/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.9059 - val_loss: -1.0016 - learning_rate: 2.5000e-05\n",
      "Epoch 177/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.9076 - val_loss: -1.0009 - learning_rate: 2.5000e-05\n",
      "Epoch 178/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.8751 - val_loss: -0.9993 - learning_rate: 2.5000e-05\n",
      "Epoch 179/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.8674 - val_loss: -1.0008 - learning_rate: 1.2500e-05\n",
      "Epoch 180/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7772 - val_loss: -1.0018 - learning_rate: 1.2500e-05\n",
      "Epoch 181/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.9072 - val_loss: -0.9961 - learning_rate: 1.2500e-05\n",
      "Epoch 182/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.8658 - val_loss: -0.9985 - learning_rate: 1.2500e-05\n",
      "Epoch 183/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.9110 - val_loss: -0.9965 - learning_rate: 1.2500e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.6169 - val_loss: 0.0448 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.3510 - val_loss: 0.0208 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1907 - val_loss: 0.0136 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1916 - val_loss: 0.0081 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1277 - val_loss: 0.0053 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1063 - val_loss: 0.0135 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1000 - val_loss: 0.0029 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0917 - val_loss: 0.0052 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0748 - val_loss: 0.0035 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0765 - val_loss: 0.0042 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0586 - val_loss: 0.0038 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0481 - val_loss: 0.0038 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0365 - val_loss: 0.0031 - learning_rate: 5.0000e-05\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0586 - val_loss: 0.0032 - learning_rate: 5.0000e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0369 - val_loss: 0.0035 - learning_rate: 5.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0349 - val_loss: 0.0025 - learning_rate: 5.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0339 - val_loss: 0.0038 - learning_rate: 5.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0398 - val_loss: 0.0040 - learning_rate: 5.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0407 - val_loss: 0.0031 - learning_rate: 5.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0394 - val_loss: 0.0027 - learning_rate: 5.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0345 - val_loss: 0.0026 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0397 - val_loss: 0.0021 - learning_rate: 2.5000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0309 - val_loss: 0.0022 - learning_rate: 2.5000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0339 - val_loss: 0.0022 - learning_rate: 2.5000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0263 - val_loss: 0.0023 - learning_rate: 2.5000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0369 - val_loss: 0.0018 - learning_rate: 2.5000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0301 - val_loss: 0.0020 - learning_rate: 2.5000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0263 - val_loss: 0.0019 - learning_rate: 2.5000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0265 - val_loss: 0.0014 - learning_rate: 2.5000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0214 - val_loss: 0.0021 - learning_rate: 2.5000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0192 - val_loss: 0.0018 - learning_rate: 2.5000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0298 - val_loss: 0.0016 - learning_rate: 2.5000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0187 - val_loss: 0.0013 - learning_rate: 2.5000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0229 - val_loss: 0.0013 - learning_rate: 2.5000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0256 - val_loss: 0.0015 - learning_rate: 2.5000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0143 - val_loss: 0.0016 - learning_rate: 2.5000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0173 - val_loss: 0.0013 - learning_rate: 2.5000e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0249 - val_loss: 0.0017 - learning_rate: 2.5000e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0221 - val_loss: 0.0016 - learning_rate: 1.2500e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0232 - val_loss: 0.0014 - learning_rate: 1.2500e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0216 - val_loss: 0.0013 - learning_rate: 1.2500e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0175 - val_loss: 0.0014 - learning_rate: 1.2500e-05\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0210 - val_loss: 0.0017 - learning_rate: 1.2500e-05\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0287 - val_loss: 0.0018 - learning_rate: 6.2500e-06\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0225 - val_loss: 0.0017 - learning_rate: 6.2500e-06\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0219 - val_loss: 0.0017 - learning_rate: 6.2500e-06\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0179 - val_loss: 0.0017 - learning_rate: 6.2500e-06\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0212 - val_loss: 0.0019 - learning_rate: 6.2500e-06\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0126 - val_loss: 0.0018 - learning_rate: 3.1250e-06\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0119 - val_loss: 0.0016 - learning_rate: 3.1250e-06\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0276 - val_loss: 0.0016 - learning_rate: 3.1250e-06\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.0022 - val_loss: 0.0126 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.3276 - val_loss: -0.0654 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1999 - val_loss: -0.1331 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0747 - val_loss: -0.1764 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0182 - val_loss: -0.2122 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.0267 - val_loss: -0.2319 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.0165 - val_loss: -0.2432 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.0503 - val_loss: -0.2659 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.1161 - val_loss: -0.2868 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.1175 - val_loss: -0.2963 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.1357 - val_loss: -0.3097 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.1127 - val_loss: -0.3155 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.1635 - val_loss: -0.3251 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.1634 - val_loss: -0.3326 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.1777 - val_loss: -0.3400 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.2147 - val_loss: -0.3433 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.1878 - val_loss: -0.3539 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.1815 - val_loss: -0.3587 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.2340 - val_loss: -0.3648 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.2520 - val_loss: -0.3708 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.2130 - val_loss: -0.3795 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.2689 - val_loss: -0.3858 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.2292 - val_loss: -0.3905 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.2263 - val_loss: -0.3975 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3010 - val_loss: -0.4008 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.2972 - val_loss: -0.4049 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.2905 - val_loss: -0.4115 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3215 - val_loss: -0.4146 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.3172 - val_loss: -0.4223 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.2900 - val_loss: -0.4283 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.3066 - val_loss: -0.4329 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3133 - val_loss: -0.4368 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3310 - val_loss: -0.4395 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3173 - val_loss: -0.4440 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.3275 - val_loss: -0.4428 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.3246 - val_loss: -0.4507 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.3543 - val_loss: -0.4445 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3425 - val_loss: -0.4635 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3474 - val_loss: -0.4655 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.3780 - val_loss: -0.4709 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3767 - val_loss: -0.4735 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3868 - val_loss: -0.4807 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3781 - val_loss: -0.4829 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3710 - val_loss: -0.4848 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3943 - val_loss: -0.4920 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3826 - val_loss: -0.4966 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4010 - val_loss: -0.4978 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4100 - val_loss: -0.5006 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4062 - val_loss: -0.5083 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4278 - val_loss: -0.5082 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4327 - val_loss: -0.5169 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4096 - val_loss: -0.5233 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4474 - val_loss: -0.5268 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4597 - val_loss: -0.5314 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4506 - val_loss: -0.5352 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4324 - val_loss: -0.5382 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4482 - val_loss: -0.5467 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4352 - val_loss: -0.5462 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4675 - val_loss: -0.5522 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4717 - val_loss: -0.5499 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4296 - val_loss: -0.5573 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4505 - val_loss: -0.5593 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4454 - val_loss: -0.5629 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4562 - val_loss: -0.5714 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4618 - val_loss: -0.5754 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4867 - val_loss: -0.5746 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.5076 - val_loss: -0.5780 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5028 - val_loss: -0.5828 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5056 - val_loss: -0.5844 - learning_rate: 1.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.4793 - val_loss: -0.5887 - learning_rate: 1.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5072 - val_loss: -0.6019 - learning_rate: 1.0000e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5238 - val_loss: -0.5976 - learning_rate: 1.0000e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5080 - val_loss: -0.6011 - learning_rate: 1.0000e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5110 - val_loss: -0.6039 - learning_rate: 1.0000e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5189 - val_loss: -0.6048 - learning_rate: 1.0000e-04\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5431 - val_loss: -0.6147 - learning_rate: 1.0000e-04\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5885 - val_loss: -0.6211 - learning_rate: 1.0000e-04\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5317 - val_loss: -0.6127 - learning_rate: 1.0000e-04\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5225 - val_loss: -0.6216 - learning_rate: 1.0000e-04\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5688 - val_loss: -0.6354 - learning_rate: 1.0000e-04\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5435 - val_loss: -0.6393 - learning_rate: 1.0000e-04\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5223 - val_loss: -0.6369 - learning_rate: 1.0000e-04\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5486 - val_loss: -0.6454 - learning_rate: 1.0000e-04\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5638 - val_loss: -0.6480 - learning_rate: 1.0000e-04\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5406 - val_loss: -0.6410 - learning_rate: 1.0000e-04\n",
      "Epoch 86/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5571 - val_loss: -0.6537 - learning_rate: 1.0000e-04\n",
      "Epoch 87/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5849 - val_loss: -0.6590 - learning_rate: 1.0000e-04\n",
      "Epoch 88/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5820 - val_loss: -0.6623 - learning_rate: 1.0000e-04\n",
      "Epoch 89/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5839 - val_loss: -0.6653 - learning_rate: 1.0000e-04\n",
      "Epoch 90/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5973 - val_loss: -0.6676 - learning_rate: 1.0000e-04\n",
      "Epoch 91/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6388 - val_loss: -0.6761 - learning_rate: 1.0000e-04\n",
      "Epoch 92/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6131 - val_loss: -0.6820 - learning_rate: 1.0000e-04\n",
      "Epoch 93/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5698 - val_loss: -0.6843 - learning_rate: 1.0000e-04\n",
      "Epoch 94/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5825 - val_loss: -0.6968 - learning_rate: 1.0000e-04\n",
      "Epoch 95/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6103 - val_loss: -0.6918 - learning_rate: 1.0000e-04\n",
      "Epoch 96/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6155 - val_loss: -0.6963 - learning_rate: 1.0000e-04\n",
      "Epoch 97/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5849 - val_loss: -0.6815 - learning_rate: 1.0000e-04\n",
      "Epoch 98/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5850 - val_loss: -0.7022 - learning_rate: 1.0000e-04\n",
      "Epoch 99/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6106 - val_loss: -0.7150 - learning_rate: 1.0000e-04\n",
      "Epoch 100/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6164 - val_loss: -0.7123 - learning_rate: 1.0000e-04\n",
      "Epoch 101/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6558 - val_loss: -0.7166 - learning_rate: 1.0000e-04\n",
      "Epoch 102/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5847 - val_loss: -0.7166 - learning_rate: 1.0000e-04\n",
      "Epoch 103/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6549 - val_loss: -0.7207 - learning_rate: 1.0000e-04\n",
      "Epoch 104/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5962 - val_loss: -0.7303 - learning_rate: 1.0000e-04\n",
      "Epoch 105/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6300 - val_loss: -0.7353 - learning_rate: 1.0000e-04\n",
      "Epoch 106/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5993 - val_loss: -0.7335 - learning_rate: 1.0000e-04\n",
      "Epoch 107/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6570 - val_loss: -0.7270 - learning_rate: 1.0000e-04\n",
      "Epoch 108/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6588 - val_loss: -0.7564 - learning_rate: 1.0000e-04\n",
      "Epoch 109/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6200 - val_loss: -0.7397 - learning_rate: 1.0000e-04\n",
      "Epoch 110/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6571 - val_loss: -0.7500 - learning_rate: 1.0000e-04\n",
      "Epoch 111/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6647 - val_loss: -0.7561 - learning_rate: 1.0000e-04\n",
      "Epoch 112/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6676 - val_loss: -0.7501 - learning_rate: 1.0000e-04\n",
      "Epoch 113/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6670 - val_loss: -0.7537 - learning_rate: 1.0000e-04\n",
      "Epoch 114/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6364 - val_loss: -0.7606 - learning_rate: 5.0000e-05\n",
      "Epoch 115/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6415 - val_loss: -0.7615 - learning_rate: 5.0000e-05\n",
      "Epoch 116/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6946 - val_loss: -0.7669 - learning_rate: 5.0000e-05\n",
      "Epoch 117/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6653 - val_loss: -0.7761 - learning_rate: 5.0000e-05\n",
      "Epoch 118/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6931 - val_loss: -0.7751 - learning_rate: 5.0000e-05\n",
      "Epoch 119/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6440 - val_loss: -0.7732 - learning_rate: 5.0000e-05\n",
      "Epoch 120/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6654 - val_loss: -0.7750 - learning_rate: 5.0000e-05\n",
      "Epoch 121/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6708 - val_loss: -0.7743 - learning_rate: 5.0000e-05\n",
      "Epoch 122/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6676 - val_loss: -0.7760 - learning_rate: 5.0000e-05\n",
      "Epoch 123/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7103 - val_loss: -0.7715 - learning_rate: 2.5000e-05\n",
      "Epoch 124/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6493 - val_loss: -0.7820 - learning_rate: 2.5000e-05\n",
      "Epoch 125/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6839 - val_loss: -0.7766 - learning_rate: 2.5000e-05\n",
      "Epoch 126/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6754 - val_loss: -0.7777 - learning_rate: 2.5000e-05\n",
      "Epoch 127/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6788 - val_loss: -0.7825 - learning_rate: 2.5000e-05\n",
      "Epoch 128/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6701 - val_loss: -0.7799 - learning_rate: 2.5000e-05\n",
      "Epoch 129/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6666 - val_loss: -0.7770 - learning_rate: 2.5000e-05\n",
      "Epoch 130/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7243 - val_loss: -0.7860 - learning_rate: 2.5000e-05\n",
      "Epoch 131/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6705 - val_loss: -0.7799 - learning_rate: 2.5000e-05\n",
      "Epoch 132/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7106 - val_loss: -0.7846 - learning_rate: 2.5000e-05\n",
      "Epoch 133/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7167 - val_loss: -0.7817 - learning_rate: 2.5000e-05\n",
      "Epoch 134/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7293 - val_loss: -0.7818 - learning_rate: 2.5000e-05\n",
      "Epoch 135/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7138 - val_loss: -0.7882 - learning_rate: 2.5000e-05\n",
      "Epoch 136/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7223 - val_loss: -0.7820 - learning_rate: 2.5000e-05\n",
      "Epoch 137/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6694 - val_loss: -0.7902 - learning_rate: 2.5000e-05\n",
      "Epoch 138/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7082 - val_loss: -0.7879 - learning_rate: 2.5000e-05\n",
      "Epoch 139/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6734 - val_loss: -0.7852 - learning_rate: 2.5000e-05\n",
      "Epoch 140/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6859 - val_loss: -0.7889 - learning_rate: 2.5000e-05\n",
      "Epoch 141/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6662 - val_loss: -0.7945 - learning_rate: 2.5000e-05\n",
      "Epoch 142/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7402 - val_loss: -0.7931 - learning_rate: 2.5000e-05\n",
      "Epoch 143/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.7442 - val_loss: -0.7927 - learning_rate: 2.5000e-05\n",
      "Epoch 144/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7089 - val_loss: -0.7924 - learning_rate: 2.5000e-05\n",
      "Epoch 145/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7104 - val_loss: -0.7834 - learning_rate: 2.5000e-05\n",
      "Epoch 146/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7286 - val_loss: -0.7917 - learning_rate: 2.5000e-05\n",
      "Epoch 147/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6780 - val_loss: -0.7937 - learning_rate: 1.2500e-05\n",
      "Epoch 148/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7127 - val_loss: -0.7866 - learning_rate: 1.2500e-05\n",
      "Epoch 149/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7135 - val_loss: -0.7903 - learning_rate: 1.2500e-05\n",
      "Epoch 150/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7059 - val_loss: -0.7847 - learning_rate: 1.2500e-05\n",
      "Epoch 151/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7207 - val_loss: -0.7969 - learning_rate: 1.2500e-05\n",
      "Epoch 152/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7591 - val_loss: -0.7944 - learning_rate: 1.2500e-05\n",
      "Epoch 153/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.7171 - val_loss: -0.7955 - learning_rate: 1.2500e-05\n",
      "Epoch 154/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7241 - val_loss: -0.7938 - learning_rate: 1.2500e-05\n",
      "Epoch 155/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6999 - val_loss: -0.7965 - learning_rate: 1.2500e-05\n",
      "Epoch 156/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7164 - val_loss: -0.7995 - learning_rate: 1.2500e-05\n",
      "Epoch 157/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7322 - val_loss: -0.7971 - learning_rate: 1.2500e-05\n",
      "Epoch 158/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6714 - val_loss: -0.7962 - learning_rate: 1.2500e-05\n",
      "Epoch 159/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7646 - val_loss: -0.8005 - learning_rate: 1.2500e-05\n",
      "Epoch 160/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6862 - val_loss: -0.8060 - learning_rate: 1.2500e-05\n",
      "Epoch 161/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7150 - val_loss: -0.8034 - learning_rate: 1.2500e-05\n",
      "Epoch 162/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7622 - val_loss: -0.8008 - learning_rate: 1.2500e-05\n",
      "Epoch 163/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6961 - val_loss: -0.8034 - learning_rate: 1.2500e-05\n",
      "Epoch 164/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7139 - val_loss: -0.8007 - learning_rate: 1.2500e-05\n",
      "Epoch 165/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6833 - val_loss: -0.8012 - learning_rate: 1.2500e-05\n",
      "Epoch 166/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7192 - val_loss: -0.7949 - learning_rate: 6.2500e-06\n",
      "Epoch 167/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.7433 - val_loss: -0.8005 - learning_rate: 6.2500e-06\n",
      "Epoch 168/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6728 - val_loss: -0.8004 - learning_rate: 6.2500e-06\n",
      "Epoch 169/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.6955 - val_loss: -0.8034 - learning_rate: 6.2500e-06\n",
      "Epoch 170/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.7085 - val_loss: -0.7989 - learning_rate: 6.2500e-06\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.5984 - val_loss: 0.0885 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.4097 - val_loss: 0.0585 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.2889 - val_loss: 0.0453 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1914 - val_loss: 0.0438 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.1964 - val_loss: 0.0410 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1388 - val_loss: 0.0390 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1382 - val_loss: 0.0285 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1296 - val_loss: 0.0183 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0901 - val_loss: 0.0158 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0782 - val_loss: 0.0244 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0667 - val_loss: 0.0217 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0692 - val_loss: 0.0134 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0598 - val_loss: 0.0106 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0635 - val_loss: 0.0085 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0638 - val_loss: 0.0077 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0681 - val_loss: 0.0101 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0617 - val_loss: 0.0055 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0582 - val_loss: 0.0041 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0492 - val_loss: 0.0061 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0473 - val_loss: 0.0049 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0373 - val_loss: 0.0056 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0344 - val_loss: 0.0041 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0371 - val_loss: 0.0059 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0266 - val_loss: 0.0042 - learning_rate: 5.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0261 - val_loss: 0.0047 - learning_rate: 5.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0292 - val_loss: 0.0059 - learning_rate: 5.0000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0365 - val_loss: 0.0039 - learning_rate: 5.0000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0359 - val_loss: 0.0041 - learning_rate: 5.0000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0212 - val_loss: 0.0023 - learning_rate: 5.0000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0284 - val_loss: 0.0049 - learning_rate: 5.0000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0313 - val_loss: 0.0041 - learning_rate: 5.0000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0211 - val_loss: 0.0035 - learning_rate: 5.0000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0168 - val_loss: 0.0031 - learning_rate: 5.0000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0244 - val_loss: 0.0038 - learning_rate: 5.0000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0189 - val_loss: 0.0029 - learning_rate: 2.5000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0335 - val_loss: 0.0033 - learning_rate: 2.5000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0249 - val_loss: 0.0030 - learning_rate: 2.5000e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0199 - val_loss: 0.0036 - learning_rate: 2.5000e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0220 - val_loss: 0.0032 - learning_rate: 2.5000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.7612 - val_loss: -0.0771 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.3240 - val_loss: -0.1447 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1801 - val_loss: -0.1799 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0864 - val_loss: -0.2138 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0235 - val_loss: -0.2433 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.0581 - val_loss: -0.2524 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.0741 - val_loss: -0.2729 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.0868 - val_loss: -0.2885 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.1002 - val_loss: -0.3061 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.0695 - val_loss: -0.3080 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.1208 - val_loss: -0.3206 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.1227 - val_loss: -0.3003 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.1654 - val_loss: -0.3254 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.1882 - val_loss: -0.3520 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.1856 - val_loss: -0.3568 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.1992 - val_loss: -0.3481 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.1673 - val_loss: -0.3646 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.1820 - val_loss: -0.3739 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2028 - val_loss: -0.3797 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2487 - val_loss: -0.3821 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2314 - val_loss: -0.3788 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2108 - val_loss: -0.3859 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2864 - val_loss: -0.3933 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2768 - val_loss: -0.3941 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2581 - val_loss: -0.4000 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2817 - val_loss: -0.4042 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.2499 - val_loss: -0.4065 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.2981 - val_loss: -0.4033 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2878 - val_loss: -0.4147 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.3056 - val_loss: -0.4145 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.3181 - val_loss: -0.4148 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3266 - val_loss: -0.4146 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3381 - val_loss: -0.4024 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3313 - val_loss: -0.4199 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3155 - val_loss: -0.4216 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.3804 - val_loss: -0.4367 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.3401 - val_loss: -0.4326 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.3412 - val_loss: -0.4333 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.3842 - val_loss: -0.4277 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.3704 - val_loss: -0.4477 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.3673 - val_loss: -0.4392 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.3517 - val_loss: -0.4512 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.3800 - val_loss: -0.4610 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.3893 - val_loss: -0.4552 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.3860 - val_loss: -0.4576 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.3991 - val_loss: -0.4586 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3926 - val_loss: -0.4628 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4001 - val_loss: -0.4569 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4186 - val_loss: -0.4561 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.4399 - val_loss: -0.4594 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.4151 - val_loss: -0.4585 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.4410 - val_loss: -0.4545 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.4400 - val_loss: -0.4628 - learning_rate: 5.0000e-05\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.3947 - val_loss: -0.4678 - learning_rate: 5.0000e-05\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.4300 - val_loss: -0.4606 - learning_rate: 5.0000e-05\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.4195 - val_loss: -0.4651 - learning_rate: 5.0000e-05\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.3887 - val_loss: -0.4764 - learning_rate: 5.0000e-05\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.4544 - val_loss: -0.4694 - learning_rate: 5.0000e-05\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.4286 - val_loss: -0.4720 - learning_rate: 5.0000e-05\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.3805 - val_loss: -0.4754 - learning_rate: 5.0000e-05\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.4304 - val_loss: -0.4774 - learning_rate: 5.0000e-05\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4148 - val_loss: -0.4776 - learning_rate: 5.0000e-05\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.4462 - val_loss: -0.4750 - learning_rate: 5.0000e-05\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.4666 - val_loss: -0.4760 - learning_rate: 5.0000e-05\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.4332 - val_loss: -0.4781 - learning_rate: 5.0000e-05\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.4295 - val_loss: -0.4818 - learning_rate: 5.0000e-05\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.4827 - val_loss: -0.4826 - learning_rate: 5.0000e-05\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.4413 - val_loss: -0.4842 - learning_rate: 5.0000e-05\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.4407 - val_loss: -0.4830 - learning_rate: 5.0000e-05\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.4729 - val_loss: -0.4851 - learning_rate: 5.0000e-05\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.4380 - val_loss: -0.4903 - learning_rate: 5.0000e-05\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.4523 - val_loss: -0.4815 - learning_rate: 5.0000e-05\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.4787 - val_loss: -0.4944 - learning_rate: 5.0000e-05\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4555 - val_loss: -0.4917 - learning_rate: 5.0000e-05\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.4595 - val_loss: -0.4892 - learning_rate: 5.0000e-05\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.4384 - val_loss: -0.4950 - learning_rate: 5.0000e-05\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.4745 - val_loss: -0.4913 - learning_rate: 5.0000e-05\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5059 - val_loss: -0.4926 - learning_rate: 5.0000e-05\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4776 - val_loss: -0.4950 - learning_rate: 5.0000e-05\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4734 - val_loss: -0.4907 - learning_rate: 5.0000e-05\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.4465 - val_loss: -0.4954 - learning_rate: 5.0000e-05\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4518 - val_loss: -0.4960 - learning_rate: 5.0000e-05\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4937 - val_loss: -0.5062 - learning_rate: 5.0000e-05\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.4418 - val_loss: -0.5054 - learning_rate: 5.0000e-05\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4813 - val_loss: -0.5175 - learning_rate: 5.0000e-05\n",
      "Epoch 86/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4538 - val_loss: -0.5141 - learning_rate: 5.0000e-05\n",
      "Epoch 87/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4974 - val_loss: -0.5078 - learning_rate: 5.0000e-05\n",
      "Epoch 88/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4965 - val_loss: -0.5152 - learning_rate: 5.0000e-05\n",
      "Epoch 89/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.4662 - val_loss: -0.5127 - learning_rate: 5.0000e-05\n",
      "Epoch 90/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4834 - val_loss: -0.5137 - learning_rate: 5.0000e-05\n",
      "Epoch 91/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4822 - val_loss: -0.5131 - learning_rate: 2.5000e-05\n",
      "Epoch 92/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5016 - val_loss: -0.5111 - learning_rate: 2.5000e-05\n",
      "Epoch 93/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5011 - val_loss: -0.5175 - learning_rate: 2.5000e-05\n",
      "Epoch 94/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.5005 - val_loss: -0.5190 - learning_rate: 2.5000e-05\n",
      "Epoch 95/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4929 - val_loss: -0.5127 - learning_rate: 2.5000e-05\n",
      "Epoch 96/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5147 - val_loss: -0.5185 - learning_rate: 2.5000e-05\n",
      "Epoch 97/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4926 - val_loss: -0.5231 - learning_rate: 2.5000e-05\n",
      "Epoch 98/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5042 - val_loss: -0.5210 - learning_rate: 2.5000e-05\n",
      "Epoch 99/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.5069 - val_loss: -0.5222 - learning_rate: 2.5000e-05\n",
      "Epoch 100/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4878 - val_loss: -0.5200 - learning_rate: 2.5000e-05\n",
      "Epoch 101/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4765 - val_loss: -0.5275 - learning_rate: 2.5000e-05\n",
      "Epoch 102/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5106 - val_loss: -0.5226 - learning_rate: 2.5000e-05\n",
      "Epoch 103/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4977 - val_loss: -0.5282 - learning_rate: 2.5000e-05\n",
      "Epoch 104/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5002 - val_loss: -0.5280 - learning_rate: 2.5000e-05\n",
      "Epoch 105/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4708 - val_loss: -0.5241 - learning_rate: 2.5000e-05\n",
      "Epoch 106/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5321 - val_loss: -0.5311 - learning_rate: 2.5000e-05\n",
      "Epoch 107/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5197 - val_loss: -0.5251 - learning_rate: 2.5000e-05\n",
      "Epoch 108/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5330 - val_loss: -0.5252 - learning_rate: 2.5000e-05\n",
      "Epoch 109/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5127 - val_loss: -0.5271 - learning_rate: 2.5000e-05\n",
      "Epoch 110/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5024 - val_loss: -0.5377 - learning_rate: 2.5000e-05\n",
      "Epoch 111/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4886 - val_loss: -0.5319 - learning_rate: 2.5000e-05\n",
      "Epoch 112/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5064 - val_loss: -0.5349 - learning_rate: 2.5000e-05\n",
      "Epoch 113/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5207 - val_loss: -0.5333 - learning_rate: 2.5000e-05\n",
      "Epoch 114/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4952 - val_loss: -0.5334 - learning_rate: 2.5000e-05\n",
      "Epoch 115/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5105 - val_loss: -0.5371 - learning_rate: 2.5000e-05\n",
      "Epoch 116/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5267 - val_loss: -0.5372 - learning_rate: 1.2500e-05\n",
      "Epoch 117/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4825 - val_loss: -0.5375 - learning_rate: 1.2500e-05\n",
      "Epoch 118/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5088 - val_loss: -0.5385 - learning_rate: 1.2500e-05\n",
      "Epoch 119/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5206 - val_loss: -0.5376 - learning_rate: 1.2500e-05\n",
      "Epoch 120/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5314 - val_loss: -0.5374 - learning_rate: 1.2500e-05\n",
      "Epoch 121/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5347 - val_loss: -0.5416 - learning_rate: 1.2500e-05\n",
      "Epoch 122/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5094 - val_loss: -0.5340 - learning_rate: 1.2500e-05\n",
      "Epoch 123/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5073 - val_loss: -0.5342 - learning_rate: 1.2500e-05\n",
      "Epoch 124/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5083 - val_loss: -0.5350 - learning_rate: 1.2500e-05\n",
      "Epoch 125/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5119 - val_loss: -0.5369 - learning_rate: 1.2500e-05\n",
      "Epoch 126/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5054 - val_loss: -0.5383 - learning_rate: 1.2500e-05\n",
      "Epoch 127/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5292 - val_loss: -0.5355 - learning_rate: 6.2500e-06\n",
      "Epoch 128/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5018 - val_loss: -0.5399 - learning_rate: 6.2500e-06\n",
      "Epoch 129/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5409 - val_loss: -0.5371 - learning_rate: 6.2500e-06\n",
      "Epoch 130/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4809 - val_loss: -0.5401 - learning_rate: 6.2500e-06\n",
      "Epoch 131/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4869 - val_loss: -0.5379 - learning_rate: 6.2500e-06\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.7409 - val_loss: 0.0276 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.3580 - val_loss: 0.0301 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.2621 - val_loss: 0.0319 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1771 - val_loss: 0.0275 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1453 - val_loss: 0.0272 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1260 - val_loss: 0.0270 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1063 - val_loss: 0.0219 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0953 - val_loss: 0.0240 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0769 - val_loss: 0.0134 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0837 - val_loss: 0.0182 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0434 - val_loss: 0.0265 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0653 - val_loss: 0.0158 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0393 - val_loss: 0.0258 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0693 - val_loss: 0.0177 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0690 - val_loss: 0.0160 - learning_rate: 5.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0578 - val_loss: 0.0193 - learning_rate: 5.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0274 - val_loss: 0.0185 - learning_rate: 5.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0454 - val_loss: 0.0131 - learning_rate: 5.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0542 - val_loss: 0.0188 - learning_rate: 5.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0486 - val_loss: 0.0159 - learning_rate: 5.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0372 - val_loss: 0.0152 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0417 - val_loss: 0.0137 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0429 - val_loss: 0.0193 - learning_rate: 5.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0357 - val_loss: 0.0140 - learning_rate: 2.5000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0362 - val_loss: 0.0145 - learning_rate: 2.5000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0421 - val_loss: 0.0125 - learning_rate: 2.5000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0293 - val_loss: 0.0148 - learning_rate: 2.5000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0211 - val_loss: 0.0126 - learning_rate: 2.5000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0315 - val_loss: 0.0125 - learning_rate: 2.5000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0272 - val_loss: 0.0137 - learning_rate: 2.5000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0304 - val_loss: 0.0121 - learning_rate: 2.5000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0470 - val_loss: 0.0127 - learning_rate: 2.5000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0245 - val_loss: 0.0132 - learning_rate: 2.5000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0324 - val_loss: 0.0130 - learning_rate: 2.5000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0326 - val_loss: 0.0128 - learning_rate: 2.5000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0381 - val_loss: 0.0126 - learning_rate: 2.5000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0239 - val_loss: 0.0114 - learning_rate: 1.2500e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0417 - val_loss: 0.0121 - learning_rate: 1.2500e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0217 - val_loss: 0.0109 - learning_rate: 1.2500e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0321 - val_loss: 0.0111 - learning_rate: 1.2500e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0181 - val_loss: 0.0113 - learning_rate: 1.2500e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0303 - val_loss: 0.0120 - learning_rate: 1.2500e-05\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0253 - val_loss: 0.0112 - learning_rate: 1.2500e-05\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0406 - val_loss: 0.0106 - learning_rate: 1.2500e-05\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0353 - val_loss: 0.0114 - learning_rate: 1.2500e-05\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0208 - val_loss: 0.0106 - learning_rate: 1.2500e-05\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0248 - val_loss: 0.0106 - learning_rate: 1.2500e-05\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0244 - val_loss: 0.0115 - learning_rate: 1.2500e-05\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0174 - val_loss: 0.0128 - learning_rate: 1.2500e-05\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0143 - val_loss: 0.0128 - learning_rate: 6.2500e-06\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0129 - val_loss: 0.0121 - learning_rate: 6.2500e-06\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0214 - val_loss: 0.0121 - learning_rate: 6.2500e-06\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0325 - val_loss: 0.0128 - learning_rate: 6.2500e-06\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0219 - val_loss: 0.0128 - learning_rate: 6.2500e-06\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0247 - val_loss: 0.0127 - learning_rate: 3.1250e-06\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0177 - val_loss: 0.0121 - learning_rate: 3.1250e-06\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.5010 - val_loss: -0.0149 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.2894 - val_loss: -0.0765 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1310 - val_loss: -0.1344 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0552 - val_loss: -0.1711 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.0123 - val_loss: -0.2039 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.0371 - val_loss: -0.2282 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.0761 - val_loss: -0.2311 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.0676 - val_loss: -0.2639 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.0606 - val_loss: -0.2790 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.1276 - val_loss: -0.2941 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.1208 - val_loss: -0.2914 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.1473 - val_loss: -0.3123 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.1705 - val_loss: -0.3209 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.1687 - val_loss: -0.3341 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.1947 - val_loss: -0.3387 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.1859 - val_loss: -0.3362 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.2078 - val_loss: -0.3504 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.1950 - val_loss: -0.3599 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.2189 - val_loss: -0.3697 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.2516 - val_loss: -0.3455 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.2591 - val_loss: -0.3718 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.2420 - val_loss: -0.3829 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.2644 - val_loss: -0.3776 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2671 - val_loss: -0.3893 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.2343 - val_loss: -0.3916 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2416 - val_loss: -0.4063 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.2871 - val_loss: -0.4029 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.2808 - val_loss: -0.4089 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3114 - val_loss: -0.4017 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.2755 - val_loss: -0.3938 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.2870 - val_loss: -0.4073 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3233 - val_loss: -0.4330 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3275 - val_loss: -0.4303 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3295 - val_loss: -0.4289 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3122 - val_loss: -0.4336 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3347 - val_loss: -0.4307 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3156 - val_loss: -0.4529 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3662 - val_loss: -0.4639 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3339 - val_loss: -0.4683 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.3355 - val_loss: -0.4747 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3676 - val_loss: -0.4708 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3667 - val_loss: -0.4818 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3639 - val_loss: -0.4830 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3710 - val_loss: -0.4870 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3915 - val_loss: -0.4968 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4004 - val_loss: -0.4946 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3765 - val_loss: -0.5030 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.3834 - val_loss: -0.4951 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.4007 - val_loss: -0.5043 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.4174 - val_loss: -0.5116 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3735 - val_loss: -0.4891 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.4072 - val_loss: -0.5025 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4279 - val_loss: -0.5128 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4145 - val_loss: -0.5145 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4552 - val_loss: -0.5327 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.4085 - val_loss: -0.5234 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4207 - val_loss: -0.5097 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4577 - val_loss: -0.5107 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.4085 - val_loss: -0.5452 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4644 - val_loss: -0.5412 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4280 - val_loss: -0.5393 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4725 - val_loss: -0.5655 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4607 - val_loss: -0.5619 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4460 - val_loss: -0.5557 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4479 - val_loss: -0.5565 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4887 - val_loss: -0.5582 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4575 - val_loss: -0.5753 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5119 - val_loss: -0.5889 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.5001 - val_loss: -0.5715 - learning_rate: 1.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4867 - val_loss: -0.5764 - learning_rate: 1.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.5071 - val_loss: -0.5926 - learning_rate: 1.0000e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.5094 - val_loss: -0.5913 - learning_rate: 1.0000e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4905 - val_loss: -0.5822 - learning_rate: 1.0000e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4885 - val_loss: -0.5918 - learning_rate: 1.0000e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5003 - val_loss: -0.5845 - learning_rate: 1.0000e-04\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5065 - val_loss: -0.6002 - learning_rate: 1.0000e-04\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4936 - val_loss: -0.6173 - learning_rate: 1.0000e-04\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5219 - val_loss: -0.6282 - learning_rate: 1.0000e-04\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5154 - val_loss: -0.6346 - learning_rate: 1.0000e-04\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5279 - val_loss: -0.6169 - learning_rate: 1.0000e-04\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5017 - val_loss: -0.6262 - learning_rate: 1.0000e-04\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5724 - val_loss: -0.6249 - learning_rate: 1.0000e-04\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5314 - val_loss: -0.6342 - learning_rate: 1.0000e-04\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5486 - val_loss: -0.6239 - learning_rate: 1.0000e-04\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5573 - val_loss: -0.6379 - learning_rate: 5.0000e-05\n",
      "Epoch 86/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5170 - val_loss: -0.6367 - learning_rate: 5.0000e-05\n",
      "Epoch 87/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5441 - val_loss: -0.6336 - learning_rate: 5.0000e-05\n",
      "Epoch 88/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5532 - val_loss: -0.6311 - learning_rate: 5.0000e-05\n",
      "Epoch 89/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5900 - val_loss: -0.6351 - learning_rate: 5.0000e-05\n",
      "Epoch 90/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5322 - val_loss: -0.6326 - learning_rate: 5.0000e-05\n",
      "Epoch 91/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5570 - val_loss: -0.6369 - learning_rate: 2.5000e-05\n",
      "Epoch 92/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5734 - val_loss: -0.6359 - learning_rate: 2.5000e-05\n",
      "Epoch 93/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5775 - val_loss: -0.6345 - learning_rate: 2.5000e-05\n",
      "Epoch 94/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.5522 - val_loss: -0.6389 - learning_rate: 2.5000e-05\n",
      "Epoch 95/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.6083 - val_loss: -0.6336 - learning_rate: 2.5000e-05\n",
      "Epoch 96/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5620 - val_loss: -0.6348 - learning_rate: 2.5000e-05\n",
      "Epoch 97/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5406 - val_loss: -0.6456 - learning_rate: 2.5000e-05\n",
      "Epoch 98/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5311 - val_loss: -0.6449 - learning_rate: 2.5000e-05\n",
      "Epoch 99/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5756 - val_loss: -0.6394 - learning_rate: 2.5000e-05\n",
      "Epoch 100/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5797 - val_loss: -0.6331 - learning_rate: 2.5000e-05\n",
      "Epoch 101/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5625 - val_loss: -0.6360 - learning_rate: 2.5000e-05\n",
      "Epoch 102/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.6013 - val_loss: -0.6431 - learning_rate: 2.5000e-05\n",
      "Epoch 103/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5809 - val_loss: -0.6508 - learning_rate: 1.2500e-05\n",
      "Epoch 104/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5435 - val_loss: -0.6432 - learning_rate: 1.2500e-05\n",
      "Epoch 105/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5943 - val_loss: -0.6486 - learning_rate: 1.2500e-05\n",
      "Epoch 106/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5868 - val_loss: -0.6421 - learning_rate: 1.2500e-05\n",
      "Epoch 107/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.5835 - val_loss: -0.6508 - learning_rate: 1.2500e-05\n",
      "Epoch 108/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5679 - val_loss: -0.6508 - learning_rate: 1.2500e-05\n",
      "Epoch 109/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5432 - val_loss: -0.6464 - learning_rate: 6.2500e-06\n",
      "Epoch 110/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.5742 - val_loss: -0.6490 - learning_rate: 6.2500e-06\n",
      "Epoch 111/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.5659 - val_loss: -0.6492 - learning_rate: 6.2500e-06\n",
      "Epoch 112/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5620 - val_loss: -0.6436 - learning_rate: 6.2500e-06\n",
      "Epoch 113/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5662 - val_loss: -0.6481 - learning_rate: 6.2500e-06\n",
      "Epoch 114/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5481 - val_loss: -0.6447 - learning_rate: 3.1250e-06\n",
      "Epoch 115/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.5796 - val_loss: -0.6428 - learning_rate: 3.1250e-06\n",
      "Epoch 116/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.6029 - val_loss: -0.6511 - learning_rate: 3.1250e-06\n",
      "Epoch 117/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5763 - val_loss: -0.6504 - learning_rate: 3.1250e-06\n",
      "Epoch 118/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5910 - val_loss: -0.6411 - learning_rate: 3.1250e-06\n",
      "Epoch 119/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5192 - val_loss: -0.6481 - learning_rate: 3.1250e-06\n",
      "Epoch 120/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.5485 - val_loss: -0.6491 - learning_rate: 3.1250e-06\n",
      "Epoch 121/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5637 - val_loss: -0.6533 - learning_rate: 3.1250e-06\n",
      "Epoch 122/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5865 - val_loss: -0.6465 - learning_rate: 3.1250e-06\n",
      "Epoch 123/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5697 - val_loss: -0.6480 - learning_rate: 3.1250e-06\n",
      "Epoch 124/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5604 - val_loss: -0.6497 - learning_rate: 3.1250e-06\n",
      "Epoch 125/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.6367 - val_loss: -0.6489 - learning_rate: 3.1250e-06\n",
      "Epoch 126/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5652 - val_loss: -0.6521 - learning_rate: 3.1250e-06\n",
      "Epoch 127/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5753 - val_loss: -0.6491 - learning_rate: 1.5625e-06\n",
      "Epoch 128/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5669 - val_loss: -0.6480 - learning_rate: 1.5625e-06\n",
      "Epoch 129/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5736 - val_loss: -0.6508 - learning_rate: 1.5625e-06\n",
      "Epoch 130/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.5993 - val_loss: -0.6482 - learning_rate: 1.5625e-06\n",
      "Epoch 131/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5838 - val_loss: -0.6496 - learning_rate: 1.5625e-06\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.5472 - val_loss: 0.0413 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.2766 - val_loss: 0.0161 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.2141 - val_loss: 0.0129 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1588 - val_loss: 0.0139 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1314 - val_loss: 0.0170 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1327 - val_loss: 0.0094 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0797 - val_loss: 0.0156 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0783 - val_loss: 0.0091 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0635 - val_loss: 0.0073 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0591 - val_loss: 0.0075 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0514 - val_loss: 0.0039 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0443 - val_loss: 0.0077 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0477 - val_loss: 0.0046 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0476 - val_loss: 0.0056 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0424 - val_loss: 0.0089 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0415 - val_loss: 0.0100 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0300 - val_loss: 0.0059 - learning_rate: 5.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0313 - val_loss: 0.0041 - learning_rate: 5.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0282 - val_loss: 0.0044 - learning_rate: 5.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0353 - val_loss: 0.0025 - learning_rate: 5.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0415 - val_loss: 0.0025 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0306 - val_loss: 0.0031 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0291 - val_loss: 0.0030 - learning_rate: 5.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0309 - val_loss: 0.0034 - learning_rate: 5.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0273 - val_loss: 0.0038 - learning_rate: 5.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0273 - val_loss: 0.0038 - learning_rate: 2.5000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0195 - val_loss: 0.0030 - learning_rate: 2.5000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0177 - val_loss: 0.0040 - learning_rate: 2.5000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0236 - val_loss: 0.0035 - learning_rate: 2.5000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0360 - val_loss: 0.0029 - learning_rate: 2.5000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.6796 - val_loss: -0.0509 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.2184 - val_loss: -0.1457 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1013 - val_loss: -0.1949 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0208 - val_loss: -0.2284 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.0208 - val_loss: -0.2487 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.0439 - val_loss: -0.2590 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.0834 - val_loss: -0.2876 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.0695 - val_loss: -0.2989 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.1327 - val_loss: -0.3107 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.1343 - val_loss: -0.3242 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.1278 - val_loss: -0.3357 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.1383 - val_loss: -0.3441 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.1617 - val_loss: -0.3519 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.1744 - val_loss: -0.3497 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.1975 - val_loss: -0.3664 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.1862 - val_loss: -0.3725 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.1985 - val_loss: -0.3818 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.1830 - val_loss: -0.3821 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2431 - val_loss: -0.3895 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.2147 - val_loss: -0.3906 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.2119 - val_loss: -0.3935 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.2519 - val_loss: -0.4006 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.2152 - val_loss: -0.4055 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.2375 - val_loss: -0.4135 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.2697 - val_loss: -0.4179 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.2682 - val_loss: -0.4199 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.2719 - val_loss: -0.4292 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.2803 - val_loss: -0.4317 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3084 - val_loss: -0.4362 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3024 - val_loss: -0.4420 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3119 - val_loss: -0.4473 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.3105 - val_loss: -0.4478 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.3122 - val_loss: -0.4530 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3382 - val_loss: -0.4650 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3318 - val_loss: -0.4689 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.3543 - val_loss: -0.4768 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.3532 - val_loss: -0.4782 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.3297 - val_loss: -0.4723 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.3408 - val_loss: -0.4868 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.3589 - val_loss: -0.4905 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.3701 - val_loss: -0.5002 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.3741 - val_loss: -0.5048 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.3925 - val_loss: -0.5060 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.3677 - val_loss: -0.5007 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.3990 - val_loss: -0.5147 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.4087 - val_loss: -0.5203 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.3792 - val_loss: -0.5268 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.3878 - val_loss: -0.5216 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.4147 - val_loss: -0.5248 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.4241 - val_loss: -0.5320 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.4313 - val_loss: -0.5220 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.4270 - val_loss: -0.5390 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.4243 - val_loss: -0.5378 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.4297 - val_loss: -0.5436 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.4233 - val_loss: -0.5310 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.4289 - val_loss: -0.5428 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.4116 - val_loss: -0.5470 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.4257 - val_loss: -0.5535 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.4252 - val_loss: -0.5646 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.4444 - val_loss: -0.5620 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.4210 - val_loss: -0.5572 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.4395 - val_loss: -0.5657 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.4624 - val_loss: -0.5670 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.4567 - val_loss: -0.5668 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.4736 - val_loss: -0.5604 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.4465 - val_loss: -0.5676 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.4594 - val_loss: -0.5749 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.4720 - val_loss: -0.5838 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.4823 - val_loss: -0.5912 - learning_rate: 1.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.5037 - val_loss: -0.5910 - learning_rate: 1.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.4699 - val_loss: -0.5936 - learning_rate: 1.0000e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.5252 - val_loss: -0.6056 - learning_rate: 1.0000e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.5107 - val_loss: -0.6151 - learning_rate: 1.0000e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5160 - val_loss: -0.6149 - learning_rate: 1.0000e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.4999 - val_loss: -0.6127 - learning_rate: 1.0000e-04\n",
      "Epoch 76/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.5200 - val_loss: -0.6164 - learning_rate: 1.0000e-04\n",
      "Epoch 77/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.4927 - val_loss: -0.6232 - learning_rate: 1.0000e-04\n",
      "Epoch 78/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5265 - val_loss: -0.6265 - learning_rate: 1.0000e-04\n",
      "Epoch 79/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.5401 - val_loss: -0.6295 - learning_rate: 1.0000e-04\n",
      "Epoch 80/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5152 - val_loss: -0.6231 - learning_rate: 1.0000e-04\n",
      "Epoch 81/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.5225 - val_loss: -0.6427 - learning_rate: 1.0000e-04\n",
      "Epoch 82/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.5441 - val_loss: -0.6410 - learning_rate: 1.0000e-04\n",
      "Epoch 83/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.5288 - val_loss: -0.6435 - learning_rate: 1.0000e-04\n",
      "Epoch 84/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5525 - val_loss: -0.6381 - learning_rate: 1.0000e-04\n",
      "Epoch 85/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.5064 - val_loss: -0.6318 - learning_rate: 1.0000e-04\n",
      "Epoch 86/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5819 - val_loss: -0.6430 - learning_rate: 1.0000e-04\n",
      "Epoch 87/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.5927 - val_loss: -0.6474 - learning_rate: 1.0000e-04\n",
      "Epoch 88/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.5390 - val_loss: -0.6477 - learning_rate: 1.0000e-04\n",
      "Epoch 89/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.5295 - val_loss: -0.6444 - learning_rate: 1.0000e-04\n",
      "Epoch 90/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5711 - val_loss: -0.6474 - learning_rate: 1.0000e-04\n",
      "Epoch 91/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.6227 - val_loss: -0.6654 - learning_rate: 1.0000e-04\n",
      "Epoch 92/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.5727 - val_loss: -0.6621 - learning_rate: 1.0000e-04\n",
      "Epoch 93/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.5813 - val_loss: -0.6676 - learning_rate: 1.0000e-04\n",
      "Epoch 94/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.5687 - val_loss: -0.6566 - learning_rate: 1.0000e-04\n",
      "Epoch 95/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.6018 - val_loss: -0.6723 - learning_rate: 1.0000e-04\n",
      "Epoch 96/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5381 - val_loss: -0.6820 - learning_rate: 1.0000e-04\n",
      "Epoch 97/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.6216 - val_loss: -0.6697 - learning_rate: 1.0000e-04\n",
      "Epoch 98/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.5555 - val_loss: -0.6744 - learning_rate: 1.0000e-04\n",
      "Epoch 99/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5852 - val_loss: -0.6870 - learning_rate: 1.0000e-04\n",
      "Epoch 100/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5570 - val_loss: -0.6890 - learning_rate: 1.0000e-04\n",
      "Epoch 101/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5797 - val_loss: -0.6810 - learning_rate: 1.0000e-04\n",
      "Epoch 102/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.5918 - val_loss: -0.6919 - learning_rate: 1.0000e-04\n",
      "Epoch 103/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.5924 - val_loss: -0.7062 - learning_rate: 1.0000e-04\n",
      "Epoch 104/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.5835 - val_loss: -0.7035 - learning_rate: 1.0000e-04\n",
      "Epoch 105/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.6572 - val_loss: -0.7189 - learning_rate: 1.0000e-04\n",
      "Epoch 106/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.5880 - val_loss: -0.7172 - learning_rate: 1.0000e-04\n",
      "Epoch 107/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.6322 - val_loss: -0.7230 - learning_rate: 1.0000e-04\n",
      "Epoch 108/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6428 - val_loss: -0.7236 - learning_rate: 1.0000e-04\n",
      "Epoch 109/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.6138 - val_loss: -0.7132 - learning_rate: 1.0000e-04\n",
      "Epoch 110/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.6572 - val_loss: -0.7140 - learning_rate: 1.0000e-04\n",
      "Epoch 111/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5531 - val_loss: -0.7281 - learning_rate: 1.0000e-04\n",
      "Epoch 112/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5876 - val_loss: -0.7220 - learning_rate: 1.0000e-04\n",
      "Epoch 113/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6296 - val_loss: -0.7447 - learning_rate: 1.0000e-04\n",
      "Epoch 114/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.6554 - val_loss: -0.7294 - learning_rate: 1.0000e-04\n",
      "Epoch 115/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.5844 - val_loss: -0.7547 - learning_rate: 1.0000e-04\n",
      "Epoch 116/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.6283 - val_loss: -0.7558 - learning_rate: 1.0000e-04\n",
      "Epoch 117/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.5718 - val_loss: -0.7364 - learning_rate: 1.0000e-04\n",
      "Epoch 118/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.6462 - val_loss: -0.7346 - learning_rate: 1.0000e-04\n",
      "Epoch 119/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.6740 - val_loss: -0.7401 - learning_rate: 1.0000e-04\n",
      "Epoch 120/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.5916 - val_loss: -0.7501 - learning_rate: 1.0000e-04\n",
      "Epoch 121/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5854 - val_loss: -0.7542 - learning_rate: 1.0000e-04\n",
      "Epoch 122/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5986 - val_loss: -0.7563 - learning_rate: 5.0000e-05\n",
      "Epoch 123/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.6191 - val_loss: -0.7659 - learning_rate: 5.0000e-05\n",
      "Epoch 124/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.5769 - val_loss: -0.7565 - learning_rate: 5.0000e-05\n",
      "Epoch 125/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.5861 - val_loss: -0.7606 - learning_rate: 5.0000e-05\n",
      "Epoch 126/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.6234 - val_loss: -0.7688 - learning_rate: 5.0000e-05\n",
      "Epoch 127/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: -0.6901 - val_loss: -0.7773 - learning_rate: 5.0000e-05\n",
      "Epoch 128/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6981 - val_loss: -0.7758 - learning_rate: 5.0000e-05\n",
      "Epoch 129/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6145 - val_loss: -0.7741 - learning_rate: 5.0000e-05\n",
      "Epoch 130/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.6059 - val_loss: -0.7763 - learning_rate: 5.0000e-05\n",
      "Epoch 131/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.5968 - val_loss: -0.7753 - learning_rate: 5.0000e-05\n",
      "Epoch 132/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.6209 - val_loss: -0.7889 - learning_rate: 5.0000e-05\n",
      "Epoch 133/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.7096 - val_loss: -0.7888 - learning_rate: 5.0000e-05\n",
      "Epoch 134/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6885 - val_loss: -0.7807 - learning_rate: 5.0000e-05\n",
      "Epoch 135/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.7127 - val_loss: -0.7877 - learning_rate: 5.0000e-05\n",
      "Epoch 136/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6183 - val_loss: -0.7897 - learning_rate: 5.0000e-05\n",
      "Epoch 137/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6879 - val_loss: -0.7888 - learning_rate: 5.0000e-05\n",
      "Epoch 138/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.6056 - val_loss: -0.7980 - learning_rate: 5.0000e-05\n",
      "Epoch 139/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.7337 - val_loss: -0.7861 - learning_rate: 5.0000e-05\n",
      "Epoch 140/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.6797 - val_loss: -0.7932 - learning_rate: 5.0000e-05\n",
      "Epoch 141/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.6901 - val_loss: -0.7936 - learning_rate: 5.0000e-05\n",
      "Epoch 142/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.6779 - val_loss: -0.7884 - learning_rate: 5.0000e-05\n",
      "Epoch 143/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.6382 - val_loss: -0.8043 - learning_rate: 5.0000e-05\n",
      "Epoch 144/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.5466 - val_loss: -0.7931 - learning_rate: 5.0000e-05\n",
      "Epoch 145/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.6727 - val_loss: -0.8066 - learning_rate: 5.0000e-05\n",
      "Epoch 146/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7457 - val_loss: -0.7973 - learning_rate: 5.0000e-05\n",
      "Epoch 147/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.6039 - val_loss: -0.8113 - learning_rate: 5.0000e-05\n",
      "Epoch 148/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6988 - val_loss: -0.8023 - learning_rate: 5.0000e-05\n",
      "Epoch 149/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6461 - val_loss: -0.8025 - learning_rate: 5.0000e-05\n",
      "Epoch 150/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.6548 - val_loss: -0.7952 - learning_rate: 5.0000e-05\n",
      "Epoch 151/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: -0.6510 - val_loss: -0.8000 - learning_rate: 5.0000e-05\n",
      "Epoch 152/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.6554 - val_loss: -0.8098 - learning_rate: 5.0000e-05\n",
      "Epoch 153/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: -0.7316 - val_loss: -0.7967 - learning_rate: 2.5000e-05\n",
      "Epoch 154/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.7325 - val_loss: -0.7986 - learning_rate: 2.5000e-05\n",
      "Epoch 155/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.6629 - val_loss: -0.8004 - learning_rate: 2.5000e-05\n",
      "Epoch 156/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.5793 - val_loss: -0.8041 - learning_rate: 2.5000e-05\n",
      "Epoch 157/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: -0.7077 - val_loss: -0.8068 - learning_rate: 2.5000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.7675 - val_loss: 0.0285 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.4295 - val_loss: 0.0249 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.3171 - val_loss: 0.0289 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1738 - val_loss: 0.0241 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1839 - val_loss: 0.0163 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1424 - val_loss: 0.0203 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1064 - val_loss: 0.0151 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0965 - val_loss: 0.0162 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0723 - val_loss: 0.0120 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0859 - val_loss: 0.0175 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0775 - val_loss: 0.0138 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0722 - val_loss: 0.0107 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0575 - val_loss: 0.0080 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0375 - val_loss: 0.0110 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0632 - val_loss: 0.0092 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0427 - val_loss: 0.0150 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0468 - val_loss: 0.0090 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0361 - val_loss: 0.0114 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0434 - val_loss: 0.0123 - learning_rate: 5.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0479 - val_loss: 0.0153 - learning_rate: 5.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0311 - val_loss: 0.0098 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0327 - val_loss: 0.0087 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0402 - val_loss: 0.0089 - learning_rate: 5.0000e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsgAAAGoCAYAAABbtxOxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA2SklEQVR4nO3dd5gtVZn3/e8PDgygICpHRRAPMoiDAcRjdlAwERxQxxzBgDqDio4BH59R1HmfwTjqGBhQzFlBQVTAAI4B5YCAREVAOIJwwIQJBO/3j6rWou3eXbvP2b07fD/XVVfvCqvq7t17r7p71apVqSokSZIkNdYbdwCSJEnSfGKCLEmSJHWYIEuSJEkdJsiSJElShwmyJEmS1GGCLEmSJHWYIEvrWJKTkjxnmnVfTvLMuY5JkpayJPsl+dY0656a5IS5jknzmwmy5p0kT0myKslvk1zRJpUPatcdkqSSvGhSmYPa5Ye08w9JsnrAMS5J8of2GD9P8sEkNx/pLwZU1Z5V9aFRH0eS4C913cMGrE+Si5KcO8W6uyY5Ickvk/wqyWlJ9uqs/z9JLm7r0dVJPjWp/KOSfD/J75Jck+RjSbYeEMshSf7U7u9XSb6T5P6z/d37qqqPVdUjRn0cLSwmyJpXkrwUeDvw/4DbAtsA7wH27Wz2I2ByK+wz2uXD+KequjmwM3BP4FXDRyxJC9quwG2AOyW596R1xwIn0tTFtwFeBPwGoL0S9nTgYW09uhL42kTBJI8DPg68A9gCuCtwHfCtJLccEM+n2v1tAXwD+Mza/oLSbJgga95Icgvg9cC/VtVRVfW7qvpTVR1bVS/vbHoqsEmSu7bl7gps3C4fWlX9HDieJlGeiOXgJD9Jcm2Sc5M8prNuvyTfSvKWtmXl4iR7TvM7bZnkrCQva+f/0v1ipv0k2TbJN9sYvprk3Uk+OpvfUZKm8UzgC8CX6DQ8JNkC2BY4oqqub6dvV9VEN4V7A8dX1U+gqUer6vC2bIC3Av/Rts7+oa1nnwP8FnjJTEFV1Q3Ax4Ctkixv93ufJN9tW5evSPKuJBt2Yq4kz0/y47ZOfXcby99I8ua2/r3F5O4Xg/aTZP0kb01ydVtnH9huv6zf262FwgRZ88n9gY2Ao3ts+xGaVmNoKvUPz/ag7SW/PYELO4t/AvwjcAvgdcBHk2zZWX9f4AKaVo43Ae+fXBEnWQGcDLyrqt4yzeEH7efjwPeBWwOH0LTWSNI6kWQT4HE0iejHgCd1Es5raOrEjyZ5dJLbTip+CvCMJC9PsjLJ+p11O9Bc/btJ629V/Rn4HPDwHrFtSFPHXwP8sl18I01yvQXN+eKhwL9MKvoomuR9J+AJwCMn7Xe9JEcA9wAeUVW/niaE6fbzXJrzxc7ALsCjZ/pdtDCZIGs+uTVwddtyMJOPAk9OsgHwpHZ+WJ9Pci1wGXAV8NqJFVX1maq6vKr+XFWfAn4M3KdT9qdVdURV3Qh8CNiS5jLkhB2Bk4DXTrSqTGPK/STZhqZyfk3bcvMt4JhZ/I6SNJ3H0nR7OAH4IrAM2BugqgrYDbiEpjX4ivaK1vbt+o8CL6RJHE8GrkpycLvfLdqfV0xxzCs666fyhCS/Av5Ak4w+buKcUFWnVdUpVXVDVV0C/A/w4EnlD62qX1XVpTRdNHburNsA+ARwK5oudr8fEMd0+3kC8I6qWl1VvwQOHbAPLWAmyJpPrgG26HOpqq20LqTpq/zjqrpsFsd7dFVtCjwEuAudSjvJM5Kc0V7K+xVwN25aqf+8E8tEJdu9ye+pwM+Az84Qw3T7uT3wi0kV+Gx+R0mazjOBT7cJ53XAUXS6WbRJ4IFVtR1wR+B3dK7Wtd0nHgZsDjwfeH2SRwJXt5t0r7rRWXb1FMsnfLqqNqdpcDgbuNfEiiR3TvLFNDdW/4am/p+cbP+88/r33LRe/nua+1leV1XXD4hh0H5uz03rYuvlRcoEWfPJd4E/0v+S1YeBf2MtulcAVNXJwAeBtwAkuSNwBHAgcOu2sj4bmLIv2zQOoTkJfHzSpce+rgBu1V4CnXCHWexHkv5G27Vsd+BpbcL5c5ruFnu1/Y9vom2EeDdNY8HkdX+qqs8AZ7XrLwBWA4+fdMz1gH+mczPfdKrqauB5wCGd7m3vBc4Htq+qzYD/w3D18nnA/sCXk+wwRLmuK4DuSBzWy4uUCbLmjbYv2GuAd7d93jZJskGSPZO8aYoinwIeAXx6HRz+7cDDk+wM3AwoYA1Akv2Z4qQwgz/RnBxuBnykPTH0VlU/BVbRnBw2bIc6+qchY5AkgA2SbNSZltHc0/Ajmv7CO7fTnWkS2ycnuWWS1yX5+7bf7hbAs2j6Hk/cZLx3kk3b9XvSjFTxvbZ7xsuA/5tm2M6Nk9wOeB+wGfBffYKuqvNpbqB+RbtoU5pRNH6b5C7AC4Z9I6rqEzSJ9VeTbDdseZrzzYuTbJVkc+CVs9iHFgATZM0rVfU24KXA/6VJUC+jacn9/BTb/qGqvlpVf1gHx11D0xL971V1Lk2fu+8CVwJ3B749i31eT9PH7zbAkcMmyTTdNO5P0/XkP2j+Ibhu2DgkLXlfounTOzEdQtOV4j3t6BN/mYDD2nXXAyuAr9IkpWfT1D/7tfv8DU2ieSnwK5qbjF8wMcpFe+/G02luqrsaOJdmtKEHVtU1Q8T+ZuCAJLehSbqfAlxLc5XvU4MKTqcdi/71wNfbm6mHcQRNn+2zgB/QvLc30NxAqEUkzT96kua7NIPwn19Vr51xY0nSyLUt54dV1R3HHYvWLVuQpXkqyb2TbNdevtyD5uaSz485LElastruInslWZZkK5rRj/oMTaoFxgRZmr9uRzNU3G+Bd9JcvvzBWCOSpKUtNGPj/5Kmi8V5NPfOaJGxi4UkSZLUYQuyJEmS1LHgnh2+xRZb1IoVK8YdhiStc6eddtrVVbV83HFMZr0rabGart5dcAnyihUrWLVq1bjDkKR1LslP5+g4LwGeQzPe9w+B/avqj9Ntb70rabGart61i4UkLSHtnfcvAlZW1d2A9YEnjTcqSZpfTJAlaelZBmzcPlFtE+DyMccjSfOKCbIkLSFV9TPgLTRPQLsC+HVVnTB5uyQHJFmVZNWaNWvmOkxJGisTZElaQpLckuahM9sCtwduluRpk7erqsOramVVrVy+fN7dNyhJI2WCLElLy8OAi6tqTVX9CTgKeMCYY5KkecUEWZKWlkuB+yXZJEmAh9I8DUyS1DJBlqQlpKq+B3wWOJ1miLf1gMPHGpQkzTMLbhxkSdLaqarXAq8ddxySNF/ZgixJkiR1mCBLkiRJHSbIkiRJUocJsiRJktRhgixJkiR1mCBLkiRJHSbIkiRJUocJsiRJktSxZB4UsuLg44ba/pJD9x5RJJK0NFjvSlqobEGWJEmSOkyQJUmSpA4TZEmSJKnDBFmSJEnqMEGWJEmSOkyQJUmSpA4TZEmSJKnDBFmSJEnqMEGWJEmSOkyQJUmSpA4TZEmSJKnDBFmSJEnqMEGWJEmSOkyQJUmSpA4TZEmSJKnDBFmSJEnqMEGWJEmSOkyQJUmSpA4TZEmSJKnDBFmSJEnqMEGWJEmSOkyQJUmSpA4TZEmSJKlj2bgDWAhWHHxc720vOXTvEUYiSZKkUbMFWZIkSeowQZYkSZI67GIxQnbNkCRJWnhsQZakJSTJDknO6Ey/SXLQuOOSpPnEFmRJWkKq6gJgZ4Ak6wM/A44eZ0ySNN/YgixJS9dDgZ9U1U/HHYgkzScmyJK0dD0J+MRUK5IckGRVklVr1qyZ47AkabzsYjEPDXNzH3iDn6ThJdkQ2Ad41VTrq+pw4HCAlStX1hyGJkljZwuyJC1NewKnV9WV4w5EkuYbE2RJWpqezDTdKyRpqbOLxSLj2MuSZpJkE+DhwPPGHYskzUcmyJK0xFTV74FbjzsOSZqv7GIhSZIkdZggS5IkSR0myJIkSVKHCbIkSZLUYYIsSZIkdZggS5IkSR0myJIkSVKHCbIkSZLUYYIsSZIkdZggS5IkSR0jTZCT7JHkgiQXJjl4ivW3SHJskjOTnJNk/1HGI0mSJM1kZAlykvWBdwN7AjsCT06y46TN/hU4t6p2Ah4CvDXJhqOKSZIkSZrJKFuQ7wNcWFUXVdX1wCeBfSdtU8CmSQLcHPgFcMMIY5IkSZIGGmWCvBVwWWd+dbus613APwCXAz8EXlxVfx5hTJIkSdJAo0yQM8WymjT/SOAM4PbAzsC7kmz2NztKDkiyKsmqNWvWrOs4JUmSpL8YZYK8GrhDZ35rmpbirv2Bo6pxIXAxcJfJO6qqw6tqZVWtXL58+cgCliRJkkaZIJ8KbJ9k2/bGuycBx0za5lLgoQBJbgvsAFw0wpgkSZKkgZaNasdVdUOSA4HjgfWBI6vqnCTPb9cfBrwB+GCSH9J0yXhlVV09qpgkSZKkmYwsQQaoqi8BX5q07LDO68uBR4wyBkmSJGkYPklPkiRJ6jBBliRJkjpMkCVJkqQOE2RJkiSpwwRZkiRJ6jBBliRJkjpMkCVJkqQOE2RJkiSpwwRZkiRJ6jBBliRJkjpMkCVJkqSOZeMOQPPDioOP673tJYfuPcJIJEmSxssWZEmSJKnDFmStlWFansHWZ0mSNP/ZgixJkiR1mCBLkiRJHSbIkiRJUocJsiQtMUk2T/LZJOcnOS/J/ccdkyTNJ96kJ0lLzzuAr1TV45JsCGwy7oAkaT4xQZakJSTJZsCuwH4AVXU9cP04Y5Kk+cYEWWPjw0mksbgTsAb4QJKdgNOAF1fV77obJTkAOABgm222mfMgJWmc7IMsSUvLMmAX4L1VdU/gd8DBkzeqqsOramVVrVy+fPlcxyhJY2WCLElLy2pgdVV9r53/LE3CLElqmSBL0hJSVT8HLkuyQ7voocC5YwxJkuYd+yBL0tLzQuBj7QgWFwH7jzkeSZpXTJAlaYmpqjOAleOOQ5LmK7tYSJIkSR0myJIkSVKHCbIkSZLUYYIsSZIkdXiTnhYcn8AnSZJGyRZkSZIkqcMEWZIkSeqYMUFO8tgkP07y6yS/SXJtkt/MRXCSJEnSXOvTB/lNwD9V1XmjDkaSJEkatz5dLK40OZYkSdJS0acFeVWSTwGfB66bWFhVR40qKEmSJGlc+iTImwG/Bx7RWVaACbIWlGGGhwOHiJMkaamaMUGuqv3nIhBJkiRpPugzisXWSY5OclWSK5N8LsnWcxGcJEmSNNf63KT3AeAY4PbAVsCx7TJJkiRp0emTIC+vqg9U1Q3t9EFg+YjjkiRJksaiT4J8dZKnJVm/nZ4GXDPqwCRJkqRx6DOKxbOAdwH/RTN6xXfaZdKSsDajXwxT1lEzJEmaH/qMYnEpsM8cxCJJkiSN3bQJcpJXVNWbkvw3TcvxTVTVi0YamSRJkjQGg1qQJx4vvWouApEkSZLmg2kT5Ko6tn35+6r6THddksePNCpJkiRpTPqMYvGqnsskSZKkBW9QH+Q9gb2ArZK8s7NqM+CGUQcmSZIkjcOgPsiX0/Q/3gc4rbP8WuAlowxKkiRJGpdBfZDPBM5M8vGq+tMcxiQteY6fLEnS+PR5UMiKJP8J7AhsNLGwqu40sqgkSZKkMelzk94HgPfS9DveDfgw8JFRBiVJkiSNS58EeeOq+hqQqvppVR0C7D7asCRJkqTx6NPF4o9J1gN+nORA4GfAbUYbliRJkjQefVqQDwI2AV4E3At4OvDMEcYkSZIkjc2MLchVdWr78rfA/qMNR5IkSRqvGRPkJCuBVwN37G5fVfcYYVySJEnSWPTpg/wx4OXAD4E/jzYcSZIkabz6JMhrquqYkUciSZIkzQN9EuTXJnkf8DXguomFVXXUyKKSJEmSxqRPgrw/cBdgA/7axaIAE2RpnhnmEdXgY6oXuiQPBM6oqt8leRqwC/COqvrpDOUuAa4FbgRuqKqVIw9WkhaQPgnyTlV195FHIkka1nuBnZLsBLwCeD/N004f3KPsblV19SiDk6SFqk+CfEqSHavq3JFHI2lshml9tuV53rihqirJvjQtx+9P4jj1krSW+jwo5EHAGUkuSHJWkh8mOavPzpPs0Za7MMnB02zzkCRnJDknycnDBC9JS9y1SV4FPA04Lsn6NN3hZlLACUlOS3LAVBskOSDJqiSr1qxZsw5DlqT5b2ALcpIAzwMG9mebpuz6wLuBhwOrgVOTHNNtiU6yOfAeYI+qujSJj7CWpP6eCDwFeHZV/TzJNsCbe5R7YFVd3ta5JyY5v6q+2d2gqg4HDgdYuXJlrevAJWk+G5ggt5fu/quq7jWLfd8HuLCqLgJI8klgX6DbVeMpwFFVdWl7vKtmcRxJWqpeUlWvnJhpGxruOlOhqrq8/XlVkqNp6utvDi4lSUtHny4WpyS59yz2vRVwWWd+dbus687ALZOc1F7qe8ZUO/JSnyRN6eFTLNtzUIEkN0uy6cRr4BHA2SOITZIWrD436e0GPL8dFuh3QGgal2d61HSmWDb5Mt0y4F7AQ4GNge8mOaWqfnSTQl7qk6S/SPIC4F+AO026J2RT4DszFL8tcHTTg45lwMer6isjCVSSFqg+CfLA1ogBVgN36MxvDVw+xTZXV9XvgN8l+SawE/AjJEnT+TjwZeA/ge4N0NdW1S8GFWy7ve00wtgkacGbMUGuqp+2Y2z+Y7vof6vqzB77PhXYPsm2wM+AJ9H0Oe76AvCuJMuADYH7Av/VN3hJ4+fwcHOvqn4N/Bp4cntD9G1p6vObJ7n5xH0dkqTZmTFBTvJi4Ln89cl5H01yeFX996ByVXVDkgOB44H1gSOr6pwkz2/XH1ZV5yX5CnAWzVP63ldV9oWTpB7aOvYQ4Epu+qTTmbrASZIG6NPF4tnAfdtuECR5I/BdYGCCDFBVXwK+NGnZYZPm30y/YYkkSTd1ELBDVV0z7kAkaTHpM4pFgBs78zcy9Q14kqS5dRlNVwtJ0jrUpwX5A8D32rEyAR4NvH9kEUmS+roIOCnJccB1Ewur6m3jC0mSFr5pE+Qk21bVxVX1tiQn0TxyOsD+VfWDuQpQkjStS9tpw3aSJK0Dg1qQPwvcK8nXquqhwOlzFJMkqYeqeh00D/yYuE9EkrT2BiXI6yV5LXDnJC+dvNJLeJI0XknuT9Pl7ebANu2QnM+rqn8Zb2SStLANuknvScAfaZLoTaeYJEnj9XbgkcA1AO0Y9buOMyBJWgymbUGuqguANyY5q6q+PIcxSZJ6qqrL2sdGT7hxum0lSf30GcXi60meAqzobl9Vrx9VUJKkXi5L8gCgkmwIvAg4b8wxSdKC1ydB/gLNOJun0RlGSJI0ds8H3gFsBawGTgD+dawRSdIi0CdB3rqq9hh5JJKkoVTV1cBTxx2HJC02fRLk7yS5e1X9cOTRSJJmlOQVVfWmJP8N1OT1VfWiMYQlSYtGnwT5QcB+SS6m6WIRoKrqHiONTJI0nYl+xqvGGoUkLVJ9EuQ9Rx6FJKm3qjq2/fmhccciSYvRtOMgJ7lVklsB104zSZLGKMmJSTbvzN8yyfFjDEmSFoVBLcin0fRtyxTrCrjTSCKSJPW1vKp+NTFTVb9McpsxxiNJi8KgB4VsO5eBSFpaVhx83FDbX3Lo3iOKZEG7Mck2VXUpQJI7MsVNe5Kk4fTpgyxJmp9eDXwrycnt/K7AAWOMR5IWBRNkSVqgquorSXYB7kfTHe4l7djIkqS1MO1NepKk+SnJXdqfuwDbAJcDPwO2aZdJktbCtC3I7QgW06qqX6z7cCRJPbyUpivFW6dYV8DucxuOJC0ujmIhSQvPie3PZ1fVRWONRJIWIUexkKSF51XAZ4DPAnapkKR1rNdNekluCWwPbDSxrKq+OaqgJEkD/SLJN4A7JTlm8sqq2mcMMUnSojFjgpzkOcCLga2BM2julv4u9nGTpHHZi6bl+CNM3Q9ZkrQW+rQgvxi4N3BKVe3W3j39utGGJUka4P1V9fQkR1TVyTNvLkkaRp8E+Y9V9cckJPm7qjo/yQ4jj0ySpjHMU/gW6RP47tU+Ne+pSY5g0s3UjjIkSWunT4K8OsnmwOeBE5P8kmbMTUnSeBwGfIVmNKHTuGmC7ChDkrSWZkyQq+ox7ctD2ptCbkFTMUuSxqCq3gm8M8l7q+oF445HkhabPjfpbdOZvbj9eTvg0pFEJEnqpapekORBwPZV9YEkWwCbVtXFM5WVJE2vTxeL4/jrA0M2ArYFLgDuOsK4JEkzSPJaYCWwA/ABYEPgo8ADxxmXJC10fbpY3L07n2QX4Hkji0iS1NdjgHsCpwNU1eVJNh1vSJK08K03bIGqOp1m2DdJ0nhdX1VFc5WPJDcbczyStCj06YP80s7sejSD068ZWUSSpL4+neR/gM2TPBd4FnDEmGOSpAWvTx/k7uW6G2j6JH9uNOFIkvqqqrckeTjwG5p+yK+pqhP7lE2yPrAK+FlVPWqEYUrSgtMnQT63qj7TXZDk8cBnptlekjR3zgL+rn195hDlXgycB2y2ziOSpAWuTx/kV/VcJkmaQ0meAHwfeDzwBOB7SR7Xo9zWwN7A+0YboSQtTNO2ICfZE9gL2CrJOzurNqPpaiFJGq9XA/euqqsAkiwHvgp8doZybwdewU270N1EkgOAAwC22Wab6TaTpEVpUAvy5TT90/5I8yjTiekY4JGjD02SNIP1JpLj1jXMcGUwyaOAq6rqtEHbVdXhVbWyqlYuX758HYQqSQvHtC3IVXUmcGaSj1WVLcaSNP98JcnxwCfa+ScCX56hzAOBfZLsRfPwp82SfLSqnjbCOCVpQelzk96Pk9TkhVV1pxHEI0nqqapenuSxwINonnZ6eFUdPUOZV9HeR5LkIcDLTI4l6ab6JMgrO683orkZ5FajCUeSNJMkfw/ctqq+XVVHAUe1y3dNsl1V/WS8EUrSwjbjKBZVdU1n+llVvR3YffShSZKm8Xbg2imW/75d10tVneQYyJL0t/o8SW+Xzux6NC3K0975LEkauRVVddbkhVW1KsmKMcQjSYtKny4Wb+28vgG4hGa8TUlaUFYcfFzvbS85dO8RRrLWNhqwbuM5i0KSFqkZE+Sq2m0uApEk9XZqkudW1RHdhUmeTTMcpyRpLQx6UMhLBxWsqret+3AkST0cBByd5Kn8NSFeCWwIPGZcQUnSYjGoBfktwBk0Y2peRzOEkCRpzKrqSuABSXYD7tYuPq6qvj7GsCRp0RiUIO8CPAnYm6aF4hPA16rqb8ZEliTNvar6BvCNccchSYvNtMO8VdUZVXVwVe0MvB/YFzg3yT5zFZwkSZI012YcBznJcuCewN2B1cBVow5KkiRJGpdBN+ntDzyRZjihzwJPqCqTY0maJ5JsC9wVKOC8qrpozCFJ0qIwqA/y+4EfApcCjwQekfz1Pr2qsquFJI1Bks2A99GMXHEGzU3UOyU5DXh2Vf1mjOFJ0oI3KEF2/GNJmp/eCZwLPKmq/gyQpgXj34F3Ac8YY2yStOBNmyBX1clzGYgkqbcHVtV+3QXtCEOvT/Lj8YQkSYvHjDfpSZLmHcell6QRMkGWpIXn20lek+6NIUCSfwdOGVNMkrRoDOqDLEman15IcyP1hUnOoBnFYhfgdODZY4xLkhaFQcO8HUtT6U7JUSwkaTzaUSoen2Q7YEeaLhevrKqfjDcySVocBrUgv2XOopAk9ZbkjsCv2oT4J0l2A16U5KfAu6rq+vFGKEkLm6NYSNLC82ngMcCvk+wMfAb4T2An4D3Ac8YXmiQtfDP2QU6yPU3FuyPNU/UAqKo7jTAuSdL0Nq6qy9vXTwOOrKq3JlmP5sEhkqS10GcUiw8A7wVuoHl4yIeBj4wyKEnSQN3RK3YHvgYw8dAQSdLa6ZMgb1xVXwNSVT+tqkNoKmRJ0nh8Pcmnk7wDuCXwdYAkWwL2P5aktdRnmLc/tpftfpzkQOBnwG1GG5YkaYCDgCcCWwIPqqo/tctvB7x6XEFJ0mLRJ0E+CNgEeBHwBprW42eOMCZJ0gDtY6U/OTGf5NbArsClVXX82AKTpEVixi4WVXVqVf22qlZX1f5V9diq6vWkpiR7JLkgyYVJDh6w3b2T3JjkccMEL0lLUZIvJrlb+3pL4GzgWcBHkhw0ztgkaTHoM4rFnYGXA3fsbl9VA/shJ1kfeDfwcGA1cGqSY6rq3Cm2eyNgq4ck9bNtVZ3dvt4fOLGqnpFkU+DbwNvHFpkkLQJ9ulh8BjgMOAK4cYh93we4sKouAkjySWBf4NxJ270Q+Bxw7yH2LUlL2Z86rx9KUz9TVdcmcSQLSVpLfRLkG6rqvbPY91bAZZ351cB9uxsk2YpmsPvdGZAgJzkAOABgm222mUUokrSoXJbkhTT16i7AVwCSbAxsMM7AJGkx6DPM27FJ/iXJlkluNTH1KJcpltWk+bcDr6yqgS3TVXV4Va2sqpXLly/vcWhJWtSeDdwV2A94YlX9ql1+P5qx6yVJa6FPC/LEiBUv7ywrYKYn6a0G7tCZ3xq4fNI2K4FPJgHYAtgryQ1V9fkecUnSklRVVwHPn2LVd2nqUknSWpgxQa6qbWe571OB7ZNsSzN28pOAp0y37yQfBL5ocixJ/bU3Oj8CeDLwSOB/ae4dkSTNUp9RLDYAXkAzxibAScD/dAamn1JV3dA+WOR4YH3gyKo6J8nz2/WHrU3gkrSUJdmVptFhb+D7wANpRrf4/VgDk6RFoE8Xi/fS3PTxnnb+6e2y58xUsKq+BHxp0rIpE+Oq2q9HLJK05CVZDVxKUxe/vB294mKTY0laN/okyPeuqp06819PcuaoApIkzehzwKNpHjd9Y5Iv8Lc3QUuSZqnPKBY3JtluYibJnRhuPGRJ0jpUVS8GVgBvA3YDfgQsT/KEJDcfZ2yStBj0aUF+OfCNJBfRDN12R5onN0mSxqSqCvg6zVW9DYA9aG7Uew+OZCFJa6XPKBZfS7I9sANNgnx+VV038sgkSb20N00fSzNu/avGHY8kLXTTdrFIsnv787E0d0n/PbAdsHe7TJI0/7xg0MokGyX5fpIzk5yT5HVzFZgkLRSDWpAfTHP57p+mWFfAUSOJSJK0NqZ6imnXdcDuVfXbtmvGt5J8uapOmYPYellx8HFDbX/JoXuPKBJJS9W0CXJVvbZ9+fqquri7rn34hyRp/hk4mkXbd/m37ewG7eQIGJLU0WcUi89Nseyz6zoQSVI/Sa5N8psppmuB2/cov36SM4CrgBOr6ntTbHNAklVJVq1Zs2bd/xKSNI9N24Kc5C7AXYFbTOpzvBmw0agDkyRNrao2XcvyNwI7J9kcODrJ3arq7EnbHA4cDrBy5UpbmCUtKYP6IO8APArYnJv2Q74WeO4IY5IkzYGq+lWSk2iGiDt7hs0lackY1Af5C8AXkty/qr47hzFJkkYkyXLgT21yvDHwMOCNYw5LkuaVQV0sXlFVbwKekuTJk9dX1YtGGpkkaRS2BD6UZH2a+1A+XVVfHHNMkjSvDOpicV77c9VcBCJJGr2qOgu457jjkKT5bFAXi2Pbnx+au3AkSZKk8RrUxeJYBoyNWVX7jCQiSZIkaYwGdbF4S/vzscDtgI+2808GLhlhTJIkSdLYDOpicTJAkjdU1a6dVccm+ebII5MkSZLGoM+T9JYnudPETPuY6eWjC0mSJEkan0FdLCa8BDgpyUXt/ArgeSOLSJIkSRqjGRPkqvpKku2Bu7SLzq+q60YbliRJkjQefVqQAe5F03K8DNgpCVX14ZFFJUmSJI3JjAlyko8A2wFnADe2iwswQZYkSdKi06cFeSWwY1VNOyayJEmStFj0GcXibJpxkCVJkqRFr08L8hbAuUm+D/zl5jyfpCdJkqTFqE+CfMiog5AkSZLmiz7DvJ2c5LbAvdtF36+qq0YbliRJkjQeM/ZBTvIE4PvA44EnAN9L8rhRByZJkiSNQ58uFq8G7j3RapxkOfBV4LOjDEySJEkahz6jWKw3qUvFNT3LSZIkSQtOnxbkryQ5HvhEO/9E4MujC0mSJEkanz436b08yWOBBwEBDq+qo0cemSRJkjQG0ybISf4euG1VfbuqjgKOapfvmmS7qvrJXAUpSZIkzZVBfYnfDlw7xfLft+skSZKkRWdQgryiqs6avLCqVgErRhaRJEmSNEaDEuSNBqzbeF0HIkmSJM0HgxLkU5M8d/LCJM8GThtdSJIkSdL4DBrF4iDg6CRP5a8J8UpgQ+AxI45LkiRJGotpE+SquhJ4QJLdgLu1i4+rqq/PSWSSJEnSGPQZB/kbwDfmIBZJkiRp7HxktCRJktRhgixJkiR1mCBLkiRJHSbIkiRJUocJsiRJktRhgixJkiR1mCBLkiRJHSbIkiRJUocJsiRJktRhgixJS0iSOyT5RpLzkpyT5MXjjkmS5psZHzUtSVpUbgD+rapOT7IpcFqSE6vq3HEHJknzhS3IkrSEVNUVVXV6+/pa4Dxgq/FGJUnziwmyJC1RSVYA9wS+N8W6A5KsSrJqzZo1cx6bJI2TCbIkLUFJbg58Djioqn4zeX1VHV5VK6tq5fLly+c+QEkaIxNkSVpikmxAkxx/rKqOGnc8kjTfmCBL0hKSJMD7gfOq6m3jjkeS5iMTZElaWh4IPB3YPckZ7bTXuIOSpPnEYd4kaQmpqm8BGXcco7Li4ON6b3vJoXuPMBJJC5ktyJIkSVKHCbIkSZLUYYIsSZIkdZggS5IkSR0myJIkSVKHCbIkSZLUYYIsSZIkdYw0QU6yR5ILklyY5OAp1j81yVnt9J0kO40yHkmSJGkmI0uQk6wPvBvYE9gReHKSHSdtdjHw4Kq6B/AG4PBRxSNJkiT1McoW5PsAF1bVRVV1PfBJYN/uBlX1nar6ZTt7CrD1COORJEmSZjTKBHkr4LLO/Op22XSeDXx5qhVJDkiyKsmqNWvWrMMQJUmSpJsaZYKcKZbVlBsmu9EkyK+can1VHV5VK6tq5fLly9dhiJIkSdJNLRvhvlcDd+jMbw1cPnmjJPcA3gfsWVXXjDAeSZIkaUajbEE+Fdg+ybZJNgSeBBzT3SDJNsBRwNOr6kcjjEWSJEnqZWQtyFV1Q5IDgeOB9YEjq+qcJM9v1x8GvAa4NfCeJAA3VNXKUcUkSZIkzWSUXSyoqi8BX5q07LDO6+cAzxllDJIkSdIwfJKeJEmS1GGCLEmSJHWYIEuSJEkdJsiSJElShwmyJEmS1GGCLEmSJHWYIEuSJEkdJsiSJElShwmyJEmS1GGCLEmSJHWYIEuSJEkdJsiSJElShwmyJEmS1GGCLEmSJHWYIEuSJEkdJsiSJElShwmyJEmS1GGCLEmSJHWYIEuSJEkdJsiSJElShwmyJC0xSY5MclWSs8cdiyTNRybIkrT0fBDYY9xBSNJ8ZYIsSUtMVX0T+MW445Ck+coEWZL0N5IckGRVklVr1qwZdziSNKdMkCVJf6OqDq+qlVW1cvny5eMOR5LmlAmyJEmS1GGCLEmSJHWYIEvSEpPkE8B3gR2SrE7y7HHHJEnzybJxByBJmltV9eRxxyBJ85ktyJIkSVKHCbIkSZLUYYIsSZIkdZggS5IkSR0myJIkSVKHo1hI0gxWHHzcUNtfcujeI4pEkjQXbEGWJEmSOkyQJUmSpA4TZEmSJKnDBFmSJEnqMEGWJEmSOkyQJUmSpA4TZEmSJKnDBFmSJEnqMEGWJEmSOkyQJUmSpA4TZEmSJKlj2bgDkCRp3FYcfNxQ219y6N4jikTSfGALsiRJktRhgixJkiR1mCBLkiRJHfZBliRpluy7LC1OtiBLkiRJHSbIkiRJUocJsiRJktRhgixJkiR1mCBLkiRJHSbIkiRJUocJsiRJktRhgixJkiR1mCBLkiRJHSbIkiRJUocJsiRJktSxbNwBSJK0FK04+Lje215y6N4jjETSZLYgS5IkSR0myJIkSVLHSLtYJNkDeAewPvC+qjp00vq06/cCfg/sV1WnjzImSVrqZqqbNb/ZNUMavZElyEnWB94NPBxYDZya5JiqOrez2Z7A9u10X+C97U9J0gj0rJu1CA2TWMNNk+vZJuUm81qoRtmCfB/gwqq6CCDJJ4F9gW4lvC/w4aoq4JQkmyfZsqquGGFckrSU9ambpbFaSMn82sSq+StNbjqCHSePA/aoque0808H7ltVB3a2+SJwaFV9q53/GvDKqlo1aV8HAAe0szsAF6zDULcArp7DcuM4prEujnLjOKaxju6YU7ljVS1fh/v7G33q5nb5Yqp3F9Jnw1jnV7lxHNPfcXRlpzJlvTvKFuRMsWxyNt5nG6rqcODwdRHUZElWVdXKuSo3jmMa6+IoN45jGuvojjlGS67eXUifDWOdX+XGcUx/x9GVHcYoR7FYDdyhM781cPkstpEkrTvWu5I0g1EmyKcC2yfZNsmGwJOAYyZtcwzwjDTuB/za/seSNFJ96mZJWtJG1sWiqm5IciBwPM1QQkdW1TlJnt+uPwz4Es0QbxfSDPO2/6jiGWC2lxDX5tLjXB/TWBdHuXEc01hHd8yxmK5unuMw/Gys+3LjOKaxLo5y4zjmOGIdyshu0pMkSZIWIp+kJ0mSJHWYIEuSJEkdSzpBTrJ+kh+04zEP2u7IJFclOXvS8hcmuSDJOUne1KdcklslOTHJj9uftxzmmO26lyWpJFv0+B1f0sZ3dpJPJNlopjJtuRe3Zc5JclCfMjPFPUO5OyT5RpLz2mO+eIiylyT5YZIzkqwasN2Ux+j7N+nsZ4f2WBPTb6Z7j6b5DHyqU/aSJGf0+B03T/LZJOe38d9/wLZTHfPx7e/85yRTDo8zTbk3JDmrjfWEJLfvWW6nJN9t/y7HJtlsiGO+uf09z0pydJLNe5bbOckpE5+DJPfpWe6QJD/r/E32mirWzvYbJfl+kjPb9/R1g7ZXY23et3HUK235XueIKcr1rZNm9TmeYj/jqh9m/J7P9js+xX56n5Om+7xkdufsXvX1bOuW6T6jGeK8lCHOSVOUfUl65gjT/I6zOkd01k2bz0xzvKHO12ulqpbsBLwU+DjwxRm22xXYBTi7s2w34KvA37Xzt+lZ7k3Awe3rg4E39j1mu/wONDfX/BTYYoa4twIuBjZu5z8N7NfjfbkbcDawCc2NnF8Ftu/5nk4Zd49yWwK7tK83BX4E7Niz7CUzvReDjtH3bzLNPtcHfk4z0PjQ7wfwVuA1PY7zIeA57esNgc2H/Lz+A83DHk4CVg5RbrPO6xcBh/Usdyrw4Pb1s4A3DHHMRwDL2tdvnOrvMU25E4A929d7ASf1LHcI8LIh/uYBbt6+3gD4HnC/YT7vS3Fam/dtHPVKW6bXOWKKcn3rpFl9jqfYz7jqhxm/57P9jk/ax1DnpGmOOatz9qT109bXs61bpvuMMsvzEjOckyZtO1SOMM3vOKtzRLt8YD4zzfFmfb4edlqyLchJtgb2Bt4307ZV9U3gF5MWv4DmKYDXtdtc1bPcvjSVGe3PRw9xTID/Al7BFAP7T2MZsHGSZTSVS5/xTv8BOKWqfl9VNwAnA4/pc7ABcc9U7oqqOr19fS1wHs2Xd50ZcIxef5NpPBT4SVX9dJpjTvt+JAnwBOATgw7QtsrsCry/3ef1VfWr6baf6phVdV5VDXwS2jTlftOZvRlTP1Biqt9xB+Cb7esTgX8e4pgntJ87gFNoxuntc8wCJlqwbsEUn/XZfj4n7aOq6rft7Abt5N3OM1ib920c9cow54jZmu3nuGuc9QM9vuez/Y5PMtQ5aR2fs4GZ6+sRfEZne14aeE6aQu8cYR2fI2CGfGZtcqh1YckmyMDbaf4wf55l+TsD/5jke0lOTnLvnuVuW+1Yz+3P2/Q9YJJ9gJ9V1Zl9tq+qnwFvAS4FrqAZZ/qEHkXPBnZNcuskm9C0YtxhhjLrTJIVwD1pWpj6KOCEJKeleTzusMeY9d+EZgzZgQnuAP8IXFlVP55huzsBa4APpLnc+74kN5vlMYeW5P9LchnwVOA1PYudDezTvn48s//8PAv4cs9tDwLe3Mb6FuBVQxznwPYy4ZF9LtmlufR+BnAVcGJV9f2sLmnjfN9mUa+8ndmfI4aukzoOYrjP8Tjrh3XxPe/zHV8X56TZnrMn9K2vJ+tdt6yj81Lvc9Ja5Ag3MZtzxLD5TMfanK+HsiQT5CSPAq6qqtPWYjfLgFsC9wNeDny6/Q9zJNpK4dX0T1Bov4z7AtsCtwduluRpM5WrqvNoLnudCHwFOBO4YWChdSTJzYHPAQdN+s90kAdW1S7AnsC/Jtl1BMeYaj8b0pwcPjPLXTyZfhXZMprLTO+tqnsCv6O5tDQnqurVVXUH4GPAgT2LPYvmb3EazWXD64c9bpJX03zuPtazyAuAl7SxvoS2Ra2H9wLbATvTnCTeOlOBqrqxqnamafm6T5K79TzWkjau923Y7/w6OEcMVSdNMuzneJz1w1p9z/t+x9fROWltz9l96+uu3nXLujgvDXtOmm2OMNmw54jZ5DPjsCQTZOCBwD5JLgE+Ceye5KND7mM1cFR72fD7NK0MM940B1yZZEuA9uffXOaZxnY0H+Iz27i3Bk5PcrsBZR4GXFxVa6rqT8BRwAP6HKyq3l9Vu1TVrjSXOIb9r3loSTagqSA+VlVH9S1XVZe3P68CjgamvallmmPM9m+yJ3B6VV3ZN9ZOHMuAxwKf6rH5amB1p7XtszQnxLn2cabpKjFZVZ1fVY+oqnvRnFR+MsyBkjwTeBTw1Krq233hmTSfcWhOEDPe3NTGemWbuP0ZOKJvubbsr2j6be7Rt4zm9n2bZb2yVueIYeqkKQz7OR5b/bA23/Nhv+Pr4Jw023P2sPV1N+Zedcs6PC8Ne06adY4wjb7niNnkMxNme74e2pJMkKvqVVW1dVWtoLkc8fWqGva/ps8DuwMkuTPNjRFX9yh3DE0FSPvzCz1j/mFV3aaqVrRxr6bp2P/zAcUuBe6XZJP2P+WH0vRvmlGS27Q/t6GpGGbbjaCXNr73A+dV1duGKHezJJtOvKa5+WPKO90HHGNWfxNm16Iw4WHA+VW1eqYN27/xZUl2aBc9FDh3lscdSpLtO7P7AOf3LDfx+VkP+L/AYUMccw/glcA+VfX7/tFyOfDg9vXu9DyBTlS2rccwzeens/3ytHfdJ9mY9m85RJxL0jjet9nWK2tzjhimTprGUJ/jMdcPs/qez+Y7vg7OSZ9ndudsGKK+7upTt6zj89Kw56RZ5wgTZnOOmGU+M2G25+vh1Yju/lsoE/AQZh7F4hM0l0f+RPOHfDbNl+ujNB/404Hde5a7NfA1mkrva8Ct+h5z0vpL6HeX9OtoPrBnAx+hvYO3R7n/palkzwQeOsT7OTDuAeUeRNNv7yzgjHbaq0e5O7UxngmcA7x62GP0/ZtM2tcmwDXALWbzfgAfBJ4/xPu6M7Cqjf3zwC2H/Lw+pn19HXAlcHzPcp9rPztnAccCW/Us92Kau7F/BBwKzVM7e5a9ELis8zea6q7oqco9CDit/Sx8D7hXz3IfAX7Y/o7HAFvO8Le4B/CDdvuz6TEKidPavW/TfY96lJtVvTJpHw9hiFEsGK5OmtXneIr9jKt+mPF7Ptvv+BT76X1OmuaYszpnt8s/yAz19Wzrluk+owx5XqLnOWmKcr1zhGl+x1mdIyatv4SpR7GYdQ61LiYfNS1JkiR1LMkuFpIkSdJ0TJAlSZKkDhNkSZIkqcMEWZIkSeowQZYkSZI6TJA1byW5MckZnWnFLPbx6CQ7jiA8kqxIMsz4piTZL8m7RhGPJK0t612psWzcAUgD/KGax9KujUcDX2SIgfOTLKuqOXm0tiTNM9a7ErYga4FJcq8kJyc5LcnxnUdOPjfJqUnOTPK59slAD6B5ss+b25aQ7ZKclGRlW2aL9jGXEy0Mn0lyLHBC+zSsI9t9/iDJvjPEtV+So5J8JcmPk7yps27/JD9KcjLNI2wnli9vYz21nR7YLv9Ckme0r5+X5GPr9E2UpCFY72pJGtUTSJyc1nYCbuSvTxY6GtgA+A6wvF3/RODI9vWtO+X+A3hh+/qDwOM6604CVravtwAuaV/vR/Oknlu18/8PeFr7enOaJ0XdbFJ8K4CzO+UvAm4BbAT8FLgDsCXN4zyX0zzJ6dvAu9oyHwce1L7ehuZRowC3pXnS1D+2xx3Zk4KcnJycupP1rvWuUzPZxULz2U0u9SW5G3A34MTmsfGsT/MYSoC7JfkPmkr15sDxszjeiVX1i/b1I4B9krysnd+ItjIdUP5rVfXrNtZzgTvSnAxOqqo17fJPAXdut38YsGP7uwBslmTTqroyyWuAbwCP6cQkSaNmvWu9K+yDrIUlwDlVdf8p1n0QeHRVnZlkP+Ah0+zjBv7atWijSet+N+lY/1xVFwwR33Wd1zfy1+/XdM9zXw+4f1X9YYp1dweuAW4/xPElaV2z3tWSZB9kLSQXAMuT3B8gyQZJ7tqu2xS4IskGwFM7Za5t1024BLhX+/pxA451PPDCtM0MSe45y5i/Bzwkya3b2B7fWXcCcODETJKd25/3AfYE7gm8LMm2szy2JK0t610tSSbIWjCq6nqayvWNSc6k6SP3gHb1v9NUiicC53eKfRJ4eXvDx3bAW4AXJPkOzWW46byBpu/dWWmGFHrDLGO+AjgE+C7wVeD0zuoXASuTnNVeGnx+kr8DjgCeVVWXA/8GHDlxwpCkuWS9q6UqVdNdhZAkSZKWHluQJUmSpA4TZEmSJKnDBFmSJEnqMEGWJEmSOkyQJUmSpA4TZEmSJKnDBFmSJEnq+P8BYFcDBdTVuOQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 zmiennych na podstawie CMI: [ 4 16 10 14  8  9  1  2  5 20]\n",
      "Top 10 zmiennych na podstawie LASSO: [ 3  1  2  4  5 18  6 11 19 12]\n",
      "Liczba odwróconych par: 97\n",
      "Top 10 agreement score: 0.4\n",
      "Top 5 agreement score: 0.2\n"
     ]
    }
   ],
   "source": [
    "#est2\n",
    "\n",
    "cmi_scores = []\n",
    "for i in range(X.shape[1]):\n",
    "    Z = np.delete(X, i, axis=1)  \n",
    "    cmi_scores.append(est2(X[:, i].reshape(-1, 1), Y.reshape(-1, 1), Z))\n",
    "\n",
    "# Ranking zmiennych na podstawie CMI\n",
    "cmi_ranking = np.argsort(cmi_scores)[::-1]\n",
    "\n",
    "\n",
    "# Wizualizacja rankingów\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(range(1, n_features + 1), np.array(cmi_scores)[cmi_ranking], tick_label=cmi_ranking + 1)\n",
    "plt.title(\"CMI Ranking\")\n",
    "plt.xlabel(\"Feature Index\")\n",
    "plt.ylabel(\"Conditional Mutual Information\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(range(1, n_features + 1), lasso_importances[lasso_ranking], tick_label=lasso_ranking + 1)\n",
    "plt.title(\"LASSO Ranking\")\n",
    "plt.xlabel(\"Feature Index\")\n",
    "plt.ylabel(\"LASSO Coefficients\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Wyświetlamy top 10 zmiennych\n",
    "print(\"Top 10 zmiennych na podstawie CMI:\", cmi_ranking[:10] + 1)\n",
    "print(\"Top 10 zmiennych na podstawie LASSO:\", lasso_ranking[:10] + 1)\n",
    "\n",
    "\n",
    "\n",
    "# Liczenie liczby odwróconych par\n",
    "inversions = count_inversions(cmi_ranking, lasso_ranking)\n",
    "print(f\"Liczba odwróconych par: {inversions}\")\n",
    "\n",
    "# Liczenie liczby przypadków, w których top 10 zmiennych się pokrywają\n",
    "top_k_agreement_10 = top_k_agreement(cmi_ranking, lasso_ranking, 10)\n",
    "top_k_agreement_5 = top_k_agreement(cmi_ranking, lasso_ranking, 5)\n",
    "\n",
    "print(f\"Top 10 agreement score: {top_k_agreement_10}\")\n",
    "print(f\"Top 5 agreement score: {top_k_agreement_5}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I_XZY: 1.1924219245481318\n",
      "I_XY: 0.14719406219425046\n",
      "I_XZY: 1.1924219245481318\n",
      "I_XY: 0.06119170239935379\n",
      "I_XZY: 1.1924219245481318\n",
      "I_XY: 0.9648731364794436\n",
      "I_XZY: 1.1924219245481318\n",
      "I_XY: 0.007549875605306511\n",
      "I_XZY: 1.1924219245481318\n",
      "I_XY: 0.0014050718141627172\n",
      "I_XZY: 1.1924219245481318\n",
      "I_XY: 0.0003673274987905373\n",
      "I_XZY: 1.1924219245481318\n",
      "I_XY: 0\n",
      "I_XZY: 1.1924219245481318\n",
      "I_XY: 0\n",
      "I_XZY: 1.1924219245481318\n",
      "I_XY: 0\n",
      "I_XZY: 1.1924219245481318\n",
      "I_XY: 0\n",
      "I_XZY: 1.1924219245481318\n",
      "I_XY: 0\n",
      "I_XZY: 1.1924219245481318\n",
      "I_XY: 0.0032639896893877918\n",
      "I_XZY: 1.1924219245481318\n",
      "I_XY: 0\n",
      "I_XZY: 1.1924219245481318\n",
      "I_XY: 0.003456393848982664\n",
      "I_XZY: 1.1924219245481318\n",
      "I_XY: 0\n",
      "I_XZY: 1.1924219245481318\n",
      "I_XY: 0\n",
      "I_XZY: 1.1924219245481318\n",
      "I_XY: 0\n",
      "I_XZY: 1.1924219245481318\n",
      "I_XY: 0.003120365018453697\n",
      "I_XZY: 1.1924219245481318\n",
      "I_XY: 0\n",
      "I_XZY: 1.1924219245481318\n",
      "I_XY: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 zmiennych na podstawie CMI: [20 13  7  8  9 19 11 10 15 16]\n",
      "Top 10 zmiennych na podstawie LASSO: [ 3  1  2  4  5 18  6 11 19 12]\n",
      "Liczba odwróconych par: 95\n",
      "Top 10 agreement score: 0.2\n",
      "Top 5 agreement score: 0.0\n"
     ]
    }
   ],
   "source": [
    "#est3\n",
    "\n",
    "cmi_scores = []\n",
    "for i in range(X.shape[1]):\n",
    "    Z = np.delete(X, i, axis=1)  \n",
    "    cmi_scores.append(estimate_cmi(X[:, i].reshape(-1, 1), Y.ravel(), Z))\n",
    "\n",
    "# Ranking zmiennych na podstawie CMI\n",
    "cmi_ranking = np.argsort(cmi_scores)[::-1]\n",
    "\n",
    "# Wizualizacja rankingów\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(range(1, n_features + 1), np.array(cmi_scores)[cmi_ranking], tick_label=cmi_ranking + 1)\n",
    "plt.title(\"CMI Ranking\")\n",
    "plt.xlabel(\"Feature Index\")\n",
    "plt.ylabel(\"Conditional Mutual Information\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(range(1, n_features + 1), lasso_importances[lasso_ranking], tick_label=lasso_ranking + 1)\n",
    "plt.title(\"LASSO Ranking\")\n",
    "plt.xlabel(\"Feature Index\")\n",
    "plt.ylabel(\"LASSO Coefficients\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Wyświetlamy top 10 zmiennych\n",
    "print(\"Top 10 zmiennych na podstawie CMI:\", cmi_ranking[:10] + 1)\n",
    "print(\"Top 10 zmiennych na podstawie LASSO:\", lasso_ranking[:10] + 1)\n",
    "\n",
    "\n",
    "\n",
    "# Liczenie liczby odwróconych par\n",
    "inversions = count_inversions(cmi_ranking, lasso_ranking)\n",
    "print(f\"Liczba odwróconych par: {inversions}\")\n",
    "\n",
    "# Liczenie liczby przypadków, w których top 10 zmiennych się pokrywają\n",
    "top_k_agreement_10 = top_k_agreement(cmi_ranking, lasso_ranking, 10)\n",
    "top_k_agreement_5 = top_k_agreement(cmi_ranking, lasso_ranking, 5)\n",
    "\n",
    "print(f\"Top 10 agreement score: {top_k_agreement_10}\")\n",
    "print(f\"Top 5 agreement score: {top_k_agreement_5}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## dataset example of ranking variable importance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 przykład 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytanie zbioru danych California Housing\n",
    "housing = fetch_california_housing()\n",
    "X = housing.data\n",
    "Y = housing.target.reshape(-1, 1)\n",
    "\n",
    "n_samples = 20000\n",
    "X = X[:n_samples]\n",
    "Y = Y[:n_samples]\n",
    "\n",
    "# Ranking cech na podstawie LASSO\n",
    "lasso = LassoCV(cv=5).fit(X, Y.ravel())\n",
    "lasso_importances = np.abs(lasso.coef_)\n",
    "lasso_ranking = np.argsort(lasso_importances)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 0.8047 - val_loss: 0.0356 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.2863 - val_loss: 0.0550 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.1575 - val_loss: 0.1075 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.1257 - val_loss: 0.2083 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0908 - val_loss: 0.2406 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0809 - val_loss: 0.2589 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0658 - val_loss: 0.1580 - learning_rate: 5.0000e-05\n",
      "Epoch 8/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0642 - val_loss: 0.1790 - learning_rate: 5.0000e-05\n",
      "Epoch 9/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0595 - val_loss: 0.1366 - learning_rate: 5.0000e-05\n",
      "Epoch 10/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0597 - val_loss: 0.2746 - learning_rate: 5.0000e-05\n",
      "Epoch 11/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0556 - val_loss: 0.2463 - learning_rate: 5.0000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.4595 - val_loss: 0.2338 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.2464 - val_loss: 0.1783 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.1653 - val_loss: 0.1514 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.1211 - val_loss: 0.2122 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0995 - val_loss: 0.2589 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0871 - val_loss: 0.1953 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0819 - val_loss: 0.2388 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0512 - val_loss: 0.1293 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0557 - val_loss: 0.0825 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0588 - val_loss: 0.1351 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0492 - val_loss: 0.1415 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0475 - val_loss: 0.2380 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0272 - val_loss: 0.1379 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0331 - val_loss: 0.2155 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0356 - val_loss: 0.1960 - learning_rate: 5.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0324 - val_loss: 0.2759 - learning_rate: 5.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0307 - val_loss: 0.2268 - learning_rate: 5.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0296 - val_loss: 0.1188 - learning_rate: 5.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0132 - val_loss: 0.2393 - learning_rate: 5.0000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.4947 - val_loss: 0.0514 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.2177 - val_loss: 0.0247 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.1527 - val_loss: 0.0316 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.1103 - val_loss: 0.0370 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0933 - val_loss: 0.0576 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0851 - val_loss: 0.0275 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0648 - val_loss: 0.0191 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0472 - val_loss: 0.0209 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0527 - val_loss: 0.0094 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0488 - val_loss: 0.0131 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0451 - val_loss: 0.0114 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0337 - val_loss: 0.0164 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0354 - val_loss: 0.0096 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0257 - val_loss: 0.0135 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0229 - val_loss: 0.0112 - learning_rate: 5.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0298 - val_loss: 0.0098 - learning_rate: 5.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0245 - val_loss: 0.0093 - learning_rate: 5.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0269 - val_loss: 0.0038 - learning_rate: 5.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0157 - val_loss: 0.0029 - learning_rate: 5.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0192 - val_loss: 0.0077 - learning_rate: 5.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0215 - val_loss: 0.0038 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0123 - val_loss: 0.0068 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0166 - val_loss: 0.0057 - learning_rate: 5.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0159 - val_loss: 0.0040 - learning_rate: 5.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0107 - val_loss: 0.0042 - learning_rate: 2.5000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0137 - val_loss: 0.0031 - learning_rate: 2.5000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0126 - val_loss: 0.0031 - learning_rate: 2.5000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0065 - val_loss: 0.0026 - learning_rate: 2.5000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0128 - val_loss: 0.0033 - learning_rate: 2.5000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0051 - val_loss: 0.0029 - learning_rate: 2.5000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0120 - val_loss: 0.0080 - learning_rate: 2.5000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0148 - val_loss: 0.0013 - learning_rate: 2.5000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0146 - val_loss: 0.0031 - learning_rate: 2.5000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0054 - val_loss: 0.0030 - learning_rate: 2.5000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0066 - val_loss: 0.0040 - learning_rate: 2.5000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0116 - val_loss: 0.0033 - learning_rate: 2.5000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0109 - val_loss: 0.0011 - learning_rate: 2.5000e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0141 - val_loss: 0.0022 - learning_rate: 2.5000e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0028 - val_loss: 2.4728e-04 - learning_rate: 2.5000e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0059 - val_loss: 8.8041e-04 - learning_rate: 2.5000e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0084 - val_loss: 7.0508e-04 - learning_rate: 2.5000e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0108 - val_loss: 1.5141e-04 - learning_rate: 2.5000e-05\n",
      "Epoch 43/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0103 - val_loss: 0.0025 - learning_rate: 2.5000e-05\n",
      "Epoch 44/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0040 - val_loss: 6.2705e-04 - learning_rate: 2.5000e-05\n",
      "Epoch 45/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0043 - val_loss: 4.7887e-04 - learning_rate: 1.2500e-05\n",
      "Epoch 46/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0020 - val_loss: 1.9193e-04 - learning_rate: 1.2500e-05\n",
      "Epoch 47/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0052 - val_loss: 3.1898e-04 - learning_rate: 1.2500e-05\n",
      "Epoch 48/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0057 - val_loss: 4.0860e-04 - learning_rate: 1.2500e-05\n",
      "Epoch 49/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0050 - val_loss: 0.0020 - learning_rate: 1.2500e-05\n",
      "Epoch 50/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0069 - val_loss: 0.0022 - learning_rate: 6.2500e-06\n",
      "Epoch 51/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0023 - val_loss: 0.0025 - learning_rate: 6.2500e-06\n",
      "Epoch 52/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0040 - val_loss: 0.0038 - learning_rate: 6.2500e-06\n",
      "Epoch 1/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.5707 - val_loss: 0.0831 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.2787 - val_loss: 0.1453 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1528 - val_loss: 0.0601 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1183 - val_loss: 0.0880 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1116 - val_loss: 0.0285 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0915 - val_loss: 0.0470 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0687 - val_loss: 0.0126 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0566 - val_loss: 0.0448 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0512 - val_loss: 0.0194 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0532 - val_loss: 0.0097 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0477 - val_loss: 0.0152 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0400 - val_loss: 0.0166 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0354 - val_loss: 0.0202 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0375 - val_loss: 0.0142 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0313 - val_loss: 0.0262 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0275 - val_loss: 0.0069 - learning_rate: 5.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0240 - val_loss: 0.0105 - learning_rate: 5.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0194 - val_loss: 0.0075 - learning_rate: 5.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0279 - val_loss: 0.0141 - learning_rate: 5.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0255 - val_loss: 0.0181 - learning_rate: 5.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0221 - val_loss: 0.0074 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0180 - val_loss: 0.0240 - learning_rate: 2.5000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0177 - val_loss: 0.0163 - learning_rate: 2.5000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0239 - val_loss: 0.0068 - learning_rate: 2.5000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0194 - val_loss: 0.0249 - learning_rate: 2.5000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0182 - val_loss: 0.0207 - learning_rate: 2.5000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0192 - val_loss: 0.0112 - learning_rate: 2.5000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0242 - val_loss: 0.0300 - learning_rate: 2.5000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0207 - val_loss: 0.0101 - learning_rate: 2.5000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0203 - val_loss: 0.0098 - learning_rate: 1.2500e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0228 - val_loss: 0.0179 - learning_rate: 1.2500e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0214 - val_loss: 0.0205 - learning_rate: 1.2500e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0209 - val_loss: 0.0195 - learning_rate: 1.2500e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0177 - val_loss: 0.0196 - learning_rate: 1.2500e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 0.5888 - val_loss: 0.0357 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.2834 - val_loss: 0.0168 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.1597 - val_loss: 0.0212 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.1026 - val_loss: 0.0246 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0755 - val_loss: 0.0117 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0651 - val_loss: 0.0144 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0570 - val_loss: 0.0146 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0478 - val_loss: 0.0059 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0372 - val_loss: 0.0163 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0357 - val_loss: 0.0026 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0283 - val_loss: 0.0019 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0237 - val_loss: 4.1497e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0360 - val_loss: 2.5769e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0226 - val_loss: 3.1928e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0176 - val_loss: 0.0015 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0187 - val_loss: 0.0027 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0134 - val_loss: 0.0016 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0167 - val_loss: 0.0025 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0118 - val_loss: -0.0023 - learning_rate: 5.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0150 - val_loss: 0.0035 - learning_rate: 5.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0187 - val_loss: 8.5321e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0070 - val_loss: 0.0028 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0150 - val_loss: 1.4830e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0080 - val_loss: 0.0018 - learning_rate: 5.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0112 - val_loss: 1.3118e-04 - learning_rate: 2.5000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0081 - val_loss: 0.0024 - learning_rate: 2.5000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.0163 - val_loss: -7.3365e-04 - learning_rate: 2.5000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0117 - val_loss: -3.9334e-04 - learning_rate: 2.5000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.0035 - val_loss: -3.0799e-04 - learning_rate: 2.5000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 0.7618 - val_loss: 0.0385 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.2483 - val_loss: 0.0025 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.1596 - val_loss: 0.0089 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.1194 - val_loss: 0.0057 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0889 - val_loss: 0.0302 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0680 - val_loss: 0.0088 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0579 - val_loss: 0.0034 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0690 - val_loss: 0.0038 - learning_rate: 5.0000e-05\n",
      "Epoch 9/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0587 - val_loss: 0.0026 - learning_rate: 5.0000e-05\n",
      "Epoch 10/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0527 - val_loss: 0.0032 - learning_rate: 5.0000e-05\n",
      "Epoch 11/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0425 - val_loss: 0.0035 - learning_rate: 5.0000e-05\n",
      "Epoch 12/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0369 - val_loss: 0.0055 - learning_rate: 5.0000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.3310 - val_loss: 0.0414 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.2744 - val_loss: 0.0041 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.1816 - val_loss: 3.1703e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.1107 - val_loss: 0.0017 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0837 - val_loss: -4.8225e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0610 - val_loss: -0.0076 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0396 - val_loss: -0.0040 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0338 - val_loss: -0.0051 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0224 - val_loss: 0.0091 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0270 - val_loss: -3.5767e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0256 - val_loss: -0.0092 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0197 - val_loss: -0.0072 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0181 - val_loss: -0.0202 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: -0.0019 - val_loss: -0.0123 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: -0.0026 - val_loss: -0.0174 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0027 - val_loss: -0.0225 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: -0.0022 - val_loss: -0.0118 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: -4.7721e-04 - val_loss: -0.0211 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0019 - val_loss: -0.0221 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: -0.0125 - val_loss: 0.0545 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: -0.0135 - val_loss: 0.0524 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: -0.0170 - val_loss: 0.0376 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: -0.0162 - val_loss: 0.0316 - learning_rate: 5.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: -0.0166 - val_loss: 0.0076 - learning_rate: 5.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: -0.0114 - val_loss: 0.0249 - learning_rate: 5.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0209 - val_loss: 0.0358 - learning_rate: 5.0000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.4487 - val_loss: 0.0908 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.2020 - val_loss: 0.0936 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.1271 - val_loss: 0.1129 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0860 - val_loss: 0.0104 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0581 - val_loss: 0.0189 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0466 - val_loss: 0.0346 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0275 - val_loss: -0.0246 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0325 - val_loss: -0.0060 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0200 - val_loss: -0.0221 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0140 - val_loss: -0.0312 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0089 - val_loss: -0.0262 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 7.6959e-04 - val_loss: 0.0146 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: -0.0067 - val_loss: -0.0244 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: -0.0097 - val_loss: -0.0300 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: -0.0017 - val_loss: -0.0363 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: -0.0104 - val_loss: -0.0261 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0209 - val_loss: -0.0231 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0075 - val_loss: -0.0293 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: -0.0157 - val_loss: -0.0078 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 219ms/step - loss: -0.0191 - val_loss: -0.0051 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0183 - val_loss: -0.0254 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3296s\u001b[0m 7s/step - loss: -0.0235 - val_loss: -0.0293 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0302 - val_loss: -0.0301 - learning_rate: 5.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0312 - val_loss: -0.0165 - learning_rate: 5.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21098s\u001b[0m 42s/step - loss: -0.0279 - val_loss: -0.0241 - learning_rate: 5.0000e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 cech na podstawie CMI: [8 7 6 5 4 3 2 1]\n",
      "Top 10 cech na podstawie LASSO: [1 7 8 2 6 5 4 3]\n",
      "Liczba odwróconych par: 12\n",
      "Zgodność top 10: 0.80\n",
      "Zgodność top 5: 0.60\n"
     ]
    }
   ],
   "source": [
    "#est1\n",
    "\n",
    "cmi_scores = []\n",
    "for i in range(X.shape[1]):\n",
    "    Z = np.delete(X, i, axis=1)\n",
    "    cmi_scores.append(est1(X[:, i].reshape(-1, 1), Y, Z))\n",
    "\n",
    "# Ranking cech na podstawie CMI\n",
    "cmi_ranking = np.argsort(cmi_scores)[::-1]\n",
    "\n",
    "# Wizualizacja rankingów\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(range(1, X.shape[1] + 1), np.array(cmi_scores)[cmi_ranking], tick_label=cmi_ranking + 1)\n",
    "plt.title(\"CMI Ranking\")\n",
    "plt.xlabel(\"Feature Index\")\n",
    "plt.ylabel(\"Conditional Mutual Information\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(range(1, X.shape[1] + 1), np.array(lasso_importances)[lasso_ranking], tick_label=lasso_ranking + 1)\n",
    "plt.title(\"LASSO Ranking\")\n",
    "plt.xlabel(\"Feature Index\")\n",
    "plt.ylabel(\"LASSO Coefficients\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Wyświetlenie top 10 cech\n",
    "print(\"Top 10 cech na podstawie CMI:\", cmi_ranking[:10] + 1)\n",
    "print(\"Top 10 cech na podstawie LASSO:\", lasso_ranking[:10] + 1)\n",
    "\n",
    "\n",
    "# Liczba odwróconych par\n",
    "inversions = count_inversions(cmi_ranking, lasso_ranking)\n",
    "print(f\"Liczba odwróconych par: {inversions}\")\n",
    "\n",
    "# Zgodność w top-10 i top-5\n",
    "top_k_agreement_10 = top_k_agreement(cmi_ranking, lasso_ranking, 10)\n",
    "top_k_agreement_5 = top_k_agreement(cmi_ranking, lasso_ranking, 5)\n",
    "\n",
    "print(f\"Zgodność top 10: {top_k_agreement_10:.2f}\")\n",
    "print(f\"Zgodność top 5: {top_k_agreement_5:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 2.9533 - val_loss: 0.1292 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.3912 - val_loss: 0.1327 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.1959 - val_loss: 0.1041 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.1487 - val_loss: 0.0573 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0936 - val_loss: 0.0545 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0806 - val_loss: 0.0423 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0766 - val_loss: 0.0263 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0631 - val_loss: 0.0253 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0560 - val_loss: 0.0257 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0456 - val_loss: 0.0178 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0336 - val_loss: 0.0159 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0375 - val_loss: 0.0205 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0398 - val_loss: 0.0162 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0310 - val_loss: 0.0135 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0299 - val_loss: 0.0153 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0297 - val_loss: 0.0121 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0221 - val_loss: 0.0127 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0230 - val_loss: 0.0127 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0205 - val_loss: 0.0142 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0171 - val_loss: 0.0156 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0199 - val_loss: 0.0147 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0209 - val_loss: 0.0138 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0149 - val_loss: 0.0105 - learning_rate: 5.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0179 - val_loss: 0.0115 - learning_rate: 5.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0136 - val_loss: 0.0131 - learning_rate: 5.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0121 - val_loss: 0.0122 - learning_rate: 5.0000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0133 - val_loss: 0.0097 - learning_rate: 5.0000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0143 - val_loss: 0.0078 - learning_rate: 5.0000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0110 - val_loss: 0.0122 - learning_rate: 5.0000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0166 - val_loss: 0.0101 - learning_rate: 5.0000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0080 - val_loss: 0.0105 - learning_rate: 5.0000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0091 - val_loss: 0.0157 - learning_rate: 5.0000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0113 - val_loss: 0.0076 - learning_rate: 5.0000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0074 - val_loss: 0.0115 - learning_rate: 5.0000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0104 - val_loss: 0.0094 - learning_rate: 5.0000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0092 - val_loss: 0.0135 - learning_rate: 5.0000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0071 - val_loss: 0.0118 - learning_rate: 5.0000e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0059 - val_loss: 0.0112 - learning_rate: 5.0000e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0054 - val_loss: 0.0101 - learning_rate: 2.5000e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0054 - val_loss: 0.0112 - learning_rate: 2.5000e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0034 - val_loss: 0.0041 - learning_rate: 2.5000e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0051 - val_loss: 0.0071 - learning_rate: 2.5000e-05\n",
      "Epoch 43/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0087 - val_loss: 0.0083 - learning_rate: 2.5000e-05\n",
      "Epoch 44/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: -7.3975e-04 - val_loss: 0.0040 - learning_rate: 2.5000e-05\n",
      "Epoch 45/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0061 - val_loss: 0.0070 - learning_rate: 2.5000e-05\n",
      "Epoch 46/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0039 - val_loss: 0.0076 - learning_rate: 2.5000e-05\n",
      "Epoch 47/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0024 - val_loss: 0.0116 - learning_rate: 2.5000e-05\n",
      "Epoch 48/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 4.1348e-04 - val_loss: 0.0031 - learning_rate: 2.5000e-05\n",
      "Epoch 49/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0029 - val_loss: 0.0077 - learning_rate: 2.5000e-05\n",
      "Epoch 50/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0073 - val_loss: 0.0048 - learning_rate: 2.5000e-05\n",
      "Epoch 51/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0052 - val_loss: 0.0088 - learning_rate: 2.5000e-05\n",
      "Epoch 52/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0028 - val_loss: 0.0025 - learning_rate: 2.5000e-05\n",
      "Epoch 53/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0019 - val_loss: 0.0025 - learning_rate: 2.5000e-05\n",
      "Epoch 54/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0017 - val_loss: 0.0041 - learning_rate: 2.5000e-05\n",
      "Epoch 55/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: -9.8959e-04 - val_loss: 0.0018 - learning_rate: 2.5000e-05\n",
      "Epoch 56/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0044 - val_loss: 0.0027 - learning_rate: 2.5000e-05\n",
      "Epoch 57/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0055 - val_loss: 0.0019 - learning_rate: 2.5000e-05\n",
      "Epoch 58/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0029 - val_loss: 0.0015 - learning_rate: 2.5000e-05\n",
      "Epoch 59/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0036 - val_loss: 0.0068 - learning_rate: 2.5000e-05\n",
      "Epoch 60/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: -0.0047 - val_loss: 0.0066 - learning_rate: 2.5000e-05\n",
      "Epoch 61/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 7.1084e-04 - val_loss: 0.0037 - learning_rate: 2.5000e-05\n",
      "Epoch 62/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0014 - val_loss: 0.0039 - learning_rate: 2.5000e-05\n",
      "Epoch 63/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0037 - val_loss: 0.0028 - learning_rate: 2.5000e-05\n",
      "Epoch 64/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0050 - val_loss: 0.0034 - learning_rate: 1.2500e-05\n",
      "Epoch 65/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: -0.0012 - val_loss: 0.0026 - learning_rate: 1.2500e-05\n",
      "Epoch 66/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 8.9602e-04 - val_loss: 0.0029 - learning_rate: 1.2500e-05\n",
      "Epoch 67/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0012 - val_loss: 0.0034 - learning_rate: 1.2500e-05\n",
      "Epoch 68/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 5.6687e-04 - val_loss: 0.0041 - learning_rate: 1.2500e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.3205 - val_loss: -0.3216 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0797 - val_loss: -0.3194 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: -0.1551 - val_loss: -0.3072 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.1855 - val_loss: -0.3219 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: -0.2146 - val_loss: -0.3196 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: -0.2254 - val_loss: -0.3089 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: -0.2331 - val_loss: -0.3216 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: -0.2374 - val_loss: -0.3256 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: -0.2505 - val_loss: -0.3194 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: -0.2345 - val_loss: -0.3349 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: -0.2588 - val_loss: -0.3336 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: -0.2260 - val_loss: -0.3312 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.2540 - val_loss: -0.3291 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: -0.2702 - val_loss: -0.3338 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: -0.2641 - val_loss: -0.3420 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: -0.2789 - val_loss: -0.3369 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: -0.3064 - val_loss: -0.3365 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: -0.2873 - val_loss: -0.3379 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: -0.2957 - val_loss: -0.3325 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: -0.2792 - val_loss: -0.3377 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: -0.2879 - val_loss: -0.3347 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: -0.2765 - val_loss: -0.3388 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: -0.3106 - val_loss: -0.3424 - learning_rate: 5.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: -0.3095 - val_loss: -0.3392 - learning_rate: 5.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: -0.3013 - val_loss: -0.3356 - learning_rate: 5.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: -0.3053 - val_loss: -0.3441 - learning_rate: 5.0000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: -0.2854 - val_loss: -0.3338 - learning_rate: 5.0000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: -0.3010 - val_loss: -0.3318 - learning_rate: 5.0000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: -0.2700 - val_loss: -0.3266 - learning_rate: 5.0000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: -0.2940 - val_loss: -0.3347 - learning_rate: 5.0000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: -0.2910 - val_loss: -0.3364 - learning_rate: 5.0000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: -0.3116 - val_loss: -0.3321 - learning_rate: 2.5000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: -0.2851 - val_loss: -0.3384 - learning_rate: 2.5000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: -0.2848 - val_loss: -0.3387 - learning_rate: 2.5000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: -0.2811 - val_loss: -0.3399 - learning_rate: 2.5000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: -0.3116 - val_loss: -0.3333 - learning_rate: 2.5000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.5364 - val_loss: 0.0556 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.2812 - val_loss: 0.0329 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.1752 - val_loss: 0.0215 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.1465 - val_loss: 0.0183 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0936 - val_loss: 0.0214 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.1075 - val_loss: 0.0169 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0660 - val_loss: 0.0116 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0689 - val_loss: 0.0116 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0624 - val_loss: 0.0116 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0563 - val_loss: 0.0133 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0382 - val_loss: 0.0081 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0444 - val_loss: 0.0072 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0413 - val_loss: 0.0144 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0282 - val_loss: 0.0122 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0287 - val_loss: 0.0074 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0344 - val_loss: 0.0090 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0284 - val_loss: 0.0100 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0298 - val_loss: 0.0078 - learning_rate: 5.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0214 - val_loss: 0.0073 - learning_rate: 5.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0151 - val_loss: 0.0078 - learning_rate: 5.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0265 - val_loss: 0.0071 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0203 - val_loss: 0.0068 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0143 - val_loss: 0.0082 - learning_rate: 5.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0166 - val_loss: 0.0079 - learning_rate: 5.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0184 - val_loss: 0.0060 - learning_rate: 5.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0194 - val_loss: 0.0088 - learning_rate: 5.0000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0182 - val_loss: 0.0077 - learning_rate: 5.0000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0211 - val_loss: 0.0081 - learning_rate: 5.0000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0160 - val_loss: 0.0056 - learning_rate: 5.0000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0170 - val_loss: 0.0079 - learning_rate: 5.0000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0185 - val_loss: 0.0072 - learning_rate: 5.0000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0145 - val_loss: 0.0078 - learning_rate: 5.0000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0169 - val_loss: 0.0103 - learning_rate: 5.0000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0103 - val_loss: 0.0066 - learning_rate: 5.0000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0158 - val_loss: 0.0067 - learning_rate: 2.5000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0157 - val_loss: 0.0068 - learning_rate: 2.5000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0093 - val_loss: 0.0078 - learning_rate: 2.5000e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0146 - val_loss: 0.0068 - learning_rate: 2.5000e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0160 - val_loss: 0.0074 - learning_rate: 2.5000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.5788 - val_loss: 0.0135 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.1569 - val_loss: 0.0026 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.1064 - val_loss: 0.0039 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0796 - val_loss: 0.0021 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0488 - val_loss: -0.0011 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0449 - val_loss: 1.9097e-05 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0478 - val_loss: -0.0037 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0391 - val_loss: 0.0017 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0185 - val_loss: -5.7298e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0311 - val_loss: -0.0052 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0251 - val_loss: -0.0052 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0184 - val_loss: -0.0056 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0154 - val_loss: -0.0021 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0165 - val_loss: -0.0039 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0142 - val_loss: -0.0058 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0118 - val_loss: -0.0051 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0117 - val_loss: -0.0037 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0081 - val_loss: 8.1738e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0094 - val_loss: -0.0037 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0064 - val_loss: -0.0029 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0062 - val_loss: -0.0050 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 9.6809e-04 - val_loss: -0.0037 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.0073 - val_loss: -0.0056 - learning_rate: 5.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0110 - val_loss: -0.0057 - learning_rate: 5.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0080 - val_loss: -0.0028 - learning_rate: 5.0000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.4174 - val_loss: 0.0520 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.2607 - val_loss: 0.0357 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.1836 - val_loss: 0.0158 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.1458 - val_loss: 0.0441 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.1069 - val_loss: 0.0332 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0864 - val_loss: 0.0855 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0728 - val_loss: 0.0216 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0597 - val_loss: 0.0203 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0451 - val_loss: 0.0279 - learning_rate: 5.0000e-05\n",
      "Epoch 10/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0622 - val_loss: 0.0206 - learning_rate: 5.0000e-05\n",
      "Epoch 11/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0489 - val_loss: 0.0191 - learning_rate: 5.0000e-05\n",
      "Epoch 12/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0499 - val_loss: 0.0184 - learning_rate: 5.0000e-05\n",
      "Epoch 13/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0449 - val_loss: 0.0201 - learning_rate: 5.0000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 0.5738 - val_loss: -0.0402 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.1952 - val_loss: -0.0344 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.1026 - val_loss: -0.0506 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0792 - val_loss: -0.0474 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0643 - val_loss: -0.0487 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0664 - val_loss: -0.0482 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0344 - val_loss: -0.0489 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0347 - val_loss: -0.0438 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0081 - val_loss: -0.0492 - learning_rate: 5.0000e-05\n",
      "Epoch 10/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0089 - val_loss: -0.0347 - learning_rate: 5.0000e-05\n",
      "Epoch 11/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0126 - val_loss: -0.0438 - learning_rate: 5.0000e-05\n",
      "Epoch 12/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0171 - val_loss: -0.0514 - learning_rate: 5.0000e-05\n",
      "Epoch 13/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0100 - val_loss: -0.0494 - learning_rate: 5.0000e-05\n",
      "Epoch 14/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: -6.4995e-04 - val_loss: -0.0490 - learning_rate: 5.0000e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: -0.0082 - val_loss: -0.0449 - learning_rate: 5.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: -0.0095 - val_loss: -0.0493 - learning_rate: 5.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: -0.0041 - val_loss: -0.0536 - learning_rate: 5.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0066 - val_loss: -0.0535 - learning_rate: 5.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: -0.0169 - val_loss: -0.0533 - learning_rate: 5.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: -0.0082 - val_loss: -0.0515 - learning_rate: 5.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: -0.0274 - val_loss: -0.0594 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: -0.0098 - val_loss: -0.0495 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: -0.0123 - val_loss: -0.0560 - learning_rate: 5.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: -0.0184 - val_loss: -0.0512 - learning_rate: 5.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: -0.0173 - val_loss: -0.0545 - learning_rate: 5.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: -0.0207 - val_loss: -0.0577 - learning_rate: 5.0000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: -0.0207 - val_loss: -0.0585 - learning_rate: 2.5000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0288 - val_loss: -0.0533 - learning_rate: 2.5000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: -0.0246 - val_loss: -0.0540 - learning_rate: 2.5000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: -0.0172 - val_loss: -0.0544 - learning_rate: 2.5000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: -0.0332 - val_loss: -0.0531 - learning_rate: 2.5000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 1.6568 - val_loss: 0.4047 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.2245 - val_loss: 0.6160 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.1451 - val_loss: 0.4424 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.1108 - val_loss: 0.4625 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0911 - val_loss: 0.4939 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0778 - val_loss: 0.4843 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0782 - val_loss: 0.6042 - learning_rate: 5.0000e-05\n",
      "Epoch 8/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0773 - val_loss: 0.4234 - learning_rate: 5.0000e-05\n",
      "Epoch 9/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0635 - val_loss: 0.5197 - learning_rate: 5.0000e-05\n",
      "Epoch 10/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0650 - val_loss: 0.0970 - learning_rate: 5.0000e-05\n",
      "Epoch 11/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0553 - val_loss: 0.3852 - learning_rate: 5.0000e-05\n",
      "Epoch 12/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0485 - val_loss: 0.1202 - learning_rate: 5.0000e-05\n",
      "Epoch 13/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0445 - val_loss: 0.3552 - learning_rate: 5.0000e-05\n",
      "Epoch 14/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0455 - val_loss: 0.3882 - learning_rate: 5.0000e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0504 - val_loss: 0.2705 - learning_rate: 5.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0481 - val_loss: 0.0780 - learning_rate: 2.5000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0385 - val_loss: 0.3541 - learning_rate: 2.5000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0396 - val_loss: 0.1746 - learning_rate: 2.5000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0373 - val_loss: 0.0420 - learning_rate: 2.5000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0406 - val_loss: 0.1379 - learning_rate: 2.5000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0384 - val_loss: 0.2499 - learning_rate: 2.5000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0458 - val_loss: 0.1370 - learning_rate: 2.5000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0374 - val_loss: 0.0247 - learning_rate: 2.5000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0341 - val_loss: 0.0233 - learning_rate: 2.5000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0479 - val_loss: 0.0768 - learning_rate: 2.5000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0403 - val_loss: 0.2763 - learning_rate: 2.5000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0334 - val_loss: 0.1674 - learning_rate: 2.5000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0367 - val_loss: 0.1262 - learning_rate: 2.5000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0286 - val_loss: 0.1434 - learning_rate: 2.5000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0365 - val_loss: 0.1303 - learning_rate: 1.2500e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0239 - val_loss: 0.0673 - learning_rate: 1.2500e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0286 - val_loss: 0.1784 - learning_rate: 1.2500e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0359 - val_loss: 0.1311 - learning_rate: 1.2500e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0370 - val_loss: 0.2202 - learning_rate: 1.2500e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.5829 - val_loss: 0.0128 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.2427 - val_loss: 0.0093 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1483 - val_loss: 0.0275 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0992 - val_loss: 0.2220 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0845 - val_loss: 0.0268 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0649 - val_loss: 0.2429 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0571 - val_loss: 0.1303 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0617 - val_loss: 0.4368 - learning_rate: 5.0000e-05\n",
      "Epoch 9/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0514 - val_loss: 0.2258 - learning_rate: 5.0000e-05\n",
      "Epoch 10/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0523 - val_loss: 0.3088 - learning_rate: 5.0000e-05\n",
      "Epoch 11/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0318 - val_loss: 0.2999 - learning_rate: 5.0000e-05\n",
      "Epoch 12/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0453 - val_loss: 0.2396 - learning_rate: 5.0000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.5141 - val_loss: 0.0704 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.2330 - val_loss: 0.0377 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.1512 - val_loss: 0.0245 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.1135 - val_loss: 0.0226 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0825 - val_loss: 0.0102 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0764 - val_loss: 0.0153 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0689 - val_loss: 0.0133 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0671 - val_loss: 0.0109 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0484 - val_loss: 0.0089 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0462 - val_loss: 0.0071 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0338 - val_loss: 0.0062 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0365 - val_loss: 0.0046 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0304 - val_loss: 0.0091 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0257 - val_loss: 0.0058 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0271 - val_loss: 0.0058 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0263 - val_loss: 0.0062 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0163 - val_loss: 0.0057 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0168 - val_loss: 0.0035 - learning_rate: 5.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0129 - val_loss: 0.0037 - learning_rate: 5.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0197 - val_loss: 0.0057 - learning_rate: 5.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0161 - val_loss: 0.0050 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0155 - val_loss: 0.0024 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0173 - val_loss: 0.0047 - learning_rate: 5.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0160 - val_loss: 0.0023 - learning_rate: 5.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0099 - val_loss: 0.0032 - learning_rate: 5.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0169 - val_loss: 0.0035 - learning_rate: 5.0000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0086 - val_loss: 0.0030 - learning_rate: 5.0000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0144 - val_loss: 0.0031 - learning_rate: 2.5000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0107 - val_loss: 0.0041 - learning_rate: 2.5000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0116 - val_loss: 0.0033 - learning_rate: 2.5000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0106 - val_loss: 0.0041 - learning_rate: 2.5000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0104 - val_loss: 0.0036 - learning_rate: 2.5000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0122 - val_loss: 0.0031 - learning_rate: 1.2500e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0149 - val_loss: 0.0031 - learning_rate: 1.2500e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.3710 - val_loss: 0.0309 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.2319 - val_loss: 0.0153 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.1325 - val_loss: 0.0032 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.1064 - val_loss: 0.0029 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0753 - val_loss: 0.0033 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0535 - val_loss: 0.0013 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0592 - val_loss: 0.0027 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0496 - val_loss: 0.0046 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0396 - val_loss: 0.0017 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0383 - val_loss: 0.0020 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0262 - val_loss: 0.0016 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0244 - val_loss: 0.0033 - learning_rate: 5.0000e-05\n",
      "Epoch 13/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0233 - val_loss: 0.0032 - learning_rate: 5.0000e-05\n",
      "Epoch 14/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0202 - val_loss: 0.0014 - learning_rate: 5.0000e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0219 - val_loss: 0.0012 - learning_rate: 5.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0230 - val_loss: 0.0025 - learning_rate: 5.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0286 - val_loss: 0.0028 - learning_rate: 5.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0191 - val_loss: 0.0028 - learning_rate: 5.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0252 - val_loss: 0.0020 - learning_rate: 5.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0180 - val_loss: 0.0015 - learning_rate: 5.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0239 - val_loss: 0.0019 - learning_rate: 2.5000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0237 - val_loss: 0.0028 - learning_rate: 2.5000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0175 - val_loss: 0.0011 - learning_rate: 2.5000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0195 - val_loss: 0.0013 - learning_rate: 2.5000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0178 - val_loss: 0.0018 - learning_rate: 2.5000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0167 - val_loss: 9.9578e-04 - learning_rate: 2.5000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0209 - val_loss: 0.0014 - learning_rate: 2.5000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0140 - val_loss: 0.0012 - learning_rate: 2.5000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0142 - val_loss: 0.0013 - learning_rate: 1.2500e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0116 - val_loss: 0.0017 - learning_rate: 1.2500e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0197 - val_loss: 0.0020 - learning_rate: 1.2500e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0156 - val_loss: 0.0020 - learning_rate: 1.2500e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0114 - val_loss: 0.0020 - learning_rate: 1.2500e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0146 - val_loss: 0.0013 - learning_rate: 6.2500e-06\n",
      "Epoch 35/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0088 - val_loss: 0.0017 - learning_rate: 6.2500e-06\n",
      "Epoch 36/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0186 - val_loss: 0.0016 - learning_rate: 6.2500e-06\n",
      "Epoch 1/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.7539 - val_loss: 0.0868 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.3144 - val_loss: 0.0908 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.2126 - val_loss: nan - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.1378 - val_loss: 0.0757 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.1059 - val_loss: 0.0246 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.1119 - val_loss: 0.0293 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0744 - val_loss: 0.0117 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0709 - val_loss: 0.0176 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0623 - val_loss: 0.0167 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0563 - val_loss: 0.0203 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0546 - val_loss: 0.0162 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0445 - val_loss: 0.0158 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0388 - val_loss: 0.0297 - learning_rate: 5.0000e-05\n",
      "Epoch 14/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0332 - val_loss: 0.0220 - learning_rate: 5.0000e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0359 - val_loss: 0.0128 - learning_rate: 5.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0333 - val_loss: 0.0210 - learning_rate: 5.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0253 - val_loss: 0.0221 - learning_rate: 5.0000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.5935 - val_loss: 0.0950 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.1749 - val_loss: -0.0038 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0919 - val_loss: -0.0190 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0526 - val_loss: 0.0174 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0620 - val_loss: 8.8901e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0387 - val_loss: 0.0177 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0337 - val_loss: 0.0240 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0487 - val_loss: 0.0162 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0377 - val_loss: 0.0276 - learning_rate: 5.0000e-05\n",
      "Epoch 10/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0442 - val_loss: 0.0762 - learning_rate: 5.0000e-05\n",
      "Epoch 11/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0308 - val_loss: 0.0068 - learning_rate: 5.0000e-05\n",
      "Epoch 12/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: -0.0012 - val_loss: 0.0183 - learning_rate: 5.0000e-05\n",
      "Epoch 13/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0174 - val_loss: -8.4082e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.3729 - val_loss: 0.1016 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.1966 - val_loss: 0.0399 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.1318 - val_loss: 0.0265 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0981 - val_loss: 0.0237 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0808 - val_loss: 0.0612 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0651 - val_loss: 0.0155 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0443 - val_loss: 0.0231 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0433 - val_loss: 0.0180 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0373 - val_loss: 0.0170 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0395 - val_loss: 0.0144 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0300 - val_loss: 0.0113 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0374 - val_loss: 0.0099 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0276 - val_loss: 0.0133 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0249 - val_loss: 0.0098 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0228 - val_loss: 0.0078 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0244 - val_loss: 0.0099 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0250 - val_loss: 0.0187 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0226 - val_loss: 0.0072 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0190 - val_loss: 0.0114 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0170 - val_loss: 0.0077 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0156 - val_loss: 0.0072 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0182 - val_loss: 0.0084 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0138 - val_loss: 0.0103 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0162 - val_loss: 0.0094 - learning_rate: 5.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0126 - val_loss: 0.0046 - learning_rate: 5.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0169 - val_loss: 0.0120 - learning_rate: 5.0000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0098 - val_loss: 0.0074 - learning_rate: 5.0000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0108 - val_loss: 0.0063 - learning_rate: 5.0000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0091 - val_loss: 0.0063 - learning_rate: 5.0000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0142 - val_loss: 0.0079 - learning_rate: 5.0000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0127 - val_loss: 0.0061 - learning_rate: 2.5000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0125 - val_loss: 0.0048 - learning_rate: 2.5000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0077 - val_loss: 0.0058 - learning_rate: 2.5000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0069 - val_loss: 0.0052 - learning_rate: 2.5000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0098 - val_loss: 0.0054 - learning_rate: 2.5000e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.5413 - val_loss: -2.5684e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.1638 - val_loss: -0.0026 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0932 - val_loss: -0.0057 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0664 - val_loss: -0.0060 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0447 - val_loss: -0.0096 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0487 - val_loss: -0.0171 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0261 - val_loss: -0.0052 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0468 - val_loss: -0.0031 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0259 - val_loss: -0.0236 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0221 - val_loss: -0.0145 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0205 - val_loss: -0.0229 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0149 - val_loss: -0.0142 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0149 - val_loss: -0.0135 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0077 - val_loss: -0.0166 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0087 - val_loss: -0.0202 - learning_rate: 5.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0107 - val_loss: -0.0232 - learning_rate: 5.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0078 - val_loss: -0.0224 - learning_rate: 5.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 1.8515e-04 - val_loss: -0.0257 - learning_rate: 5.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0070 - val_loss: -0.0224 - learning_rate: 5.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0022 - val_loss: -0.0226 - learning_rate: 5.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: -3.8289e-04 - val_loss: -0.0275 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0011 - val_loss: -0.0245 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0067 - val_loss: -0.0244 - learning_rate: 5.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: -4.9486e-04 - val_loss: -0.0273 - learning_rate: 5.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0024 - val_loss: -0.0254 - learning_rate: 5.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: -0.0088 - val_loss: -0.0250 - learning_rate: 5.0000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: -0.0117 - val_loss: -0.0282 - learning_rate: 2.5000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0019 - val_loss: -0.0277 - learning_rate: 2.5000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: -0.0046 - val_loss: -0.0277 - learning_rate: 2.5000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0028 - val_loss: -0.0280 - learning_rate: 2.5000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0063 - val_loss: -0.0275 - learning_rate: 2.5000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0033 - val_loss: -0.0264 - learning_rate: 2.5000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0093 - val_loss: -0.0278 - learning_rate: 1.2500e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 6.8888e-04 - val_loss: -0.0281 - learning_rate: 1.2500e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: -0.0118 - val_loss: -0.0277 - learning_rate: 1.2500e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: -0.0098 - val_loss: -0.0273 - learning_rate: 1.2500e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: -6.6779e-05 - val_loss: -0.0277 - learning_rate: 1.2500e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.5134 - val_loss: 0.0533 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.2207 - val_loss: 0.0495 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.1799 - val_loss: 0.0213 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.1030 - val_loss: 0.0212 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0968 - val_loss: 0.0133 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0758 - val_loss: 0.0149 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0621 - val_loss: 0.0116 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0516 - val_loss: 0.0088 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0520 - val_loss: 0.0150 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0355 - val_loss: 0.0121 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0444 - val_loss: 0.0095 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0381 - val_loss: 0.0141 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0373 - val_loss: 0.0149 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0333 - val_loss: 0.0145 - learning_rate: 5.0000e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0257 - val_loss: 0.0103 - learning_rate: 5.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0238 - val_loss: 0.0078 - learning_rate: 5.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0217 - val_loss: 0.0062 - learning_rate: 5.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0196 - val_loss: 0.0087 - learning_rate: 5.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0161 - val_loss: 0.0119 - learning_rate: 5.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0227 - val_loss: 0.0066 - learning_rate: 5.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0156 - val_loss: 0.0075 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0199 - val_loss: 0.0038 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0166 - val_loss: 0.0060 - learning_rate: 5.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0142 - val_loss: 0.0039 - learning_rate: 5.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0118 - val_loss: 0.0035 - learning_rate: 5.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0135 - val_loss: 0.0033 - learning_rate: 5.0000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0098 - val_loss: 0.0012 - learning_rate: 5.0000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0113 - val_loss: 7.3232e-05 - learning_rate: 5.0000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0073 - val_loss: 0.0019 - learning_rate: 5.0000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0088 - val_loss: 0.0019 - learning_rate: 5.0000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0110 - val_loss: -4.8349e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0065 - val_loss: 0.0027 - learning_rate: 5.0000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0031 - val_loss: 4.9165e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0015 - val_loss: -0.0024 - learning_rate: 5.0000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 3.1174e-04 - val_loss: -0.0081 - learning_rate: 5.0000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0026 - val_loss: -0.0076 - learning_rate: 5.0000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0029 - val_loss: -0.0113 - learning_rate: 5.0000e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: -3.8216e-04 - val_loss: -0.0150 - learning_rate: 5.0000e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: -0.0079 - val_loss: -0.0178 - learning_rate: 5.0000e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: -0.0143 - val_loss: -0.0226 - learning_rate: 5.0000e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: -0.0163 - val_loss: -0.0297 - learning_rate: 5.0000e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: -0.0207 - val_loss: -0.0243 - learning_rate: 5.0000e-05\n",
      "Epoch 43/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: -0.0174 - val_loss: -0.0238 - learning_rate: 5.0000e-05\n",
      "Epoch 44/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0219 - val_loss: -0.0314 - learning_rate: 5.0000e-05\n",
      "Epoch 45/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0142 - val_loss: -0.0214 - learning_rate: 5.0000e-05\n",
      "Epoch 46/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: -0.0260 - val_loss: -0.0441 - learning_rate: 5.0000e-05\n",
      "Epoch 47/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0116 - val_loss: -0.0252 - learning_rate: 5.0000e-05\n",
      "Epoch 48/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: -0.0259 - val_loss: -0.0387 - learning_rate: 5.0000e-05\n",
      "Epoch 49/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: -0.0288 - val_loss: -0.0441 - learning_rate: 5.0000e-05\n",
      "Epoch 50/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0208 - val_loss: -0.0463 - learning_rate: 5.0000e-05\n",
      "Epoch 51/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0317 - val_loss: -0.0481 - learning_rate: 5.0000e-05\n",
      "Epoch 52/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: -0.0258 - val_loss: -0.0483 - learning_rate: 5.0000e-05\n",
      "Epoch 53/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0259 - val_loss: -0.0518 - learning_rate: 5.0000e-05\n",
      "Epoch 54/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1188s\u001b[0m 2s/step - loss: -0.0330 - val_loss: -0.0575 - learning_rate: 5.0000e-05\n",
      "Epoch 55/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18713s\u001b[0m 37s/step - loss: -0.0291 - val_loss: -0.0620 - learning_rate: 5.0000e-05\n",
      "Epoch 56/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: -0.0469 - val_loss: -0.0713 - learning_rate: 5.0000e-05\n",
      "Epoch 57/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: -0.0406 - val_loss: -0.0573 - learning_rate: 5.0000e-05\n",
      "Epoch 58/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: -0.0471 - val_loss: -0.0808 - learning_rate: 5.0000e-05\n",
      "Epoch 59/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: -0.0560 - val_loss: -0.0709 - learning_rate: 5.0000e-05\n",
      "Epoch 60/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: -0.0600 - val_loss: -0.0851 - learning_rate: 5.0000e-05\n",
      "Epoch 61/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: -0.0752 - val_loss: -0.0897 - learning_rate: 5.0000e-05\n",
      "Epoch 62/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: -0.0723 - val_loss: -0.0949 - learning_rate: 5.0000e-05\n",
      "Epoch 63/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: -0.0949 - val_loss: -0.1176 - learning_rate: 5.0000e-05\n",
      "Epoch 64/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: -0.0960 - val_loss: -0.0992 - learning_rate: 5.0000e-05\n",
      "Epoch 65/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: -0.1029 - val_loss: -0.1262 - learning_rate: 5.0000e-05\n",
      "Epoch 66/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: -0.1228 - val_loss: -0.1510 - learning_rate: 5.0000e-05\n",
      "Epoch 67/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: -0.1225 - val_loss: -0.1267 - learning_rate: 5.0000e-05\n",
      "Epoch 68/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: -0.1209 - val_loss: -0.1492 - learning_rate: 5.0000e-05\n",
      "Epoch 69/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: -0.1279 - val_loss: -0.1726 - learning_rate: 5.0000e-05\n",
      "Epoch 70/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: -0.1282 - val_loss: -0.1559 - learning_rate: 5.0000e-05\n",
      "Epoch 71/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: -0.1335 - val_loss: -0.1683 - learning_rate: 5.0000e-05\n",
      "Epoch 72/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: -0.1406 - val_loss: -0.1674 - learning_rate: 5.0000e-05\n",
      "Epoch 73/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: -0.1365 - val_loss: -0.1775 - learning_rate: 5.0000e-05\n",
      "Epoch 74/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.1473 - val_loss: -0.1878 - learning_rate: 5.0000e-05\n",
      "Epoch 75/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.1574 - val_loss: -0.1940 - learning_rate: 5.0000e-05\n",
      "Epoch 76/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.1437 - val_loss: -0.2096 - learning_rate: 5.0000e-05\n",
      "Epoch 77/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.1584 - val_loss: -0.2181 - learning_rate: 5.0000e-05\n",
      "Epoch 78/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: -0.1623 - val_loss: -0.2130 - learning_rate: 5.0000e-05\n",
      "Epoch 79/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.1579 - val_loss: -0.1871 - learning_rate: 5.0000e-05\n",
      "Epoch 80/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: -0.1600 - val_loss: -0.2252 - learning_rate: 5.0000e-05\n",
      "Epoch 81/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.1471 - val_loss: -0.2168 - learning_rate: 5.0000e-05\n",
      "Epoch 82/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.1512 - val_loss: -0.1907 - learning_rate: 5.0000e-05\n",
      "Epoch 83/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: -0.1490 - val_loss: -0.2279 - learning_rate: 5.0000e-05\n",
      "Epoch 84/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.1483 - val_loss: -0.2135 - learning_rate: 5.0000e-05\n",
      "Epoch 85/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: -0.1622 - val_loss: -0.2279 - learning_rate: 5.0000e-05\n",
      "Epoch 86/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: -0.1469 - val_loss: -0.2063 - learning_rate: 5.0000e-05\n",
      "Epoch 87/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.1615 - val_loss: -0.2023 - learning_rate: 5.0000e-05\n",
      "Epoch 88/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.1563 - val_loss: -0.2179 - learning_rate: 5.0000e-05\n",
      "Epoch 89/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.1691 - val_loss: -0.2109 - learning_rate: 2.5000e-05\n",
      "Epoch 90/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.1607 - val_loss: -0.2409 - learning_rate: 2.5000e-05\n",
      "Epoch 91/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.1679 - val_loss: -0.2213 - learning_rate: 2.5000e-05\n",
      "Epoch 92/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.1597 - val_loss: -0.2319 - learning_rate: 2.5000e-05\n",
      "Epoch 93/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.1694 - val_loss: -0.1968 - learning_rate: 2.5000e-05\n",
      "Epoch 94/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.1623 - val_loss: -0.2306 - learning_rate: 2.5000e-05\n",
      "Epoch 95/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.1628 - val_loss: -0.2325 - learning_rate: 2.5000e-05\n",
      "Epoch 96/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.1746 - val_loss: -0.2304 - learning_rate: 1.2500e-05\n",
      "Epoch 97/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.1614 - val_loss: -0.2329 - learning_rate: 1.2500e-05\n",
      "Epoch 98/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: -0.1730 - val_loss: -0.2217 - learning_rate: 1.2500e-05\n",
      "Epoch 99/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: -0.1778 - val_loss: -0.2354 - learning_rate: 1.2500e-05\n",
      "Epoch 100/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: -0.1690 - val_loss: -0.2349 - learning_rate: 1.2500e-05\n",
      "Epoch 1/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.5925 - val_loss: 0.0345 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.2234 - val_loss: 0.0200 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.1244 - val_loss: -0.0042 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0854 - val_loss: -0.0121 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0681 - val_loss: -0.0067 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0595 - val_loss: -0.0256 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0458 - val_loss: -0.0175 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0398 - val_loss: -0.0266 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0402 - val_loss: -0.0253 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0281 - val_loss: -0.0357 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0250 - val_loss: -0.0294 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0304 - val_loss: -0.0386 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0124 - val_loss: -0.0414 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0074 - val_loss: -0.0462 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0058 - val_loss: -0.0468 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -7.8117e-04 - val_loss: -0.0519 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0049 - val_loss: -0.0511 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: -0.0057 - val_loss: -0.0520 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: -0.0074 - val_loss: -0.0557 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: -0.0130 - val_loss: -0.0535 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: -0.0065 - val_loss: -0.0627 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: -0.0118 - val_loss: -0.0528 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: -0.0138 - val_loss: -0.0653 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: -0.0111 - val_loss: -0.0640 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: -0.0159 - val_loss: -0.0627 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: -0.0168 - val_loss: -0.0635 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: -0.0184 - val_loss: -0.0723 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0261 - val_loss: -0.0672 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: -0.0296 - val_loss: -0.0683 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: -0.0201 - val_loss: -0.0744 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: -0.0312 - val_loss: -0.0695 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0240 - val_loss: -0.0721 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0266 - val_loss: -0.0750 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0288 - val_loss: -0.0778 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0288 - val_loss: -0.0769 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0349 - val_loss: -0.0767 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0338 - val_loss: -0.0783 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0357 - val_loss: -0.0814 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: -0.0364 - val_loss: -0.0819 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0432 - val_loss: -0.0883 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: -0.0362 - val_loss: -0.0772 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: -0.0370 - val_loss: -0.0876 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: -0.0435 - val_loss: -0.0858 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: -0.0373 - val_loss: -0.0917 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: -0.0447 - val_loss: -0.0901 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: -0.0462 - val_loss: -0.0914 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0454 - val_loss: -0.0844 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0431 - val_loss: -0.0958 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0497 - val_loss: -0.0924 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0433 - val_loss: -0.0923 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0513 - val_loss: -0.0954 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0541 - val_loss: -0.0945 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0506 - val_loss: -0.0948 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0495 - val_loss: -0.0939 - learning_rate: 5.0000e-05\n",
      "Epoch 55/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0524 - val_loss: -0.0989 - learning_rate: 5.0000e-05\n",
      "Epoch 56/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: -0.0562 - val_loss: -0.0992 - learning_rate: 5.0000e-05\n",
      "Epoch 57/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0558 - val_loss: -0.0982 - learning_rate: 5.0000e-05\n",
      "Epoch 58/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0525 - val_loss: -0.1011 - learning_rate: 5.0000e-05\n",
      "Epoch 59/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: -0.0497 - val_loss: -0.0939 - learning_rate: 5.0000e-05\n",
      "Epoch 60/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: -0.0584 - val_loss: -0.1009 - learning_rate: 5.0000e-05\n",
      "Epoch 61/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0620 - val_loss: -0.1004 - learning_rate: 5.0000e-05\n",
      "Epoch 62/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0541 - val_loss: -0.1005 - learning_rate: 5.0000e-05\n",
      "Epoch 63/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: -0.0587 - val_loss: -0.1012 - learning_rate: 5.0000e-05\n",
      "Epoch 64/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0626 - val_loss: -0.1005 - learning_rate: 5.0000e-05\n",
      "Epoch 65/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0528 - val_loss: -0.1003 - learning_rate: 5.0000e-05\n",
      "Epoch 66/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0515 - val_loss: -0.1008 - learning_rate: 5.0000e-05\n",
      "Epoch 67/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0604 - val_loss: -0.1019 - learning_rate: 5.0000e-05\n",
      "Epoch 68/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0565 - val_loss: -0.1016 - learning_rate: 5.0000e-05\n",
      "Epoch 69/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0652 - val_loss: -0.1047 - learning_rate: 5.0000e-05\n",
      "Epoch 70/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0558 - val_loss: -0.1051 - learning_rate: 5.0000e-05\n",
      "Epoch 71/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0631 - val_loss: -0.1044 - learning_rate: 5.0000e-05\n",
      "Epoch 72/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0689 - val_loss: -0.1014 - learning_rate: 5.0000e-05\n",
      "Epoch 73/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: -0.0652 - val_loss: -0.1016 - learning_rate: 5.0000e-05\n",
      "Epoch 74/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0626 - val_loss: -0.1044 - learning_rate: 5.0000e-05\n",
      "Epoch 75/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0610 - val_loss: -0.1069 - learning_rate: 5.0000e-05\n",
      "Epoch 76/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0644 - val_loss: -0.1074 - learning_rate: 5.0000e-05\n",
      "Epoch 77/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0688 - val_loss: -0.1060 - learning_rate: 5.0000e-05\n",
      "Epoch 78/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0651 - val_loss: -0.1056 - learning_rate: 5.0000e-05\n",
      "Epoch 79/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0647 - val_loss: -0.1079 - learning_rate: 5.0000e-05\n",
      "Epoch 80/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0638 - val_loss: -0.1098 - learning_rate: 5.0000e-05\n",
      "Epoch 81/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: -0.0682 - val_loss: -0.1082 - learning_rate: 5.0000e-05\n",
      "Epoch 82/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0717 - val_loss: -0.1071 - learning_rate: 5.0000e-05\n",
      "Epoch 83/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0692 - val_loss: -0.1053 - learning_rate: 5.0000e-05\n",
      "Epoch 84/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0678 - val_loss: -0.1107 - learning_rate: 5.0000e-05\n",
      "Epoch 85/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0672 - val_loss: -0.1087 - learning_rate: 5.0000e-05\n",
      "Epoch 86/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: -0.0649 - val_loss: -0.1103 - learning_rate: 5.0000e-05\n",
      "Epoch 87/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: -0.0636 - val_loss: -0.1091 - learning_rate: 5.0000e-05\n",
      "Epoch 88/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: -0.0623 - val_loss: -0.1074 - learning_rate: 5.0000e-05\n",
      "Epoch 89/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0599 - val_loss: -0.1097 - learning_rate: 5.0000e-05\n",
      "Epoch 90/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: -0.0681 - val_loss: -0.1125 - learning_rate: 2.5000e-05\n",
      "Epoch 91/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0676 - val_loss: -0.1137 - learning_rate: 2.5000e-05\n",
      "Epoch 92/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0616 - val_loss: -0.1132 - learning_rate: 2.5000e-05\n",
      "Epoch 93/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0655 - val_loss: -0.1138 - learning_rate: 2.5000e-05\n",
      "Epoch 94/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: -0.0686 - val_loss: -0.1114 - learning_rate: 2.5000e-05\n",
      "Epoch 95/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0669 - val_loss: -0.1131 - learning_rate: 2.5000e-05\n",
      "Epoch 96/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: -0.0633 - val_loss: -0.1134 - learning_rate: 2.5000e-05\n",
      "Epoch 97/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: -0.0667 - val_loss: -0.1133 - learning_rate: 2.5000e-05\n",
      "Epoch 98/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: -0.0682 - val_loss: -0.1124 - learning_rate: 2.5000e-05\n",
      "Epoch 99/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0610 - val_loss: -0.1127 - learning_rate: 1.2500e-05\n",
      "Epoch 100/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: -0.0634 - val_loss: -0.1125 - learning_rate: 1.2500e-05\n",
      "Epoch 101/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0742 - val_loss: -0.1111 - learning_rate: 1.2500e-05\n",
      "Epoch 102/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: -0.0684 - val_loss: -0.1127 - learning_rate: 1.2500e-05\n",
      "Epoch 103/200\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: -0.0746 - val_loss: -0.1116 - learning_rate: 1.2500e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 cech na podstawie CMI: [8 7 6 5 4 3 2 1]\n",
      "Top 10 cech na podstawie LASSO: [1 7 8 2 6 5 4 3]\n",
      "Liczba odwróconych par: 12\n",
      "Zgodność top 10: 0.80\n",
      "Zgodność top 5: 0.60\n"
     ]
    }
   ],
   "source": [
    "#est2\n",
    "\n",
    "cmi_scores = []\n",
    "for i in range(X.shape[1]):\n",
    "    Z = np.delete(X, i, axis=1)\n",
    "    cmi_scores.append(est2(X[:, i].reshape(-1, 1), Y, Z))\n",
    "\n",
    "\n",
    "cmi_ranking = np.argsort(cmi_scores)[::-1]\n",
    "\n",
    "# Wizualizacja rankingów\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(range(1, X.shape[1] + 1), np.array(cmi_scores)[cmi_ranking], tick_label=cmi_ranking + 1)\n",
    "plt.title(\"CMI Ranking\")\n",
    "plt.xlabel(\"Feature Index\")\n",
    "plt.ylabel(\"Conditional Mutual Information\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(range(1, X.shape[1] + 1), np.array(lasso_importances)[lasso_ranking], tick_label=lasso_ranking + 1)\n",
    "plt.title(\"LASSO Ranking\")\n",
    "plt.xlabel(\"Feature Index\")\n",
    "plt.ylabel(\"LASSO Coefficients\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Wyświetlenie top 10 cech\n",
    "print(\"Top 10 cech na podstawie CMI:\", cmi_ranking[:10] + 1)\n",
    "print(\"Top 10 cech na podstawie LASSO:\", lasso_ranking[:10] + 1)\n",
    "\n",
    "\n",
    "# Liczba odwróconych par\n",
    "inversions = count_inversions(cmi_ranking, lasso_ranking)\n",
    "print(f\"Liczba odwróconych par: {inversions}\")\n",
    "\n",
    "# Zgodność w top-10 i top-5\n",
    "top_k_agreement_10 = top_k_agreement(cmi_ranking, lasso_ranking, 10)\n",
    "top_k_agreement_5 = top_k_agreement(cmi_ranking, lasso_ranking, 5)\n",
    "\n",
    "print(f\"Zgodność top 10: {top_k_agreement_10:.2f}\")\n",
    "print(f\"Zgodność top 5: {top_k_agreement_5:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I_XZY: 1.3216262675167103\n",
      "I_XY: 0.3736867937255788\n",
      "I_XZY: 1.3224666700137968\n",
      "I_XY: 0.023811675906504348\n",
      "I_XZY: 1.3200463384684182\n",
      "I_XY: 0.0899042936006147\n",
      "I_XZY: 1.3217727804107602\n",
      "I_XY: 0.023380453342102037\n",
      "I_XZY: 1.322558649908494\n",
      "I_XY: 0.013050011195638866\n",
      "I_XZY: 1.3203243356312742\n",
      "I_XY: 0.07856446901611136\n",
      "I_XZY: 1.3240170194136898\n",
      "I_XY: 0.32952265192257624\n",
      "I_XZY: 1.3214433077374528\n",
      "I_XY: 0.38985652516672253\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 cech na podstawie CMI: [5 2 4 6 3 7 1 8]\n",
      "Top 10 cech na podstawie LASSO: [1 7 8 2 6 5 4 3]\n",
      "Liczba odwróconych par: 17\n",
      "Zgodność top 10: 0.80\n",
      "Zgodność top 5: 0.40\n"
     ]
    }
   ],
   "source": [
    "#est3\n",
    "\n",
    "cmi_scores = []\n",
    "for i in range(X.shape[1]):\n",
    "    Z = np.delete(X, i, axis=1)\n",
    "    cmi_scores.append(estimate_cmi(X[:, i].reshape(-1, 1), Y.ravel(), Z))\n",
    "\n",
    "cmi_ranking = np.argsort(cmi_scores)[::-1]\n",
    "\n",
    "# Wizualizacja rankingów\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(range(1, X.shape[1] + 1), np.array(cmi_scores)[cmi_ranking], tick_label=cmi_ranking + 1)\n",
    "plt.title(\"CMI Ranking\")\n",
    "plt.xlabel(\"Feature Index\")\n",
    "plt.ylabel(\"Conditional Mutual Information\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(range(1, X.shape[1] + 1), np.array(lasso_importances)[lasso_ranking], tick_label=lasso_ranking + 1)\n",
    "plt.title(\"LASSO Ranking\")\n",
    "plt.xlabel(\"Feature Index\")\n",
    "plt.ylabel(\"LASSO Coefficients\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Wyświetlenie top 10 cech\n",
    "print(\"Top 10 cech na podstawie CMI:\", cmi_ranking[:10] + 1)\n",
    "print(\"Top 10 cech na podstawie LASSO:\", lasso_ranking[:10] + 1)\n",
    "\n",
    "\n",
    "# Liczba odwróconych par\n",
    "inversions = count_inversions(cmi_ranking, lasso_ranking)\n",
    "print(f\"Liczba odwróconych par: {inversions}\")\n",
    "\n",
    "# Zgodność w top-10 i top-5\n",
    "top_k_agreement_10 = top_k_agreement(cmi_ranking, lasso_ranking, 10)\n",
    "top_k_agreement_5 = top_k_agreement(cmi_ranking, lasso_ranking, 5)\n",
    "\n",
    "print(f\"Zgodność top 10: {top_k_agreement_10:.2f}\")\n",
    "print(f\"Zgodność top 5: {top_k_agreement_5:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
